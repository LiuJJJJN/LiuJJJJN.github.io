[{"categories":null,"content":"\rRecruitment Management System IBM定制班 实训项目 招聘管理系统 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#recruitment-management-system"},{"categories":null,"content":"\r项目技术栈 后端 SpringBoot SpringSecurity Mybatis MySQL Redis 前端 Vue axios Pinia Element-Plus i18n 项目管理 SVN ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#项目技术栈"},{"categories":null,"content":"\r前后端分离的校验规则 前端携带用户名密码访问登录接口 后端负责验证并生成一个 JWT (加密的 json 格式的用户的签名(唯一标识)) 响应给前端 之后前端的每次请求都要在请求头中携带这个 JWT(Json Web Token) 每次后端接收到请求后都会解析这个 token 验证用户权限返回资源 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前后端分离的校验规则"},{"categories":null,"content":"\r前后端分离的会话管理 【问题】前后端分离后，后端怎么知道这次请求是否是认证过了的（已经登录过的）难道每次请求都要查询数据库验证账号密码嘛？ 在成功登录后将用户信息以 用户 ID 为 Key，用户信息 为 Value 存入 Redis 之后的每次校验解析 token 获取 用户 ID 从 Redis 中获取用户信息存入 SecurityContextHolder (Session) 【问题】为什么是存到 SecurityContextHolder 而不是 Session 中？ SpringSecurity 会在认证成功后将用户信息保存到 SecurityContextHolder 中，是通过 ThreadLocal 来实现的 线程绑定 这里面的变量只能被当前线程使用，不能被其它线程访问和修改 在每次请求到来时，SpringSecurity 会从 Session 中将数据存入 SecurityContextHolder, 请求处理结束后将其中的数据拿出来保存到 Session 中，然后将 SecurityContextHolder 中的数据清空 这一策略非常方便用户在 Controller、Service 层以及任何代码中获取当前登录用户数据 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前后端分离的会话管理"},{"categories":null,"content":"\r简略认证授权流程 当用户第一次登录时发送 login 接口请求，服务器将这个允许匿名访问的接口放行进入 Service 层 在 Service 层会将前端传来的用户名和密码存入 authenticationManager 进行认证 认证：在 UserDetailsService 的实现类中查询数据库中的用户名密码是否正确 错误：抛出异常，由前端处理 正确：查询对应的权限信息，将用户实例和权限列表封装成 UserDetails 的实现类 认证通过后将 UserDetails 的实现类存入 Redis 缓存服务器，将用户ID 创建为 JWT 返回给前端存储 当用户发送非 login 接口请求时，进入过滤器 检查请求头中是否含有 token ，如果没有则报认证错误 解析 token 得到用户 ID ，如果解析失败抛出 token 不合法异常 通过用户 ID 从 Redis 中获取用户信息，如果没此用户抛出用户未登录异常 将用户信息和查询到的权限信息交给 SpringSecurity 的 SecurityContextHolder 放行 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#简略认证授权流程"},{"categories":null,"content":"\r使用 UUID 做主键 MySQL 的 8.0 通过实现三个新的 SQL 函数提高 UUID 操作的易用性：UUID_TO_BIN()，BIN_TO_UUID()，和 IS_UUID()。第一个从 UUID 格式化文本转换 VARBINARY(16) 为第二个 VARBINARY(16) 到 UUID 格式化文本，最后一个检查 UUID 格式文本的有效性。存储为 UUID VARBINARY(16) 可以使用功能索引进行索引。功能 UUID_TO_BIN() 和 UUID_TO_BIN() 也可以洗牌与时间相关的位，在开始移动它们使得指数友好，避免在 B 树中的随机插入，这样降低了插入时间。这种功能的缺乏被认为是使用 UUID 的缺点之一。 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#使用-uuid-做主键"},{"categories":null,"content":"\r数据库定义 数据字典类型表 所属公司 company 用户状态 user_status 性别 sex 学历 education 技术能力 tech_ability 语言能力 lang_ability 简历来源 source 是否服从 obey 面试状态 interview_status 面试结果 result 面试结果得分项 item 备注类型 comment_type 用户表 status：0正常、1禁用 简历表 sex：0女、1男 education：0无、1专科、2本科、3硕士、4海归、5其它 tech_ability：0无、1Java、2C++、3Python、4Go、5PHP、6Vue lang_ability：0无、1日语N4、2日语N3、3日语N2、4日语N1、5英语4级、6英语6级 source：0校招、1官网、2内推、3宣讲会、4招聘软件、5其它 obey：0不服从、1服从 面试表 status：0等待指定Reviewer、0+1等待简历Review、1+1等待指定面试官、2+1等待确定面试时间、3+1等待面试、4+1等待面试提交反馈、5+1简历ReviewNG、6+1面试OK、7+1面试NG、8+1HOLD 面试反馈表 result：0NG、1OK 面试反馈得分表 item：…… 备注表 comment_type：0简历上传备注、1review备注、2面试反馈备注 权限表 code 的意义 CVUpload:*:* ：的权限就是对 CVUpload 的所有数据的所有操作 表 ：操作 ：数据 ：例如 user:update:* 的权限就是对 user 表的所有字段都有更新权限 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#数据库定义"},{"categories":null,"content":"\r代码规范","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#代码规范"},{"categories":null,"content":"\r通用规范 代码必须经过 format 代码必须经过自检运行跑通后才能提交 SVN 代码书写应遵循 没做完或需要后期更改的地方，应写上 todo 注释，并注明用途 一行代码不得超过 120 字符 变量名必须见名知意，不得用拼音 注释书写应遵循 注释内容由空格开始、注释中英文前后添加空格 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:1","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#通用规范"},{"categories":null,"content":"\r前端代码规范 功能相近的变量、方法、css 样式应写在一起 templatr 标签内容顺序: 内容标签 👉 dialog 标签 script 标签内容顺序: import 👉 功能性属性 👉 ref 属性 👉 reactive 属性 👉 方法 👉 钩子方法 空的双标签应尽可能写为单标签 命名规范 views 文件名：小驼峰 script 变量和方法名：小驼峰 css 选择器：小驼峰 常量：全大写 注释 template 中代码注释 script 中 import 语句注释 script 中 const 属性注释 script 中方法注释 style 中注释：需标明生效位置 on-、before- 开头的属性后对应的方法都叫做 钩子方法，v-on、@ 开头的属性对应的方法叫做 事件 换行 分行书写标签属性时，\u003e 或 /\u003e 需单独一行 template、script、style 标签之间空一行，代码文件最后一行空一行 变量与变量之间、方法与方法之间、式样与式样之间，空一行 分号 script 中写的代码结尾都应添加分号，方法中的语句都应以分号结尾 其它 图标的用法 禁止使用 :icon 属性指定图标 elementPlus 推荐使用 el-icon 标签指定图标，且不需要单独导入 ts 说变量无法解析？ 因为这个变量没有显式定义在 resp 中 可以使用 data['variable'] 的方式取得 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前端代码规范"},{"categories":null,"content":"\r前端代码规范 功能相近的变量、方法、css 样式应写在一起 templatr 标签内容顺序: 内容标签 👉 dialog 标签 script 标签内容顺序: import 👉 功能性属性 👉 ref 属性 👉 reactive 属性 👉 方法 👉 钩子方法 空的双标签应尽可能写为单标签 命名规范 views 文件名：小驼峰 script 变量和方法名：小驼峰 css 选择器：小驼峰 常量：全大写 注释 template 中代码注释 script 中 import 语句注释 script 中 const 属性注释 script 中方法注释 style 中注释：需标明生效位置 on-、before- 开头的属性后对应的方法都叫做 钩子方法，v-on、@ 开头的属性对应的方法叫做 事件 换行 分行书写标签属性时，\u003e 或 /\u003e 需单独一行 template、script、style 标签之间空一行，代码文件最后一行空一行 变量与变量之间、方法与方法之间、式样与式样之间，空一行 分号 script 中写的代码结尾都应添加分号，方法中的语句都应以分号结尾 其它 图标的用法 禁止使用 :icon 属性指定图标 elementPlus 推荐使用 el-icon 标签指定图标，且不需要单独导入 ts 说变量无法解析？ 因为这个变量没有显式定义在 resp 中 可以使用 data['variable'] 的方式取得 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#命名规范"},{"categories":null,"content":"\r前端代码规范 功能相近的变量、方法、css 样式应写在一起 templatr 标签内容顺序: 内容标签 👉 dialog 标签 script 标签内容顺序: import 👉 功能性属性 👉 ref 属性 👉 reactive 属性 👉 方法 👉 钩子方法 空的双标签应尽可能写为单标签 命名规范 views 文件名：小驼峰 script 变量和方法名：小驼峰 css 选择器：小驼峰 常量：全大写 注释 template 中代码注释 script 中 import 语句注释 script 中 const 属性注释 script 中方法注释 style 中注释：需标明生效位置 on-、before- 开头的属性后对应的方法都叫做 钩子方法，v-on、@ 开头的属性对应的方法叫做 事件 换行 分行书写标签属性时，\u003e 或 /\u003e 需单独一行 template、script、style 标签之间空一行，代码文件最后一行空一行 变量与变量之间、方法与方法之间、式样与式样之间，空一行 分号 script 中写的代码结尾都应添加分号，方法中的语句都应以分号结尾 其它 图标的用法 禁止使用 :icon 属性指定图标 elementPlus 推荐使用 el-icon 标签指定图标，且不需要单独导入 ts 说变量无法解析？ 因为这个变量没有显式定义在 resp 中 可以使用 data['variable'] 的方式取得 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#注释"},{"categories":null,"content":"\r前端代码规范 功能相近的变量、方法、css 样式应写在一起 templatr 标签内容顺序: 内容标签 👉 dialog 标签 script 标签内容顺序: import 👉 功能性属性 👉 ref 属性 👉 reactive 属性 👉 方法 👉 钩子方法 空的双标签应尽可能写为单标签 命名规范 views 文件名：小驼峰 script 变量和方法名：小驼峰 css 选择器：小驼峰 常量：全大写 注释 template 中代码注释 script 中 import 语句注释 script 中 const 属性注释 script 中方法注释 style 中注释：需标明生效位置 on-、before- 开头的属性后对应的方法都叫做 钩子方法，v-on、@ 开头的属性对应的方法叫做 事件 换行 分行书写标签属性时，\u003e 或 /\u003e 需单独一行 template、script、style 标签之间空一行，代码文件最后一行空一行 变量与变量之间、方法与方法之间、式样与式样之间，空一行 分号 script 中写的代码结尾都应添加分号，方法中的语句都应以分号结尾 其它 图标的用法 禁止使用 :icon 属性指定图标 elementPlus 推荐使用 el-icon 标签指定图标，且不需要单独导入 ts 说变量无法解析？ 因为这个变量没有显式定义在 resp 中 可以使用 data['variable'] 的方式取得 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#换行"},{"categories":null,"content":"\r前端代码规范 功能相近的变量、方法、css 样式应写在一起 templatr 标签内容顺序: 内容标签 👉 dialog 标签 script 标签内容顺序: import 👉 功能性属性 👉 ref 属性 👉 reactive 属性 👉 方法 👉 钩子方法 空的双标签应尽可能写为单标签 命名规范 views 文件名：小驼峰 script 变量和方法名：小驼峰 css 选择器：小驼峰 常量：全大写 注释 template 中代码注释 script 中 import 语句注释 script 中 const 属性注释 script 中方法注释 style 中注释：需标明生效位置 on-、before- 开头的属性后对应的方法都叫做 钩子方法，v-on、@ 开头的属性对应的方法叫做 事件 换行 分行书写标签属性时，\u003e 或 /\u003e 需单独一行 template、script、style 标签之间空一行，代码文件最后一行空一行 变量与变量之间、方法与方法之间、式样与式样之间，空一行 分号 script 中写的代码结尾都应添加分号，方法中的语句都应以分号结尾 其它 图标的用法 禁止使用 :icon 属性指定图标 elementPlus 推荐使用 el-icon 标签指定图标，且不需要单独导入 ts 说变量无法解析？ 因为这个变量没有显式定义在 resp 中 可以使用 data['variable'] 的方式取得 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#分号"},{"categories":null,"content":"\r前端代码规范 功能相近的变量、方法、css 样式应写在一起 templatr 标签内容顺序: 内容标签 👉 dialog 标签 script 标签内容顺序: import 👉 功能性属性 👉 ref 属性 👉 reactive 属性 👉 方法 👉 钩子方法 空的双标签应尽可能写为单标签 命名规范 views 文件名：小驼峰 script 变量和方法名：小驼峰 css 选择器：小驼峰 常量：全大写 注释 template 中代码注释 script 中 import 语句注释 script 中 const 属性注释 script 中方法注释 style 中注释：需标明生效位置 on-、before- 开头的属性后对应的方法都叫做 钩子方法，v-on、@ 开头的属性对应的方法叫做 事件 换行 分行书写标签属性时，\u003e 或 /\u003e 需单独一行 template、script、style 标签之间空一行，代码文件最后一行空一行 变量与变量之间、方法与方法之间、式样与式样之间，空一行 分号 script 中写的代码结尾都应添加分号，方法中的语句都应以分号结尾 其它 图标的用法 禁止使用 :icon 属性指定图标 elementPlus 推荐使用 el-icon 标签指定图标，且不需要单独导入 ts 说变量无法解析？ 因为这个变量没有显式定义在 resp 中 可以使用 data['variable'] 的方式取得 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#其它"},{"categories":null,"content":"\r后端代码规范 后端写的代码中不要出现业务上的常量，如需获取要在 constValue.properties 文件中定义使用 @PropertySource 配合 @Value 获取 命名规范 Controller 及 Service 层接口及方法命名风格：add、remove、edit、get（getXxxxList、getXxxByXxx） Mapper 层方法命名风格：insert、delete、update、select（count） 类变量命名：类名小驼峰 功能性常量定义：全大写、_ 分隔 注释 每个类的 class 语句上方书写文档注释，并注明作者和创建时间 在控制层的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在数据访问层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层实现类中书写单行注释，要求只看注释就能明白业务的执行流程 换行 保证每一个类变量、方法前后都有一个空行 每个文件最后要有一个空行 较长的业务可按照逻辑添加空行 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:3","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端代码规范"},{"categories":null,"content":"\r后端代码规范 后端写的代码中不要出现业务上的常量，如需获取要在 constValue.properties 文件中定义使用 @PropertySource 配合 @Value 获取 命名规范 Controller 及 Service 层接口及方法命名风格：add、remove、edit、get（getXxxxList、getXxxByXxx） Mapper 层方法命名风格：insert、delete、update、select（count） 类变量命名：类名小驼峰 功能性常量定义：全大写、_ 分隔 注释 每个类的 class 语句上方书写文档注释，并注明作者和创建时间 在控制层的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在数据访问层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层实现类中书写单行注释，要求只看注释就能明白业务的执行流程 换行 保证每一个类变量、方法前后都有一个空行 每个文件最后要有一个空行 较长的业务可按照逻辑添加空行 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:3","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#命名规范-1"},{"categories":null,"content":"\r后端代码规范 后端写的代码中不要出现业务上的常量，如需获取要在 constValue.properties 文件中定义使用 @PropertySource 配合 @Value 获取 命名规范 Controller 及 Service 层接口及方法命名风格：add、remove、edit、get（getXxxxList、getXxxByXxx） Mapper 层方法命名风格：insert、delete、update、select（count） 类变量命名：类名小驼峰 功能性常量定义：全大写、_ 分隔 注释 每个类的 class 语句上方书写文档注释，并注明作者和创建时间 在控制层的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在数据访问层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层实现类中书写单行注释，要求只看注释就能明白业务的执行流程 换行 保证每一个类变量、方法前后都有一个空行 每个文件最后要有一个空行 较长的业务可按照逻辑添加空行 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:3","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#注释-1"},{"categories":null,"content":"\r后端代码规范 后端写的代码中不要出现业务上的常量，如需获取要在 constValue.properties 文件中定义使用 @PropertySource 配合 @Value 获取 命名规范 Controller 及 Service 层接口及方法命名风格：add、remove、edit、get（getXxxxList、getXxxByXxx） Mapper 层方法命名风格：insert、delete、update、select（count） 类变量命名：类名小驼峰 功能性常量定义：全大写、_ 分隔 注释 每个类的 class 语句上方书写文档注释，并注明作者和创建时间 在控制层的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在数据访问层接口的每个方法上方书写文档注释，并注明接口作用、参数内容、返回值功能 在服务层实现类中书写单行注释，要求只看注释就能明白业务的执行流程 换行 保证每一个类变量、方法前后都有一个空行 每个文件最后要有一个空行 较长的业务可按照逻辑添加空行 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:3","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#换行-1"},{"categories":null,"content":"\r式样书规范 各画面 ID 登录画面：RMSL0101 菜单画面：RMSM0101 工作台画面：RMSW0101 简历上传画面：RMSU0101 面试一览画面：RMSV0101 面试Review画面：RMSR0101 面试反馈画面：RMSF0101 历史面试画面：RMSH0101 数据字典类型管理画面：RMSD0101 数据字典值管理画面：RMSD0201 用户管理画面：RMSU0201 角色管理画面：RMSU0202 权限管理画面：RMSU0203 部门管理画面：RMSD0301 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:4","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#式样书规范"},{"categories":null,"content":"\r前端遇到的问题","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前端遇到的问题"},{"categories":null,"content":"\rVue3 如何打包成能直接运行的格式 在 vite.config.js 中设置 base 为相对路径 添加 plugin-legacy 插件生成传统浏览器的 chunk 及与其相对应 ES 语言特性方面的 polyfill 将 router 文件配置为根据 hash 匹配路径 执行打包命令 npm run build 修改打包 dist 文件夹中的 index.html 删除红框部分代码 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:1","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue3-如何打包成能直接运行的格式"},{"categories":null,"content":"\rVue 如何修改 Element-Plus 的底层样式 添加 :deep() :deep(.el-scrollbar__bar.is-horizontal\u003ediv) { height: 10px; margin-top: -5px; } ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-如何修改-element-plus-的底层样式"},{"categories":null,"content":"\rVue3 如何修改 reactive 数组做响应式处理 不使用数据接口的情况 const xxxList = reactive({ arr: [] }) 在 reactive 里面再封装一层，这样就可以直接 xxxList.arr = xxx 修改数组 使用数据接口的情况 const xxxList = reactive\u003cxxxInterface[]\u003e([]); 使用 push 方法将展开的数据传进数组中: xxxList.push(...resp.data); ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:3","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue3-如何修改-reactive-数组做响应式处理"},{"categories":null,"content":"\rVue3 ref 和 reactive 的区别 ref 是用来定义基本类型和数组类型和对象类型的，使用 ref 定义数组或对象类型时内部还是会调用 reactive 转为代理对象 reactive 一般用来定义对象类型，它是通过使用 Proxy（代理模式） 来实现响应式, 并通过 Reflect 操作 源对象 内部的数据 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:4","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue3-ref-和-reactive-的区别"},{"categories":null,"content":"\rVue @click 事件只点击一次却执行多次 在为 v-for 的标签添加 @click 事件之后，每次点击都会被执行多次，暂时不了解因为什么 【解决】: 为事件添加 $event 参数，并执行方法即可解决 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:5","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-click-事件只点击一次却执行多次"},{"categories":null,"content":"\rnpm install 下载缓慢 因为服务器在国外，大陆有时候连接不上 执行这条命令修改服务器为淘宝的就好了 npm config set registry https://registry.npm.taobao.org ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:6","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#npm-install-下载缓慢"},{"categories":null,"content":"\r后端遇到的问题","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:9:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端遇到的问题"},{"categories":null,"content":"\raxios 传递的参数结尾多了一个等于号 ‘=’ ?\r因为前端发送 axios 请求时，默认的请求头 headers 内部的 Content-Type 是 application/x-www-form-urlencoded;charset=UTF-8 这是一种键值对的数据结构，传输过程中把 json 当作 key，而 value 当作空值，所以传输到后端会多出等号 【解决】 可以通过修改前端和后端的数据编码格式解决 可以在前端用花括号包起来作为 json 传输，后端用 Map 接收 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:9:1","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#axios-传递的参数结尾多了一个等于号--"},{"categories":null,"content":"\rmybatis 的 resultMap 映射问题 当我将 id 当作参数传给另一个查询的时候，这个主查询的 id 结果都为 null ？ 【解决】因为 mybatis 理解为这个属性应该被映射为别的值就没有给这个属性赋值，再次指定这个属性的映射即可 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:9:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#mybatis-的-resultmap-映射问题"},{"categories":null,"content":"\r大写字母开头传值 springboot 为 null 因为 springboot 默认按照小驼峰解析 json 的值 【解决】将前端改为小驼峰即可，或使用 @JsonProperty 注明属性名 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:9:3","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#大写字母开头传值-springboot-为-null"},{"categories":null,"content":"\r服务器部署遇到的问题","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:10:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#服务器部署遇到的问题"},{"categories":null,"content":"\rvue 项目部署到 nginx 服务器后，除首页外刷新都跳转 404 页面 为 nginx 设置转发 try_files $uri $uri/ /index.html; ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:10:1","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-项目部署到-nginx-服务器后除首页外刷新都跳转-404-页面"},{"categories":null,"content":"\r长时间不进行操作 redis 抛出异常 异常信息： org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is io.lettuce.core.RedisException: java.io.IOException: 远程主机强迫关闭了一个现有的连接。 似乎是因为 ssh 的连接超时造成的, 根据网上的方法设置了 ssh 超时时长 和 重试次数 但似乎无效 2022-12-16 07:21:55 证实无效果，重试次数设置过高反而造成多次无响应之后才提示登录过期 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:10:2","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#长时间不进行操作-redis-抛出异常"},{"categories":null,"content":"\r项目特色 主要 灵活性、可扩展性 docker 部署、域名解析 数据库 标准的 RBAC 模型结构 MySQL8 的 UUID 数据字典 索引 前端 axios 的前后置拦截 错误页面 Vue3 + Ts transition 过度动画、v-loading i18n 组件化开发 未使用任何前端模板 实用的工作台画面 后端 minio、kkfileview 简历预览 springSecurity 安全框架、一用户可同时拥有多角色 Redis 用户认证、令牌自动续约、数据字典缓存、缓存击穿的解决 实时的用户锁定 全局异常捕获、返回值枚举类、properties 配置文件 事务、乐观锁 POI: easyExcel 数据导出 RabbitMQ 邮件 ","date":"2022-12-10","objectID":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:11:0","series":null,"tags":null,"title":"招聘管理系统项目笔记","uri":"/rms%E6%8B%9B%E8%81%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#项目特色"},{"categories":null,"content":"\rSpring Security 大连交通大学 信息学院 刘嘉宁 2022-10-22 笔记摘自：bilibili 三更草堂 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#spring-security"},{"categories":null,"content":"\rSpring Security 是 Spring 家族的一个安全管理框架 相较于 Shiro 更适合大型项目、上手复杂一些、功能和社区资源更丰富 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#spring-security-1"},{"categories":null,"content":"\r如何使用 添加 Spring Security 依赖 \u003c!-- Spring Security 的起步依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- Spring Security 测试环境的起步依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.security\u003c/groupId\u003e \u003cartifactId\u003espring-security-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#如何使用"},{"categories":null,"content":"\r粗略原理\rSpring Security 的本质就是一个过滤器链 判断用户名密码是否正确【认证】 处理过滤器链中发生的 AccessDeniedWException 和 AuthenticationException【异常处理】 判断该用户是否有执行的权限【授权】 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#粗略原理"},{"categories":null,"content":"\r认证\r大致流程： 1 - 6 在 UserDetailService 接口实现类中查找用户信息及对应权限在封装后返回 7 - 9 比对用户名及密码是否正确并设置权限信息到 Authentication 中 10 - end 将 Authentication 中的权限信息设置到一个共享作用域中方便后续认证环节使用 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:1","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#认证"},{"categories":null,"content":"\r授权 候补 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:2","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#授权"},{"categories":null,"content":"\r自定义认证\r自定义 UserDetailService 接口实现类查询数据库 把这个用户实体查出来 在 service.impl 中创建 UserDetailsService 的实现类 @Service public class UserDetailServiceImpl implements UserDetailsService { @Autowired private SysUserMapper sysUserMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { /*********************** 认证 ***********************/ // 查询有没有这个用户 List\u003cSysUser\u003e userList = sysUserMapper.selectByUsername(username); //如果没有这个账户则抛出异常 if (userList == null || userList.size() == 0) { throw new RuntimeException(\"用户名或密码错误\"); } /*********************** 授权 ***********************/ //todo //把用户封装成 UserDetail 返回 return new LoginUser(userList.get(0)); } } 在 domian 中创建 UserDetails 的实现类并代理用户实体 @Data @NoArgsConstructor @AllArgsConstructor public class LoginUser implements UserDetails { private SysUser sysUser; @Override public Collection\u003c? extends GrantedAuthority\u003e getAuthorities() { // 获取权限信息 return null; } @Override public String getPassword() { return sysUser.getPassword(); } @Override public String getUsername() { return sysUser.getUserName(); } @Override public boolean isAccountNonExpired() { return true; } @Override public boolean isAccountNonLocked() { return true; } @Override public boolean isCredentialsNonExpired() { return true; } @Override public boolean isEnabled() { return true; } } ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#自定义认证"},{"categories":null,"content":"\r配置密码加密策略 默认使用的 PasswordEncoder 要求数据库中的密码格式为：{id}password 它会根据 id 去判断密码的加密方式 一般情况下我们使用 SpringSecurity 提供的 BCryptPasswordEncoder 实现密码加密（加盐加密） 在 config 包下创建 SecurityConfig 配置类 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean public PasswordEncoder passwordEncoder(){ // 设置密码加密方式为 SpringSecurity 提供的 BCryptPasswordEncoder return new BCryptPasswordEncoder(); } } BCryptPasswordEncoder 提供的功能： BCryptPasswordEncoder b = new BCryptPasswordEncoder(); String b1 = b.encode(\"明文密码\"); // 将明文密码加密为密文 String b2 = b.encode(\"明文密码\"); // 自带加盐加密，每次的密文都不一致 boolean matches = b.matches(\"明文密码\", \"密文\"); // 比对密文是否是明文密码加密而来的 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:1","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#配置密码加密策略"},{"categories":null,"content":"\r配置认证相关配置在 SecurityConfig 配置类中添加内容 @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { /** * 配置密码加密方式 * @return */ @Bean public PasswordEncoder passwordEncoder() { // 设置密码加密方式为 SpringSecurity 提供的 BCryptPasswordEncoder return new BCryptPasswordEncoder(); } @Override protected void configure(HttpSecurity http) throws Exception { http // 关闭 csrf .csrf().disable() // 不通过 Session 获取 SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 对于登录接口 允许匿名访问 .antMatchers(\"/user/login\").anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); } /** * 暴露 AuthenticationManager 到 Spring 容器中以便 Service 层使用 * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:2","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#配置认证相关配置"},{"categories":null,"content":"\r实现登录功能 编写登录接口的 Service 层方法 // 注入 AuthenticationManager 进行用户认证 @Autowired private AuthenticationManager authenticationManager; @Autowired private RedisCacheUtil redisCacheUtil; @Override public ResponseResult login(SysUser user) { UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(user.getUserName(), user.getPassword()); Authentication authenticate = authenticationManager.authenticate(authenticationToken); // 如果认证没通过则给出提示 if (Objects.isNull(authenticate)) { throw new RuntimeException(\"用户名或密码错误\"); } // 认证通过后，使用 userid 生成 jwt LoginUser loginUser = (LoginUser) authenticate.getPrincipal(); String userId = loginUser.getSysUser().getId().toString(); String jwt = JwtUtil.createJWT(userId); // 把用户信息存入 redis redisCacheUtil.setCacheObject(\"login:\" + userId, loginUser); // 把 jwt 响应给前端 HashMap\u003cString, String\u003e map = new HashMap\u003c\u003e(); map.put(\"token\", jwt); return new ResponseResult(200, \"登陆成功\", map); } ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:3","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#实现登录功能"},{"categories":null,"content":"\r配置认证过滤器在 filter 包中创建 JwtAuthenticationTokenFilter 过滤器 @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter { @Autowired private RedisCacheUtil redisCache; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { // 获取请求头中的 token String token = request.getHeader(\"token\"); if (!StringUtils.hasText(token)) { //放行 filterChain.doFilter(request, response); return; } // 解析 token 获取到用户 ID String userid; try { Claims claims = JwtUtil.parseJWT(token); userid = claims.getSubject(); } catch (Exception e) { e.printStackTrace(); throw new RuntimeException(\"token不合法\"); } // 使用用户 ID 从 redis 中获取用户信息 String redisKey = \"login:\" + userid; LoginUser loginUser = redisCache.getCacheObject(redisKey); if(Objects.isNull(loginUser)){ throw new RuntimeException(\"用户未登录\"); } // 存入 SecurityContextHolder //TODO 获取权限信息封装到 Authentication 中 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(loginUser,null,null); SecurityContextHolder.getContext().setAuthentication(authenticationToken); // 放行 filterChain.doFilter(request, response); } } 添加配置类 @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { // 注入过滤器 @Autowired JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter; /** * 配置密码加密方式 * @return */ @Bean public PasswordEncoder passwordEncoder() { // 设置密码加密方式为 SpringSecurity 提供的 BCryptPasswordEncoder return new BCryptPasswordEncoder(); } @Override protected void configure(HttpSecurity http) throws Exception { http //关闭csrf .csrf().disable() //不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 对于登录接口 允许匿名访问 .antMatchers(\"/user/login\").anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); //把token校验过滤器添加到过滤器链中 http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); } /** * 暴露 AuthenticationManager 到 Spring 容器中以便 Service 层使用 * @return * @throws Exception */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:4","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#配置认证过滤器"},{"categories":null,"content":"\r如何退出登录 将 Redis 中的用户信息删除即可 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:5","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#如何退出登录"},{"categories":null,"content":"\r自定义授权 在 UserDetailsService 类中查询用户对应的权限 将用户的权限信息封装至 SecurityContextHandler 在 LoginUser 类中实现获取权限信息的方法 在需要权限的方法上方添加注解 123 在 SecurityConfig 类上方添加注解，开启全局的注解授权方法 @EnableGlobalMethodSecurity(prePostEnabled = true) 在需要鉴权才能访问的方法添加注解 @PreAuthorize(\"hasAuthority('test')\") // 在 UserDetailServiceImpl 类中获取用户对应的权限列表 @Service public class UserDetailServiceImpl implements UserDetailsService { @Autowired private SysUserMapper sysUserMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { /*********************** 查询用户 ***********************/ // 查询用户信息 SysUser sysUser = sysUserMapper.selectOneByUsername(username); //如果没有这个账户则抛出异常 if (sysUser == null) { throw new RuntimeException(\"用户名或密码错误\"); } /*********************** 查询权限信息 ***********************/ List\u003cString\u003e permissionList = new ArrayList\u003c\u003e(Arrays.asList(\"test2\")); //把用户封装成 UserDetail 返回 return new LoginUser(sysUser, permissionList); } } 为 LoginUser 类增加代理权限列表、实现 getAuthorities 方法 // 这个类要保证有完整的构造器、get、set 方法以供 fastJson 序列化和反序列化 public class LoginUser implements UserDetails { // 代理用户实体 private SysUser sysUser; // 代理用户对应的权限列表 private List\u003cString\u003e permissions; //存储SpringSecurity所需要的权限信息的集合 @JSONField(serialize = false) private List\u003cGrantedAuthority\u003e authorities; public LoginUser(SysUser sysUser, List\u003cString\u003e permissions) { this.sysUser = sysUser; this.permissions = permissions; } @Override public Collection\u003c? extends GrantedAuthority\u003e getAuthorities() { // 获取权限信息 if (authorities != null) { return authorities; } //把 permissions 中字符串类型的权限信息转换成 GrantedAuthority 对象存入 authorities 中 authorities = permissions.stream(). map(SimpleGrantedAuthority::new) .collect(Collectors.toList()); return authorities; } 在 JwtAuthenticationTokenFilter 传入权限信息 ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#自定义授权"},{"categories":null,"content":"\r自定义异常处理器 SpringSecurity 在认证和授权出现异常的时候会自动调用对应的异常处理器 认证过程中出现的异常会封装成 AuthenticationException 调用 AuthenticationEntryPoint 进行异常处理 授权过程中出现的异常会封装成 AccessDeniedException 调用 AccessDeniedHandler 进行异常处理 在 exceptionHandler 中创建对应的类 @Component public class AccessDeniedHandlerImpl implements AccessDeniedHandler { @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException { ResponseResult result = new ResponseResult(HttpStatus.FORBIDDEN.value(), \"权限不足\"); String json = JSON.toJSONString(result); // WebUtils.renderString(response,json); System.out.println(json); } } @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint { @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException { ResponseResult result = new ResponseResult(HttpStatus.UNAUTHORIZED.value(), \"认证失败请重新登录\"); String json = JSON.toJSONString(result); // WebUtils.renderString(response,json); System.out.println(json); } } 在 SecurityConfig 中注入这两个实现类 @Autowired private AuthenticationEntryPoint authenticationEntryPoint; @Autowired private AccessDeniedHandler accessDeniedHandler; /******************** 并配置到 http ************************/ // 注册认证和授权异常的切入点 http.exceptionHandling().authenticationEntryPoint(authenticationEntryPoint). accessDeniedHandler(accessDeniedHandler); ","date":"2022-10-22","objectID":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"Spring Security自学笔记md版","uri":"/springsecurity%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#自定义异常处理器"},{"categories":null,"content":"\r基础篇补充","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:0:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#基础篇补充"},{"categories":null,"content":"\r数据类型","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据类型"},{"categories":null,"content":"\r数值类型 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808， 9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 字节 (-3.402 823 466 E+38， -1.175 494 351 E-38)， 0， (1.175 494 351 E-38， 3.402 823 466 351 E+38) 0， (1.175 494 351 E-38， 3.402 823 466 E+38) 单精度 浮点数值 DOUBLE 8 字节 (-1.797 693 134 862 315 7 E+308， -2.225 073 858 507 201 4 E-308)， 0， (2.225 073 858 507 201 4 E-308， 1.797 693 134 862 315 7 E+308) 0， (2.225 073 858 507 201 4 E-308， 1.797 693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D) ， 如果M\u003eD，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数值类型"},{"categories":null,"content":"\r日期和时间类型 类型 大小 (字节) 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00/2038 结束时间是第 2147483647 秒 ( INT类型最大值 )， 北京时间 2038-1-19 11:14:07， 格林尼治时间 2038-1-19 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#日期和时间类型"},{"categories":null,"content":"\r字符串类型 类型 大小 用途 CHAR 0-255字节 定长字符串 VARCHAR 0-65535 字节 变长字符串 TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65 535字节 二进制形式的长文本数据 TEXT 0-65 535字节 长文本数据 MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215字节 中等长度文本数据 LONGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295字节 极大文本数据 VARCHAR 的大小可以达到 65535 ？ 在定义表结构时 VARCHAR(M) 中的 M 指的是字符长度并非字节长度，在 utf8mb4 中每个字符占 4 字节 所以在定义 varchar 字段时，最高可以定义 65535 / 4 = 16383.75 但是由于 行格式 和 行溢出 的限制实测最多可以存储 48545 字节 ≈ 12136 字符 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#字符串类型"},{"categories":null,"content":"\r存储过程、存储函数","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储过程存储函数"},{"categories":null,"content":"\r存储过程 Stored Procedure 阿里开发规范 【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 MySQL 从 5.0 开始支持存储过程和函数 将复杂的 SQL 逻辑封装在一起，应用程序无须关注内部逻辑，简单的调用存储过程和函数即可 原理： 就是将一组经过 预先编译 好的 SQL 语句封装在 MySQL 服务器上 需要执行的时候只需要发起调用命令，服务端即可执行这组 SQL 语句 好处： 简化操作，提高 SQL 语句重用性 减少网络传输量 避免失误、提高效率 减少了 SQL 在网络中暴露的风险，提高安全性 用法 create procedure 存储过程名 (in|out|inout 参数名 参数类型...) [characteristics特征...] begin 存储过程体 end 参数（分类）： 没有参数【无参数无返回】 IN【有参数无返回】默认 OUT【无参数有返回】 IN OUT / INOUT【有参数有返回】 特征： LANGUAGE SQL：说明存储过程执行体是由SQL语句组成的，当前系统支持的语言为SQL。 [NOT] DETERMINISTIC：指明存储过程执行的结果是否确定。DETERMINISTIC表示结果是确定的。每次执行存储过程时，相同的输入会得到相同的输出。NOT DETERMINISTIC表示结果是不确定的，相同的输入可能得到不同的输出。如果没有指定任意一个值，默认为NOT DETERMINISTIC。 { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }：指明子程序使用SQL语句的限制。 CONTAINS SQL表示当前存储过程的子程序包含SQL语句，但是并不包含读写数据的SQL语句； NO SQL表示当前存储过程的子程序中不包含任何SQL语句； READS SQL DATA表示当前存储过程的子程序中包含读数据的SQL语句； MODIFIES SQL DATA表示当前存储过程的子程序中包含写数据的SQL语句。 默认情况下，系统会指定为CONTAINS SQL。 SQL SECURITY { DEFINER | INVOKER }：执行当前存储过程的权限，即指明哪些用户能够执行当前存储过程。 DEFINER表示只有当前存储过程的创建者或者定义者才能执行当前存储过程； INVOKER表示拥有当前存储过程的访问权限的用户能够执行当前存储过程。 如果没有设置相关的值，则MySQL默认指定值为DEFINER。 COMMENT 'string'：注释信息，可以用来描述存储过程。 创建存储过程例： delimiter // CREATE PROCEDURE select_all_data() BEGIN SELECT * FROM emps; END // delimiter ; 调用存储过程例： CALL 存储过程名(实参列表) CALL select_all_data() ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储过程-stored-procedure"},{"categories":null,"content":"\r存储过程 Stored Procedure 阿里开发规范 【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 MySQL 从 5.0 开始支持存储过程和函数 将复杂的 SQL 逻辑封装在一起，应用程序无须关注内部逻辑，简单的调用存储过程和函数即可 原理： 就是将一组经过 预先编译 好的 SQL 语句封装在 MySQL 服务器上 需要执行的时候只需要发起调用命令，服务端即可执行这组 SQL 语句 好处： 简化操作，提高 SQL 语句重用性 减少网络传输量 避免失误、提高效率 减少了 SQL 在网络中暴露的风险，提高安全性 用法 create procedure 存储过程名 (in|out|inout 参数名 参数类型...) [characteristics特征...] begin 存储过程体 end 参数（分类）： 没有参数【无参数无返回】 IN【有参数无返回】默认 OUT【无参数有返回】 IN OUT / INOUT【有参数有返回】 特征： LANGUAGE SQL：说明存储过程执行体是由SQL语句组成的，当前系统支持的语言为SQL。 [NOT] DETERMINISTIC：指明存储过程执行的结果是否确定。DETERMINISTIC表示结果是确定的。每次执行存储过程时，相同的输入会得到相同的输出。NOT DETERMINISTIC表示结果是不确定的，相同的输入可能得到不同的输出。如果没有指定任意一个值，默认为NOT DETERMINISTIC。 { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }：指明子程序使用SQL语句的限制。 CONTAINS SQL表示当前存储过程的子程序包含SQL语句，但是并不包含读写数据的SQL语句； NO SQL表示当前存储过程的子程序中不包含任何SQL语句； READS SQL DATA表示当前存储过程的子程序中包含读数据的SQL语句； MODIFIES SQL DATA表示当前存储过程的子程序中包含写数据的SQL语句。 默认情况下，系统会指定为CONTAINS SQL。 SQL SECURITY { DEFINER | INVOKER }：执行当前存储过程的权限，即指明哪些用户能够执行当前存储过程。 DEFINER表示只有当前存储过程的创建者或者定义者才能执行当前存储过程； INVOKER表示拥有当前存储过程的访问权限的用户能够执行当前存储过程。 如果没有设置相关的值，则MySQL默认指定值为DEFINER。 COMMENT 'string'：注释信息，可以用来描述存储过程。 创建存储过程例： delimiter // CREATE PROCEDURE select_all_data() BEGIN SELECT * FROM emps; END // delimiter ; 调用存储过程例： CALL 存储过程名(实参列表) CALL select_all_data() ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用法"},{"categories":null,"content":"\r存储函数 Stored Function MySQL 自带的 count(); 计数、sum(); 求和、avg(); 平均值、max(); 最大值、min(); 最小值 都是函数 存储函数就是我们自定义的函数 存储函数是带有返回值的，存储过程可以不带返回值 用法 CREATE FUNCTION 函数名(参数名 参数类型,...) RETURNS 返回值类型 [characteristics约束 ...] BEGIN 函数体 #函数体中肯定有 RETURN 语句 END 约束/特征 同 存储过程 创建存储函数例： delimiter // CREATE FUNCTION email_by_name() RETURNS VARCHAR( 25 ) DETERMINISTIC CONTAINS SQL BEGIN RETURN (SELECT email FROM employees WHERE last_name = 'Abel'); END // delimiter ; 调用存储函数例： SELECT 函数名(实参列表) ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储函数-stored-function"},{"categories":null,"content":"\r存储函数 Stored Function MySQL 自带的 count(); 计数、sum(); 求和、avg(); 平均值、max(); 最大值、min(); 最小值 都是函数 存储函数就是我们自定义的函数 存储函数是带有返回值的，存储过程可以不带返回值 用法 CREATE FUNCTION 函数名(参数名 参数类型,...) RETURNS 返回值类型 [characteristics约束 ...] BEGIN 函数体 #函数体中肯定有 RETURN 语句 END 约束/特征 同 存储过程 创建存储函数例： delimiter // CREATE FUNCTION email_by_name() RETURNS VARCHAR( 25 ) DETERMINISTIC CONTAINS SQL BEGIN RETURN (SELECT email FROM employees WHERE last_name = 'Abel'); END // delimiter ; 调用存储函数例： SELECT 函数名(实参列表) ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用法-1"},{"categories":null,"content":"\r存储函数和存储过程对比 关键字 调用语法 返回值 应用场景 存储过程 PROCEDURE CALL 存储过程() 理解为有 0 个或多个 一般用于更新 存储函数 FUNCTION SELECT 函数() 只能是一个 一般用于查询结果为一个值并返回时 存储函数可以放在查询语句中使用，存储过程不行 。 存储过程的功能更加强大，包括能够执行对表的操作（比如创建表，删除表等）和事务操作，这些功能是存储函数不具备的。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储函数和存储过程对比"},{"categories":null,"content":"\r查看、修改、删除略 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看修改删除"},{"categories":null,"content":"\r变量、流程控制、游标 这块是为便于和 存储过程 / 存储函数 配合使用的 需要时可以查看链接学习使用 wzblog 略 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#变量流程控制游标"},{"categories":null,"content":"\r触发器 触发器和存储过程类似，都是存储在 MySQL 服务器中的一段程序 不过存储过程是手动触发的，触发器是在执行一些事件的时候自动触发的 当一个业务需要向 商品表 库存表 中添加数据时，通常我们会使用事务实现数据的完整性，但一旦遇到特殊情况忘记了其中一步，会导致数据缺失 这时就可以使用触发器，实现当 商品表 有数据插入时 库存表 自动触发插入 优点： 可以确保数据完整性 可以记录操作日志 在操作数据前，进行数据合法性校验 缺点： 可读性差 表结构或数据变更，容易导致触发器出错 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:4:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#触发器"},{"categories":null,"content":"\r用法： CREATE TRIGGER 触发器名称 {BEFORE|AFTER} {INSERT|UPDATE|DELETE} ON 表名 FOR EACH ROW BEGIN 触发器执行的语句块; END 说明： 表名：表示触发器监控的对象。 BEFORE|AFTER：表示触发的时间。BEFORE 表示在事件之前触发；AFTER 表示在事件之后触发。 INSERT|UPDATE|DELETE：表示触发的事件。 INSERT 表示插入记录时触发； UPDATE 表示更新记录时触发； DELETE 表示删除记录时触发。 触发器执行的语句块：可以是单条SQL语句，也可以是由BEGIN…END结构组成的复合语句块。 创建触发器例1： DELIMITER // create trigger before_insert_test_tri before insert on test_trigger for each row begin insert into test_trigger_log(t_log) value('insert_trigger'); end // DELIMITER ; 创建触发器例2：定义触发器“salary_check_trigger”，基于员工表“employees”的INSERT事件，在INSERT之前检查将要添加的新员工薪资是否大于他领导的薪资，如果大于领导薪资，则报sqlstate_value为’HY000’的错误，从而使得添加失败。 DELIMITER // CREATE TRIGGER salary_check_trigger BEFORE INSERT ON employees FOR EACH ROW BEGIN DECLARE mgrsalary DOUBLE; # 创建 double 类型变量 mgrsalary 用于存储当前员工领导的薪资 SELECT salary INTO mgrsalary FROM employees WHERE employee_id = NEW.manager_id; IF NEW.salary \u003e mgrsalary THEN SIGNAL SQLSTATE 'HY000' SET MESSAGE_TEXT = '薪资高于领导薪资错误'; # 抛出错误，不会继续执行插入操作 END IF; END // DELIMITER ; NEW 关键字代表 INSERT 添加语句的新记录，同理 OLD 为 DELETE 中要删除的已有的记录 SIGNAL 抛出错误，代码为 SQLSTATE 后字符错误信息为 MESSAGE_TEXT 查看触发器： 查看触发器是查看数据库中已经存在的触发器的定义、状态和语法信息等。 方式 1 ：查看当前数据库的所有触发器的定义 SHOW TRIGGERS\\G 方式 2 ：查看当前数据库中某个触发器的定义 SHOW CREATE TRIGGER 触发器名 方式 3 ：从系统库information_schema的TRIGGERS表中查询“salary_check_trigger”触发器的信息。 SELECT * FROM information_schema.TRIGGERS; 删除触发器： 触发器也是数据库对象，删除触发器也用DROP语句，语法格式如下： DROP TRIGGER IF EXISTS 触发器名称; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:4:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用法-2"},{"categories":null,"content":"\rDELIMITER 在存储过程、存储函数、触发器例子中都用到了 delimiter 作用为 修改程序执行结束的标识，避免语句块中出现分号时程序就结束执行了 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:4:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#delimiter"},{"categories":null,"content":"\rMySQL8 新特性","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql8-新特性"},{"categories":null,"content":"\r新增的内容字符集支持： MySQL 5 中默认字符集为 latin1，通常需要手动设置为 utf8 即 utf8mb3 避免乱码问题 MySQL 8 中默认字符集为 utf8md4 加密规则： MySQL 5 中默认密码加密方式为 mysql_native_password MySQL 8 中默认加密方式改为了 caching_sha2_password 授权插件、角色、密码历史记录和 FIPS 模式支持，这些特性提高了数据库的安全性和性能，使数据库管理员能够更灵活地进行账户管理工作 导致在使用一些旧版的图形界面工具连接时报异常，更新图形界面工具 或 修改密码加密方式即可解决 use mysql; ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'ThePassword'; # 修改密码加密方式 flush privileges; # 刷新权限 更简便的 NoSQL 支持： MySQL 5.6 开始就支持 NoSQL 在 MySQL 8 对这一功能进行了优化，不再使用依赖模块 (schema)， 更灵活 更好的索引： MySQL 8 中新增了 隐藏索引 降序索引 隐藏索引可以用来测试去掉索引对查询性能的影响 在查询中混合存在多列索引时，使用降序索引可以提高查询的性能 更完善的 JSON 支持： MySQL 5.7 开始支持原生 JSON 数据的存储，有一些聚合函数实现 字符串 和 JSON 数据的解析和转换等 MySQL 8 对这一功能做了优化，增加了聚合函数 JSON_ARRAYAGG() 和 JSON_OBJECTAGG() ，将参数聚合为 JSON 数组或对象，新增了行内操作符 -»，是列路径运算符 -\u003e 的增强，对 JSON 排序做了提升，并优化了 JSON 的更新操作。 改进、优化 InnoDB 存储引擎： InnoDB 是 MySQL 默认的 存储引擎，是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键。在 MySQL 8 版本中，InnoDB 在自增、索引、加密、死锁、共享锁等方面做了大量的 改进和优化，并且支持原子数据定义语言（DDL），提高了数据安全性，对事务提供更好的支持。 数据字典： 在之前的MySQL版本中，字典数据都存储在元数据文件和非事务表中。 从MySQL 8开始新增了事务数据字典，在这个字典里存储着数据库对象信息，这些数据字典存储在内部事务表中 原子数据定义语句： MySQL 8开始支持原子数据定义语句（Automic DDL），即 原子DDL。目前，只有 InnoDB 存储引擎支持原子 DDL。 在使用支持原子数据定义的存储引擎中，即事务要么完全操作成功，要么失败后回滚，不再进行部分提交。 资源管理： MySQL 8 开始支持创建和管理资源组… 资源管理更高效、合理 优化器增强： MySQL 优化器开始支持隐藏索引和降序索引。 隐藏索引不会被优化器使用，验证索引的必要性时不需要删除索引，先将索引隐藏，如果优化器性能无影响就可以真正地删除索引。 降序索引允许优化器对多个列进行排序，并且允许排序顺序不一致。 共用表表达式： 共用表表达式详情 窗口函数： 窗口函数详情 正则表达式支持： MySQL 在 8.0.4 以后的版本中采用支持 Unicode 的国际化组件库实现正则表达式操作，这种方式不仅能提供完全的 Unicode 支持，而且是多字节安全编码。 内部临时表 ： TempTable 存储引擎取代 MEMORY 存储引擎成为内部临时表的默认存储引擎 日志记录： 在 MySQL 8 中错误日志子系统由一系列 MySQL 组件构成。这些组件的构成由系统变量 log_error_services 来配置，能够实现日志事件的过滤和写入。 备份锁： 新的备份锁允许在线备份期间执行数据操作语句，同时阻止可能造成快照不一致的操作。 新备份锁由 LOCK INSTANCE FOR BACKUP 和 UNLOCK INSTANCE 语法提供支持，执行这些操作需要备份管理员特权。 增强的MySQL复制： MySQL 8 复制支持对 JSON文档 进行部分更新的 二进制日志记录，该记录 使用紧凑的二进制格式，从而节省记录完整 JSON 文档的空间。 当使用基于语句的日志记录时，这种紧凑的日志记录会自动完成，并且可以通过将新的 binlog_row_value_options 系统变量值设置为 PARTIAL_JSON 来启用。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#新增的内容"},{"categories":null,"content":"\r移除的内容查询缓存： 查询缓存命中率太小，很鸡肋 包括：语句… 、系统变量… 、状态变量… 、线程状态… 加密相关： 删除的加密相关的内容有：ENCODE()、DECODE()、ENCRYPT()、DES_ENCRYPT() 和 DES_DECRYPT() 函数 配置项 des-key-file，系统变量 have_crypt，FLUSH 语句的 DES_KEY_FILE 选项，HAVE_CRYPT CMake 选项。 对于移除的ENCRYPT() 函数，考虑使用 SHA2() 替代，对于其他移除的函数，使用 AES_ENCRYPT() 和 AES_DECRYPT() 替代。 空间函数相关： 在 MySQL 5.7 版本中，多个空间函数已被标记为过时。这些过时函数在 MySQL 8 中都已被移除，只保留了对应的 ST_ 和 MBR 函数。 \\N和NULL： 在 SQL 语句中，解析器不再将 \\N 视为 NULL，所以在 SQL 语句中应使用 NULL 代替 \\N。 这项变化不会影响使用 LOAD DATA INFILE 或者 SELECT…INTO OUTFILE操作文件的导入和导出。在这类操作中，NULL 仍等同于 \\N。 mysql_install_db： 在 MySQL 分布中，已移除了 mysql_install_db 程序，数据字典初始化需要调用带着 –initialize 或者 –initialize-insecure 选项的mysqld 来代替实现。另外，–bootstrap 和 INSTALL_SCRIPTDIR CMake 也已被删除。 通用分区处理程序： 通用分区处理程序已从 MySQL 服务中被移除。为了实现给定表分区，表所使用的存储引擎需要自有的分区处理程序。 提供本地分区支持的 MySQL 存储引擎有两个，即 InnoDB 和 NDB，而在 MySQL 8 中只支持 InnoDB。 系统和状态变量信息： 在 INFORMATION_SCHEMA 数据库中，对系统和状态变量信息不再进行维护。 GLOBAL_VARIABLES、SESSION_VARIABLES、GLOBAL_STATUS、SESSION_STATUS表都已被删除。 另外，系统变量 show_compatibility_56 也已被删除。被删除的状态变量有 Slave_heartbeat_period、Slave_last_heartbeat , Slave_received_heartbeats、Slave_retried_transactions、Slave_running 。 以上被删除的内容都可使用性能模式中对应的内容进行替代。 mysql_plugin工具： mysql_plugin 工具用来配置 MySQL 服务器插件，现已被删除，可使用 –plugin-load 或 –plugin-load-add 选项在服务器启动时加载插件或者在运行时使用 INSTALL PLUGIN 语句加载插件来替代该工具。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#移除的内容"},{"categories":null,"content":"\r共用表表达式 概念： 公用表表达式（或通用表表达式）简称为 CTE（Common Table Expressions） CTE 是一个命了名的临时结果集，作用范围是当前语句 我理解 CTE 是一个可复用的子查询，但是 CTE 可以引用其它 CTE ，子查询不行 用法 WITH CTE名称 AS （子查询） SELECT|DELETE|UPDATE 语句; 普通公用表表达式 # 查询员工所在的部门的详细信息 SELECT * FROM departments WHERE department_id IN ( SELECT DISTINCT department_id FROM employees ); 共用表表达式写法 我理解为讲一个查询中可能会重复用到的子查询表保存起来，在用的时候直接当作一个表来使用 WITH emp_dept_id AS (SELECT DISTINCT department_id FROM employees) SELECT * FROM departments d JOIN emp_dept_id e ON d.department_id = e.department_id; +---------------+------------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+------------------+------------+-------------+ | 10 | Administration | 200 | 1700 | | 20 | Marketing | 201 | 1800 | | 30 | Purchasing | 114 | 1700 | | 40 | Human Resources | 203 | 2400 | | 50 | Shipping | 121 | 1500 | | 60 | IT | 103 | 1400 | | 70 | Public Relations | 204 | 2700 | | 80 | Sales | 145 | 2500 | | 90 | Executive | 100 | 1700 | | 100 | Finance | 108 | 1700 | | 110 | Accounting | 205 | 1700 | +---------------+------------------+------------+-------------+ 11 rows in set (0.00 sec) 递归公用表表达式 CTE 可以调用自身 和自身连接，可以达到一个共同根节点的树形结构数据上非常高效 # 找到员工表中下下属的员工信息，三代下属以下 WITH RECURSIVE cte AS ( SELECT employee_id, last_name, manager_id, 1 AS n FROM employees WHERE employee_id = 100 -- 种子查询，找到第一代领导 UNION ALL SELECT a.employee_id, a.last_name, a.manager_id, n + 1 FROM employees AS a JOIN cte ON (a.manager_id = cte.employee_id) -- 递归查询，找出以递归公用表表达式的人为领导的人 ) SELECT employee_id, last_name FROM cte WHERE n \u003e= 3; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#共用表表达式-a-idgybbds-a"},{"categories":null,"content":"\r共用表表达式 概念： 公用表表达式（或通用表表达式）简称为 CTE（Common Table Expressions） CTE 是一个命了名的临时结果集，作用范围是当前语句 我理解 CTE 是一个可复用的子查询，但是 CTE 可以引用其它 CTE ，子查询不行 用法 WITH CTE名称 AS （子查询） SELECT|DELETE|UPDATE 语句; 普通公用表表达式 # 查询员工所在的部门的详细信息 SELECT * FROM departments WHERE department_id IN ( SELECT DISTINCT department_id FROM employees ); 共用表表达式写法 我理解为讲一个查询中可能会重复用到的子查询表保存起来，在用的时候直接当作一个表来使用 WITH emp_dept_id AS (SELECT DISTINCT department_id FROM employees) SELECT * FROM departments d JOIN emp_dept_id e ON d.department_id = e.department_id; +---------------+------------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+------------------+------------+-------------+ | 10 | Administration | 200 | 1700 | | 20 | Marketing | 201 | 1800 | | 30 | Purchasing | 114 | 1700 | | 40 | Human Resources | 203 | 2400 | | 50 | Shipping | 121 | 1500 | | 60 | IT | 103 | 1400 | | 70 | Public Relations | 204 | 2700 | | 80 | Sales | 145 | 2500 | | 90 | Executive | 100 | 1700 | | 100 | Finance | 108 | 1700 | | 110 | Accounting | 205 | 1700 | +---------------+------------------+------------+-------------+ 11 rows in set (0.00 sec) 递归公用表表达式 CTE 可以调用自身 和自身连接，可以达到一个共同根节点的树形结构数据上非常高效 # 找到员工表中下下属的员工信息，三代下属以下 WITH RECURSIVE cte AS ( SELECT employee_id, last_name, manager_id, 1 AS n FROM employees WHERE employee_id = 100 -- 种子查询，找到第一代领导 UNION ALL SELECT a.employee_id, a.last_name, a.manager_id, n + 1 FROM employees AS a JOIN cte ON (a.manager_id = cte.employee_id) -- 递归查询，找出以递归公用表表达式的人为领导的人 ) SELECT employee_id, last_name FROM cte WHERE n \u003e= 3; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用法-3"},{"categories":null,"content":"\r共用表表达式 概念： 公用表表达式（或通用表表达式）简称为 CTE（Common Table Expressions） CTE 是一个命了名的临时结果集，作用范围是当前语句 我理解 CTE 是一个可复用的子查询，但是 CTE 可以引用其它 CTE ，子查询不行 用法 WITH CTE名称 AS （子查询） SELECT|DELETE|UPDATE 语句; 普通公用表表达式 # 查询员工所在的部门的详细信息 SELECT * FROM departments WHERE department_id IN ( SELECT DISTINCT department_id FROM employees ); 共用表表达式写法 我理解为讲一个查询中可能会重复用到的子查询表保存起来，在用的时候直接当作一个表来使用 WITH emp_dept_id AS (SELECT DISTINCT department_id FROM employees) SELECT * FROM departments d JOIN emp_dept_id e ON d.department_id = e.department_id; +---------------+------------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+------------------+------------+-------------+ | 10 | Administration | 200 | 1700 | | 20 | Marketing | 201 | 1800 | | 30 | Purchasing | 114 | 1700 | | 40 | Human Resources | 203 | 2400 | | 50 | Shipping | 121 | 1500 | | 60 | IT | 103 | 1400 | | 70 | Public Relations | 204 | 2700 | | 80 | Sales | 145 | 2500 | | 90 | Executive | 100 | 1700 | | 100 | Finance | 108 | 1700 | | 110 | Accounting | 205 | 1700 | +---------------+------------------+------------+-------------+ 11 rows in set (0.00 sec) 递归公用表表达式 CTE 可以调用自身 和自身连接，可以达到一个共同根节点的树形结构数据上非常高效 # 找到员工表中下下属的员工信息，三代下属以下 WITH RECURSIVE cte AS ( SELECT employee_id, last_name, manager_id, 1 AS n FROM employees WHERE employee_id = 100 -- 种子查询，找到第一代领导 UNION ALL SELECT a.employee_id, a.last_name, a.manager_id, n + 1 FROM employees AS a JOIN cte ON (a.manager_id = cte.employee_id) -- 递归查询，找出以递归公用表表达式的人为领导的人 ) SELECT employee_id, last_name FROM cte WHERE n \u003e= 3; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#普通公用表表达式"},{"categories":null,"content":"\r共用表表达式 概念： 公用表表达式（或通用表表达式）简称为 CTE（Common Table Expressions） CTE 是一个命了名的临时结果集，作用范围是当前语句 我理解 CTE 是一个可复用的子查询，但是 CTE 可以引用其它 CTE ，子查询不行 用法 WITH CTE名称 AS （子查询） SELECT|DELETE|UPDATE 语句; 普通公用表表达式 # 查询员工所在的部门的详细信息 SELECT * FROM departments WHERE department_id IN ( SELECT DISTINCT department_id FROM employees ); 共用表表达式写法 我理解为讲一个查询中可能会重复用到的子查询表保存起来，在用的时候直接当作一个表来使用 WITH emp_dept_id AS (SELECT DISTINCT department_id FROM employees) SELECT * FROM departments d JOIN emp_dept_id e ON d.department_id = e.department_id; +---------------+------------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+------------------+------------+-------------+ | 10 | Administration | 200 | 1700 | | 20 | Marketing | 201 | 1800 | | 30 | Purchasing | 114 | 1700 | | 40 | Human Resources | 203 | 2400 | | 50 | Shipping | 121 | 1500 | | 60 | IT | 103 | 1400 | | 70 | Public Relations | 204 | 2700 | | 80 | Sales | 145 | 2500 | | 90 | Executive | 100 | 1700 | | 100 | Finance | 108 | 1700 | | 110 | Accounting | 205 | 1700 | +---------------+------------------+------------+-------------+ 11 rows in set (0.00 sec) 递归公用表表达式 CTE 可以调用自身 和自身连接，可以达到一个共同根节点的树形结构数据上非常高效 # 找到员工表中下下属的员工信息，三代下属以下 WITH RECURSIVE cte AS ( SELECT employee_id, last_name, manager_id, 1 AS n FROM employees WHERE employee_id = 100 -- 种子查询，找到第一代领导 UNION ALL SELECT a.employee_id, a.last_name, a.manager_id, n + 1 FROM employees AS a JOIN cte ON (a.manager_id = cte.employee_id) -- 递归查询，找出以递归公用表表达式的人为领导的人 ) SELECT employee_id, last_name FROM cte WHERE n \u003e= 3; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#递归公用表表达式"},{"categories":null,"content":"\r窗口函数 案例： 现有表：sales 计算这个网站在 每个城市的销售总额、在全国的销售总额、每个区的销售额占所在城市销售额中的比率，以及占总销售额中的比率。 # 1.创建全国总销售额临时表 CREATE TEMPORARY TABLE a -- 创建临时表 SELECT SUM(sales_value) AS sales_value -- 计算总计金额 FROM sales; # 2.创建每个城市的总销售额临时表 CREATE TEMPORARY TABLE b -- 创建临时表 SELECT city,SUM(sales_value) AS sales_value -- 计算城市销售合计 FROM sales GROUP BY city; # 3.查询 SELECT s.city AS 城市,s.county AS 区, s.sales_value AS 区销售额, b.sales_value AS 市销售额, s.sales_value/b.sales_value AS 市比率, a.sales_value AS 总销售额, s.sales_value/a.sales_value AS 总比率 FROM sales s JOIN b ON (s.city=b.city) -- 连接市统计结果临时表 JOIN a -- 连接总计金额临时表 ORDER BY s.city,s.county; 使用窗口函数实现 SELECT city AS 城市,county AS 区, sales_value AS 区销售额, SUM(sales_value) OVER(PARTITION BY city) AS 市销售额, -- 计算市销售额 sales_value/SUM(sales_value) OVER(PARTITION BY city) AS 市比率, SUM(sales_value) OVER() AS 总销售额, -- 计算总销售额 sales_value/SUM(sales_value) OVER() AS 总比率 FROM sales ORDER BY city,county; 由于没有用到临时表，执行的效率也更高了。 在这种需要用到分组统计的结果对每一条记录进行计算的场景下，使用窗口函数更好 。 概念： 窗口函数是介于单行和分组函数之间的： 分组函数是将数据分组并合并 窗口函数是将数据分组但不合并，将结果置于每一条数据记录中 窗口函数的分类： 静态窗口函数 静态窗口函数的窗口大小是固定的，不会因为记录的不同而不同 动态窗口函数 动态窗口函数的窗口大小会随着记录的不同而变化 窗口函数总体上可以分为序号函数、分布函数、前后函数、首尾函数和其他函数，如下表： 用法 PARTITION BY ：分片、分区 函数 OVER（[PARTITION BY 字段名 ][ ORDER BY 字段名 ASC|DESC]） 或者是： # 相当于给 over 后内容统一定义，在 over 后只需写窗口名即可 函数 OVER 窗口名 ... WINDOW 窗口名 AS （[PARTITION BY 字段名 ORDER BY 字段名 ASC|DESC]） 序号函数： row_number( ) 顺序排序 现有表 goods 需求：查询 goods 数据表中每个商品分类下价格降序排列的各个商品信息。 # 根据 category_id 分组并按照 price 降序排序 select row_number() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods; 需求：查询 goods 数据表中每个商品分类下价格最高的 3 种商品信息。 select * from ( select row_number() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods ) as t where row_num \u003c= 3; rank( ) 并列排序 对序号进行并列排序，并且会跳过重复的序号，比如序号为 1 、 1 、 3 【2 被覆盖了】 select rank() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods dense_rank( ) 并列排序 对序号进行并列排序，并且不会跳过重复的序号，比如序号为1 、1 、2【2 还在继续排序】 select dense_rank() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods 分布函数： percent_rank( ) 等级值百分比 按照 (rank - 1 ) / (rows - 1 ) 计算等级值百分比，值为 0 - 1 相当于计算概率分布，我理解为百分比的排序、进度条 # 计算 goods 数据表中的商品的PERCENT_RANK值。 SELECT RANK() OVER w AS r, PERCENT_RANK() OVER w AS pr, id, category_id, category, NAME, price, stock FROM goods WINDOW w AS (PARTITION BY category_id ORDER BY price DESC); cume_dist() 累计分布值 主要用于查询小于或等于某个值的比例。 # 计算小于等于当前价格的比例 SELECT CUME_DIST() OVER(PARTITION BY category_id ORDER BY price ASC) AS cd, id, category, NAME, price FROM goods; 前后函数： lag(expr, n) 返回当前行的前 n 行的 expr 的值 # 查询 goods 表中当前商品的价格和前一个商品的价格 SELECT id, category, NAME, price,LAG(price, 1 ) OVER (PARTITION BY category_id ORDER BY price) AS pre_price FROM goods # 查询 goods 数据表中前一个商品价格与当前商品价格的差值。 SELECT id, category, NAME, price, pre_price, price - pre_price AS diff_price FROM ( SELECT id, category, NAME, price,LAG(price, 1 ) OVER w AS pre_price FROM goods WINDOW w AS (PARTITION BY category_id ORDER BY price) ) t; lead() 返回当前行的后 n 行的 expr 的值 # 查询 goods 表中当前商品的价格和后第二个商品的价格 SELECT id, category, NAME, price, LEAD(price, 2 ) OVER (PARTITION BY category_id ORDER BY price) AS pre_price FROM goods 首尾函数： first_value(expr) 返回第一个 expr 的值 # 查询 category_id 分组后的商品价格信息和每组第一个商品的价格 SELECT id, category, NAME, price, first_value(price) OVER (PARTITION BY category_id ORDER BY price) AS first_price FROM goods last_value(expr) 返回最后一个 expr 的值 # 查询 category_id 分组后的商品价格信息和每组最后一个商品的价格 SELECT id, category, NAME, price, last_value(price) OVER (PARTITION BY category_id ORDER BY price range between unbounded preceding and unbounded following) AS last_price FROM goods order by 后面的 range between unbounded preceding and unbounded following 为设置取值区间为分组的前后无界限 其它函数： NTH_VALUE(expr,n) 返回第 n 个 expr 的值 # 查询 goods 数据表中排名第 2 和第 3 的价格信息 SELECT id, category, NAME, price,NTH_VALUE(price, 2 ) OVER w AS second_pric","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#窗口函数-a-idckhs-a"},{"categories":null,"content":"\r窗口函数 案例： 现有表：sales 计算这个网站在 每个城市的销售总额、在全国的销售总额、每个区的销售额占所在城市销售额中的比率，以及占总销售额中的比率。 # 1.创建全国总销售额临时表 CREATE TEMPORARY TABLE a -- 创建临时表 SELECT SUM(sales_value) AS sales_value -- 计算总计金额 FROM sales; # 2.创建每个城市的总销售额临时表 CREATE TEMPORARY TABLE b -- 创建临时表 SELECT city,SUM(sales_value) AS sales_value -- 计算城市销售合计 FROM sales GROUP BY city; # 3.查询 SELECT s.city AS 城市,s.county AS 区, s.sales_value AS 区销售额, b.sales_value AS 市销售额, s.sales_value/b.sales_value AS 市比率, a.sales_value AS 总销售额, s.sales_value/a.sales_value AS 总比率 FROM sales s JOIN b ON (s.city=b.city) -- 连接市统计结果临时表 JOIN a -- 连接总计金额临时表 ORDER BY s.city,s.county; 使用窗口函数实现 SELECT city AS 城市,county AS 区, sales_value AS 区销售额, SUM(sales_value) OVER(PARTITION BY city) AS 市销售额, -- 计算市销售额 sales_value/SUM(sales_value) OVER(PARTITION BY city) AS 市比率, SUM(sales_value) OVER() AS 总销售额, -- 计算总销售额 sales_value/SUM(sales_value) OVER() AS 总比率 FROM sales ORDER BY city,county; 由于没有用到临时表，执行的效率也更高了。 在这种需要用到分组统计的结果对每一条记录进行计算的场景下，使用窗口函数更好 。 概念： 窗口函数是介于单行和分组函数之间的： 分组函数是将数据分组并合并 窗口函数是将数据分组但不合并，将结果置于每一条数据记录中 窗口函数的分类： 静态窗口函数 静态窗口函数的窗口大小是固定的，不会因为记录的不同而不同 动态窗口函数 动态窗口函数的窗口大小会随着记录的不同而变化 窗口函数总体上可以分为序号函数、分布函数、前后函数、首尾函数和其他函数，如下表： 用法 PARTITION BY ：分片、分区 函数 OVER（[PARTITION BY 字段名 ][ ORDER BY 字段名 ASC|DESC]） 或者是： # 相当于给 over 后内容统一定义，在 over 后只需写窗口名即可 函数 OVER 窗口名 ... WINDOW 窗口名 AS （[PARTITION BY 字段名 ORDER BY 字段名 ASC|DESC]） 序号函数： row_number( ) 顺序排序 现有表 goods 需求：查询 goods 数据表中每个商品分类下价格降序排列的各个商品信息。 # 根据 category_id 分组并按照 price 降序排序 select row_number() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods; 需求：查询 goods 数据表中每个商品分类下价格最高的 3 种商品信息。 select * from ( select row_number() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods ) as t where row_num \u003c= 3; rank( ) 并列排序 对序号进行并列排序，并且会跳过重复的序号，比如序号为 1 、 1 、 3 【2 被覆盖了】 select rank() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods dense_rank( ) 并列排序 对序号进行并列排序，并且不会跳过重复的序号，比如序号为1 、1 、2【2 还在继续排序】 select dense_rank() over(partition by category_id order by price desc) as row_num, id, category_id, category, NAME, price, stock from goods 分布函数： percent_rank( ) 等级值百分比 按照 (rank - 1 ) / (rows - 1 ) 计算等级值百分比，值为 0 - 1 相当于计算概率分布，我理解为百分比的排序、进度条 # 计算 goods 数据表中的商品的PERCENT_RANK值。 SELECT RANK() OVER w AS r, PERCENT_RANK() OVER w AS pr, id, category_id, category, NAME, price, stock FROM goods WINDOW w AS (PARTITION BY category_id ORDER BY price DESC); cume_dist() 累计分布值 主要用于查询小于或等于某个值的比例。 # 计算小于等于当前价格的比例 SELECT CUME_DIST() OVER(PARTITION BY category_id ORDER BY price ASC) AS cd, id, category, NAME, price FROM goods; 前后函数： lag(expr, n) 返回当前行的前 n 行的 expr 的值 # 查询 goods 表中当前商品的价格和前一个商品的价格 SELECT id, category, NAME, price,LAG(price, 1 ) OVER (PARTITION BY category_id ORDER BY price) AS pre_price FROM goods # 查询 goods 数据表中前一个商品价格与当前商品价格的差值。 SELECT id, category, NAME, price, pre_price, price - pre_price AS diff_price FROM ( SELECT id, category, NAME, price,LAG(price, 1 ) OVER w AS pre_price FROM goods WINDOW w AS (PARTITION BY category_id ORDER BY price) ) t; lead() 返回当前行的后 n 行的 expr 的值 # 查询 goods 表中当前商品的价格和后第二个商品的价格 SELECT id, category, NAME, price, LEAD(price, 2 ) OVER (PARTITION BY category_id ORDER BY price) AS pre_price FROM goods 首尾函数： first_value(expr) 返回第一个 expr 的值 # 查询 category_id 分组后的商品价格信息和每组第一个商品的价格 SELECT id, category, NAME, price, first_value(price) OVER (PARTITION BY category_id ORDER BY price) AS first_price FROM goods last_value(expr) 返回最后一个 expr 的值 # 查询 category_id 分组后的商品价格信息和每组最后一个商品的价格 SELECT id, category, NAME, price, last_value(price) OVER (PARTITION BY category_id ORDER BY price range between unbounded preceding and unbounded following) AS last_price FROM goods order by 后面的 range between unbounded preceding and unbounded following 为设置取值区间为分组的前后无界限 其它函数： NTH_VALUE(expr,n) 返回第 n 个 expr 的值 # 查询 goods 数据表中排名第 2 和第 3 的价格信息 SELECT id, category, NAME, price,NTH_VALUE(price, 2 ) OVER w AS second_pric","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用法-4"},{"categories":null,"content":"\r高级篇","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:0:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#高级篇"},{"categories":null,"content":"\r字符集 utf8mb3 阉割过的 utf8 字符集，用 1 - 3 个字节表示字符，MySQL 中 utf8 默认指的就是 utf8mb3 utf8mb4 正宗的 utf8 字符集，用 1 - 4 个字节表示字符，如需存储 emoji 表情，就需要用到 utf8mb4 MySQL 8 之前版本默认字符集为 latin1，如果想存储中文字符，需 在 my.cnf 中设置数据库默认字符集 vim /etc/my.cnf 添加 character_set_server=utf8 重启 MySQL 服务 systemctl restart mysqld 在创建数据库或表时指定字符集 数据库 CREATE DATABASE 数据库名 [[DEFAULT] CHARACTER SET 字符集名称] [[DEFAULT] COLLATE 比较规则名称]; 表 CREATE TABLE 表名 ( 列名 字符串类型 [CHARACTER SET 字符集名称] [COLLATE 比较规则名称], 列的信息... ) [[DEFAULT] CHARACTER SET 字符集名称] [COLLATE 比较规则名称]] 修改已创建数据库的字符集 alter database dbtest1 character set 'utf8'; 修改已创建数据表的字符集 alter table t_emp convert to character set 'utf8'; 字符串比较规则： 其中 Default collation 字段为默认比较规则 后缀 英文释义 描述 _ai accent insensitive 不区分重音 _as accent sensitive 区分重音 _ci case insensitive 不区分大小写 _cs case sensitive 区分大小写 _bin binary 以二进制方式比较 查看、修改字符串比较规则 #查看服务器的字符集和比较规则 SHOW VARIABLES LIKE '%_server'; #查看数据库的字符集和比较规则 SHOW VARIABLES LIKE '%_database'; #查看具体数据库的字符集 SHOW CREATE DATABASE dbtest1; #修改具体数据库的字符集 ALTER DATABASE dbtest1 DEFAULT CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; #查看表的字符集 show create table employees; #查看表的比较规则 show table status from atguigudb like 'employees'; #修改表的字符集和比较规则 ALTER TABLE emp1 DEFAULT CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; 在数据库设置中就需要保证 character_set_client 和 character_set_connection 和 character_set_results 设置一致，以避免数据库服务器处理中出现乱码问题 使用 SET NAMES utf8; 或 设置my.cnf 中内容 或 单独设置这三个值 效果一致 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#字符集"},{"categories":null,"content":"\rSQL 大小写规范 在 windows 系统中 SHOW VARIABLES LIKE '%lower_case_table_names%' 的 value 值为 0 即: 大小写不敏感 在 linux 系统中 SHOW VARIABLES LIKE '%lower_case_table_names%' 的 value 值为 1 ，部分情况下大小写敏感 这个值也可以设置为 2 即: 无论大小写字符，凡是查找就都是按照小写进行 在 MySQL 5 设置 my.cnf 中加入 lower_case_table_names=1 【需要提前将表明全部改为小写，重启生效】 在 MySQL 8 设置【不建议改】 1、停止MySQL服务 2、删除数据目录，即删除 /var/lib/mysql 目录 3、在MySQL配置文件 (/etc/my.cnf) 中添加 lower_case_table_names=1 4、启动MySQL服务 MySQL 在 Linux 下数据库名、表名、列名、别名大小写规则是这样的： 数据库名、表名、表的别名、变量名是严格区分大小写的：dbtest99; 关键字、函数名称在 SQL 中不区分大小写：COUNT() sum() 列名（或字段名）与列的别名（或字段别名）在所有的情况下均是忽略大小写的：Id, NaME, PassWORD 建议： 关键字和函数名称全部大写 数据库名、表名、表别名、字段名、字段别名等全部小写 SQL 语句必须以分号结尾 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#sql-大小写规范"},{"categories":null,"content":"\rsql_mode sql_mode 是一组语法校验规则，会影响 MySQL 的数据验证检查 通过设置 sql_mode 实现不同严格程度的数据校验，有效保证数据准确性 【宽松模式】MySQL 5.6 默认为宽松模式 NO_ENGINE_SUBSTITUTION，是一个空值，允许一些非法数据的插入 宽松模式在插入数据时，即使给了一个错误的数据，仍然可能被接受不报错。 举例：在给一个 char(10) 的字段插入 1234567890abc 这样一个长度超过 10 的数据时，MySQL 会自行处理并接受，并不会报错，是将前十位数据插入后面的舍弃。 应用场景：在做数据迁移时可以打开宽松模式，生产环境中即便使用的是 MySQL 5.6 也应设置为严格模式 【严格模式】MySQL 5.7 默认为严格模式 STRICT_TRANS_TABLES，对数据进行严格的校验，错误时报 ERROR 并回滚 严格模式则严格按照数据的约束进行校验，当遇到的是错误的数据时立即报 ERROR 问题：使用严格模式时若设置模式中包含了 NO_ZERO_DATE 不允许插入零日期。当一个字段使用的是 TIMESTAMP 时间戳类型时，未声明为 NULL 或 default 值时，将自动分配 DEFAULT ‘0000-00-00 00:00:00’ ( 零时间戳 )，此时会报错误 ERROR sql_mode 值 描述 ONLY_FULL_GROUP_BY 对于 GROUP BY 聚合操作，如果在SELECT中的列，没有在 GROUP BY 中出现，那么这个 SQL 是不合法的，因为列不在 GROUP BY 从句中 NO_AUTO_VALUE_ON_ZERO 该值影响自增长列的插入。默认设置下，插入 0 或 NULL 代表生成下一个自增长值。如果用户 希望插入的值为 0，而该列又是自增长的，那么这个选项就有用了 ==STRICT_TRANS_TABLES== 在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制 NO_ZERO_IN_DATE 在严格模式下，不允许日期和月份为零 NO_ZERO_DATE MySQL 数据库不允许插入零日期，插入零日期会抛出错误而不是警告 ERROR_FOR_DIVISION_BY_ZERO 在 INSERT 或 UPDATE 过程中,如果数据被零除，则产生错误而非警告。如果未给出该模式，那么数据被零除时 MySQL 返回 NULL NO_AUTO_CREATE_USER 禁止 GRANT 创建密码为空的用户 ==NO_ENGINE_SUBSTITUTION== 如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT 将 “||” 视为字符串的连接操作符而非或运算符，这和 Oracle 数据库是一样，也和字符串的拼接函数 Concat 相类似 ANSI_QUOTES 启用 ANSI_QUOTES 后，不能用双引号来引用字符串，因为它被解释为识别符 查看当前的 sql_mode select @@session.sql_mode select @@global.sql_mode #或者 show variables like 'sql_mode'; 临时设置 sql_mode SET GLOBAL sql_mode = 'modes...'; #全局 SET SESSION sql_mode = 'modes...'; #当前会话 #改为严格模式。此方法在当前服务中生效，重启MySQL服务后失效。 set GLOBAL sql_mode='STRICT_TRANS_TABLES'; #改为严格模式。此方法只在当前会话中生效，关闭当前会话就不生效了。 set SESSION sql_mode='STRICT_TRANS_TABLES'; 永久设置 sql_mode 在 my.cnf 中添加 [mysqld] sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 重启 MySQL 服务【生产场景推荐使用临时 + 永久设置配合】 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:1:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#sql_mode"},{"categories":null,"content":"\rMySQL 的数据目录","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-的数据目录"},{"categories":null,"content":"\r主要目录结构Windows 中的 MySQL 数据存放目录 C:\\ProgramData\\MySQL\\MySQL Server 8.0 │ installer_config.xml │ my.ini │ ├─Data │ ├─#innodb_temp │ ├─数据库名 │ │ 表名.ibd │ │ 表名.ibd │ ├─mysql │ ├─performance_schema │ └─sys └─Uploads Linux 中的 MySQL 数据存放目录 /var/lib/mysql 相关命令目录 /usr/bin(mysqladmin、mysqlbinlog、mysqldump 等命令) 和 /usr/sbin 配置文件目录 /usr/share/mysql-8.0 (命令及配置文件) /etc/mysql (如 my.cnf) 查看 MySQL 相关的目录 find / -name mysql ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#主要目录结构"},{"categories":null,"content":"\r数据库文件系统 【存储引擎】：InnoDB / MyISAM 的作用就是 把表存储在文件系统上 。 在写入数据的时候，存储引擎将数据写入到文件系统 在读取数据的时候，存储引擎从文件系统中读取数据并返回 ==MySQL 自带的数据库== mysql：MySQL 的核心数据库，用于存储用户账户、权限信息，存储过程、事件的定义信息，日志，帮助信息、时区信息等 information_schema：存储所有其他数据库的 描述性信息 / 元数据 ，比如表、视图、存储过程/函数、触发器、列、索引等 performance_schema：存储 MySQL 数据库在运行时期的状态信息，性能指标。统计执行的语句、花费的时间、内存使用等 sys：通过 视图 将 information_schema、performance_schema 结合起来。帮助开发人员监控 MySQL 的技术性能 MySQL 5.7 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1、dbtest2 进入 dbtest1 目录 db.opt：存储当前数据库下的信息 ( 字符集、比较规则等 ) emp1.frm：存储表结构信息 ( 字段名、字段类型、约束等 ) emp1.idb：存储表数据【默认】( MySQL 5.5 前表数据存放在上级目录 ibdata1 中 ) ibdata1：【系统表空间】system tablespace MySQL 5.5 前，表数据默认都存储在此文件中 是一个 自扩展文件 默认大小 12M 可以修改 my.cnf 配置系统表空间默认路径及大小 [server] innodb_data_file_path=data1:512M;data2:512M:autoextend 表名.ibd：【独立表空间】file-per-table tablespace 在 MySQL 5.6.6 以及之后的版本中，默认为每一个表建立一个独立的表空间 设置使用系统表空间还是独立表空间： 可以修改 my.cnf 配置 [server] innodb_file_per_table=0 # 0：代表使用系统表空间； 1：代表使用独立表空间 MySQL 8 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1 进入 dbtest1 目录 emp1.ibd：集成了 表结构信息 和 表数据 的文件 解析 ibd 文件： 使用 Oracle 提供集成的 ibd2sdi 工具 ibd2sdi --dump-file=tbl_dic_type.txt tbl_dic_type.ibd 生成 tbl_dic_type.txt 文件，可以看到里面有对表结构信息的描述 MyISAM 存储引擎的文件结构 MyISAM 存储引擎的表由三个文件构成 表名.frm：等同于 InnoDB 中的 frm 文件，用于存储表结构信息 ( 字段名、字段类型、约束等 )【MySQL 8 中为 表名_xxx.sdi】 表名.MYD：MYData 存储表数据 ( MyISAM 存储引擎中的表数据和索引信息是分开存储的 ) 表名.MYI：MYIndex 存储索引 ( MyISAM 存储引擎中的索引都是二级索引 ) ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据库文件系统"},{"categories":null,"content":"\r数据库文件系统 【存储引擎】：InnoDB / MyISAM 的作用就是 把表存储在文件系统上 。 在写入数据的时候，存储引擎将数据写入到文件系统 在读取数据的时候，存储引擎从文件系统中读取数据并返回 ==MySQL 自带的数据库== mysql：MySQL 的核心数据库，用于存储用户账户、权限信息，存储过程、事件的定义信息，日志，帮助信息、时区信息等 information_schema：存储所有其他数据库的 描述性信息 / 元数据 ，比如表、视图、存储过程/函数、触发器、列、索引等 performance_schema：存储 MySQL 数据库在运行时期的状态信息，性能指标。统计执行的语句、花费的时间、内存使用等 sys：通过 视图 将 information_schema、performance_schema 结合起来。帮助开发人员监控 MySQL 的技术性能 MySQL 5.7 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1、dbtest2 进入 dbtest1 目录 db.opt：存储当前数据库下的信息 ( 字符集、比较规则等 ) emp1.frm：存储表结构信息 ( 字段名、字段类型、约束等 ) emp1.idb：存储表数据【默认】( MySQL 5.5 前表数据存放在上级目录 ibdata1 中 ) ibdata1：【系统表空间】system tablespace MySQL 5.5 前，表数据默认都存储在此文件中 是一个 自扩展文件 默认大小 12M 可以修改 my.cnf 配置系统表空间默认路径及大小 [server] innodb_data_file_path=data1:512M;data2:512M:autoextend 表名.ibd：【独立表空间】file-per-table tablespace 在 MySQL 5.6.6 以及之后的版本中，默认为每一个表建立一个独立的表空间 设置使用系统表空间还是独立表空间： 可以修改 my.cnf 配置 [server] innodb_file_per_table=0 # 0：代表使用系统表空间； 1：代表使用独立表空间 MySQL 8 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1 进入 dbtest1 目录 emp1.ibd：集成了 表结构信息 和 表数据 的文件 解析 ibd 文件： 使用 Oracle 提供集成的 ibd2sdi 工具 ibd2sdi --dump-file=tbl_dic_type.txt tbl_dic_type.ibd 生成 tbl_dic_type.txt 文件，可以看到里面有对表结构信息的描述 MyISAM 存储引擎的文件结构 MyISAM 存储引擎的表由三个文件构成 表名.frm：等同于 InnoDB 中的 frm 文件，用于存储表结构信息 ( 字段名、字段类型、约束等 )【MySQL 8 中为 表名_xxx.sdi】 表名.MYD：MYData 存储表数据 ( MyISAM 存储引擎中的表数据和索引信息是分开存储的 ) 表名.MYI：MYIndex 存储索引 ( MyISAM 存储引擎中的索引都是二级索引 ) ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-57-文件结构"},{"categories":null,"content":"\r数据库文件系统 【存储引擎】：InnoDB / MyISAM 的作用就是 把表存储在文件系统上 。 在写入数据的时候，存储引擎将数据写入到文件系统 在读取数据的时候，存储引擎从文件系统中读取数据并返回 ==MySQL 自带的数据库== mysql：MySQL 的核心数据库，用于存储用户账户、权限信息，存储过程、事件的定义信息，日志，帮助信息、时区信息等 information_schema：存储所有其他数据库的 描述性信息 / 元数据 ，比如表、视图、存储过程/函数、触发器、列、索引等 performance_schema：存储 MySQL 数据库在运行时期的状态信息，性能指标。统计执行的语句、花费的时间、内存使用等 sys：通过 视图 将 information_schema、performance_schema 结合起来。帮助开发人员监控 MySQL 的技术性能 MySQL 5.7 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1、dbtest2 进入 dbtest1 目录 db.opt：存储当前数据库下的信息 ( 字符集、比较规则等 ) emp1.frm：存储表结构信息 ( 字段名、字段类型、约束等 ) emp1.idb：存储表数据【默认】( MySQL 5.5 前表数据存放在上级目录 ibdata1 中 ) ibdata1：【系统表空间】system tablespace MySQL 5.5 前，表数据默认都存储在此文件中 是一个 自扩展文件 默认大小 12M 可以修改 my.cnf 配置系统表空间默认路径及大小 [server] innodb_data_file_path=data1:512M;data2:512M:autoextend 表名.ibd：【独立表空间】file-per-table tablespace 在 MySQL 5.6.6 以及之后的版本中，默认为每一个表建立一个独立的表空间 设置使用系统表空间还是独立表空间： 可以修改 my.cnf 配置 [server] innodb_file_per_table=0 # 0：代表使用系统表空间； 1：代表使用独立表空间 MySQL 8 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1 进入 dbtest1 目录 emp1.ibd：集成了 表结构信息 和 表数据 的文件 解析 ibd 文件： 使用 Oracle 提供集成的 ibd2sdi 工具 ibd2sdi --dump-file=tbl_dic_type.txt tbl_dic_type.ibd 生成 tbl_dic_type.txt 文件，可以看到里面有对表结构信息的描述 MyISAM 存储引擎的文件结构 MyISAM 存储引擎的表由三个文件构成 表名.frm：等同于 InnoDB 中的 frm 文件，用于存储表结构信息 ( 字段名、字段类型、约束等 )【MySQL 8 中为 表名_xxx.sdi】 表名.MYD：MYData 存储表数据 ( MyISAM 存储引擎中的表数据和索引信息是分开存储的 ) 表名.MYI：MYIndex 存储索引 ( MyISAM 存储引擎中的索引都是二级索引 ) ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-8-文件结构"},{"categories":null,"content":"\r数据库文件系统 【存储引擎】：InnoDB / MyISAM 的作用就是 把表存储在文件系统上 。 在写入数据的时候，存储引擎将数据写入到文件系统 在读取数据的时候，存储引擎从文件系统中读取数据并返回 ==MySQL 自带的数据库== mysql：MySQL 的核心数据库，用于存储用户账户、权限信息，存储过程、事件的定义信息，日志，帮助信息、时区信息等 information_schema：存储所有其他数据库的 描述性信息 / 元数据 ，比如表、视图、存储过程/函数、触发器、列、索引等 performance_schema：存储 MySQL 数据库在运行时期的状态信息，性能指标。统计执行的语句、花费的时间、内存使用等 sys：通过 视图 将 information_schema、performance_schema 结合起来。帮助开发人员监控 MySQL 的技术性能 MySQL 5.7 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1、dbtest2 进入 dbtest1 目录 db.opt：存储当前数据库下的信息 ( 字符集、比较规则等 ) emp1.frm：存储表结构信息 ( 字段名、字段类型、约束等 ) emp1.idb：存储表数据【默认】( MySQL 5.5 前表数据存放在上级目录 ibdata1 中 ) ibdata1：【系统表空间】system tablespace MySQL 5.5 前，表数据默认都存储在此文件中 是一个 自扩展文件 默认大小 12M 可以修改 my.cnf 配置系统表空间默认路径及大小 [server] innodb_data_file_path=data1:512M;data2:512M:autoextend 表名.ibd：【独立表空间】file-per-table tablespace 在 MySQL 5.6.6 以及之后的版本中，默认为每一个表建立一个独立的表空间 设置使用系统表空间还是独立表空间： 可以修改 my.cnf 配置 [server] innodb_file_per_table=0 # 0：代表使用系统表空间； 1：代表使用独立表空间 MySQL 8 文件结构 进入 Linux 版本 MySQL 的数据存放目录 /var/lib/mysql ，可以看到 MySQL 自带的数据库目录，以及我创建的数据库目录：dbtest1 进入 dbtest1 目录 emp1.ibd：集成了 表结构信息 和 表数据 的文件 解析 ibd 文件： 使用 Oracle 提供集成的 ibd2sdi 工具 ibd2sdi --dump-file=tbl_dic_type.txt tbl_dic_type.ibd 生成 tbl_dic_type.txt 文件，可以看到里面有对表结构信息的描述 MyISAM 存储引擎的文件结构 MyISAM 存储引擎的表由三个文件构成 表名.frm：等同于 InnoDB 中的 frm 文件，用于存储表结构信息 ( 字段名、字段类型、约束等 )【MySQL 8 中为 表名_xxx.sdi】 表名.MYD：MYData 存储表数据 ( MyISAM 存储引擎中的表数据和索引信息是分开存储的 ) 表名.MYI：MYIndex 存储索引 ( MyISAM 存储引擎中的索引都是二级索引 ) ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:2:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#myisam-存储引擎的文件结构"},{"categories":null,"content":"\r用户与权限管理","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用户与权限管理"},{"categories":null,"content":"\r用户管理登录 MySQL 服务器命令： mysql –h hostname|hostIP –P port –u username –p 数据库名 –e \"SQL语句\" -h 指定主机名或主机 IP，省略时为 localhost -P 指定连接的端口，省略时为 3306 -u 用户名 -p 密码 数据库名 指定登录的数据库，省略时需要登录后 use 数据库 -e 指定登录后执行的 SQL 语句，执行结束自动退出 创建用户： CREATE USER 用户名 [IDENTIFIED BY '密码'][,用户名 [IDENTIFIED BY '密码']]; 创建用户基础写法 create user zhangsan identified by '123456' 此时默认 host 为 ‘%’ 创建用户写法举例 create user 'kangshifu'@'localhost' identified by '123456'; 指定用户 kangshifu 可使用的 host 为 localhost，在 mysql 数据库的 user 表中，由 host 和 user 共同组成复合主键 修改用户： UPDATE mysql.user SET USER='lisi' WHERE USER='zhangsan'; FLUSH PRIVILEGES; 修改用户名是对 user 表进行修改，开发中很少这么做 修改数据 update user set user = 'lisi' where user = 'zhangsan'; 刷新权限 flush privileges; 删除用户： 使用 DROP 方式删除【推荐】 DROP USER user[,user]…; 使用 DELETE 方式删除 使用 delete 方式删除会有残留信息保留 修改自身密码： 在 MySQL 8 中移除了 PASSWORD( ) 函数，因此无法使用 update 语句对密码进行修改 # 修改当前用户的密码：（MySQL5.7测试有效） SET PASSWORD = PASSWORD('新密码'); 使用 alter user 命令修改自身密码 ALTER USER USER() IDENTIFIED BY '新密码'; 使用 set 命令修改自身密码 SET PASSWORD = '新密码'; 修改其它用户密码： 使用 update 修改其它用户密码【不推荐】 # 在 MySQL 5.7 及之前可用 UPDATE MySQL.user SET authentication_string=PASSWORD(\"123456\") WHERE User = \"username\" AND Host = \"hostname\"; 使用 ALTER 语句来修改普通用户的密码 可以使用 ALTER USER 语句来修改普通用户的密码 ALTER USER user [IDENTIFIED BY '新密码'] [,user[IDENTIFIED BY '新密码']]…; 使用 SET 命令来修改普通用户的密码 使用 root 用户登录到 MySQL 服务器后，可以使用 SET 语句来修改普通用户的密码 SET PASSWORD FOR 'username'@'hostname' = '新密码'; 密码过期策略、密码重用策略： 设置全局密码过期策略 方式①：使用SQL语句更改该变量的值并持久化 SET PERSIST default_password_lifetime = 180; # 建立全局策略，设置密码每隔180天过期 方式②：配置文件my.cnf中进行维护 [mysqld] default_password_lifetime=180 #建立全局策略，设置密码每隔180天过期 单独设置密码过去策略 通过 PASSWORD EXPIRE 实现单独设置密码过期策略 #设置kangshifu账号密码每90天过期： CREATE USER 'kangshifu'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY; ALTER USER 'kangshifu'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY; #设置密码永不过期： CREATE USER 'kangshifu'@'localhost' PASSWORD EXPIRE NEVER; ALTER USER 'kangshifu'@'localhost' PASSWORD EXPIRE NEVER; #延用全局密码过期策略： CREATE USER 'kangshifu'@'localhost' PASSWORD EXPIRE DEFAULT; ALTER USER 'kangshifu'@'localhost' PASSWORD EXPIRE DEFAULT; 设置全局密码重用策略 方式①：使用SQL SET PERSIST password_history = 6; #设置不能选择最近使用过的6个密码 SET PERSIST password_reuse_interval = 365; #设置不能选择最近一年内的密码 方式②：my.cnf配置文件 [mysqld] password_history=6 password_reuse_interval=365 单独设置密码重用策略 #不能使用最近5个密码： CREATE USER 'kangshifu'@'localhost' PASSWORD HISTORY 5; ALTER USER 'kangshifu'@'localhost' PASSWORD HISTORY 5; #不能使用最近365天内的密码： CREATE USER 'kangshifu'@'localhost' PASSWORD REUSE INTERVAL 365 DAY; ALTER USER 'kangshifu'@'localhost' PASSWORD REUSE INTERVAL 365 DAY; #既不能使用最近5个密码，也不能使用365天内的密码 CREATE USER 'kangshifu'@'localhost' PASSWORD HISTORY 5 PASSWORD REUSE INTERVAL 365 DAY; ALTER USER 'kangshifu'@'localhost' PASSWORD HISTORY 5 PASSWORD REUSE INTERVAL 365 DAY; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#用户管理"},{"categories":null,"content":"\r权限管理 # 查看 MySQL 都有哪些权限 show privileges; 权限分类及常用的权限 CREATE 和 DROP 权限，允许创建新的数据库和表，或删除（移掉）已有的数据库和表 SELECT 、 INSERT 、 UPDATE 和 DELETE 权限，允许在一个数据库现有的表上实施操作 SELECT 权限，只有在它们真正从一个表中检索行时才被用到 INDEX 权限，允许创建或删除索引，适用于已有的表。如果具有某个表的 CREATE 权限，就可以在 CREATE TABLE 语句中包括索引定义 ALTER 权限，允许使用 ALTER TABLE 来更改表的结构和重新命名表 CREATE ROUTINE 权限，允许创建保存的程序（函数和程序），更改和删除保存的程序， EXECUTE 权限允许执行保存的程序 GRANT 权限，允许授权给其他用户，可用于数据库、表和保存的程序 FILE 权限，允许使用 LOAD DATA INFILE 和 SELECT … INTO OUTFILE 语句读或写服务器上的文件，任何被授予 FILE 权限的用户都能读或写 MySQL 服务器上的任何文件（说明用户可以读任何数据库目录下的文件，因为服务器可以访问这些文件） 权限的查看、赋予和撤销授予权限： 可以 赋予角色权限后将角色赋予给用户，也可以 直接赋予用户权限 直接赋予权限命令： GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO 用户名@用户地址 [IDENTIFIED BY ‘密码口令’]; 举例：授予 zhangsan 查询 dbtest99 数据库中 emp 表的权限 grant select on dbtest99.emp to 'zhangsan'@'%'; 当 zhangsan 要 update 数据时，会提示权限不足 再次赋予权限 时，相当于添加权限【并集】 赋予所有权限 grant all privileges on *.* to zhangsan; 授予权限的 横向分组 与 纵向分组 所谓横向的分组，就是指用户可以接触到的数据的范围，比如可以看到哪些表的数据； 所谓纵向的分组，就是指用户对接触到的数据能访问到什么程度，比如能看、能改，甚至是 删除。 查看权限： 查看当前用户权限 SHOW GRANTS; # 或 SHOW GRANTS FOR CURRENT_USER; # 或 SHOW GRANTS FOR CURRENT_USER(); 查看某用户的全局权限 SHOW GRANTS FOR 'user'@'主机地址'; 收回权限： 回收权限命令 REVOKE 权限1,权限2,…权限n ON 数据库名称.表名称 FROM 用户名@用户地址; 举例：回收 zhangsan 用户的所有权限 REVOKE ALL PRIVILEGES ON *.* FROM zhangsan@'%'; 【注意】在将用户账户从user表删除之前，应该收回相应用户的所有权限 开发中尽可能不要使用 root 超级用户来访问数据库，因为 root 的密码放在代码中不安全，一旦泄漏，数据库将完全失去保护 权限表 MySQL 通过权限表来控制用户对数据库的访问，在 mysql 数据库中由 user、db 表和 table_priv、column_priv、proc_priv 表来记录权限信息 user 表字段解释 db 表字段解释 通过 host、db、user 组成复合主键，体现用户对某一数据库的相关操作权限 Create_routine_priv 和 Alter_routine_priv 字段决定用户是否具有创建和修改存储过程的权限 tables_priv 表和 columns_priv 表 tables_priv 表用来 对表设置操作权限 columns_priv 表用来对表的 某一列设置权限 procs_priv表 procs_priv 表可以对 存储过程和存储函数设置操作权限 连接核实阶段： 通过 user 表中的 host、user 和 authentication_string 这 3 个字段匹配客户端提供信息 请求核实阶段： 根据用户的操作，按照 user - db - tables_priv - columns_priv 检查确认权限 角色 角色，就相当于权限的集合 创建角色： 创建角色命令 CREATE ROLE 'role_name'[@'host_name'] [,'role_name'[@'host_name']]... 给角色赋予权限： 给角色赋予权限命令 GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO '角色名'[@'host_name']; 查看角色的权限： 查看指定角色权限命令 SHOW GRANTS FOR '角色名'; 回收角色的权限： 回收角色的权限命令 REVOKE privileges ON tablename FROM 'rolename'; 删除角色： 删除角色命令 DROP ROLE '角色名'; 为用户赋予角色： 为用户赋予角色命令 GRANT role [,role2,...] TO user [,user2,...]; 激活角色： 为用户赋予角色后需要激活角色，用户重新登录才真正拥有角色 激活角色命令【方式一】 SET DEFAULT ROLE ALL TO '用户名'@'host'; 激活角色命令【方式二】 # 对所有角色永久激活 SET GLOBAL activate_all_roles_on_login = ON; 查看当前用户的角色 SELECT CURRENT_ROLE(); 撤销用户的角色： 赊销用户角色命令 REVOKE 角色名 FROM 用户; 设置强制角色： 强制角色相当于为所有用户设置默认角色 服务启动前设置 my.cnf【方式一】 [mysqld] mandatory_roles='role1,role2@localhost,r3@%.atguigu.com' 运行时设置【方式二】 SET PERSIST mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后仍然 有效 SET GLOBAL mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后失效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#权限管理"},{"categories":null,"content":"\r权限管理 # 查看 MySQL 都有哪些权限 show privileges; 权限分类及常用的权限 CREATE 和 DROP 权限，允许创建新的数据库和表，或删除（移掉）已有的数据库和表 SELECT 、 INSERT 、 UPDATE 和 DELETE 权限，允许在一个数据库现有的表上实施操作 SELECT 权限，只有在它们真正从一个表中检索行时才被用到 INDEX 权限，允许创建或删除索引，适用于已有的表。如果具有某个表的 CREATE 权限，就可以在 CREATE TABLE 语句中包括索引定义 ALTER 权限，允许使用 ALTER TABLE 来更改表的结构和重新命名表 CREATE ROUTINE 权限，允许创建保存的程序（函数和程序），更改和删除保存的程序， EXECUTE 权限允许执行保存的程序 GRANT 权限，允许授权给其他用户，可用于数据库、表和保存的程序 FILE 权限，允许使用 LOAD DATA INFILE 和 SELECT … INTO OUTFILE 语句读或写服务器上的文件，任何被授予 FILE 权限的用户都能读或写 MySQL 服务器上的任何文件（说明用户可以读任何数据库目录下的文件，因为服务器可以访问这些文件） 权限的查看、赋予和撤销授予权限： 可以 赋予角色权限后将角色赋予给用户，也可以 直接赋予用户权限 直接赋予权限命令： GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO 用户名@用户地址 [IDENTIFIED BY ‘密码口令’]; 举例：授予 zhangsan 查询 dbtest99 数据库中 emp 表的权限 grant select on dbtest99.emp to 'zhangsan'@'%'; 当 zhangsan 要 update 数据时，会提示权限不足 再次赋予权限 时，相当于添加权限【并集】 赋予所有权限 grant all privileges on *.* to zhangsan; 授予权限的 横向分组 与 纵向分组 所谓横向的分组，就是指用户可以接触到的数据的范围，比如可以看到哪些表的数据； 所谓纵向的分组，就是指用户对接触到的数据能访问到什么程度，比如能看、能改，甚至是 删除。 查看权限： 查看当前用户权限 SHOW GRANTS; # 或 SHOW GRANTS FOR CURRENT_USER; # 或 SHOW GRANTS FOR CURRENT_USER(); 查看某用户的全局权限 SHOW GRANTS FOR 'user'@'主机地址'; 收回权限： 回收权限命令 REVOKE 权限1,权限2,…权限n ON 数据库名称.表名称 FROM 用户名@用户地址; 举例：回收 zhangsan 用户的所有权限 REVOKE ALL PRIVILEGES ON *.* FROM zhangsan@'%'; 【注意】在将用户账户从user表删除之前，应该收回相应用户的所有权限 开发中尽可能不要使用 root 超级用户来访问数据库，因为 root 的密码放在代码中不安全，一旦泄漏，数据库将完全失去保护 权限表 MySQL 通过权限表来控制用户对数据库的访问，在 mysql 数据库中由 user、db 表和 table_priv、column_priv、proc_priv 表来记录权限信息 user 表字段解释 db 表字段解释 通过 host、db、user 组成复合主键，体现用户对某一数据库的相关操作权限 Create_routine_priv 和 Alter_routine_priv 字段决定用户是否具有创建和修改存储过程的权限 tables_priv 表和 columns_priv 表 tables_priv 表用来 对表设置操作权限 columns_priv 表用来对表的 某一列设置权限 procs_priv表 procs_priv 表可以对 存储过程和存储函数设置操作权限 连接核实阶段： 通过 user 表中的 host、user 和 authentication_string 这 3 个字段匹配客户端提供信息 请求核实阶段： 根据用户的操作，按照 user - db - tables_priv - columns_priv 检查确认权限 角色 角色，就相当于权限的集合 创建角色： 创建角色命令 CREATE ROLE 'role_name'[@'host_name'] [,'role_name'[@'host_name']]... 给角色赋予权限： 给角色赋予权限命令 GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO '角色名'[@'host_name']; 查看角色的权限： 查看指定角色权限命令 SHOW GRANTS FOR '角色名'; 回收角色的权限： 回收角色的权限命令 REVOKE privileges ON tablename FROM 'rolename'; 删除角色： 删除角色命令 DROP ROLE '角色名'; 为用户赋予角色： 为用户赋予角色命令 GRANT role [,role2,...] TO user [,user2,...]; 激活角色： 为用户赋予角色后需要激活角色，用户重新登录才真正拥有角色 激活角色命令【方式一】 SET DEFAULT ROLE ALL TO '用户名'@'host'; 激活角色命令【方式二】 # 对所有角色永久激活 SET GLOBAL activate_all_roles_on_login = ON; 查看当前用户的角色 SELECT CURRENT_ROLE(); 撤销用户的角色： 赊销用户角色命令 REVOKE 角色名 FROM 用户; 设置强制角色： 强制角色相当于为所有用户设置默认角色 服务启动前设置 my.cnf【方式一】 [mysqld] mandatory_roles='role1,role2@localhost,r3@%.atguigu.com' 运行时设置【方式二】 SET PERSIST mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后仍然 有效 SET GLOBAL mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后失效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#权限的查看赋予和撤销"},{"categories":null,"content":"\r权限管理 # 查看 MySQL 都有哪些权限 show privileges; 权限分类及常用的权限 CREATE 和 DROP 权限，允许创建新的数据库和表，或删除（移掉）已有的数据库和表 SELECT 、 INSERT 、 UPDATE 和 DELETE 权限，允许在一个数据库现有的表上实施操作 SELECT 权限，只有在它们真正从一个表中检索行时才被用到 INDEX 权限，允许创建或删除索引，适用于已有的表。如果具有某个表的 CREATE 权限，就可以在 CREATE TABLE 语句中包括索引定义 ALTER 权限，允许使用 ALTER TABLE 来更改表的结构和重新命名表 CREATE ROUTINE 权限，允许创建保存的程序（函数和程序），更改和删除保存的程序， EXECUTE 权限允许执行保存的程序 GRANT 权限，允许授权给其他用户，可用于数据库、表和保存的程序 FILE 权限，允许使用 LOAD DATA INFILE 和 SELECT … INTO OUTFILE 语句读或写服务器上的文件，任何被授予 FILE 权限的用户都能读或写 MySQL 服务器上的任何文件（说明用户可以读任何数据库目录下的文件，因为服务器可以访问这些文件） 权限的查看、赋予和撤销授予权限： 可以 赋予角色权限后将角色赋予给用户，也可以 直接赋予用户权限 直接赋予权限命令： GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO 用户名@用户地址 [IDENTIFIED BY ‘密码口令’]; 举例：授予 zhangsan 查询 dbtest99 数据库中 emp 表的权限 grant select on dbtest99.emp to 'zhangsan'@'%'; 当 zhangsan 要 update 数据时，会提示权限不足 再次赋予权限 时，相当于添加权限【并集】 赋予所有权限 grant all privileges on *.* to zhangsan; 授予权限的 横向分组 与 纵向分组 所谓横向的分组，就是指用户可以接触到的数据的范围，比如可以看到哪些表的数据； 所谓纵向的分组，就是指用户对接触到的数据能访问到什么程度，比如能看、能改，甚至是 删除。 查看权限： 查看当前用户权限 SHOW GRANTS; # 或 SHOW GRANTS FOR CURRENT_USER; # 或 SHOW GRANTS FOR CURRENT_USER(); 查看某用户的全局权限 SHOW GRANTS FOR 'user'@'主机地址'; 收回权限： 回收权限命令 REVOKE 权限1,权限2,…权限n ON 数据库名称.表名称 FROM 用户名@用户地址; 举例：回收 zhangsan 用户的所有权限 REVOKE ALL PRIVILEGES ON *.* FROM zhangsan@'%'; 【注意】在将用户账户从user表删除之前，应该收回相应用户的所有权限 开发中尽可能不要使用 root 超级用户来访问数据库，因为 root 的密码放在代码中不安全，一旦泄漏，数据库将完全失去保护 权限表 MySQL 通过权限表来控制用户对数据库的访问，在 mysql 数据库中由 user、db 表和 table_priv、column_priv、proc_priv 表来记录权限信息 user 表字段解释 db 表字段解释 通过 host、db、user 组成复合主键，体现用户对某一数据库的相关操作权限 Create_routine_priv 和 Alter_routine_priv 字段决定用户是否具有创建和修改存储过程的权限 tables_priv 表和 columns_priv 表 tables_priv 表用来 对表设置操作权限 columns_priv 表用来对表的 某一列设置权限 procs_priv表 procs_priv 表可以对 存储过程和存储函数设置操作权限 连接核实阶段： 通过 user 表中的 host、user 和 authentication_string 这 3 个字段匹配客户端提供信息 请求核实阶段： 根据用户的操作，按照 user - db - tables_priv - columns_priv 检查确认权限 角色 角色，就相当于权限的集合 创建角色： 创建角色命令 CREATE ROLE 'role_name'[@'host_name'] [,'role_name'[@'host_name']]... 给角色赋予权限： 给角色赋予权限命令 GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO '角色名'[@'host_name']; 查看角色的权限： 查看指定角色权限命令 SHOW GRANTS FOR '角色名'; 回收角色的权限： 回收角色的权限命令 REVOKE privileges ON tablename FROM 'rolename'; 删除角色： 删除角色命令 DROP ROLE '角色名'; 为用户赋予角色： 为用户赋予角色命令 GRANT role [,role2,...] TO user [,user2,...]; 激活角色： 为用户赋予角色后需要激活角色，用户重新登录才真正拥有角色 激活角色命令【方式一】 SET DEFAULT ROLE ALL TO '用户名'@'host'; 激活角色命令【方式二】 # 对所有角色永久激活 SET GLOBAL activate_all_roles_on_login = ON; 查看当前用户的角色 SELECT CURRENT_ROLE(); 撤销用户的角色： 赊销用户角色命令 REVOKE 角色名 FROM 用户; 设置强制角色： 强制角色相当于为所有用户设置默认角色 服务启动前设置 my.cnf【方式一】 [mysqld] mandatory_roles='role1,role2@localhost,r3@%.atguigu.com' 运行时设置【方式二】 SET PERSIST mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后仍然 有效 SET GLOBAL mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后失效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#权限表"},{"categories":null,"content":"\r权限管理 # 查看 MySQL 都有哪些权限 show privileges; 权限分类及常用的权限 CREATE 和 DROP 权限，允许创建新的数据库和表，或删除（移掉）已有的数据库和表 SELECT 、 INSERT 、 UPDATE 和 DELETE 权限，允许在一个数据库现有的表上实施操作 SELECT 权限，只有在它们真正从一个表中检索行时才被用到 INDEX 权限，允许创建或删除索引，适用于已有的表。如果具有某个表的 CREATE 权限，就可以在 CREATE TABLE 语句中包括索引定义 ALTER 权限，允许使用 ALTER TABLE 来更改表的结构和重新命名表 CREATE ROUTINE 权限，允许创建保存的程序（函数和程序），更改和删除保存的程序， EXECUTE 权限允许执行保存的程序 GRANT 权限，允许授权给其他用户，可用于数据库、表和保存的程序 FILE 权限，允许使用 LOAD DATA INFILE 和 SELECT … INTO OUTFILE 语句读或写服务器上的文件，任何被授予 FILE 权限的用户都能读或写 MySQL 服务器上的任何文件（说明用户可以读任何数据库目录下的文件，因为服务器可以访问这些文件） 权限的查看、赋予和撤销授予权限： 可以 赋予角色权限后将角色赋予给用户，也可以 直接赋予用户权限 直接赋予权限命令： GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO 用户名@用户地址 [IDENTIFIED BY ‘密码口令’]; 举例：授予 zhangsan 查询 dbtest99 数据库中 emp 表的权限 grant select on dbtest99.emp to 'zhangsan'@'%'; 当 zhangsan 要 update 数据时，会提示权限不足 再次赋予权限 时，相当于添加权限【并集】 赋予所有权限 grant all privileges on *.* to zhangsan; 授予权限的 横向分组 与 纵向分组 所谓横向的分组，就是指用户可以接触到的数据的范围，比如可以看到哪些表的数据； 所谓纵向的分组，就是指用户对接触到的数据能访问到什么程度，比如能看、能改，甚至是 删除。 查看权限： 查看当前用户权限 SHOW GRANTS; # 或 SHOW GRANTS FOR CURRENT_USER; # 或 SHOW GRANTS FOR CURRENT_USER(); 查看某用户的全局权限 SHOW GRANTS FOR 'user'@'主机地址'; 收回权限： 回收权限命令 REVOKE 权限1,权限2,…权限n ON 数据库名称.表名称 FROM 用户名@用户地址; 举例：回收 zhangsan 用户的所有权限 REVOKE ALL PRIVILEGES ON *.* FROM zhangsan@'%'; 【注意】在将用户账户从user表删除之前，应该收回相应用户的所有权限 开发中尽可能不要使用 root 超级用户来访问数据库，因为 root 的密码放在代码中不安全，一旦泄漏，数据库将完全失去保护 权限表 MySQL 通过权限表来控制用户对数据库的访问，在 mysql 数据库中由 user、db 表和 table_priv、column_priv、proc_priv 表来记录权限信息 user 表字段解释 db 表字段解释 通过 host、db、user 组成复合主键，体现用户对某一数据库的相关操作权限 Create_routine_priv 和 Alter_routine_priv 字段决定用户是否具有创建和修改存储过程的权限 tables_priv 表和 columns_priv 表 tables_priv 表用来 对表设置操作权限 columns_priv 表用来对表的 某一列设置权限 procs_priv表 procs_priv 表可以对 存储过程和存储函数设置操作权限 连接核实阶段： 通过 user 表中的 host、user 和 authentication_string 这 3 个字段匹配客户端提供信息 请求核实阶段： 根据用户的操作，按照 user - db - tables_priv - columns_priv 检查确认权限 角色 角色，就相当于权限的集合 创建角色： 创建角色命令 CREATE ROLE 'role_name'[@'host_name'] [,'role_name'[@'host_name']]... 给角色赋予权限： 给角色赋予权限命令 GRANT 权限1,权限2,…权限n ON 数据库名称.表名称 TO '角色名'[@'host_name']; 查看角色的权限： 查看指定角色权限命令 SHOW GRANTS FOR '角色名'; 回收角色的权限： 回收角色的权限命令 REVOKE privileges ON tablename FROM 'rolename'; 删除角色： 删除角色命令 DROP ROLE '角色名'; 为用户赋予角色： 为用户赋予角色命令 GRANT role [,role2,...] TO user [,user2,...]; 激活角色： 为用户赋予角色后需要激活角色，用户重新登录才真正拥有角色 激活角色命令【方式一】 SET DEFAULT ROLE ALL TO '用户名'@'host'; 激活角色命令【方式二】 # 对所有角色永久激活 SET GLOBAL activate_all_roles_on_login = ON; 查看当前用户的角色 SELECT CURRENT_ROLE(); 撤销用户的角色： 赊销用户角色命令 REVOKE 角色名 FROM 用户; 设置强制角色： 强制角色相当于为所有用户设置默认角色 服务启动前设置 my.cnf【方式一】 [mysqld] mandatory_roles='role1,role2@localhost,r3@%.atguigu.com' 运行时设置【方式二】 SET PERSIST mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后仍然 有效 SET GLOBAL mandatory_roles = 'role1,role2@localhost,r3@%.example.com'; #系统重启后失效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:3:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#角色"},{"categories":null,"content":"\r配置文件与系统变量","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:4:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#配置文件与系统变量"},{"categories":null,"content":"\r配置文件 配置文件的启动选项被分为很多个组，每个组都是由 括起来的组名开头 MySQL 8 默认的 my.cnf 配置文件 类似的组名可以有很多 [server] 组名下边的启动选项将作用于所有的服务器程序 [client] 组名下边的启动选项将作用于所有的客户端程序 在指定对应的指令时会启用对应的标签组 例如：在服务器中设置的启动选项就需要写在 [mysqld] 或 [server] 标签组下 可以指定标签组执行的 MySQL 版本 例如：[mysqld-5.7] 的标签组中的内容就只能在 MySQL 5.7 的服务器版本中被执行 当配置出现矛盾时，以下方的配置为准 [server] default-storage-engine = InnoDB [mysqld] # 当配置出现矛盾时，以下行为准 default-storage-engine = MyISAM 当启动命令与 my.cnf 中内容出现矛盾时，以启动命令后方的配置为准 [server] default-storage-engine = InnoDB # 启动命令比配置文件的优先级高 mysql.server start --default-storage-engine=MyISAM ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:4:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#配置文件"},{"categories":null,"content":"\r系统变量 在 my.cnf 中的配置和在启动命令中写的都是系统变量 设置系统变量 set [global|session] 系统变量名 = 系统变量值; 查看系统变量 show [global|session] variables [like 匹配的模式]; 这里的内容仅需了解 在 my.cnf 中的配置 和 在启动命令后方写的 都是系统变量 即可 如果需要使用可以查看：wzblog ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:4:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#系统变量"},{"categories":null,"content":"\r逻辑架构 MySQL 是典型的 Client/Server 架构，客户端进程向服务端进程发送一段文本 ( SQL 语句 ) ，服务端进程处理后再向客户端进程返回一段文本 ( 处理结果 ) 逻辑架构展开说明 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#逻辑架构"},{"categories":null,"content":"\r连接层 客户端在访问 MySQL 服务器前，会先经过三次握手建立 TCP 连接，后 MySQL 服务器对 TCP 传输过来的账号密码进行验证，身份验证、权限获取 验证用户名密码，错误提示 Access denied for user 结束客户端程序 查询出账号拥有的权限并与连接关联，之后的权限判断都依照此时读到的权限 在连接池中创建一个 TCP 的长连接，后会在线程池中创建线程处理具体操作 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#连接层"},{"categories":null,"content":"\r服务层 服务器在该层会解析查询并创建对应的解析树，完成相应的优化 SQL Interface：SQL 接口 接受用户的 SQL 命令，并返回用户需要查询的结果 例如：SELECT … FROM 就是调用的 SQL Interface Parser：解析器 对 SQL 语句进行语法分析、语义分析，并生成 语法树 如果 SQL 语句的关键字拼写错误或语义不合理，在此时就会报错 Optimizer：查询优化器 确定 SQL 语句的执行路径，生成 执行计划 指定使用的索引，选取 选取-投影-连接 策略进行查询 选取 根据 where 语句进行选取，而不是将表全部查询出来再过滤 投影 根据 select 后的字段进行属性投影，而不是将全部字段都查询出来再过滤 连接 将这两个查询条件连接起来生成最终的查询结果 Caches \u0026 Buffers：查询缓存组件 内部维持着一些 Cache 和 Buffer，比如 Query Cache 用来缓存一条 SELECT 语句的执行结果 这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key 缓存，权限缓存等 查询缓存可以在不同客户端之间共享，由于命中率较低在 MySQL 8 中被删除 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#服务层"},{"categories":null,"content":"\r引擎层 是插件式的存储引擎，负责 MySQL 中数据存储和提取，对物理服务器级别的底层数据执行操作 查看 MySQL 默认支持的引擎命令 show engines; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#引擎层"},{"categories":null,"content":"\r存储层 实打实的在文件系统上存储文件 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储层"},{"categories":null,"content":"\rMySQL 的三层架构 连接层：客户端和服务器端建立连接，客户端发送 SQL 至服务器端 SQL 层（服务层）：对 SQL 语句进行查询处理；与数据库文件的存储方式无关 存储引擎层：与数据库文件打交道，负责数据的存储和读取 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:5:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-的三层架构"},{"categories":null,"content":"\rSQL 的执行流程\r","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#sql-的执行流程"},{"categories":null,"content":"\r1.查询缓存 查询 SQL 与查询结果可能是以键值对的形式存储在内存中的。如果 SQL 语句命中了 key 那么直接返回 value，如果没有命中则继续执行并将执行结果存储在查询缓存中 由于两个查询请求在任何字符上的不同（例如：空格、注释、 大小写），都会导致缓存不会命中。因此 MySQL 的 查询缓存命中率不高 在使用到一些特殊的函数如 now() 时，查询缓存就不应该开启。在执行 INSERT、UPDATE、 DELETE、TRUNCATE TABLE、 ALTER TABLE、DROPTABLE 或 DROP DATABASE 语句时缓存失效。对于更新压力大的数据库来说，查询缓存的命中率较低 一般推荐在静态表中开启查询缓存，即常常查询但不常更新的表。在 MySQL 5.7 中开启查询缓存配置 my.cnf 文件： # query_cache_type 有 3 个值 0 代表关闭查询缓存 OFF, 1 代表开启 ON , 2 (DEMAND) 按需使用 query_cache_type = 2 # 在使用 SQL_CACHE 关键字的查询中，才会开启查询缓存 select SQL_CACHE * from test where ID = 5; # 查看是否开启了查询缓存 show global variables like \"%query_cache_type%\"; # 查看查询缓存的命中率 show status like '%Qcache%'; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#1查询缓存"},{"categories":null,"content":"\r2.解析器 对 SQL 进行语法分析、语义分析 首先对 SQL 进行 **词法分析 **识别关键词和一些字符串所对应的是什么 然后对 SQL 进行 语法分析 根据语法规则判断语句是否满足 MySQL 语法 如果词法分析和语法分析均通过，会生成一个语法树 SELECT username, ismale FROM userinfo WHERE age \u003e 20 AND level \u003e 5 AND 1 = 1; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#2解析器"},{"categories":null,"content":"\r3.优化器 确定 SQL 的执行计划并交出执行计划，比如是根据全表检索还是根据索引检索等 在查询优化中主要分为 逻辑优化阶段 和 物理优化阶段 。在索引章节有补充 例如在查询语句中 where 后方有两个条件，那么先后执行哪个条件的顺序是优化器所做的事 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#3优化器"},{"categories":null,"content":"\r4.执行器 先判断是否具有执行的权限，再调用存储引擎 API 进行执行 例如在执行 select SQL_CACHE * from test where ID = 1; 语句： 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 1，如果不是则跳过，如果是则将这行存在结果集中 调用引擎接口取 “下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 MySQL 执行顺序： ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#4执行器"},{"categories":null,"content":"\rMySQL 8 执行流程 ==开启 Profiling==：让 MySQL 收集 SQL 在执行过程中所使用的资源情况 # 查看是否开启了 Profiling, 0 为未开启 select @@profiling; # 或 show variables like 'profiling'; # 开启 Profiling set profiling = 1; 查看当前会话最近几次的查询 Profiles show profiles; 查看指定的查询语句的执行计划 # 查看最近一次查询的查询计划 show profile; # 查看指定 Query_ID 的查询计划 show profile for query 6; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-8-执行流程-a-idprofile-a"},{"categories":null,"content":"\rMySQL 5.7 执行流程 开启查询缓存 query_cache 在 /etc/my.cnf 中新增一行 query_cache_type = 1 重启 MySQL 服务 systemctl restart mysqld 开启执行计划，查看执行计划：同 MySQL 8 查看 Profiles 查看 Profile 可以查看指定 type 的执行计划 例如：查看 cpu 和 io 有关的执行情况 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:6","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-57-执行流程"},{"categories":null,"content":"\rOracle 中的执行流程\r语法检查：检查 SQL 拼写，错误报语法错误 语义检查：检查访问的对象是否存在 权限检查：检查用户是否具有相应的权限 共享池检查：缓存 SQL 语句和该语句的执行计划 对 SQL 语句进行 hash 运算，如果在 库缓存(Library Cache) 中找到则直接进入 执行器【软解析】 如果没有 hash 到，则创建解析树进行解析，进入优化器生成执行计划执行【硬解析】 Oracle 数据库架构图简图 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:7","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#oracle-中的执行流程"},{"categories":null,"content":"\r数据库缓冲池 InnoDB 将 数据页 作为单位存储数据，每个数据页占 16KB DBMS 会占用内存作为缓冲池，需要把在磁盘上的页缓存到内存中的 Buffer Pool 之后才可以访问，从而减少与磁盘直接进行 I/O 的时间 缓冲原则 根据 “ 位置 * 频次 ” 这个原则，优先对使用频次高的热数据进行加载 在缓存空间允许的前提下，会提将把查询结果或将查询结果周围的数据放到缓冲池中【预读特性】 缓冲池在 MySQL 中的结构和作用： 在数据更新后不会立即更新磁盘数据，会按照一定的时间策略对本地磁盘进行更新 当 Buffer Pool 未对磁盘更新数据时宕机怎么办？ 答：Redo Log \u0026 Undo Log（在事务章节会补充） 查看缓冲池的大小： # 查看 InnoDB 缓冲池大小 show variables like 'innodb_buffer_pool_size'; # 查看 MyISAM 缓冲池大小 show variables like 'key_buffer_size'; 设置缓冲池大小： 通过变量设置缓冲池大小为 256MB : 256 * 1024 * 1024 = 268435456 set global innodb_buffer_pool_size = 268435456; 通过配置 my.cnf 设置缓冲池大小 [server] innodb_buffer_pool_size = 268435456 Buffer Pool 实例个数 将缓冲池 拆分 成若干个小 Buffer Pool ，若 Buffer Pool 大小设置为 1GB 实例个数设置为 2，则每个实例占 512 MB 当多个线程同时连接数据库时，让其分别访问各自的 Buffer Pool 避免为 Buffer Pool 加锁影响性能 通过配置 my.cnf 设置 Buffer Pool 实例个数 [server] innodb_buffer_pool_instances = 2 Buffer Pool 实例个数并不是越多越好，管理各个 Buffer Pool 也是需要性能开销的，在缓冲池内存大小 \u003e 1GB 时才有效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:8","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据库缓冲池"},{"categories":null,"content":"\r数据库缓冲池 InnoDB 将 数据页 作为单位存储数据，每个数据页占 16KB DBMS 会占用内存作为缓冲池，需要把在磁盘上的页缓存到内存中的 Buffer Pool 之后才可以访问，从而减少与磁盘直接进行 I/O 的时间 缓冲原则 根据 “ 位置 * 频次 ” 这个原则，优先对使用频次高的热数据进行加载 在缓存空间允许的前提下，会提将把查询结果或将查询结果周围的数据放到缓冲池中【预读特性】 缓冲池在 MySQL 中的结构和作用： 在数据更新后不会立即更新磁盘数据，会按照一定的时间策略对本地磁盘进行更新 当 Buffer Pool 未对磁盘更新数据时宕机怎么办？ 答：Redo Log \u0026 Undo Log（在事务章节会补充） 查看缓冲池的大小： # 查看 InnoDB 缓冲池大小 show variables like 'innodb_buffer_pool_size'; # 查看 MyISAM 缓冲池大小 show variables like 'key_buffer_size'; 设置缓冲池大小： 通过变量设置缓冲池大小为 256MB : 256 * 1024 * 1024 = 268435456 set global innodb_buffer_pool_size = 268435456; 通过配置 my.cnf 设置缓冲池大小 [server] innodb_buffer_pool_size = 268435456 Buffer Pool 实例个数 将缓冲池 拆分 成若干个小 Buffer Pool ，若 Buffer Pool 大小设置为 1GB 实例个数设置为 2，则每个实例占 512 MB 当多个线程同时连接数据库时，让其分别访问各自的 Buffer Pool 避免为 Buffer Pool 加锁影响性能 通过配置 my.cnf 设置 Buffer Pool 实例个数 [server] innodb_buffer_pool_instances = 2 Buffer Pool 实例个数并不是越多越好，管理各个 Buffer Pool 也是需要性能开销的，在缓冲池内存大小 \u003e 1GB 时才有效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:8","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#缓冲原则"},{"categories":null,"content":"\r数据库缓冲池 InnoDB 将 数据页 作为单位存储数据，每个数据页占 16KB DBMS 会占用内存作为缓冲池，需要把在磁盘上的页缓存到内存中的 Buffer Pool 之后才可以访问，从而减少与磁盘直接进行 I/O 的时间 缓冲原则 根据 “ 位置 * 频次 ” 这个原则，优先对使用频次高的热数据进行加载 在缓存空间允许的前提下，会提将把查询结果或将查询结果周围的数据放到缓冲池中【预读特性】 缓冲池在 MySQL 中的结构和作用： 在数据更新后不会立即更新磁盘数据，会按照一定的时间策略对本地磁盘进行更新 当 Buffer Pool 未对磁盘更新数据时宕机怎么办？ 答：Redo Log \u0026 Undo Log（在事务章节会补充） 查看缓冲池的大小： # 查看 InnoDB 缓冲池大小 show variables like 'innodb_buffer_pool_size'; # 查看 MyISAM 缓冲池大小 show variables like 'key_buffer_size'; 设置缓冲池大小： 通过变量设置缓冲池大小为 256MB : 256 * 1024 * 1024 = 268435456 set global innodb_buffer_pool_size = 268435456; 通过配置 my.cnf 设置缓冲池大小 [server] innodb_buffer_pool_size = 268435456 Buffer Pool 实例个数 将缓冲池 拆分 成若干个小 Buffer Pool ，若 Buffer Pool 大小设置为 1GB 实例个数设置为 2，则每个实例占 512 MB 当多个线程同时连接数据库时，让其分别访问各自的 Buffer Pool 避免为 Buffer Pool 加锁影响性能 通过配置 my.cnf 设置 Buffer Pool 实例个数 [server] innodb_buffer_pool_instances = 2 Buffer Pool 实例个数并不是越多越好，管理各个 Buffer Pool 也是需要性能开销的，在缓冲池内存大小 \u003e 1GB 时才有效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:6:8","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#buffer-pool-实例个数"},{"categories":null,"content":"\r存储引擎 存储引擎实际上就是指表的类型，之前叫表处理器 用于接受上层传下来的指令，对表中的数据进行读取和写入的操作 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储引擎"},{"categories":null,"content":"\r存储引擎的查看与修改查看支持的存储引擎： show engines; 查看系统默认的存储引擎： show variables like '%storage_engine%'; #或 SELECT @@default_storage_engine; 修改默认的存储引擎： 通过设置变量设置默认存储引擎 SET DEFAULT_STORAGE_ENGINE = MyISAM; 通过修改 my.cnf 设置默认存储引擎 default-storage-engine = MyISAM # 重启服务 systemctl restart mysqld.service 在创建表时指明存储引擎： CREATE TABLE 表名( 建表语句; ) ENGINE = 存储引擎名称; 修改表的存储引擎： ALTER TABLE 表名 ENGINE = 存储引擎名称; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储引擎的查看与修改"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#存储引擎介绍"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#innodb-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#myisam-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#archive-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#blackhole-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#csv-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#memory-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#federated-引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#merge引擎"},{"categories":null,"content":"\r存储引擎介绍\rInnoDB 引擎 具备 外键 支持功能的 事务 存储引擎，是为处理巨大数据量的最大性能设计 从 3.23.34a 版本开始包含 InnoDB 引擎，5.5 即之后的版本默认采用 InnoDB 优点： 支持外键 支持事务：事务的提交与回滚。若服务器崩溃，可以自动的恢复已提交的事务，撤销未提交的事务不需要额外的操作 频繁的增加或查询操作推荐 MyISAM，频繁的更新或删除操作推荐 InnoDB 相比 MyISAM 只支持表级锁，InnoDB 还支持行级锁 缺点： 相比 MyISAM，InnoDB 写的处理效率差一点 MyISAM 只缓存索引，InnoDB 还会缓存数据，所以对内存要求比较高 MyISAM 引擎 提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等 是 MySQL 5.5 之前的默认存储引擎 优点： 针对于增加和查询操作，MyISAM 的速度更快 有常量存储数据统计信息，count(*) 的效率高 缺点： 不支持事务、外键、行级锁 适合数据量小的场景使用，崩溃后无法安全恢复 Archive 引擎 archive (归档) 主要设计用于数据存档，仅支持插入和查询两种功能 在 MySQL 5.5 版本后支持索引 支持 zlib 压缩库，相同数据量文件体积比 MyISAM 小 75% 数据文件后缀名为 .ARZ ，支持行级锁 Blackhole 引擎 丢弃写操作，读操作会返回空内容 会记录日志，不推荐使用 CSV 引擎 存储数据时，以逗号分隔各个数据项。不支持 null 数据 数据文件后缀名为 .CSM .CSV 可以使用 Excel 打开编辑 Memory 引擎 置于内存的表，表数据存在内存中，表结构存在 .frm 文件中 要求数据是长度不变的格式，BLOB、TEXT类型的数据不可用 查询速度比 MyISAM 快一个数量级，需要设置限制表的大小 同时支持 hash 索引【默认】和 B+ 树索引 通常在数据量小访问频繁时使用，存储临时数据即时使用时使用 Federated 引擎 是一个访问其它 MySQL 数据库的代理，提供跨服务器的灵活性 问题较多，默认被禁用 Merge引擎 管理多个 MyISAM 表构成的表集合 NDB引擎 MySQL 集群专用存储引擎 也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#ndb引擎"},{"categories":null,"content":"\r常见存储引擎对比 特点 MyISAM InnoDB MEMORY MERGE NDB 存储限制 有 64TB 有 没有 有 事务安全 支持 锁机制 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 表锁，行锁：操作时只锁某一行，不对其它行有影响，适合高并发的操作 表锁 表锁 行锁 B树索引 支持 支持 支持 支持 支持 哈希索引 支持 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 支持 索引缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 支持 支持 支持 数据可压缩 支持 空间使用 低 高 N/A 低 低 内存使用 低 高 中等 低 高 批量 插入 的速度 高 低 高 高 高 支持外键 支持 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#常见存储引擎对比"},{"categories":null,"content":"\rMyISAM 与 InnoDB对比 对比项 MyISAM InnoDB 外键 不支持 支持 事务 不支持 支持 行表锁 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 行锁，操作时只锁某一行，不对其它行有影响，适合高并发的操作 缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 自带系统表使用 Y N 关注点 性能：节省资源、消耗少、简单业务 事务：并发写、事务、更大资源 默认安装 Y Y 默认使用 N Y ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#myisam-与-innodb对比"},{"categories":null,"content":"\r课外补充1、InnoDB 表的优势 InnoDB 存储引擎在实际应用中拥有诸多优势，比如操作便利、提高了数据库的性能、维护成本低等。如果由于硬件或软件的原因导致服务器崩溃，那么在重启服务器之后不需要进行额外的操作。InnoDB 崩溃恢复功能自动将之前提交的内容定型，然后撤销没有提交的进程，重启之后继续从崩溃点开始执行。 InnoDB 存储引擎在主内存中维护缓冲池，高频率使用的数据将在内存中直接被处理。这种缓存方式应用于多种信息，加速了处理进程。 在专用服务器上，物理内存中高达80%的部分被应用于缓冲池。如果需要将数据插入不同的表中，可以设置外键加强数据的完整性。更新或者删除数据，关联数据将会被自动更新或删除。如果试图将数据插入从表，但在主表中没有对应的数据，插入的数据将被自动移除。如果磁盘或内存中的数据出现崩溃，在使用脏数据之前，校验和机制会发出警告。当每个表的主键都设置合理时，与这些列有关的操作会被自动优化。插入、更新和删除操作通过做改变缓冲自动机制进行优化。 InnoDB 不仅支持当前读写，也会缓冲改变的数据到数据流磁盘 。 InnoDB 的性能优势不只存在于长时运行查询的大型表。在同一列多次被查询时，自适应哈希索引会提高查询的速度。使用 InnoDB 可以压缩表和相关的索引，可以 在不影响性能和可用性的情况下创建或删除索引 。对于大型文本和 BLOB 数据，使用动态行形式，这种存储布局更高效。通过查询 INFORMATION_SCHEMA 库中的表可以监控存储引擎的内部工作。在同一个语句中，InnoDB 表可以与其他存储引擎表混用。即使有些操作系统限制文件大小为 2GB，InnoDB 仍然可以处理。 当处理大数据量时,InnoDB 兼顾 CPU,以达到最大性能 。 2、InnoDB 和 ACID 模型 ACID 模型是一系列数据库设计规则，这些规则着重强调可靠性，而可靠性对于商业数据和任务关键型应用非常重要。MySQL 包含类似InnoDB 存储引擎的组件，与 ACID 模型紧密相连，这样出现意外时，数据不会崩溃，结果不会失真。如果依赖 ACID 模型，可以不使用一致性检查和崩溃恢复机制。如果拥有额外的软件保护，极可靠的硬件或者应用可以容忍一小部分的数据丢失和不一致，可以将 MySQL 设置调整为只依赖部分 ACID 特性，以达到更高的性能。下面讲解 InnoDB 存储引擎与 ACID 模型相同作用的四个方面。 原子方面 ACID 的原子方面主要涉及 InnoDB 事务，与 MySQL 相关的特性主要包括： 自动提交设置。 COMMIT 语句。 ROLLBACK 语句。 操作 INFORMATION_SCHEMA 库中的表数据。 一致性方面 ACID 模型的一致性主要涉及保护数据不崩溃的内部 InnoDB 处理过程，与 MySQL 相关的特性主要包括： InnoDB 双写缓存。 InnoDB 崩溃恢复。 隔离方面 隔离是应用于事务的级别，与 MySQL 相关的特性主要包括： 自动提交设置。 SET ISOLATION LEVEL 语句。 InnoDB 锁的低级别信息。 耐久性方面 ACID 模型的耐久性主要涉及与硬件配置相互影响的 MySQL 软件特性。由于硬件复杂多样化，耐久性方面没有具体的规则可循。与 MySQL 相关的特性有： InnoDB 双写缓存，通过 innodb_doublewrite 配置项配置。 配置项 innodb_flush_log_at_trx_commit。 配置项 sync_binlog。 配置项 innodb_file_per_table。 存储设备的写入缓存。 存储设备的备用电池缓存。 运行 MySQL 的操作系统。 持续的电力供应。 备份策略。 对分布式或托管的应用，最主要的在于硬件设备的地点以及网络情况。 3、InnoDB 架构 缓冲池 缓冲池是主内存中的一部分空间，用来缓存已使用的表和索引数据。缓冲池使得经常被使用的数据能够直接在内存中获得，从而提高速度。 更改缓存 更改缓存是一个特殊的数据结构，当受影响的索引页不在缓存中时，更改缓存会缓存辅助索引页的更改。索引页被其他读取操作时会加载到缓存池，缓存的更改内容就会被合并。不同于集群索引，辅助索引并非独一无二的。当系统大部分闲置时，清除操作会定期运行，将更新的索引页刷入磁盘。更新缓存合并期间，可能会大大降低查询的性能。在内存中，更新缓存占用一部分 InnoDB 缓冲池。在磁盘中，更新缓存是系统表空间的一部分。更新缓存的数据类型由 innodb_change_buffering 配置项管理。 自适应哈希索引 自适应哈希索引将负载和足够的内存结合起来，使得 InnoDB 像内存数据库一样运行， 不需要降低事务上的性能或可靠性。这个特性通过 innodb_adaptive_hash_index 选项配置，或者通过 -skip-innodb_adaptive_hash_index 命令行在服务启动时关闭。 重做日志缓存 重做日志缓存存放要放入重做日志的数据。重做日志缓存大小通过 innodb_log_buffer_size 配置项配置。重做日志缓存会定期地将日志文件刷入磁盘。大型的重做日志缓存使得大型事务能够正常运行而不需要写入磁盘。 系统表空间 系统表空间包括 InnoDB 数据字典、双写缓存、更新缓存和撤销日志，同时也包括表和索引 数据。多表共享，系统表空间被视为共享表空间。 双写缓存 双写缓存位于系统表空间中，用于写入从缓存池刷新的数据页。只有在刷新并写入双写缓存后，InnoDB 才会将数据页写入合适的位置。 撤销日志 撤销日志是一系列与事务相关的撤销记录的集合，包含如何撤销事务最近的更改。如果其他事务要查询原始数据，可以从撤销日志记录中追溯未更改的数据。撤销日志存在于撤销日志片段中，这些片段包含于回滚片段中。 每个表一个文件的表空间 每个表一个文件的表空间是指每个单独的表空间创建在自身的数据文件中， 而不是系统表空间中。这个功能通过 innodb_file_per_table 配置项开启。每个表空间由一个单独的 .ibd 数据文件代表，该文件默认被创建在数据库目录中。 通用表空间 使用 CREATE TABLESPACE 语法创建共享的 InnoDB 表空间。通用表空间可以创建在 MySQL 数据目录之外能够管理多个表并支持所有行格式的表。 撤销表空间 撤销表空间由一个或多个包含撤销日志的文件组成。撤销表空间的数量由 innodb_undo_tablespaces 配置项配置。 临时表空间 用户创建的临时表空间和基于磁盘的内部临时表都创建于临时表空间。innodb_temp_data_file_path 配置项定义了相关的路径、名称、大小和属性。如果该值为空，默认会在 innodb_data_home_dir 变量指定的目录下创建一个自动扩展的数据文件。 重做日志 重做日志是基于磁盘的数据结构，在崩溃恢复期间使用，用来纠正数据。正常操作期间， 重做日志会将请求数据进行编码，这些请求会改变 InnoDB 表数据。遇到意外崩溃后，未完成的更改会自动在初始化期间重新进行。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:7:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#课外补充"},{"categories":null,"content":"\r索引的数据结构 索引是存储引擎用于快速找到数据记录的一种数据结构 索引是在存储引擎中实现的 索引的优点： 用于减少磁盘的 I/O 次数，避免全表扫描 创建唯一索引，保证每一行数据的唯一性 对于有依赖关系的表之间可以提高查询速度 减少查询中分组和排序时间，降低 CPU 消耗 索引的缺点： 创建和维护索引都要消耗时间 索引需要占用磁盘空间（每个数据页默认占用 16KB 空间） 索引会降低更新表的速度，因为当数据更改时索引也要动态的维护 使用索引之前： 查找一条数据，需要先确认数据存在的数据页，需要从第一个数据页沿着 双向链表 一直往下找 找到数据对应的数据页后 如果已主键作为搜索条件：使用 二分法 快速查找 如果已其他列作为搜索条件：从最小记录开始依次遍历 单链表 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引的数据结构"},{"categories":null,"content":"\r索引设计的迭代过程一个简单的索引设计案例： 创建一个 行格式 为 Compact 的以 c1 为主键的表 index_demo CREATE TABLE index_demo( c1 INT, c2 INT, c3 CHAR(1), PRIMARY KEY(c1) ) ROW_FORMAT = Compact; Compact 行格式存储的一行记录 record_type ：记录头信息的一项属性，表示记录的类型， 0 表示普通记录、 2 表示最小记 录、 3 表示最大记录、 1 下面讲 next_record ：记录头信息的一项属性，表示下一条地址相对于本条记录的地址偏移量，我们用箭头来表明下一条记录是谁 各个列的值 ：这里只记录在 index_demo 表中的三个列，分别是 c1 、 c2 和 c3 其他信息 ：除了上述 3 种信息以外的所有信息，包括其他隐藏列的值以及记录的额外信息 此时向表中插入三条数据，数据被插入到数据页 10 中 insert into index_demo values(1, 4, 'u'), (3, 9, 'd'), (5, 3, 'y'); 假设页 10 最多只能存放 3 条数据，那么新插入的数据就被存放到了一个新的数据页中 由于插入的新数据使得 c1 列不符合主键值得要求，需要进行记录移动【页分裂】 由于这些 16KB 数据页是不连续的，当数据量大时无法快速定位数据所在的数据页 此时我们使用每页中主键最小的值作为 key 建立一个目录，当查询一个数据时可以快速定位数据页，之后可以再使用二分法查找数据 索引设计第一次迭代： 当数据页不断增加对应的目录项也在不断增加，此时将目录项放到目录页中 此时如果向查找一个数据，就可以先对 页目录 使用二分法快速查找到对应的目录页，即可在目录页对应的数据页中查找 此时仅需要向硬盘读取目录页和数据页两次 I/O 即可找到想要的数据 索引设计第二次迭代： 使用多个目录页连接数据页 索引设计第三次迭代： 当目录页大于 1 时生成更高一级的目录页，这个结构就是 B+ 树 B+ 树： 如果每个数据页可以存放 100 条数据，每个目录页可以存放 1000 条数据 当 B+ 树有一层，可以存放 100 条数据 当 B+ 树有两层，可以存放 1000 * 100 条数据 当 B+ 树有三层，可以存放 1000 * 1000 * 100 一亿条数据 当 B+ 树有 N 层，可以存放 1000n-1 * 100 条数据 一般情况 B+ 树的层数不会超过 4 层 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引设计的迭代过程"},{"categories":null,"content":"\r索引的常见概念 聚簇索引 【聚簇】表示数据行和相邻的键值聚簇是存储在一起的。索引即数据，数据即索引 InnoDB 支持，MyISAM 不支持 聚簇索引 如果没有显式的定义主键，InnoDB 会隐式的定义一个主键作为聚簇索引 数据页内使用单向链表，数据页间使用双向链表 目录页分为不同层，每一层内的目录页间使用双向链表 优点： 访问速度快，聚簇索引将数据和索引存储在一个 B+ 树，在查询时不需要回表 对于主键的 排序查找 和 范围查找 的速度很快 节省大量 I/O 操作 缺点： 插入的速度严重依赖于插入顺序，推荐使用自增长主键 更新主键的代价很高 二级索引需要两次索引查找，需要先找到主键值再根据主键值查找数据 二级索引 (辅助索引，非聚簇索引) 当我们为非主键字段添加索引时，这个索引就是二级索引，会根据这个非主键的字段再构建一个 B+ 树 【回表】在以非主键字段查询到了数据之后，还需要根据对应的主键字段在主键 B+ 树聚簇索引再次查询 联合索引 联合索引也属于非聚簇索引，一个联合索引最多包括 16 个字段 联合索引只会创建一颗 B+ 树，在查询时会根据第一个字段查询，找到后再根据第二个字段查询… ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引的常见概念"},{"categories":null,"content":"\rInnoDB 的 B+ 树索引 根页面位置万年不动 数据库在生成 B+ 树时实际上是先生成根目录页 当目录页的层数不足会先将数据页复制走，然后将原数据页变成目录页 内节点中目录项记录的唯一性 在二级索引的目录页中也会保存主键的值，为了保证指向的唯一性 一个页面最少存储2条记录 每个节点至少有两个分支才复合树的数据结构 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#innodb-的-b-树索引"},{"categories":null,"content":"\rMyISAM 的 B+ 树索引 MyISAM 引擎中索引和数据是分开存放的 .MYD .MYI MyISAM 不支持聚簇索引只支持二级索引，叶子节点中存储 主键值 + 数据记录地址 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#myisam-的-b-树索引"},{"categories":null,"content":"\rInnoDB 和 MyISAM 索引的区别 在 InnoDB 存储引擎中，仅需根据主键值对 聚簇索引 进行一次查找就能找到对应的记录，而在 MyISAM 中却需要进行一次 回表 操作，意味着 MyISAM 中建立的索引相当于全部都是 二级索引 。 InnoDB 的数据文件本身就是索引文件，而 MyISAM 索引文件和数据文件是 分离的 ，索引文件仅保存数据记录的地址。 InnoDB 的非聚簇索引 data 域存储相应记录 主键的值 ，而 MyISAM 索引记录的是 地址 。换句话说，InnoDB 的所有非聚簇索引都引用主键作为 data 域。 MyISAM 的回表操作是十分 快速 的，因为是拿着地址偏移量直接到文件中取数据的，反观 InnoDB 是通过获取主键之后再去聚簇索引里找记录，虽然说也不慢，但还是比不上直接用地址去访问。 InnoDB 要求表必须有主键（ MyISAM 可以没有 ）。如果没有显式指定，则 MySQL 系统会自动选择一个可以非空且唯一标识数据记录的列作为主键。如果不存在这种列，则 MySQL 自动为 InnoDB 表生成一个隐含字段作为主键，这个字段长度为 6 字节，类型为 长整型 。 不要为主键设置过长的字段 推荐使用自增长主键而不是 UUID ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#innodb-和-myisam-索引的区别"},{"categories":null,"content":"\r数据结构选择 索引的数据结构选择的原则是 对硬盘的 I/O 次数 不可能每次都加载全部数据到内存中，只能 逐一加载 全表遍历： 磁盘 I/O 次数多，速度极慢 Hash 结构： Hash 函数也称散列函数，相同的输入永远可以得到相同的输出 Hash 算法的复杂度为 O(1) ，速度较 B+ 快很多 为什么没有采用 Hash 而是 B+ ? Hash 仅能满足 ==、\u003c\u003e、in 查询，如果进行范围查询时间复杂度为 O(n)，而 B+ 树的时间复杂度为 O(log2N) Hash 的存储是没有顺序的，使用 order by 时还需要重新排序 对于联合索引，Hash 会将索引键合并后再计算，无法对单独的键计算 如果索引列的重复值比较多，效率会降低 开启 自适应 Hash 索引 方便根据 SQL 的查询条件加速定位到叶子节点 # 查看是否开启了自适应 Hash 索引，默认为 on show variables like '%adaptive_hash_index'; 二叉搜索树： 左节点 \u003c 本节点，又节点 \u003e= 本节点 使用二叉搜索树应尽可能的降低树的高度，让树变得矮胖，由此降低对磁盘的 I/O 次数 AVL 树： 平衡二叉搜索树，它是一棵空树或左右两个子树的高度差不能超过 1，并且左右两个子树都是一颗平衡二叉树 采用 M 叉树 (M \u003e 2)，降低树的层数减少 I/O 次数 B-Tree B 树： 多路平衡查找树 每个节点存储两个值，通过比对值的 \u003c \u003c= \u003e= \u003e 来找到对应的指针 B+Tree B+ 树： 改进的 B-Tree 更适合文件检索系统 B+Tree 与 B-Tree 的区别： 关键字数 = 子节点数，B 树中关键字数 = 子节点数 - 1 非叶子节点中也会存在叶子节点中的值，B 树不会 只有叶子节点存储数据，B 树所有节点都存储数据 由叶子节点可以直接构成一个有序列表，B 树的叶子节点数据不全 R 树： 解决了高纬度空间的搜索问题 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:6","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据结构选择"},{"categories":null,"content":"\r算法的时间复杂度\r","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:8:7","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#算法的时间复杂度"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#innodb-数据存储结构"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据页内部结构"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#一文件头部和文件尾部"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#二空闲空间-用户记录-最大最小记录"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#三页目录-页面头部"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#innodb-行格式"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#compact-行格式"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#dynamic-行格式-a-id行溢出-a"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#compressed-行格式"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#redundant-行格式"},{"categories":null,"content":"\rInnoDB 数据存储结构\r数据页内部结构 InnoDB 将数据以 页 为基本单位作为磁盘与内存的交互单位（默认16KB） 每页之间用 双向链表 逻辑连接，数据页中的记录使用 单链表 连接 每个数据页中都会生成一个 页目录 ，页目录以 数组 的数据结构存储，方便使用二分法查找对应记录 页的上层为 区 ：每个区分配 64 个连续的页，64 * 16KB = 1MB 区的上层为 段 ：段是数据库的分配单位，按照数据库对象来分（表段、索引段） 段的上层为 表空间 ：分为 系统表空间 和 独立表空间 页按照类型划分分为 数据页 、系统页、undo页、事务数据页 等 每个数据页占 16KB 大小，被划分为七个部分 File Header (文件头部)、Page Header (页面头部)、Infimum + Supremum (最小最大记录)、User Records (用户记录)、Free Space (空闲空间)、Page Directory (页目录)、File Trailer (文件尾部) 一、文件头部和文件尾部文件头：38字节，描述页的信息 FIL_PAGE_OFFSET（4字节）：记录一个页号，InnoDB 通过页号唯一定位一个页 FIL_PAGE_TYPE（2字节）：表示当前页的类型 FIL_PAGE_PREV（4字节）和FIL_PAGE_NEXT（4字节）：记录上一页和下一页的页号，形成双向链表使页之间逻辑连续 FIL_PAGE_SPACE_OR_CHKSUM（4字节）：当前页面的 校验和（checksum）。 【校验和】通过某种算法生成的较短的值，避免对比 长字符串 或 两个页 时的时间消耗 在 刷盘前在文件头 记录一个校验和，刷盘 完成后在文件尾 记录一个校验和，根据两个校验和是否相同来验证数据页在 磁盘和内存在同步时 是否出现异常。这里，校验方式就是采用 Hash 算法进行校验。 FIL_PAGE_LSN（8字节）：页面被最后修改时对应的日志序列位置 文件尾：8字节，校验页是否完整 前 4 个字节代表 页的校验和 ：这个部分是和 File Header 中的校验和相对应的。 后 4 个字节代表 页面被最后修改时对应的日志序列位置(LSN) ：这个部分也是为了校验页的完整性的，验证同步过程是否出现了问题。 二、空闲空间 用户记录 最大最小记录空闲空间：不确定大小，页中还没被使用的空间 没有用户记录的空间就是空闲空间 用户记录：不确定大小，存储行记录内容 按照指定的行格式一条一条的存储在用户记录中，构成 单链表 最大最小记录：26字节，是两个虚拟行记录 最小记录和最大记录分别占 13 字节 这两个是作为数据行在数据页内存储的，最小记录的 heap_no 为 0 , 最大记录的 heap_no 为 1，2 开始就是用户记录 三、页目录 页面头部页目录：不确定大小，存储用户记录的相对位置（使用数组存储每组数据的偏移量，方便使用二分法快速查找） 将当前目录页指向的记录分为多个组，每组中包括最大最小记录但不包括标记为已删除的记录 第一组只有一条记录为最小记录，其余会按照 4-8 条记录尽量平分 页目录存储每组最后一条记录的地址偏移量（每个槽中记录的是每组最大的一个记录） 页头：56字节，页的状态信息 PAGE_DIRECTION：插入的方向，假如新插入的主键值比上一条记录的主键值大，那么这条记录的插入方向是向右，反之则是向左，便于下次插入。 PAGE_N_DIRECTION：假设连续几次插入的方向都是一致的，InnoDB 会把沿着同一个方向插入记录的条数用 PAGE_N_DIRECTION 记下来。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。 InnoDB 行格式 查看默认行格式 SELECT @@innodb_default_row_format; 创建指定行格式的表 CREATE TABLE record_test_table ( col1 VARCHAR(8), col2 VARCHAR(8) NOT NULL, col3 CHAR(8), col4 VARCHAR(8) ) CHARSET = ascii ROW_FORMAT = COMPACT; Compact 行格式\r变长字段长度列表 存储可变长度字段的长度：varchar、varbinary、text、blob 按照变长字段的顺序已 16 进制的格式逆序存储：060408 NULL 值列表 由于数据在存储时是需要对齐的，需要存储行中 NULL 的位置 按照可为 NULL 的字段的顺序已 0 / 1 的格式逆序存储：110 记录头信息 delete_mask：记录该记录是否被删除 0 / 1，避免真实删除需要重新排列，维护一个垃圾链表 min_rec_mask：记录该记录是否是非叶子节点的最小记录，也就是目录页的最小记录标记为 1 record_type：记录该记录的记录类型，0：普通记录，1：非叶子节点的记录，2：最小记录，3：最大记录 heap_no：记录该记录在本页中的位置，0 表示最小记录，1表示最大记录，2 3 4 5 … n_owned：记录该（页目录）组中有多少条记录 next_record：记录到下一记录的地址偏移量 删除时：将上一记录的 next_record 指向下一记录，将当前记录的 next_record 设为 0（同时调整 delete_mask、n_owned 的值） 添加时：如果添加的主键和之前删除的主键相同，则复用之前的存储空间 真实数据 存储真实的数据以及三个隐藏列 在事务中使用隐藏列 Dynamic 行格式 行溢出 由于 变长字段长度列表 需要占用 2 字节， NULL 值列表 需要占用 1 字节 在定义 varchar 类型时需要考虑最大字符长度：ascii 中 varchar(65533) 是可以的 由于数据页最大 16KB 也就是 16384 字节，当设置字段长度为 65533 时就发生了【行溢出】 此时会使用 20 字节作为指针指向剩余数据所在的页面… 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式 在处理 BLOB 行溢出时，单独存储该字段的溢出页，然后在原数据页只存储溢出页的地址不存数据 Compressed 行格式在 Dynamic 行格式的基础上添加了 zlib 压缩算法，对于 富文本 字段数据可以更有效的存储 Redundant 行格式 是 MySQL 5.0 之前的默认行格式，保留的目的是为了向下兼容 使用 字段长度便宜列表 将所有字段的长度都逆序存储，比较冗余 记录头列表 Redundant 行格式多了 n_field 和 1byte_offs_flag 这两个属性。没有 record_type 这个属性 区、段、碎片区、表空间区： 一个区可以连续 64 个页，每个区 1MB 空间 为了减少 随机读取 的磁盘寻道和半圈旋转时间，将页和页做到顺序存储，提升效率 段： 将存放叶子节点的区和存放非叶子节点的区分开在不同的段中存储 段是逻辑上的概念，由零散的页面和完整的区组成。常见的段有 数据段、索引段、回滚段 碎片区： 每个表都要拥有一个索引段一个数据段，当一个表只有很少的数据却也要占用 2MB 空间 于是引入碎片区的概念，在碎片区中存储着一些零散的数据页和目录页。碎片区直属于表 当某个段已经占用了 32 个碎片区，则会申请 完整的区 为单位的存储空间 此时区就可以分为： 空闲的区(free) 有剩余空间的碎片区(free_frag) 没有剩余空间的碎片区(full_frag) 附属于某个段的区(fseg) 表空间： 是 InnoDB 存储引擎的最高层，分为 系统表空间、独立表空间、撤销表空间、临时表空间 独立表空间：便于表迁移，默认 .ibd 占 6 个页大小自扩展 系统表空间：还会记录系统的信息，数据字典 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:9:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#区段碎片区表空间"},{"categories":null,"content":"\r索引的创建与设计原则 按照 功能逻辑 划分为 普通索引、唯一索引、主键索引、全文索引 按照 物理实现 划分为 聚簇索引、非聚簇索引 按照 作用字段个数 划分为 单列索引、联合索引 普通索引： 没有任何约束的索引，可以创建在任何数据类型上 唯一索引： 使用 unique 参数声明的字段自动创建唯一索引，数据不能重复、可以为空、可以有多个唯一索引 主键索引： 在创建主键字段时会自动创建主键索引，主键索引是 not null + unique，一张表中最多只能有一个主键索引 单列索引： 作用在一个字段上的索引，一个表可以有多个单列索引 多列索引（联合索引、组合索引）： 为多个字段组合创建一个索引，遵循 最左前缀集合 全文索引： 是 搜索引擎 使用的一种关键技术，用到了 分词技术。分为 自然语言的全文检索 和 布尔全文检索 在 3.23.23 版本支持，在 5.6.4 后 InnoDB 支持。现使用 solr、ElasticSearch 专用的搜索引擎替代 空间索引： 略 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:10:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引的创建与设计原则"},{"categories":null,"content":"\r索引的创建 在创建表的时候创建索引 隐式的创建索引：在创建主键、外键、唯一性约束时，自动创建对应索引 显式的创建索引： CREATE TABLE table_name [col_name data_type] [UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [index_name] (col_name [length]) [ASC | DESC] UNIQUE 、 FULLTEXT 和 SPATIAL 为可选参数，分别表示唯一索引、全文索引和空间索引 INDEX 与 KEY 为同义词，两者的作用相同，用来指定创建索引 index_name 指定索引的名称，为可选参数，默认 col_name 为索引名 col_name 为需要创建索引的字段列，该列必须从数据表中定义的多个列中选择 length 为可选参数，表示索引的长度，只有字符串类型的字段才能指定索引长度 ASC 或 DESC 指定升序或者降序的索引值存储 案例： CREATE TABLE book( book_id INT , book_name VARCHAR(100), AUTHORS VARCHAR(100), info VARCHAR(100) , COMMENT VARCHAR(100), year_publication YEAR, # 声明普通索引（单例索引） INDEX idx_bname(book_name) # 声明唯一索引 # UNIQUE INDEX idx_bname(book_name) # 声明主键索引 # PRIMARY KEY(book_id) # 声明联合索引 # INDEX multi_idx(book_id,book_name,info) # 声明全文索引 # FULLTEXT INDEX futxt_idx_info(info) # 需要使用 match + against 查询 # SELECT * FROM papers WHERE MATCH(title,content) AGAINST (‘查询字符串’); # 声明空间索引（要求字段为 GEOMETRY 类型且非空） # SPATIAL INDEX spa_idx_geo(geo) ); ==查看创建的索引== show create table 表名 \\G # 或 SHOW INDEX FROM 表名 \\G ==使用 explain 性能分析工具==，可以看到是否用到了索引等信息 explain sql语句 单独创建索引 使用 ALTER TABLE … ADD 语句创建索引 ALTER TABLE 表名 ADD [UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [索引名] (字段名[length],...) [ASC | DESC] 使用 CREATE INDEX … ON 创建索引 CREATE [UNIQUE | FULLTEXT | SPATIAL] INDEX 索引名 ON 表名 (字段名[length],...) [ASC | DESC] ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:10:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引的创建"},{"categories":null,"content":"\r索引的删除 删除主键索引（修改主键索引要先删除原主键再创建新主键） # 非自增长主键才可删除 ALTER TABLE 表名 drop PRIMARY KEY; 使用 ALTER TABLE … DROP INDEX 删除索引 ALTER TABLE 表名 DROP INDEX 索引名; 使用 DROP INDEX … ON 语句删除索引 DROP INDEX 索引名 ON 表名; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:10:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引的删除"},{"categories":null,"content":"\rMySQL 8 降序索引、隐藏索引 降序索引 举例：在创建索引时指定字段的排序方式 CREATE TABLE ts1(a int,b int,index idx_a_b(a,b desc)); # 可以看到在执行计划中扫描数仅为 5, 而不是整表的数据量 EXPLAIN SELECT * FROM ts1 ORDER BY a,b DESC LIMIT 5; 隐藏索引 设置为隐藏的索引就不会被使用。设为隐藏索引之后再删除【软删除】 当索引被隐藏时其内容还会跟着内部同步更新，不要长期使用隐藏索引降低 DML 操作速度 可以使隐藏的索引有效：set session optimizer_switch=\"use_invisible_indexes=on\"; 在创建表时隐藏索引 CREATE TABLE book7( book_id INT , book_name VARCHAR(100), AUTHORS VARCHAR(100), info VARCHAR(100) , COMMENT VARCHAR(100), year_publication YEAR, #创建不可见的索引 INDEX idx_cmt(COMMENT) invisible ); 修改表中索引是否可见 ALTER TABLE 表名 ALTER INDEX 索引名 (INVISIBLE | VISIBLE); #切换成隐藏索引 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:10:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-8-降序索引隐藏索引"},{"categories":null,"content":"\r适合创建索引的 11 种情况 字段有唯一性限制 阿里巴巴规定业务上有唯一特性的字段，就算字段是组合字段，也必须添加唯一性索引 频繁作为 where 查询条件的字段 经常 group by 和 order by 的列 由于创建索引之后就会为索引列排序，在进行 order by 及 group by 时不必再次排序节省时间 在同时使用 group by 和 order by 时，若 分别建立索引 ：按照执行顺序，只会使用到 group by 后的索引 在同时使用 group by 和 order by 时，若 建立联合索引 ：建立 order by 字段在前，group by 字段在后 的联合索引 在同时使用 group by 和 order by 时，若 建立联合索引 ：建立 group by 字段在前，order by 字段（降序）在后 的联合索引 update 和 delete 种的 where 字段 在更新时为非索引字段更新的效果更明显，因为省去了维护索引的时间 经常 distinct 去重的字段 字段按照顺序排序之后对去重的速度也有提升 join on 连接条件上的字段 注意 on 条件连接的字段类型需要一致，否则索引失效 为类型小的列添加索引 在创建表的时候就应注意在满足存储条件下使用尽可能小的类型 数据类型约小那么每个数据页中存储的内容就越多，使得 B+ 树变得扁平加快索引效率 使用字符串的前缀创建索引 避免过长的字符全部存储至索引内存浪费空间，只将字符串的前 n 个字符建立索引 # 前缀索引 create index 索引名 on 表名(字段名(n)) 阿里规范强制为 varchar 类型创建索引时使用前缀索引 # 前缀长度公式，值越接近于 1 越好 count(distinct left(列名, 索引长度))/count(*) 使用前缀索引会导致索引排序时无法排序出真正的顺序 区分度（散列度）高的列适合做索引 使用最频繁的列放到联合索引的左侧 最左前缀原则 在多个字段都要创建索引的情况下，联合索引优于单值索引 联合索引中的每个索引列都可以被单独使用 建议单表索引不要超过 6 个 索引会占用空间 索引会影响增删改的速度 会为优化器选择索引时添加负担 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:10:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#适合创建索引的-11-种情况"},{"categories":null,"content":"\r不适合创建索引的 7 种情况 where 使用不到的字段 包括 group by 、 order by 数据量小的表 不要杀鸡用牛刀，在数据量低于 1000 条的时候不需要创建索引 有大量重复数据的列 频繁更新的字段 不建议用无序的值作为索引 比如 身份证号、UUID ，在比较时需要转为 ascii ，在插入时容易产生页分裂 删除不再使用或不常使用的索引 不要定义冗余或重复的索引 定义了联合索引中包含的列就不要再单独创建索引了 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:10:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#不适合创建索引的-7-种情况"},{"categories":null,"content":"\r性能分析工具的使用 数据库的优化思路：S (Show Status) 代表观察，A (Action) 代表行动 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#性能分析工具的使用"},{"categories":null,"content":"\r查看系统性能参数 SHOW [GLOBAL|SESSION] STATUS LIKE '参数'; Connections：连接 MySQL 服务器的次数 Uptime：MySQL 服务器的上线时间 Slow_queries：慢查询的次数 Innodb_rows_read：Select 查询返回的行数 Innodb_rows_inserted：执行 INSERT 操作插入的行数 Innodb_rows_updated：执行 UPDATE 操作更新的行数 Innodb_rows_deleted：执行 DELETE 操作删除的行数 Com_select：查询操作的次数 Com_insert：插入操作的次数。对于批量插入的 INSERT 操作，只累加一次 Com_update：更新操作 的次数 Com_delete：删除操作的次数 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看系统性能参数"},{"categories":null,"content":"\r查看末次查询成本 查看最后一次查询用到的页数 但是这个值并和查询时间并不成正比，因为采用顺序读取（顺序 I/O）的方式已经将页面一次性存储只缓冲池中了 show status like 'last_query_cost'; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看末次查询成本"},{"categories":null,"content":"\r查看慢查询日志 slow_query_log 是日志的一种，用于记录 响应时间超过阈值 的 SQL 慢查询日志参数 查看慢查询是否开启（默认不启用） show variables like '%slow_query_log%'; 开启慢查询日志 set global slow_query_log = 'ON'; 查看响应时间阈值 show variables like '%long_query_time%'; 设置响应时间阈值 set global long_query_time = 1; # 设置 global 对当前 session 连接无效, 应继续设置 set long_query_time = 1; 也可以通过编辑配置文件永久设置响应时间阈值（编辑 my.cnf 后重启 MySQL） [mysqld] # 开启慢查询日志的开关 slow_query_log = ON # 慢查询日志的目录和文件名信息 slow_query_log_file = /var/lib/mysql/atguigu-slow.1og # 设置慢查询的阀值为3秒, 超出此设定值的 SQL 即被记录到慢查询日志 long_query_time = 3 log_output = FILE 慢查询阈值（long_query_time）和 扫描过的最少记录量（min_examined_row_limit）共同组成判别是否慢查询的条件 默认的 min_examined_row_limit 值为 0，即：就算一条记录都没被扫描过，也会被判别为慢查询 慢查询日志分析工具 mysqldumpslow MySQL 提供的日志分析工具 mysqldumpslow 具体参数如下： -a: 不将数字抽象成N，字符串抽象成S -s: 是表示按照何种方式排序 c: 访问次数 l: 锁定时间 r: 返回记录 t: 查询时间 al:平均锁定时间 ar:平均返回记录数 at:平均查询时间 （默认方式） ac:平均查询次数 -t: 即为返回前面多少条的数据 -g: 后边搭配一个正则匹配模式，大小写不敏感的 当开启了慢查询日志并存在复合条件的慢查询时，在 /var/lib/mysql 目录中出现 用户名-slow.log 的日志文件 使用 mysqldumpslow -s t -t 5 按照查询时间排序，返回前 5 条慢查询数据 关闭慢查询日志 临时关闭慢查询日志 SET GLOBAL slow_query_log=off; systemctl restart mysqld.service 修改 my.cnf 配置文件关闭慢查询日志 [mysqld] # slow_query_log = off ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看慢查询日志-slow_query_log"},{"categories":null,"content":"\r查看慢查询日志 slow_query_log 是日志的一种，用于记录 响应时间超过阈值 的 SQL 慢查询日志参数 查看慢查询是否开启（默认不启用） show variables like '%slow_query_log%'; 开启慢查询日志 set global slow_query_log = 'ON'; 查看响应时间阈值 show variables like '%long_query_time%'; 设置响应时间阈值 set global long_query_time = 1; # 设置 global 对当前 session 连接无效, 应继续设置 set long_query_time = 1; 也可以通过编辑配置文件永久设置响应时间阈值（编辑 my.cnf 后重启 MySQL） [mysqld] # 开启慢查询日志的开关 slow_query_log = ON # 慢查询日志的目录和文件名信息 slow_query_log_file = /var/lib/mysql/atguigu-slow.1og # 设置慢查询的阀值为3秒, 超出此设定值的 SQL 即被记录到慢查询日志 long_query_time = 3 log_output = FILE 慢查询阈值（long_query_time）和 扫描过的最少记录量（min_examined_row_limit）共同组成判别是否慢查询的条件 默认的 min_examined_row_limit 值为 0，即：就算一条记录都没被扫描过，也会被判别为慢查询 慢查询日志分析工具 mysqldumpslow MySQL 提供的日志分析工具 mysqldumpslow 具体参数如下： -a: 不将数字抽象成N，字符串抽象成S -s: 是表示按照何种方式排序 c: 访问次数 l: 锁定时间 r: 返回记录 t: 查询时间 al:平均锁定时间 ar:平均返回记录数 at:平均查询时间 （默认方式） ac:平均查询次数 -t: 即为返回前面多少条的数据 -g: 后边搭配一个正则匹配模式，大小写不敏感的 当开启了慢查询日志并存在复合条件的慢查询时，在 /var/lib/mysql 目录中出现 用户名-slow.log 的日志文件 使用 mysqldumpslow -s t -t 5 按照查询时间排序，返回前 5 条慢查询数据 关闭慢查询日志 临时关闭慢查询日志 SET GLOBAL slow_query_log=off; systemctl restart mysqld.service 修改 my.cnf 配置文件关闭慢查询日志 [mysqld] # slow_query_log = off ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#慢查询日志参数"},{"categories":null,"content":"\r查看慢查询日志 slow_query_log 是日志的一种，用于记录 响应时间超过阈值 的 SQL 慢查询日志参数 查看慢查询是否开启（默认不启用） show variables like '%slow_query_log%'; 开启慢查询日志 set global slow_query_log = 'ON'; 查看响应时间阈值 show variables like '%long_query_time%'; 设置响应时间阈值 set global long_query_time = 1; # 设置 global 对当前 session 连接无效, 应继续设置 set long_query_time = 1; 也可以通过编辑配置文件永久设置响应时间阈值（编辑 my.cnf 后重启 MySQL） [mysqld] # 开启慢查询日志的开关 slow_query_log = ON # 慢查询日志的目录和文件名信息 slow_query_log_file = /var/lib/mysql/atguigu-slow.1og # 设置慢查询的阀值为3秒, 超出此设定值的 SQL 即被记录到慢查询日志 long_query_time = 3 log_output = FILE 慢查询阈值（long_query_time）和 扫描过的最少记录量（min_examined_row_limit）共同组成判别是否慢查询的条件 默认的 min_examined_row_limit 值为 0，即：就算一条记录都没被扫描过，也会被判别为慢查询 慢查询日志分析工具 mysqldumpslow MySQL 提供的日志分析工具 mysqldumpslow 具体参数如下： -a: 不将数字抽象成N，字符串抽象成S -s: 是表示按照何种方式排序 c: 访问次数 l: 锁定时间 r: 返回记录 t: 查询时间 al:平均锁定时间 ar:平均返回记录数 at:平均查询时间 （默认方式） ac:平均查询次数 -t: 即为返回前面多少条的数据 -g: 后边搭配一个正则匹配模式，大小写不敏感的 当开启了慢查询日志并存在复合条件的慢查询时，在 /var/lib/mysql 目录中出现 用户名-slow.log 的日志文件 使用 mysqldumpslow -s t -t 5 按照查询时间排序，返回前 5 条慢查询数据 关闭慢查询日志 临时关闭慢查询日志 SET GLOBAL slow_query_log=off; systemctl restart mysqld.service 修改 my.cnf 配置文件关闭慢查询日志 [mysqld] # slow_query_log = off ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#慢查询日志分析工具-mysqldumpslow"},{"categories":null,"content":"\r查看慢查询日志 slow_query_log 是日志的一种，用于记录 响应时间超过阈值 的 SQL 慢查询日志参数 查看慢查询是否开启（默认不启用） show variables like '%slow_query_log%'; 开启慢查询日志 set global slow_query_log = 'ON'; 查看响应时间阈值 show variables like '%long_query_time%'; 设置响应时间阈值 set global long_query_time = 1; # 设置 global 对当前 session 连接无效, 应继续设置 set long_query_time = 1; 也可以通过编辑配置文件永久设置响应时间阈值（编辑 my.cnf 后重启 MySQL） [mysqld] # 开启慢查询日志的开关 slow_query_log = ON # 慢查询日志的目录和文件名信息 slow_query_log_file = /var/lib/mysql/atguigu-slow.1og # 设置慢查询的阀值为3秒, 超出此设定值的 SQL 即被记录到慢查询日志 long_query_time = 3 log_output = FILE 慢查询阈值（long_query_time）和 扫描过的最少记录量（min_examined_row_limit）共同组成判别是否慢查询的条件 默认的 min_examined_row_limit 值为 0，即：就算一条记录都没被扫描过，也会被判别为慢查询 慢查询日志分析工具 mysqldumpslow MySQL 提供的日志分析工具 mysqldumpslow 具体参数如下： -a: 不将数字抽象成N，字符串抽象成S -s: 是表示按照何种方式排序 c: 访问次数 l: 锁定时间 r: 返回记录 t: 查询时间 al:平均锁定时间 ar:平均返回记录数 at:平均查询时间 （默认方式） ac:平均查询次数 -t: 即为返回前面多少条的数据 -g: 后边搭配一个正则匹配模式，大小写不敏感的 当开启了慢查询日志并存在复合条件的慢查询时，在 /var/lib/mysql 目录中出现 用户名-slow.log 的日志文件 使用 mysqldumpslow -s t -t 5 按照查询时间排序，返回前 5 条慢查询数据 关闭慢查询日志 临时关闭慢查询日志 SET GLOBAL slow_query_log=off; systemctl restart mysqld.service 修改 my.cnf 配置文件关闭慢查询日志 [mysqld] # slow_query_log = off ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#关闭慢查询日志"},{"categories":null,"content":"\r查看 SQL 执行成本 profile 见 MySQL 8 执行流程 profile 的使用 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看-sql-执行成本-profile"},{"categories":null,"content":"\r查看分析查询语句 explain explain 同 descibe 是分析查询的语句，查看优化器的执行计划 可以看到：表的读取顺序、数据读取操作的操作类型、哪些索引可以被使用、哪些索引实际被使用、表之间的使用、每张表有多少行被优化器查询 查询分析语句的使用 EXPLAIN SELECT 'SQL语句' #或者 DESCRIBE SELECT 'SQL语句' explain 输出的各个列说明 列名 描述 id 在一个大的查询语句中每个 SELECT 关键字都对应一个 唯一的 id select_type SELECT 关键字对应的那个查询的类型 table 表名 partitions 匹配的分区信息 type 针对单表的访问方法 possible_keys 可能用到的索引 key 实际上使用的索引 key_len 实际使用到的索引长度 ref 当使用索引列等值查询时，与索引列进行等值匹配的对象信息 rows 预估的需要读取的记录条数 filtered 某个表经过搜索条件过滤后剩余记录条数的百分比 Extra 一些额外的信息 table 列 表名，查询的每一行记录都对应着一个单表 id 列 每一个 select 关键字对应着一个 id，第一个的为驱动表，第二个的为被驱动表 优化器将两次查询优化为一个多表连接的查询，此时两个 select 关键字只会有一个 id 在使用 union 关键字连接两次查询时，会进行去重操作，此时会出现临时表（但是 union all 没有去重，还是两条记录） select 列 当前查询在整个查询中扮演的角色 名称 描述 SIMPLE 不包含子查询和 union 关键字的都是 simple 简单的查询 PRIMARY 对于包含子查询或 union 关键字的最外层的查询 UNION 使用 union 关键字时被连接的查询 UNION RESULT 使用 union 关键字生成的临时表 SUBQUERY 当查询即不能被优化为 semi-join 又不是相关子查询，此时的子查询 DEPENDENT SUBQUERY 当查询不能被优化为 semi-join 且是相关子查询（子查询中用到外部表），此时的子查询 DEPENDENT UNION 当查询不能被优化为 semi-join 且使用到了 union（子查询中用到外部表），此时的 union 子查询 DERIVED 派生表，在用到 from 子查询时使用到的由子查询中表派生出的查询结果 MATERIALIZED 物化表，在用到 in 子查询时只需要取几个常量的查询结果 UNCACHEABLE SUBQUERY 不常用 UNCACHEABLE UNION 不常用 partitions 列 分区信息，略 当查询的表为分区表时显示分区信息 type 列 执行查询时的访问方法 system 当表中只有一条记录并使用的存储引擎的 统计数据 是精确的如 MyISAM、Memory const 当对唯一索引或主键索这种常数进行 等值匹配 时 eq_ref 当被驱动表通过主键或唯一二级索引进行 等值匹配 时，被驱动表的访问方法是 eq_ref ref 当使用的是普通的二级索引与 常量 直接进行 等值匹配 时 fulltext 全文检索时 ref_or_null 当使用的是普通的二级索引与 常量 直接进行匹配，条件中有 OR xx IS NULL 时 index_merge 当使用多个索引合并查询时 unique_subquery 当查询优化器将 in 的子查询优化成 exits 查询时（子查询的连接条件可以使语句转换为连接查询时） index_subquery 类似于 unique_subquery range 当语句的条件中用到 in 或有明确的 范围区间 时 index 当使用到 索引覆盖 但需要扫描全部索引记录时（不符合联合索引 最左前缀原则，此时需要扫描整个索引但不需要回表） ALL 全表扫描 possible_keys 列 可能使用到的索引 key 列 实际用到的索引 key_len 列 实际使用到的索引长度字节数。针对于 联合索引，值越大证明越充分利用到索引 key2 为 int 类型占 4 个字节，但 key2 并不是非空字段，所以 4 + 1 = 5 key1 为 varchar(100) 类型，但 key1 有可能为空，还需要两个字节记录变长类型的实际长度，所以 3 * 100 + 1 + 2 = 303 ref 列 当索引列为等值连接时，与索引列进行等值匹配的对象信息 rows 列 预估的需要读取的条目数，越少越好 filtered 列 经过搜索条件过滤后剩余记录条数的百分比，越大越好 在连接查询中驱动表 需要读取的条目 * 过滤后剩余记录的百分比 就是被驱动表的执行次数：9895 * 10% ≈ 989 次 Extra 列 通过这些额外的信息可以 更准确的理解 MySQL 到底将如何执行给定的查询语句 No tables used 没有 from 条件时 Impossible WHERE 不可能的过滤条件 Using where 当使用全表扫描并指定了 where 条件时 No matching min/max row 没有匹配的数据 Using index 使用到了 覆盖索引 Using index condition 索引条件下推，有索引列但是不能使用索引，此时会根据 ‘%a’ 的条件进行回表 Using join buffer (hash join) 驱动表不能利用索引时，MySQL 一般会分配一个名叫 join buffer 的内存块来加快查询速度，也就是 基于块的嵌套循环算法 Not exists 不存在的，当使用左外连接时，右表的 s2 主键不可能为 NULL Using union(idx_key1,idx_key3); Using where 用到了合并 Zero limit 当 limit 值为 0 时 Using filesort 🙂对结果集 order by 时使用到了索引 或 ☹没有使用到索引，需要在内存中或磁盘中进行排序 Using temporary 用到了内部临时表，应尽量规避 EXPLAIN 不考虑各种 Cache EXPLAIN 不能显示 MySQL 在执行查询时所作的优化工作 EXPLAIN 不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况 部分统计信息是估算的，并非精确值 更改 explain 的输出格式 EXPLAIN FORMAT=xxx SELECT .... # JSON 格式, TREE 格式, 可视化输出：使用 MySQL 提供的 workbench 工具 查看查询优化器优化后的语句 # 在执行 explain 语句后 SHOW WARNINGS\\G ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看分析查询语句-explain"},{"categories":null,"content":"\r查看优化器执行计划 trace 开启跟踪功能 # 设置开启跟踪功能，配置格式为 json SET optimizer_trace=\"enabled=on\",end_markers_in_json=on; # 设置 trace 能够使用的最大内存 set optimizer_trace_max_mem_size=1000000; 查看追踪的相关信息 select * from information_schema.optimizer_trace \\G ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:6","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看优化器执行计划-trace"},{"categories":null,"content":"\r查看监控分析视图 sys schema 索引相关 #1. 查询冗余索引 select * from sys.schema_redundant_indexes; #2. 查询未使用过的索引 select * from sys.schema_unused_indexes; #3. 查询索引的使用情况 select index_name,rows_selected,rows_inserted,rows_updated,rows_deleted from sys.schema_index_statistics where table_schema='dbname'; 表相关 # 1. 查询表的访问量 select table_schema,table_name,sum(io_read_requests+io_write_requests) as io from sys.schema_table_statistics group by table_schema,table_name order by io desc; # 2. 查询占用bufferpool较多的表 select object_schema,object_name,allocated,data from sys.innodb_buffer_stats_by_table order by allocated limit 10; # 3. 查看表的全表扫描情况 select * from sys.statements_with_full_table_scans where db='dbname'; 语句相关 #1. 监控SQL执行的频率 select db,exec_count,query from sys.statement_analysis order by exec_count desc; #2. 监控使用了排序的SQL select db,exec_count,first_seen,last_seen,query from sys.statements_with_sorting limit 1; #3. 监控使用了临时表或者磁盘临时表的SQL select db,exec_count,tmp_tables,tmp_disk_tables,query from sys.statement_analysis where tmp_tables\u003e0 or tmp_disk_tables \u003e0 order by (tmp_tables+tmp_disk_tables) desc; IO 相关 #1. 查看消耗磁盘IO的文件 select file,avg_read,avg_write,avg_read+avg_write as avg_io from sys.io_global_by_file_by_bytes order by avg_read limit 10; Innodb 相关 #1. 行锁阻塞情况 select * from sys.innodb_lock_waits; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:11:7","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#查看监控分析视图-sys-schema"},{"categories":null,"content":"\r索引优化与查询优化 SQL 优化大致分为 物理查询优化 和 逻辑查询优化 两大块 物理查询优化： 数据太多 —— 分库分表 服务器调节缓存、线程数等 —— 调整 my.cnf 逻辑查询优化： 索引实现、没有充分利用到索引 —— 索引建立 设计缺陷、JOIN 太多 —— SQL 优化 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引优化与查询优化"},{"categories":null,"content":"\r索引失效的案例 全值匹配：针对没有索引的列进行条件查询 最佳左前缀法则：当使用联合索引等值条件时最左侧的字段优先，可以不按顺序，但 不能跨字段 现有联合索引 age, classId, name 字段，查询为按照 age, name 的条件，此时只有 age 索引生效，name 索引未生效 主键插入顺序： 插入的主键不是依次增大的话，主键索引需要重新维护甚至页面分裂，造成性能损耗 计算、函数、类型转换 (自动或手动)：当 where 条件中使用到 函数 \\ 计算 \\ 类型转换 则不会使用索引 用到函数时 用到计算时 用到类型转换时 范围条件右边的列索引失效：当使用联合索引查询时，其中一项使用的是范围条件，其右侧的索引失效 不等于 ( != 或 \u003c\u003e ) 索引失效：B+ 树无法根据不等于来快速定位 is null ✔，is not null ❌ ：is null 可以使用索引，is not null 无法使用索引 like 以通配符 % 开头：like ‘%xxx’ 索引失效 OR 前后存在非索引的列：OR 的前后存在非索引的列就会导致全表扫描，就算 使用了一个索引另一侧还需要全表扫描 字符集不统一：当不同的字符集进行比较时，索引失效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引失效的案例"},{"categories":null,"content":"\r关联查询的优化 外连接：查询出驱动表以及对应的被驱动表的所有数据，被驱动表不存在数据时自动补充 null 针对于左外连接，为右表（被驱动表）添加索引即可避免全表扫描 内连接：查询出两个表同复合条件的字段 查询优化器会自动选择驱动表和被驱动表，将拥有索引的表作为 被驱动表 JOIN 语句原理 使用 JOIN 连接多个表，实际上就是各个表之间的数据循环匹配，就是【嵌套循环】算法 驱动表与被驱动表 在 EXPLAIN 的结果中，上方的是驱动表，下方的是被驱动表 对于外连接和内连接来说，驱动表和被驱动表 都由查询优化器决定 当两个表都有索引或都没有索引时，小表驱动大表 嵌套循环索引（Index Nested-Loop Join） 驱动表根据索引向被驱动表匹配数据，不需要扫描 t1 表（内表） 根据索引读取匹配的 t2 表数据，不需要全表扫描 如果 t2 表为二级索引则需要回表，回 t2 表的索引匹配次数即可 块嵌套循环索引（Block Nested-Loop Join） 将驱动表数据分为几块，多次向被驱动表匹配 根据缓冲区（join_buffer ）的大小将 t1 表分为多块 不要将过多的驱动表无用字段，这样会占用 JOIN_BUFFER 导致每次缓冲区的条目数变少 调节 join_buffer 大小： # 查看缓冲区大小 默认开启 256k show variables like '%join_buffer%'; # 32 位系统最多可以设置为 4G 、64 位系统可以设置 4G 以上 整体效率：INLJ \u003e BNLJ \u003e SNLJ 永远使用 小的结果集 驱动 大的结果集（结果集 = 表行数 * 每行大小） 为被驱动表添加索引 增大 join_buffer 大小 减少驱动表的不必要字段参与查询 MySQL 8 的 Hash join MySQL 8 将 Hash join 替代了 BNLJ Hash join 是 大数据散列集 的常用方式，优化器将相对较小的表利用 join key 在内存中建立 散列表 依据散列表直接进行连接，效率高。但第一次查询需要建立哈希表占用大量内存，第一次的结果返回慢 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#关联查询的优化"},{"categories":null,"content":"\r关联查询的优化 外连接：查询出驱动表以及对应的被驱动表的所有数据，被驱动表不存在数据时自动补充 null 针对于左外连接，为右表（被驱动表）添加索引即可避免全表扫描 内连接：查询出两个表同复合条件的字段 查询优化器会自动选择驱动表和被驱动表，将拥有索引的表作为 被驱动表 JOIN 语句原理 使用 JOIN 连接多个表，实际上就是各个表之间的数据循环匹配，就是【嵌套循环】算法 驱动表与被驱动表 在 EXPLAIN 的结果中，上方的是驱动表，下方的是被驱动表 对于外连接和内连接来说，驱动表和被驱动表 都由查询优化器决定 当两个表都有索引或都没有索引时，小表驱动大表 嵌套循环索引（Index Nested-Loop Join） 驱动表根据索引向被驱动表匹配数据，不需要扫描 t1 表（内表） 根据索引读取匹配的 t2 表数据，不需要全表扫描 如果 t2 表为二级索引则需要回表，回 t2 表的索引匹配次数即可 块嵌套循环索引（Block Nested-Loop Join） 将驱动表数据分为几块，多次向被驱动表匹配 根据缓冲区（join_buffer ）的大小将 t1 表分为多块 不要将过多的驱动表无用字段，这样会占用 JOIN_BUFFER 导致每次缓冲区的条目数变少 调节 join_buffer 大小： # 查看缓冲区大小 默认开启 256k show variables like '%join_buffer%'; # 32 位系统最多可以设置为 4G 、64 位系统可以设置 4G 以上 整体效率：INLJ \u003e BNLJ \u003e SNLJ 永远使用 小的结果集 驱动 大的结果集（结果集 = 表行数 * 每行大小） 为被驱动表添加索引 增大 join_buffer 大小 减少驱动表的不必要字段参与查询 MySQL 8 的 Hash join MySQL 8 将 Hash join 替代了 BNLJ Hash join 是 大数据散列集 的常用方式，优化器将相对较小的表利用 join key 在内存中建立 散列表 依据散列表直接进行连接，效率高。但第一次查询需要建立哈希表占用大量内存，第一次的结果返回慢 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#join-语句原理"},{"categories":null,"content":"\r关联查询的优化 外连接：查询出驱动表以及对应的被驱动表的所有数据，被驱动表不存在数据时自动补充 null 针对于左外连接，为右表（被驱动表）添加索引即可避免全表扫描 内连接：查询出两个表同复合条件的字段 查询优化器会自动选择驱动表和被驱动表，将拥有索引的表作为 被驱动表 JOIN 语句原理 使用 JOIN 连接多个表，实际上就是各个表之间的数据循环匹配，就是【嵌套循环】算法 驱动表与被驱动表 在 EXPLAIN 的结果中，上方的是驱动表，下方的是被驱动表 对于外连接和内连接来说，驱动表和被驱动表 都由查询优化器决定 当两个表都有索引或都没有索引时，小表驱动大表 嵌套循环索引（Index Nested-Loop Join） 驱动表根据索引向被驱动表匹配数据，不需要扫描 t1 表（内表） 根据索引读取匹配的 t2 表数据，不需要全表扫描 如果 t2 表为二级索引则需要回表，回 t2 表的索引匹配次数即可 块嵌套循环索引（Block Nested-Loop Join） 将驱动表数据分为几块，多次向被驱动表匹配 根据缓冲区（join_buffer ）的大小将 t1 表分为多块 不要将过多的驱动表无用字段，这样会占用 JOIN_BUFFER 导致每次缓冲区的条目数变少 调节 join_buffer 大小： # 查看缓冲区大小 默认开启 256k show variables like '%join_buffer%'; # 32 位系统最多可以设置为 4G 、64 位系统可以设置 4G 以上 整体效率：INLJ \u003e BNLJ \u003e SNLJ 永远使用 小的结果集 驱动 大的结果集（结果集 = 表行数 * 每行大小） 为被驱动表添加索引 增大 join_buffer 大小 减少驱动表的不必要字段参与查询 MySQL 8 的 Hash join MySQL 8 将 Hash join 替代了 BNLJ Hash join 是 大数据散列集 的常用方式，优化器将相对较小的表利用 join key 在内存中建立 散列表 依据散列表直接进行连接，效率高。但第一次查询需要建立哈希表占用大量内存，第一次的结果返回慢 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-8-的-hash-join"},{"categories":null,"content":"\r子查询优化 子查询是 MySQL 4.1 开始支持的功能，其 效率不高 执行子查询时需要为内部查询 建立一个临时表，在查询结束后还要 撤销这个临时表，造成 CPU 和 IO 的消耗 子查询结果集存储的临时表 不会存在索引，查询性能低 子查询的 结果集越大 对查询效率的影响越大 结论：尽量不要使用 NOT IN 或者 NOT EXISTS，用 LEFT JOIN xxx ON xx WHERE xx IS NULL 替代 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#子查询优化"},{"categories":null,"content":"\r排序优化 在 SQL 语句中推荐为 WHERE 和 ORDER BY 子句中使用索引 在 WHERE 中使用索引可以避免全表扫描 在 ORDER BY 中使用索引可以避免 File Sort 排序 如果 WHERE 和 ORDER BY 后面的列不相同，推荐使用联合索引（先 WHERE 后 ORDER BY 字段） 【索引失效】在 ORDER BY 后面不 LIMIT 时（查询优化器觉得 数据量小 时不使用索引效率更高） 【索引失效】复合最左前缀原则但有字段降序时（查询优化器觉得 数据量小 时不使用索引效率更高） 【索引生效】WHERE 条件不复合最左前缀原则但 ORDER BY 条件具有 LIMIT 时（查询优化器觉得 数据量小 时先使用 ORDER BY 索引排序后 WHERE 效率更高） FileSort 算法 出现 FileSort 并不意味着效率比使用索引的效率低 如果 WHERE 条件就可以过滤掉大部分数据，即使 ORDER BY 条件拥有索引，查询优化器也未必会使用【反之亦然】 【双路排序】：在 MySQL 4.1 前使用，对于 ORDER BY 的列先进行排序，再二次根据 ORDER BY 的顺序查找表中其它字段的完整数据（两次 IO） 【单路排序】：先读取所有列，根据 ORDER BY 条件在 buffer 进行排序，然后扫描排序后的列表进行输出（只需要依次顺序 IO） 由于使用的是 单路排序 应尝试提高 sort_buffer_size 尝试提高 max_length_for_sort_data，如果字段的长度大于这个变量的值，会采用双路排序 Order by 时select * 是一个大忌，有可能使字段长度超过 max_length_for_sort_data，最好只 Query 需要的字段。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#排序优化"},{"categories":null,"content":"\r排序优化 在 SQL 语句中推荐为 WHERE 和 ORDER BY 子句中使用索引 在 WHERE 中使用索引可以避免全表扫描 在 ORDER BY 中使用索引可以避免 File Sort 排序 如果 WHERE 和 ORDER BY 后面的列不相同，推荐使用联合索引（先 WHERE 后 ORDER BY 字段） 【索引失效】在 ORDER BY 后面不 LIMIT 时（查询优化器觉得 数据量小 时不使用索引效率更高） 【索引失效】复合最左前缀原则但有字段降序时（查询优化器觉得 数据量小 时不使用索引效率更高） 【索引生效】WHERE 条件不复合最左前缀原则但 ORDER BY 条件具有 LIMIT 时（查询优化器觉得 数据量小 时先使用 ORDER BY 索引排序后 WHERE 效率更高） FileSort 算法 出现 FileSort 并不意味着效率比使用索引的效率低 如果 WHERE 条件就可以过滤掉大部分数据，即使 ORDER BY 条件拥有索引，查询优化器也未必会使用【反之亦然】 【双路排序】：在 MySQL 4.1 前使用，对于 ORDER BY 的列先进行排序，再二次根据 ORDER BY 的顺序查找表中其它字段的完整数据（两次 IO） 【单路排序】：先读取所有列，根据 ORDER BY 条件在 buffer 进行排序，然后扫描排序后的列表进行输出（只需要依次顺序 IO） 由于使用的是 单路排序 应尝试提高 sort_buffer_size 尝试提高 max_length_for_sort_data，如果字段的长度大于这个变量的值，会采用双路排序 Order by 时select * 是一个大忌，有可能使字段长度超过 max_length_for_sort_data，最好只 Query 需要的字段。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#filesort-算法"},{"categories":null,"content":"\rGROUP BY 优化 GROUP BY 的索引使用原理同 ORDER BY ，GROUP BY 会先排序后分组 无法使用索引列时也尝试提高 sort_buffer_size max_length_for_sort_data WHERE 的效率高于 HAVING 能使用 WHERE 就不要使用 HAVING 使用了 ORDER BY、GROUP BY、DISTINCT 的语句，WHERE 条件过滤出来的条数不要超过 1000 条，否则 SQL 会很慢 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#group-by-优化"},{"categories":null,"content":"\r优化分页查询 当出现 limit 2000000, 10 这种情况时 explain select * from student limit 2000000, 10; # 可以使用其它索引列将 limit 转换成某个位置的查询 EXPLAIN SELECT * FROM student WHERE id \u003e 2000000 LIMIT 10; # 在索引上实现 limit 查询，然后根据主键连接回表查询其他列【推荐】 EXPLAIN SELECT * FROM student t,(SELECT id FROM student ORDER BY id LIMIT 2000000,10) a WHERE t.id = a.id; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:6","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#优化分页查询"},{"categories":null,"content":"\r优先考虑覆盖索引 覆盖：指查询使用到的索引字段以及主键字段覆盖了要查询的字段 就是说可以直接在一个 B+ 树中查询到想要的字段，而不用回表查询其它 索引中没有 的字段 一个索引包含了满足查询结果的数据就叫做覆盖索引 在一些索引失效的案例中，使用覆盖索引并不一定会导致索引失效 覆盖索引的优点： 避免 Innodb 表进行索引的二次查询（回表） 可以把 随机 IO 变成 顺序 IO 加快查询效率 覆盖索引的缺点： 索引字段的维护 总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这是业务 DBA，或者称为业务数据架构师的工作。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:7","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#优先考虑覆盖索引"},{"categories":null,"content":"\r字符串的索引 对字符串的索引优化主要是使用 前缀索引 例如对邮箱号进行检索，使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本 结论： 使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:8","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#字符串的索引"},{"categories":null,"content":"\r索引下推 ICP Index Condition Pushdown (ICP) 是 MySQL 5.6 中新特性 是一种 在存储引擎层 使用索引 过滤数据 的一种优化方式 ICP 可以减少存储引擎访问基表的次数以及 MySQL 服务器访问存储引擎的次数 在这次查询中 lastname like '%张%' 的条件理应使无法使用到索引，由查询引擎查询出复合 zipcode = '000001' 的数据后再由服务层依次回表 但是由于使用到了 ICP 索引下推，在存储引擎中就直接过滤出 zipcode 和 lastname 的数据，减少回表以及传递到服务层的成本 # 打开索引下推 【默认开启】 SET optimizer_switch = 'index_condition_pushdown=on'; # 关闭索引下推 SET optimizer_switch = 'index_condition_pushdown=off'; 在 type 为 range 、 ref 、 eq_ref 或者 ref_or_null 时可使用 ICP 仅对二级索引（需要回表）时有效，在用到覆盖索引（不需要回表）时无效 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:9","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#索引下推-icp"},{"categories":null,"content":"\r其它优化策略 EXISTS 和 IN 的区分 exists：是否存在，会直接返回布尔类型 SELECT * FROM A WHERE cc IN (SELECT cc FROM B) # 【 B表小 时推荐】 SELECT * FROM A WHERE EXISTS (SELECT cc FROM B WHERE B.cc = A.cc) # 【 A表小 时推荐】 COUNT(*) 的效率 当使用 InnoDB 时：COUNT(*) 和 COUNT(1) 都需要对所有结果进行 count，效率为 O(n) 当使用 MyISAM 时：统计数据的行数由 meta 信息记录记录数 row_count ，效率为 O(1) 其一致性由 表级锁 保证 SELECT * 的效率 在解析时需要将 * 转化为具体的字段，会大大浪费时间 无法使用 覆盖索引 LIMIT 1 的效率 针对会全表扫描的查询，使用 LIMIT 1 当查询到一条数据就不会继续扫描了，会提高效率 但当已经对字段建立了唯一索引时，就不需要 LIMI 1 了 多使用 commit 释放用于恢复数据消息的空间 释放获得的锁 释放日志文件的空间 减少以上的管理成本 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:10","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#其它优化策略"},{"categories":null,"content":"\r淘宝的数据库设计 淘宝使用自增长主键嘛？ 答：没有！ 自增长主键的问题 可靠性不高：MySQL 8 之前版本存在 ID 回溯问题 安全性不高：很容易被猜到 ID 值和数据量等信息 性能差：需要在数据库服务端生成 交互多：需要 last_insert_id() 查询刚插入的自增值 局部唯一性：在自身表是唯一的，但在分布式中无法确定唯一性 使用业务字段作为主键？ 使用会员卡号作为主键 当会员卡更换主人时，其之前关联的业务数据就无法确定主人了 使用身份证号作为主键 存在被回收，重复值，个人隐私的问题 使用 UUID 做主键？ UUID 的特点：全局唯一，占用36字节，数据无序，插入性能差 在 MySQL 8 中可以使用 uuid_to_bin(UUID(), true) 生成 调换了时间高低位 的 有序单调递增 16位 UUID ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:11","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#淘宝的数据库设计"},{"categories":null,"content":"\r淘宝的数据库设计 淘宝使用自增长主键嘛？ 答：没有！ 自增长主键的问题 可靠性不高：MySQL 8 之前版本存在 ID 回溯问题 安全性不高：很容易被猜到 ID 值和数据量等信息 性能差：需要在数据库服务端生成 交互多：需要 last_insert_id() 查询刚插入的自增值 局部唯一性：在自身表是唯一的，但在分布式中无法确定唯一性 使用业务字段作为主键？ 使用会员卡号作为主键 当会员卡更换主人时，其之前关联的业务数据就无法确定主人了 使用身份证号作为主键 存在被回收，重复值，个人隐私的问题 使用 UUID 做主键？ UUID 的特点：全局唯一，占用36字节，数据无序，插入性能差 在 MySQL 8 中可以使用 uuid_to_bin(UUID(), true) 生成 调换了时间高低位 的 有序单调递增 16位 UUID ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:11","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#自增长主键的问题"},{"categories":null,"content":"\r淘宝的数据库设计 淘宝使用自增长主键嘛？ 答：没有！ 自增长主键的问题 可靠性不高：MySQL 8 之前版本存在 ID 回溯问题 安全性不高：很容易被猜到 ID 值和数据量等信息 性能差：需要在数据库服务端生成 交互多：需要 last_insert_id() 查询刚插入的自增值 局部唯一性：在自身表是唯一的，但在分布式中无法确定唯一性 使用业务字段作为主键？ 使用会员卡号作为主键 当会员卡更换主人时，其之前关联的业务数据就无法确定主人了 使用身份证号作为主键 存在被回收，重复值，个人隐私的问题 使用 UUID 做主键？ UUID 的特点：全局唯一，占用36字节，数据无序，插入性能差 在 MySQL 8 中可以使用 uuid_to_bin(UUID(), true) 生成 调换了时间高低位 的 有序单调递增 16位 UUID ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:11","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#使用业务字段作为主键"},{"categories":null,"content":"\r淘宝的数据库设计 淘宝使用自增长主键嘛？ 答：没有！ 自增长主键的问题 可靠性不高：MySQL 8 之前版本存在 ID 回溯问题 安全性不高：很容易被猜到 ID 值和数据量等信息 性能差：需要在数据库服务端生成 交互多：需要 last_insert_id() 查询刚插入的自增值 局部唯一性：在自身表是唯一的，但在分布式中无法确定唯一性 使用业务字段作为主键？ 使用会员卡号作为主键 当会员卡更换主人时，其之前关联的业务数据就无法确定主人了 使用身份证号作为主键 存在被回收，重复值，个人隐私的问题 使用 UUID 做主键？ UUID 的特点：全局唯一，占用36字节，数据无序，插入性能差 在 MySQL 8 中可以使用 uuid_to_bin(UUID(), true) 生成 调换了时间高低位 的 有序单调递增 16位 UUID ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:12:11","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#使用-uuid-做主键"},{"categories":null,"content":"\r数据库的设计规范","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:13:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据库的设计规范"},{"categories":null,"content":"\r六大范式 关系型数据库中，关于数据表设计的基本原则、规则的级别就称为范式 键： 超键：能唯一标识元组的属性集 候选键：不包括多余的属性的超键 主键：用户可以从候选键中选择一个作为主键 外键：A 表中的某属性集不是 A 的主键，而是另一个数据表 B 的主键，那么这个属性集就是 B 的外键 主属性：包含再任一候选键中的属性 非主属性：不包含再任何一个候选键中的属性 第一范式（1NF） 任何一张表都应该有主键，并且每一个字段原子性不可再分 第二范式 （2NF） 建立在第一范式基础之上，所有非主键字段 完全依赖 主键，不能产生 部分依赖 违反第二范式容易造成：数据冗余、增删改的异常 第三范式（3NF） 建立在第二范式基础之上，所有非主键字段 直接依赖 主键，不能产生 传递依赖 三范式的优点: 消除了数据库中的数据冗余，在性能、扩展性、数据完整性方面做到了最好的平衡 三范式的缺点： 会降低查询的效率，进行查询时需要关联多张表，可能导致索引失效等 巴斯-科德范式（BCNF） 在第三范式上的改进，一个表中只有一个候选键，其它都是单属性时 第四范式 (4NF） 第四范式的概念 即在巴斯-科德范式的基础上，消除非平凡和非函数依赖的多值传递（消除同一张表中的多对多关系） 在职工表中，一个职工编号可以有多个孩子，一个职工编号可以有多个课程 存在多值依赖，应拆分成 职工表（职工编号，职工选修课程） 和 职工表（职工编号，职工孩子姓名） 第五范式（5NF，又称完美 范式） 域键范式 在第四范式基础上，消除不是由候选键所蕴含的连接依赖 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:13:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#六大范式"},{"categories":null,"content":"\r反范式化 为避免完全满足三范式而造成的效率降低，增加一些冗余来提高数据库性能 案例： 经常在查询员工信息时需要看到部门名，如果将部门名存储在员工表中就避免每次都进行连接操作了 select 员工_id,部门_name from 员工表 e join 部门表 d on e.员工_id = d.部门_id; 反范式化的新问题： 存储 空间变大 了 一个表中字段做了修改，另一个表中冗余的字段也需要做同步修改，否则 数据不一致 若采用存储过程来支持数据的更新、删除等额外操作，如果更新频繁，会非常 消耗系统资源 在 数据量小 的情况下，反范式不能体现性能的优势，可能还会让数据库的设计更加 复杂 当冗余信息有价值或者能 大幅度提高查询效率 的时候，再采取反范式的优化 这个冗余字段，需要经常查询不经常修改 这个冗余字段，在查询时不可或缺 在记录历史 快照 、历史数据时使用 在记录 数据仓库 数据时使用 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:13:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#反范式化"},{"categories":null,"content":"\r“三少一多” 数据表的个数越少越好 数据表中的字段个数越少越好 数据表中联合主键的字段个数越少越好 使用主键和外键越多越好 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:13:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#三少一多"},{"categories":null,"content":"\rSQL 编写关于库 【强制】库的名称必须控制在 32 个字符以内，只能使用英文字母、数字和下划线，建议以英文字母开头。 【强制】库名中英文一律小写 ，不同单词采用 下划线 分割。须见名知意。 【强制】库的名称格式：业务系统名称_子系统名。 【强制】库名禁止使用关键字（如 type, order 等）。 【强制】创建数据库时必须 显式指定字符集 ，并且字符集只能是 utf8 或者 utf8mb4。 创建数据库SQL举例：CREATE DATABASE crm_fund DEFAULT CHARACTER SET 'utf8' ; 【建议】对于程序连接数据库账号，遵循 权限最小原则 使用数据库账号只能在一个 DB 下使用，不准跨库。程序使用的账号原则上不准有 drop 权限 。 【建议】临时库以 tmp_ 为前缀，并以日期为后缀； 备份库以 bak_ 为前缀，并以日期为后缀。 关于表、列 【强制】表和列的名称必须控制在 32 个字符以内，表名只能使用英文字母、数字和下划线，建议以英文字母开头 。 【强制】 表名、列名一律小写 ，不同单词采用下划线分割。须见名知意。 【强制】表名要求有模块名强相关，同一模块的表名尽量使用 统一前缀 。比如：crm_fund_item 【强制】创建表时必须 显式指定字符集 为 utf8 或 utf8mb4。 【强制】表名、列名禁止使用关键字（如 type, order 等）。 【强制】创建表时必须 显式指定表存储引擎 类型。如无特殊需求，一律为 InnoDB。 【强制】建表必须有 comment。 【强制】字段命名应尽可能使用表达实际含义的英文单词或 缩写 。如：公司 ID，不要使用 corporation_id, 而用 corp_id 即可。 【强制】布尔值类型的字段命名为 is_ 描述 。如 member 表上表示是否为 enabled 的会员的字段命 名为 is_enabled。 【强制】禁止在数据库中存储图片、文件等大的二进制数据通常文件很大，短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时。通常存储于文件服务器，数据库只存储文件地址信息。 【建议】建表时关于主键： 表必须有主键 (1) 强制要求主键为 id，类型为 int 或 bigint，且为 auto_increment 建议使用 unsigned 无符号型。 (2) 标识表里每一行主体的字段不要设为主键，建议 设为其他字段如 user_id，order_id 等，并建立 unique key 索引。因为如果设为主键且主键值为随机插入，则会导致 innodb 内部页分裂和大量随机 I/O，性能下降。 【建议】核心表（如用户表）必须有行数据的 创建时间字段 （create_time）和 最后更新时间字段 （update_time），便于查问题。 【建议】表中所有字段尽量都是 NOT NULL 属性，业务可以根据需要定义 DEFAULT 值 。 因为使用 NULL 值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问 题。 【建议】所有存储相同数据的 列名和列类型必须一致 （一般作为关联列，如果查询时关联列类型 不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低）。 【建议】中间表（或临时表）用于保留中间结果集，名称以 tmp_ 开头。 备份表用于备份或抓取源表快照，名称以 bak_ 开头。中间表和备份表定期清理。 【建议】创建表时，可以使用可视化工具。这样可以确保表、字段相关的约定都能设置上。 实际上，我们通常很少自己写 DDL 语句，可以使用一些可视化工具来创建和操作数据库和数据表。可视化工具除了方便，还能直接帮我们将数据库的结构定义转化成 SQL 语言，方便数据库和数据表结构 的导出和导入。 关于索引 【强制】InnoDB 表必须主键为 id int/bigint auto_increment，且主键值 禁止被更新 。 【强制】InnoDB 和 MyISAM 存储引擎表，索引类型必须为 BTREE 。 【建议】主键的名称以 pk_ 开头，唯一键以 uni_ 或 uk_ 开头，普通索引以 idx_ 开头，一律 使用小写格式，以字段的名称或缩写作为后缀。 【建议】多单词组成的 columnname，取前几个单词首字母，加末单词组成 column_name。如: sample 表 member_id 上的索引：idx_sample_mid。 【建议】单个表上的索引个数 不能超过 6 个 。 【建议】在建立索引时，多考虑建立 联合索引 ，并把区分度最高的字段放在最前面。 【建议】在多表 JOIN 的SQL里，保证被驱动表的连接列上有索引，这样 JOIN 执行效率最高。 【建议】建表或加索引时，保证表里互相不存在 冗余索引 。 比如：如果表里已经存在 key(a,b)， 则 key(a) 为冗余索引，需要删除。 SQL编写 【强制】程序端 SELECT 语句必须指定具体字段名称，禁止写成 *。 【建议】程序端 insert 语句指定具体字段名称，不要写成 INSERT INTO t1 VALUES(…)。 【建议】除静态表或小表（100行以内），DML 语句必须有 WHERE 条件，且使用索引查找。 【建议】INSERT INTO…VALUES(XX),(XX),(XX).. 这里 XX 的值不要超过 5000 个。 值过多虽然上线很快，但会引起主从同步延迟。 【建议】SELECT 语句不要使用 UNION，推荐使用 UNION ALL ，并且 UNION 子句个数限制在 5 个以内。 【建议】线上环境，多表 JOIN 不要超过 5 个表。 【建议】减少使用 ORDER BY，和业务沟通能不排序就不排序，或将排序放到程序端去做。ORDER BY、GROUP BY、DISTINCT 这些语句较为耗费 CPU，数据库的 CPU 资源是极其宝贵的。 【建议】包含了 ORDER BY、GROUP BY、DISTINCT 这些查询的语句，WHERE 条件过滤出来的结果集请保持在 1000 行以内，否则 SQL 会很慢。 【建议】对单表的多次 alter 操作必须合并为一次对于超过100W行的大表进行 alter table，必须经过 DBA 审核，并在业务低峰期执行，多个 alter 需整合在一起。 因为 alter table 会产生 表锁 ，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。 【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的 sleep。 【建议】事务里包含 SQL 不超过5个。 因为过长的事务会导致锁数据较久，MySQL 内部缓存、连接消耗过多等问题。 【建议】事务里更新语句尽量基于主键或 UNIQUE KEY，如 UPDATE… WHERE id=XX; 否则会产生间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:13:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#sql-编写"},{"categories":null,"content":"\r数据库其它调优策略","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:14:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据库其它调优策略"},{"categories":null,"content":"\r数据库调优的措施 选择合适的数据库管理系统 Oracle、SQL Server 单表存储上亿条数据也没问题 MySQL 开源免费 优化表的设计 遵循第三范式 / 巴斯范式 使用反范式化 空间换时间 表数据类型的选择 优化逻辑查询 逻辑查询优化 SQL 查询重写：子查询优化、等价谓词重写、视图重写、条件简化、连接消除、嵌套连接消除等 小表驱动大表、不在 WHERE 语句中使用函数等 物理查询优化 使用索引 …… 使用 Redis 或 Memcached 作缓存 Redis 支持持久化，支持 Key-Value、List、Set、Hash 等数据结构 Memcached 不支持持久化，仅支持 Key-Value 数据类型 库级优化 采用主从架构 读写分离 一主一从模式：主机负责写请求，从机负责读请求 双主双从模式：主从复制 数据分片 分库：根据模块将表放在不同主机中 分表 垂直分表：冷热数据划分 水平分表：按照取模、范围约定、日期等方式划分 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:14:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据库调优的措施"},{"categories":null,"content":"\r优化 MySQL 服务器 优化服务器硬件 配置较大的内存 配置高速的磁盘系统 合理分布磁盘 I/O 配备多处理器 优化 MySQL 参数 配置 my.cnf 配置文件 innodb_buffer_pool_size：缓冲区大小，配置表和索引的最大缓存 key_buffer_size：索引缓冲区大小，对于内存在 4GB 左右 的服务器该参数可设置为 256M 或 384M table_cache：同时打开表的个数，默认为 2402，调到 512-1024 最佳 query_cache_size：查询缓冲区的大小 query_cache_type：有 3 个值：0 代表关闭查询缓存 OFF, 1 代表开启 ON , 2 (DEMAND) 按需使用 sort_buffer_size：需要进行排序的线程分配的缓冲区的大小，可提高 ORDER BY 或 GROUP BY 操作的速度，对于内存在 4GB 左右的服务器推荐设置为 6-8M join_buffer_size = 8M：联合查询操作所能使用的缓冲区大小，和 sort_buffer_size 一样每个线程独享 read_buffer_size ：每个线程连续扫描时为扫描的每个表分配的缓冲区的大小（字节），默认为 64K，可以设置为 4M innodb_flush_log_at_trx_commit：何时将缓冲区的数据写入日志文件 0：每秒一次 1：提交事务时 2：提交事务时写入日志，每秒刷盘 innodb_log_buffer_size：事务日志所使用的缓冲区 max_connections：允许连接到MySQL数据库的最大数量，默认 151，性能好可支持 500-1000 back_log：控制 MySQL 监听 TCP 端口时设置的积压请求栈大小，5.6.6 版本之前默 认值为 50 ， 之后的版本默认为 (max_connections / 5)， 对于 Linux 系统推荐设置为小于 512 的整数，但最大不超过 900 thread_cache_size：线程池缓存线程数量的大小，默认为 60，可以设置为 120 wait_timeout：一个请求的最大连接时间，4GB 左右内存可以设置为 5-10 interactive_timeout：表示服务器在关闭连接前等待行动的秒数 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:14:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#优化-mysql-服务器"},{"categories":null,"content":"\r优化数据库结构 拆分表（冷热数据分离） 减少磁盘 I/O，保证数据命中率 有效利用缓存，避免读入无用冷数据 增加中间表 将经常进行联合查询的数据统一存放在中间表中 将原来的联合查询改为对中间表的查询提高效率 使用 insert into ... select ... 的方式保证数据一致性 增加冗余字段 同反范式化 优化数据类型 优先选择复合存储需要的最小的数据类型 对于整形类型 优先 INT 类型，对于年龄可以选用 unsigned tinyint 存储范围为 0 - 255 能用字符类型也能用整数类型的，尽可能的使用整数类型 避免使用 TEXT、BLOB 这样的大数据类型 内存临时表不支持这种类型，只能使用磁盘临时表 对于这种数据还需要二次查询，性能很差 可以将这类字段存储在单独的扩展表中 避免使用 ENUM 类型 修改枚举类型需要 ALTER 语句，ORDER BY 效率低 推荐使用 TINYINT 替代枚举类型 使用 TIMESTAMP 存储时间 可以存储 1970-01-01 00:00:00 - 2038-1-19 11:14:07，存储 2147483647 秒，相当于 INT 类型占 4 字节 用 DECIMAL 代替 FLOAT 和 DOUBLE 因为 DECIMAL 不会丢失精度 优化插入速度 MyISAM 引擎的表 禁用索引 禁用唯一性检查 使用批量插入 使用 LOAD DATA INFILE 批量导入 InnoDB 引擎的表 禁用唯一性检查 禁用外键检查 禁用自动提交 使用非空约束 尽量使用 NOT NULL 约束 IS NOT NULL 会使索引失效 需要额外的空间存储是否为 NULL 分析、检查、优化表 分析表：分析关键字的分布 ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name[,tbl_name]… 分析表的过程中会为表添加 只读锁，期间无法更新和插入数据 ANALYZE TABLE 分析后的统计结果会反应到 show index from xxx 中 cardinality 的值，该值统计了表中某一键所在的列不重复的值的个数。该值越接近表中的总行数，则在表连接查询或者索引查询时，就越优先被优化器选择使用 检查表：检查表是否存在错误 CHECK TABLE tbl_name [, tbl_name] ... [option] ... option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED} 检查表的过程中会为表添加 只读锁，期间无法更新和插入数据 执行结果最后一行有一个状态的 Msg_type 值，Msg_text 通常为 OK。 如果得到的不是 OK，通常要对其进行修复 优化表：消除删除或更新造成的空间浪费 针对于 VARCHAR、TEXT、BLOB 类型进行碎片整理 OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 优化表的过程中会为表添加 只读锁，期间无法更新和插入数据 在MyISAM中，是先分析这张表，然后会整理相关的 MySQL datafile，之后回收未使用的空间； 在InnoDB 中，回收空间是简单通过 Alter table 进行整理空间。在优化期间，MySQL 会创建一个临时表，优化完成之后会删除原始表，然后会将临时表 rename 成为原始表 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:14:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#优化数据库结构"},{"categories":null,"content":"\r大表优化 限定查询的范围 不要使用不加条件的查询 读写分离 一主一从模式 双主双从模式 垂直拆分 当数据量达到千万级以上时，采用分库分表 采用 垂直分库 的方式，将关联的数据表划分在一个数据库中 采用 垂直分表 的方式，按照冷热数据将一张数据表拆分成多张数据表 水平拆分 按照取模、范围约定、日期等方式划分。 在《Java工程师修炼之道》中推荐尽量不要进行对数据进行 分片 因为会增加 逻辑、部署、运维 的复杂度 客户端代理：分片逻辑在应用端，封装在 jar 包中，通过修改或者封装 JDBC 层来实现。 【推荐】 当当网的 Sharding-JDBC 、阿里的TDDL是两种比较常用的实现。 中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 Mycat 、360 的 Atlas、网易的 DDB 等等都是这种架构的实现。 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:14:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#大表优化"},{"categories":null,"content":"\r其它调优策略 服务器语句超时处理 设置服务器语句超时的限制，当中断的执行语句超过设置的毫秒数后，服务器将终止查询影响不大的事务或连接，然后将错误报给客户端 SET GLOBAL MAX_EXECUTION_TIME=2000; SET SESSION MAX_EXECUTION_TIME=2000; #指定该会话中SELECT语句的超时时间 创建全局通用表空间 使用通用表空间可以节约元数据方面的内存 使用 MySQL 8 的隐藏索引 当一个索引被设置成 invisible 时，它将不会被查询优化器使用。 当一个索引被隐藏后数据库性能不受影响，这个索引就可以被删除了 索引不要长期隐藏，因为在添加数据时还要维护隐藏的索引 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:14:5","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#其它调优策略"},{"categories":null,"content":"\r事务基础知识","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务基础知识"},{"categories":null,"content":"\r什么是事务 事务：是一组逻辑操作单元，使数据从一种状态转变为另一种状态 事务的处理原则：是 一个工作单元 ，在一个事务执行多个操作时，要么同时成功要么同时失败 只有 InnoDB 存储引擎支持事务 事务的 ACID 特性 原子性（atomicity） 指事务是一个不可分割的工作单位，要么同时成功提交（commit）要么同时失败回滚（rollback） 一致性（consistency） 一致性是指事务执行前后，数据从一个 合法性状态 变换到另外一个 合法性状态 这种状态是 语义上 的而不是语法上的，跟具体的业务有关 隔离型（isolation） 一个事务内部的操作和使用的数据对 并发 的其它事务是隔离的，并发执行的各个事务 互不干扰 通过 锁 来保障隔离性 持久性（durability） 事务一旦提交了，它对数据的改变就是 永久性 的了 通过 事务日志 来保障持久性 事务的状态 活动的（active）：指事务对应的数据库操作是 正在执行过程中 部分提交的（partially committed）：事务已经在内存中执行完毕但是 还没有刷新到磁盘中 失败的（failed）：数据库在 活动的 / 部分提交的 过程中遇到了错误 无法继续执行 中止的（aborted）：在 失败的 状态之后，将数据 回滚 后就是中止的状态 提交的（committed）：将部分提交的内容都 已经同步到磁盘上 事务的分类 扁平事务（Flat Transactions）：普通的事务就是扁平事务 带有保存点的扁平事务（Flat Transactions with Savepoints）：使用上 savepoint 的扁平事务 链事务（Chained Transactions）：当一个事务处理结束会自动开启下一个事务 嵌套事务（Nested Transactions）：一个大的事务中可以嵌套子事务 分布式事务（Distributed Transactions）：一个事务可能分布在网络中的不同节点中 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#什么是事务"},{"categories":null,"content":"\r什么是事务 事务：是一组逻辑操作单元，使数据从一种状态转变为另一种状态 事务的处理原则：是 一个工作单元 ，在一个事务执行多个操作时，要么同时成功要么同时失败 只有 InnoDB 存储引擎支持事务 事务的 ACID 特性 原子性（atomicity） 指事务是一个不可分割的工作单位，要么同时成功提交（commit）要么同时失败回滚（rollback） 一致性（consistency） 一致性是指事务执行前后，数据从一个 合法性状态 变换到另外一个 合法性状态 这种状态是 语义上 的而不是语法上的，跟具体的业务有关 隔离型（isolation） 一个事务内部的操作和使用的数据对 并发 的其它事务是隔离的，并发执行的各个事务 互不干扰 通过 锁 来保障隔离性 持久性（durability） 事务一旦提交了，它对数据的改变就是 永久性 的了 通过 事务日志 来保障持久性 事务的状态 活动的（active）：指事务对应的数据库操作是 正在执行过程中 部分提交的（partially committed）：事务已经在内存中执行完毕但是 还没有刷新到磁盘中 失败的（failed）：数据库在 活动的 / 部分提交的 过程中遇到了错误 无法继续执行 中止的（aborted）：在 失败的 状态之后，将数据 回滚 后就是中止的状态 提交的（committed）：将部分提交的内容都 已经同步到磁盘上 事务的分类 扁平事务（Flat Transactions）：普通的事务就是扁平事务 带有保存点的扁平事务（Flat Transactions with Savepoints）：使用上 savepoint 的扁平事务 链事务（Chained Transactions）：当一个事务处理结束会自动开启下一个事务 嵌套事务（Nested Transactions）：一个大的事务中可以嵌套子事务 分布式事务（Distributed Transactions）：一个事务可能分布在网络中的不同节点中 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的-acid-特性"},{"categories":null,"content":"\r什么是事务 事务：是一组逻辑操作单元，使数据从一种状态转变为另一种状态 事务的处理原则：是 一个工作单元 ，在一个事务执行多个操作时，要么同时成功要么同时失败 只有 InnoDB 存储引擎支持事务 事务的 ACID 特性 原子性（atomicity） 指事务是一个不可分割的工作单位，要么同时成功提交（commit）要么同时失败回滚（rollback） 一致性（consistency） 一致性是指事务执行前后，数据从一个 合法性状态 变换到另外一个 合法性状态 这种状态是 语义上 的而不是语法上的，跟具体的业务有关 隔离型（isolation） 一个事务内部的操作和使用的数据对 并发 的其它事务是隔离的，并发执行的各个事务 互不干扰 通过 锁 来保障隔离性 持久性（durability） 事务一旦提交了，它对数据的改变就是 永久性 的了 通过 事务日志 来保障持久性 事务的状态 活动的（active）：指事务对应的数据库操作是 正在执行过程中 部分提交的（partially committed）：事务已经在内存中执行完毕但是 还没有刷新到磁盘中 失败的（failed）：数据库在 活动的 / 部分提交的 过程中遇到了错误 无法继续执行 中止的（aborted）：在 失败的 状态之后，将数据 回滚 后就是中止的状态 提交的（committed）：将部分提交的内容都 已经同步到磁盘上 事务的分类 扁平事务（Flat Transactions）：普通的事务就是扁平事务 带有保存点的扁平事务（Flat Transactions with Savepoints）：使用上 savepoint 的扁平事务 链事务（Chained Transactions）：当一个事务处理结束会自动开启下一个事务 嵌套事务（Nested Transactions）：一个大的事务中可以嵌套子事务 分布式事务（Distributed Transactions）：一个事务可能分布在网络中的不同节点中 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的状态"},{"categories":null,"content":"\r什么是事务 事务：是一组逻辑操作单元，使数据从一种状态转变为另一种状态 事务的处理原则：是 一个工作单元 ，在一个事务执行多个操作时，要么同时成功要么同时失败 只有 InnoDB 存储引擎支持事务 事务的 ACID 特性 原子性（atomicity） 指事务是一个不可分割的工作单位，要么同时成功提交（commit）要么同时失败回滚（rollback） 一致性（consistency） 一致性是指事务执行前后，数据从一个 合法性状态 变换到另外一个 合法性状态 这种状态是 语义上 的而不是语法上的，跟具体的业务有关 隔离型（isolation） 一个事务内部的操作和使用的数据对 并发 的其它事务是隔离的，并发执行的各个事务 互不干扰 通过 锁 来保障隔离性 持久性（durability） 事务一旦提交了，它对数据的改变就是 永久性 的了 通过 事务日志 来保障持久性 事务的状态 活动的（active）：指事务对应的数据库操作是 正在执行过程中 部分提交的（partially committed）：事务已经在内存中执行完毕但是 还没有刷新到磁盘中 失败的（failed）：数据库在 活动的 / 部分提交的 过程中遇到了错误 无法继续执行 中止的（aborted）：在 失败的 状态之后，将数据 回滚 后就是中止的状态 提交的（committed）：将部分提交的内容都 已经同步到磁盘上 事务的分类 扁平事务（Flat Transactions）：普通的事务就是扁平事务 带有保存点的扁平事务（Flat Transactions with Savepoints）：使用上 savepoint 的扁平事务 链事务（Chained Transactions）：当一个事务处理结束会自动开启下一个事务 嵌套事务（Nested Transactions）：一个大的事务中可以嵌套子事务 分布式事务（Distributed Transactions）：一个事务可能分布在网络中的不同节点中 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的分类"},{"categories":null,"content":"\r事务的使用\r显式事务 开启事务 BEGIN; #或者 START TRANSACTION; 使用 START TRANSACTION 后面可以跟修饰符 READ ONLY：只读事务，只能查询不能增删改 READ WRITE：读写事务，可读可删改【默认】 WITH CONSISTENT SNAPSHOT：一致性读（可与 READ ONLY / READ WRITE 搭配使用） # 提交事务 COMMIT; # 回滚事务 ROLLBACK; # 将事务回滚到某个保存点 ROLLBACK TO [SAVEPOINT] 隐式事务 默认 autocommit 为开启状态，执行的 DML 语句即刻提交 当执行 start transaction 或 begin 则 autocommit 自动关闭 隐式提交的情况 执行数据定义 DDL 语言时，create、alter、drop 等语句时【DDL 操作不受 autocommit 影响】 隐式使用或修改 mysql 数据库中的表 当一个事务没有 commit 又开启了另一个事务时 当一个事务没有 commit 设置了 autocommit = on 时 使用 LOCK TABLES 、 UNLOCK TABLES 等关于锁定的语句 load data 往数据库批量导入数据时 执行关于 MySQL 复制的语句时 其它的一些语句 @@completion_type 设置执行事务后的操作 @@completion_type = 0 时，在 commit 之后还需再次开启下一个事务【默认】 @@completion_type = 1 时，开启链式事务，在 commit 之后会自动开启下一个事务，相当于 COMMIT AND CHAIN @@completion_type = 2 时，在 commit 之后会自动与服务器断连，相当于 COMMIT AND RELEASE ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的使用"},{"categories":null,"content":"\r事务的使用\r显式事务 开启事务 BEGIN; #或者 START TRANSACTION; 使用 START TRANSACTION 后面可以跟修饰符 READ ONLY：只读事务，只能查询不能增删改 READ WRITE：读写事务，可读可删改【默认】 WITH CONSISTENT SNAPSHOT：一致性读（可与 READ ONLY / READ WRITE 搭配使用） # 提交事务 COMMIT; # 回滚事务 ROLLBACK; # 将事务回滚到某个保存点 ROLLBACK TO [SAVEPOINT] 隐式事务 默认 autocommit 为开启状态，执行的 DML 语句即刻提交 当执行 start transaction 或 begin 则 autocommit 自动关闭 隐式提交的情况 执行数据定义 DDL 语言时，create、alter、drop 等语句时【DDL 操作不受 autocommit 影响】 隐式使用或修改 mysql 数据库中的表 当一个事务没有 commit 又开启了另一个事务时 当一个事务没有 commit 设置了 autocommit = on 时 使用 LOCK TABLES 、 UNLOCK TABLES 等关于锁定的语句 load data 往数据库批量导入数据时 执行关于 MySQL 复制的语句时 其它的一些语句 @@completion_type 设置执行事务后的操作 @@completion_type = 0 时，在 commit 之后还需再次开启下一个事务【默认】 @@completion_type = 1 时，开启链式事务，在 commit 之后会自动开启下一个事务，相当于 COMMIT AND CHAIN @@completion_type = 2 时，在 commit 之后会自动与服务器断连，相当于 COMMIT AND RELEASE ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#显式事务"},{"categories":null,"content":"\r事务的使用\r显式事务 开启事务 BEGIN; #或者 START TRANSACTION; 使用 START TRANSACTION 后面可以跟修饰符 READ ONLY：只读事务，只能查询不能增删改 READ WRITE：读写事务，可读可删改【默认】 WITH CONSISTENT SNAPSHOT：一致性读（可与 READ ONLY / READ WRITE 搭配使用） # 提交事务 COMMIT; # 回滚事务 ROLLBACK; # 将事务回滚到某个保存点 ROLLBACK TO [SAVEPOINT] 隐式事务 默认 autocommit 为开启状态，执行的 DML 语句即刻提交 当执行 start transaction 或 begin 则 autocommit 自动关闭 隐式提交的情况 执行数据定义 DDL 语言时，create、alter、drop 等语句时【DDL 操作不受 autocommit 影响】 隐式使用或修改 mysql 数据库中的表 当一个事务没有 commit 又开启了另一个事务时 当一个事务没有 commit 设置了 autocommit = on 时 使用 LOCK TABLES 、 UNLOCK TABLES 等关于锁定的语句 load data 往数据库批量导入数据时 执行关于 MySQL 复制的语句时 其它的一些语句 @@completion_type 设置执行事务后的操作 @@completion_type = 0 时，在 commit 之后还需再次开启下一个事务【默认】 @@completion_type = 1 时，开启链式事务，在 commit 之后会自动开启下一个事务，相当于 COMMIT AND CHAIN @@completion_type = 2 时，在 commit 之后会自动与服务器断连，相当于 COMMIT AND RELEASE ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#隐式事务"},{"categories":null,"content":"\r事务的隔离级别\r数据的并发问题 脏写（ Dirty Write ） 事务 A 修改了未提交的事务 B 的修改过的数据 A B 同时开启事务，A commit 之后 B 又 rollback 了，导致 A 提交的内容丢失 脏读（ Dirty Read ） 事务 A 读取了已经被 事务 B 更新但还没有被提交的字段 A B 同时开启事务，B 将数据修改之后没有提交，但是 A 读取到了 B 未提交的数据【脏读】，此时 B 回滚 … 不可重复读（ Non-Repeatable Read ） 事务 A 读取 了一个字段，然后事务 B 更新了该字段。 之后 A 再次读取同一个字段， 值就不同了 A 开启事务之后在未提交时 B 就修改了数据，导致 A 每次读到的内容都不一致 幻读（ Phantom ） 事务 A 从一个表中读取了一个字段, 然后事务 B 在该表中插入一些新的行。 之后，如果事务 A 再次读取同一个表, 就会多出几行 A 开启事务之后在未提交时读到了 B 修改前和修改后的值，A 好像发生了幻觉一样 严重性： 脏写 \u003e 脏读 \u003e 不可重复读 \u003e 幻读 事务的隔离级别 READ UNCOMMITTED ：读未提交 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果 不能避免脏读、不可重复读、幻读 READ COMMITTED ：读已提交 【Oracle 默认】 一个事务只能看见已经提交事务所做的改变。在 A 事务提交之后，B 事务中即可看到改变 可以避免脏读，但不可重复读、幻读问题仍然存在 REPEATABLE READ ：可重复读 【MySQL 默认】 事务 A 在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务 A 再读该数据，读到的还是原来的内容 可以避免脏读、不可重复读，但幻读问题仍然存在 SERIALIZABLE ：串行化读 确保事务可以从一个表中读取相同的行。在这个事务持续期间，禁止其他事务对该表执行插入、更新和删除操作 所有的并发问题都可以避免，但性能十分低下。能避免脏读、不可重复读和幻读 事务的使用 查看当前隔离级别 SELECT @@transaction_isolation; 设置隔离级别 SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL 隔离级别; #其中，隔离级别格式： \u003e READ UNCOMMITTED \u003e READ COMMITTED \u003e REPEATABLE READ \u003e SERIALIZABLE SET [GLOBAL|SESSION] TRANSACTION_ISOLATION = '隔离级别' #其中，隔离级别格式： \u003e READ-UNCOMMITTED \u003e READ-COMMITTED \u003e REPEATABLE-READ \u003e SERIALIZABLE 设置 global 的隔离级别对当前 session 无效 设置 session 的隔离级别：可以在已经开启的事务中间执行，但不会影响当前正在执行的事务 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的隔离级别"},{"categories":null,"content":"\r事务的隔离级别\r数据的并发问题 脏写（ Dirty Write ） 事务 A 修改了未提交的事务 B 的修改过的数据 A B 同时开启事务，A commit 之后 B 又 rollback 了，导致 A 提交的内容丢失 脏读（ Dirty Read ） 事务 A 读取了已经被 事务 B 更新但还没有被提交的字段 A B 同时开启事务，B 将数据修改之后没有提交，但是 A 读取到了 B 未提交的数据【脏读】，此时 B 回滚 … 不可重复读（ Non-Repeatable Read ） 事务 A 读取 了一个字段，然后事务 B 更新了该字段。 之后 A 再次读取同一个字段， 值就不同了 A 开启事务之后在未提交时 B 就修改了数据，导致 A 每次读到的内容都不一致 幻读（ Phantom ） 事务 A 从一个表中读取了一个字段, 然后事务 B 在该表中插入一些新的行。 之后，如果事务 A 再次读取同一个表, 就会多出几行 A 开启事务之后在未提交时读到了 B 修改前和修改后的值，A 好像发生了幻觉一样 严重性： 脏写 \u003e 脏读 \u003e 不可重复读 \u003e 幻读 事务的隔离级别 READ UNCOMMITTED ：读未提交 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果 不能避免脏读、不可重复读、幻读 READ COMMITTED ：读已提交 【Oracle 默认】 一个事务只能看见已经提交事务所做的改变。在 A 事务提交之后，B 事务中即可看到改变 可以避免脏读，但不可重复读、幻读问题仍然存在 REPEATABLE READ ：可重复读 【MySQL 默认】 事务 A 在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务 A 再读该数据，读到的还是原来的内容 可以避免脏读、不可重复读，但幻读问题仍然存在 SERIALIZABLE ：串行化读 确保事务可以从一个表中读取相同的行。在这个事务持续期间，禁止其他事务对该表执行插入、更新和删除操作 所有的并发问题都可以避免，但性能十分低下。能避免脏读、不可重复读和幻读 事务的使用 查看当前隔离级别 SELECT @@transaction_isolation; 设置隔离级别 SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL 隔离级别; #其中，隔离级别格式： \u003e READ UNCOMMITTED \u003e READ COMMITTED \u003e REPEATABLE READ \u003e SERIALIZABLE SET [GLOBAL|SESSION] TRANSACTION_ISOLATION = '隔离级别' #其中，隔离级别格式： \u003e READ-UNCOMMITTED \u003e READ-COMMITTED \u003e REPEATABLE-READ \u003e SERIALIZABLE 设置 global 的隔离级别对当前 session 无效 设置 session 的隔离级别：可以在已经开启的事务中间执行，但不会影响当前正在执行的事务 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据的并发问题"},{"categories":null,"content":"\r事务的隔离级别\r数据的并发问题 脏写（ Dirty Write ） 事务 A 修改了未提交的事务 B 的修改过的数据 A B 同时开启事务，A commit 之后 B 又 rollback 了，导致 A 提交的内容丢失 脏读（ Dirty Read ） 事务 A 读取了已经被 事务 B 更新但还没有被提交的字段 A B 同时开启事务，B 将数据修改之后没有提交，但是 A 读取到了 B 未提交的数据【脏读】，此时 B 回滚 … 不可重复读（ Non-Repeatable Read ） 事务 A 读取 了一个字段，然后事务 B 更新了该字段。 之后 A 再次读取同一个字段， 值就不同了 A 开启事务之后在未提交时 B 就修改了数据，导致 A 每次读到的内容都不一致 幻读（ Phantom ） 事务 A 从一个表中读取了一个字段, 然后事务 B 在该表中插入一些新的行。 之后，如果事务 A 再次读取同一个表, 就会多出几行 A 开启事务之后在未提交时读到了 B 修改前和修改后的值，A 好像发生了幻觉一样 严重性： 脏写 \u003e 脏读 \u003e 不可重复读 \u003e 幻读 事务的隔离级别 READ UNCOMMITTED ：读未提交 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果 不能避免脏读、不可重复读、幻读 READ COMMITTED ：读已提交 【Oracle 默认】 一个事务只能看见已经提交事务所做的改变。在 A 事务提交之后，B 事务中即可看到改变 可以避免脏读，但不可重复读、幻读问题仍然存在 REPEATABLE READ ：可重复读 【MySQL 默认】 事务 A 在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务 A 再读该数据，读到的还是原来的内容 可以避免脏读、不可重复读，但幻读问题仍然存在 SERIALIZABLE ：串行化读 确保事务可以从一个表中读取相同的行。在这个事务持续期间，禁止其他事务对该表执行插入、更新和删除操作 所有的并发问题都可以避免，但性能十分低下。能避免脏读、不可重复读和幻读 事务的使用 查看当前隔离级别 SELECT @@transaction_isolation; 设置隔离级别 SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL 隔离级别; #其中，隔离级别格式： \u003e READ UNCOMMITTED \u003e READ COMMITTED \u003e REPEATABLE READ \u003e SERIALIZABLE SET [GLOBAL|SESSION] TRANSACTION_ISOLATION = '隔离级别' #其中，隔离级别格式： \u003e READ-UNCOMMITTED \u003e READ-COMMITTED \u003e REPEATABLE-READ \u003e SERIALIZABLE 设置 global 的隔离级别对当前 session 无效 设置 session 的隔离级别：可以在已经开启的事务中间执行，但不会影响当前正在执行的事务 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的隔离级别-1"},{"categories":null,"content":"\r事务的隔离级别\r数据的并发问题 脏写（ Dirty Write ） 事务 A 修改了未提交的事务 B 的修改过的数据 A B 同时开启事务，A commit 之后 B 又 rollback 了，导致 A 提交的内容丢失 脏读（ Dirty Read ） 事务 A 读取了已经被 事务 B 更新但还没有被提交的字段 A B 同时开启事务，B 将数据修改之后没有提交，但是 A 读取到了 B 未提交的数据【脏读】，此时 B 回滚 … 不可重复读（ Non-Repeatable Read ） 事务 A 读取 了一个字段，然后事务 B 更新了该字段。 之后 A 再次读取同一个字段， 值就不同了 A 开启事务之后在未提交时 B 就修改了数据，导致 A 每次读到的内容都不一致 幻读（ Phantom ） 事务 A 从一个表中读取了一个字段, 然后事务 B 在该表中插入一些新的行。 之后，如果事务 A 再次读取同一个表, 就会多出几行 A 开启事务之后在未提交时读到了 B 修改前和修改后的值，A 好像发生了幻觉一样 严重性： 脏写 \u003e 脏读 \u003e 不可重复读 \u003e 幻读 事务的隔离级别 READ UNCOMMITTED ：读未提交 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果 不能避免脏读、不可重复读、幻读 READ COMMITTED ：读已提交 【Oracle 默认】 一个事务只能看见已经提交事务所做的改变。在 A 事务提交之后，B 事务中即可看到改变 可以避免脏读，但不可重复读、幻读问题仍然存在 REPEATABLE READ ：可重复读 【MySQL 默认】 事务 A 在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务 A 再读该数据，读到的还是原来的内容 可以避免脏读、不可重复读，但幻读问题仍然存在 SERIALIZABLE ：串行化读 确保事务可以从一个表中读取相同的行。在这个事务持续期间，禁止其他事务对该表执行插入、更新和删除操作 所有的并发问题都可以避免，但性能十分低下。能避免脏读、不可重复读和幻读 事务的使用 查看当前隔离级别 SELECT @@transaction_isolation; 设置隔离级别 SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL 隔离级别; #其中，隔离级别格式： \u003e READ UNCOMMITTED \u003e READ COMMITTED \u003e REPEATABLE READ \u003e SERIALIZABLE SET [GLOBAL|SESSION] TRANSACTION_ISOLATION = '隔离级别' #其中，隔离级别格式： \u003e READ-UNCOMMITTED \u003e READ-COMMITTED \u003e REPEATABLE-READ \u003e SERIALIZABLE 设置 global 的隔离级别对当前 session 无效 设置 session 的隔离级别：可以在已经开启的事务中间执行，但不会影响当前正在执行的事务 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:15:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#事务的使用-1"},{"categories":null,"content":"\rMySQL 事务日志 事务的隔离型（isolation）由 锁机制 实现 事务的原子性、一致性、持久性 由 redo、undo 日志 实现 REDO LOG 重做日志 提供再写入操作、恢复提交事务的页操作，用于保证 持久性 记录 物理级别 上的页修改操作，比如再 xx 页号 xx 偏移量写入了 xx 数据 UNDO LOG 回滚日志 回滚行记录到某个特定的版本，用于保证 原子性、一致性 用于 事务的回滚 和 一致性非锁定读 记录 逻辑操作 的日志，比如对某一行进行了 insert 操作，则记录相反的 delete 操作 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:16:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mysql-事务日志"},{"categories":null,"content":"\rredo 日志 对数据的变更都要先更新内存中的 缓冲池 ，然后以一定的频率将这些 脏页 刷新到磁盘中 当内存中的数据更改完成但还未刷盘时系统宕机，此时内存中的数据丢失，就要靠 redo 日志来保证持久性 redo 日志也要向磁盘写入数据，刷盘也是向磁盘写入数据，为什么还要用日志呢？ 日志的写入速度比较快，刷盘需要将一整个页 16K 的数据全部刷入（结合优点） 优点： 降低了刷盘的频率 占用空间小 使用顺序 I/O，效率比随机 I/O 快 事务执行过程中，redo 日志不断记录 redo 日志的组成： 重做日志的缓冲（redo log buffer）：保存在内存中，易丢失 最大值是 4096M，最小值为1M 重做日志文件（redo log file）：保存在硬盘中，是持久的 redo 日志的执行流程： ==**Write-Ahead Log (预先日志持久化) **==：在持久化一个数据页之前，先将内存中相应的日志页持久化 文件系统缓存 （page cache）：由操作系统提供的缓存机制，在数据刷新到磁盘前先进缓存加快刷新效率 innodb_flush_log_at_trx_commit 参数，设置 redo 数据从 redo log buffer 刷新到 redo log file 的策略 0 ：表示每次事务提交时不进行刷盘操作（系统默认 master thread 每隔 1s 进行一次重做日志的同步） 1 ：表示每次事务提交时都将进行同步，刷盘操作【默认值】 2 ：表示每次事务提交时都只把 redo log buffer 内容写入 page cache 由系统决定什么时候同步到磁盘文件 开启 3W 条事务的执行时间情况，当设置为 2 确实可提高效率，但丧失了事务 ACID 特性 写入 redo log buffer 每个语句包含若干个 mtr（Mini-Transaction）每个 mtr 包含若干个 redo 日志 在并发的写入 redo log buffer 时，mtr_t1_x 和 mtr_t2_x 会交替的依次写入 每个 log block 占用 512 字节，刚好是机械硬盘一个扇区的大小 写入 redo log file innodb_log_group_home_dir ：指定 redo log 文件组所在的路径，默认值为 ./ innodb_log_files_in_group：指明 redo log file 的个数，默认 2 最大 100 innodb_log_file_size：单个 redo log 文件设置大小，默认值为 48M 最大值为 512G（个数 * 大小 的值） 日志文件组： 日志文件组类似于循环链表的结构 当前记录的位置 没有赶上 当前擦除的位置时，前方的记录都是覆盖写入的。当前记录的位置 已经赶上 当前擦除的位置时，MySQL 得停下来，清空一些记录推进一下 write position 表示当前记录的位置 checkpoint 表示当前要擦除的位置 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:16:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#redo-日志"},{"categories":null,"content":"\rundo 日志 为保证事务原子性，在事务中 更新数据 的 前置操作 是要 先写入一个 undo log 当执行事务的中途出现 意外情况 需要将事务 回滚，此时就需要 undo 日志 当 插入了一条记录 时，会记录这条记录的 主键值，回滚时根据主键值 删除 即可 当 删除了一条记录 时，会记录这条记录的 全部数据，回滚时再将这些数据 插入 即可 当 修改了一条记录 时，会记录修改前的 旧值，回滚时执行相反的 更新 即可 作用： 回滚数据：回滚数据并非是物理回滚，只会将数据 逻辑恢复 到原先的样子。比如，insert 操作开辟了一个新的数据页，此时回滚并不会将此数据页删除，而是将此数据页上的这条记录行标记 delete 而已 MVCC：InnoDB 中 多版本并发开始是由 undo 日志控制的。当用户读取一条记录时，若该记录已经被其它事务占用，当前事务可以通过 undo 日志读取之前的行版本信息 存储结构 undo log 采用 回滚段(rollback segment) 管理 。每个回滚段记录了 1024 个 undo log segment (1024 次操作) 在 InnoDB 1.1 之前只支持一个回滚段 (只支持 1024 个并发) 在 InnoDB 1.1 开始支持 128 个回滚段 (支持 128 * 1024 个并发) 从 InnoDB 1.2 开始这些回滚段不仅限于存储在 ibdata (共享表空间) 中了 当一个事务开始时，会指定一个回滚段 (当前这个回滚段在同一时刻可能服务多个事务) 当数据修改时，原始的数据会复制到回滚段中。事务会不断填充盘区，当前盘区不够用时，会扩展新的盘区 回滚段存在 undo 表空间中，数据库可以存在多个 undo 表空间 (最少 2 个)，但同一时间只能使用一个 表空间 \u003e 段 \u003e 区 \u003e 页 \u003e 行 undo 页的重用：每一个事务都要申请一个 16KB 的 undo 页的话非常浪费空间，所以 undo log 在 commit 之后会先存在一个链表中，如果 undo 页小于 3/4 的话则重用 回滚段中数据分类： 未提交的回滚数据(uncommitted undo information) 不能被覆盖 已经提交但未过期的回滚数据(committed undo information) 可以被覆盖 事务已经提交并过期的数据(expired undo information) 优先被覆盖 事务提交之后不能立刻删除 undo log、页，因为可能还有其它线程需要使用，由一个单独的线程判断 链 中的 undo log 以及所在页 是否可以删除 undo 的分类： insert undo log：insert 操作的记录对其它线程不可见，在事务提交后可直接删除 update undo log：update 和 delete 的 undo log 需要提供 MVCC 机制，不能被直接删除 bin log 主要用于实现分布式中的主从复制 详细过程： 行格式中隐藏的列 当插入了一条数据时 对这条数据执行 update 时 当修改这条数据的主键值时 回滚时： 标记删除新的数据行，修改原数据行的 deletemark = 0 根据 undo 日志恢复更新的数据 标记删除数据行 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:16:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#undo-日志"},{"categories":null,"content":"\r锁 事务的隔离性由锁机制实现 T1 和 T2 事务并发操作，T1 获取到了锁，T2 进入等待状态 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#锁"},{"categories":null,"content":"\r并发问题的解决 对 读操作 采用 MVCC、对 写操作 加锁 MVCC (多版本并发控制) 就是生成一个 ReadView 找到复合条件的记录版本 在 读已提交 READ COMMITTED 中，事务的每次 SELECT 都生成一个 ReadView，ReadView 本身就保证了 事务只能读到已提交事务所做的更改 在 可重复读 REPEATABLE READ 中，事务中只有第一次 SELECT 才会生成 ReadView，之后的 SELECT 都 复用 这个 ReadView 读写操作 都加锁 对读和写操作都加锁，效率较低 一般情况下我们当然愿意采用 MVCC 来解决读写操作并发执行的问题，但是业务在某些特殊情况 下，要求必须采用加锁的方式执行 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#并发问题的解决"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#锁的分类"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#从数据操作的类型划分"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#读操作"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#写操作"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#从数据操作的粒度划分"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#表级锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#表级别的-s-锁和-x-锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#意向锁intention-lock"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#自增锁auto-inc-锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#元数据锁mdl锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#页级锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#行锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#记录锁record-locks"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#间歇锁gap-locks"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#临键锁next-key-locks"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#插入意向锁insert-intention-locks"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#从对待锁的态度上划分"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#悲观锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#乐观锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#从加锁的方式上划分"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#显式锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#隐式锁"},{"categories":null,"content":"\r锁的分类\r从数据操作的类型划分 读锁 ：也称为 共享锁 （Shared Lock）、英文用 S 表示。 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。 写锁 ：也称为 排他锁 （Exclusive Lock）、英文用 X 表示。 当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 读操作： 添加 S 共享 锁 SELECT ... LOCK IN SHARE MODE # 或 SELECT ... FOR SHARE 添加 X 排它 锁 SELECT ... FOR UPDATE 在 MySQL 5.7 中，在添加排他锁时如果获取不到锁会一直等待，直到 innodb_lock_wait_timeout 超时 在 MySQL 8 中，在添加共享锁或排它锁时，可以添加 NOWAIT 或 SKIP LOCKED (返回未被锁定的行) 跳过锁等待 / 锁定 写操作： DELETE 操作：先定位 B+ 树中这条记录的位置，添加 X锁，执行 delete mark 操作 UPDATE 操作： 未修改 主键值 且 修改后的存储空间 没变化：先定位 B+ 树中这条记录的位置，添加 X锁，在原位置进行更改 未修改 主键值 且 修改后的存储空间 有变化：先定位 B+ 树中这条记录的位置，添加 X锁 彻底删除该记录 (移入垃圾链表) ，通过 INSERT 的 隐式锁 保护插入一条新记录 修改了 主键值：相当于在原记录上进行 DELETE 操作后进行 INSERT 操作 INSERT 操作：插入数据时不需要加锁，通过 隐式锁 保证插入操作在提交前不被别的事务访问 从数据操作的粒度划分 锁粒度：当锁的范围越小则并发度越高，但管理锁需要消耗的资源就越多，因此需要在 并发响应 和 系统性能 两方面进行平衡 MyISAM 只支持表锁不支持行锁，InnoDB 表锁行锁都支持 表级锁：\r①表级别的 S 锁和 X 锁 对表进行增删改查时 InnoDB 都会使用行锁而不是表锁，但是在一些 DDL 语句执行时会使用表锁 (元数据锁) 在 autocommit=0，innodb_table_locks = 1 时手动获取表锁： LOCK TABLES t READ # InnoDB 存储引擎会对表 t 加表级别的 S 锁 LOCK TABLES t WRITE # InnoDB 存储引擎会对表 t 加表级别的 X 锁 UNLOCK TABLES; # 解除表锁 ②意向锁（intention lock） InnoDB 允许 行级锁 和 表级锁 并存，意向锁 是一种 表锁 意向锁： 当我们想要向表添加表级锁，但表中已经存在行级锁时则无法添加 那么如何知道表中是否存在行级锁呢？一条条遍历吗？ 由此引入意向锁，在表中添加行级锁时向 大一级的空间 同时添加一个 ( 对应的 S/X ) 意向锁 这是再想要添加表级锁只需要查看有没有意向锁存在即可 意向共享锁：事务有意向对表中的某些行加 共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排它锁：事务有意向对表中的某些行加 排它锁（S锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③自增锁（AUTO-INC 锁） 插入数据的模式 简单的插入：使用 insert into ... values .. , .. 预先确定插入的行数 批量的插入：使用 isnert into ... select ... 事先不知道插入的行数 混合模式的插入：使用 insert into ... values(1,'a'),(NULL,'b') 只指定了部分主键时 在向含有 auto_increment 主键的表中插入数据时，都需要获取 自增锁 一个事务在持有 AUTO-INC 锁时，其它插入语句都要被阻塞 当我们向有 auto_increment 的主键插入值的时候，每条语句都要竞争表级锁导致效率低下 innodb_autoinc_lock_mode = 0 ( “传统” 锁定模式 ) 每个事务都要争抢表级锁，并发能力差 innodb_autoinc_lock_mode = 1 ( “连续” 锁定模式 )【MySQL 5.7 前 默认】对于简单的插入会先获取 轻量锁 mutex 避免表级 AUTO-INC 锁 innodb_autoinc_lock_mode = 2 ( “交错” 锁定模式 )【MySQL 8.0 默认】可以保证自动递增得值是 唯一 且 单调递增 的，但是 混合 或 批量 插入时生成的值可能是不连续的，在使用 BIN LOG 实现主从复制时是不安全的 ④元数据锁（MDL锁） 在 MySQL 5.5 引入了 meta data lock，简称 MDL 锁 当对一个表做 增删改查 操作的时候，加 MDL读锁 当要对表做 结构变更 操作的时候，加 MDL 写锁 页级锁： 页锁介于表锁和行锁之间：开销、粒度、并发 页锁也会出现死锁 锁空间大小是有限的，当某个层级的锁数量超过阈值时，就会进行 锁升级 行锁：\r①记录锁（Record Locks） 当一个事务获取了一条记录的 S 型记录锁后，其他事务也 可以 继续获取该记录的 S 型记录锁，但 不可以 继续获取 X 型记录锁； 当一个事务获取了一条记录的 X 型记录锁后，其他事务既 不可以 继续获取该记录的 S 型记录锁，也 不可以 继续获取 X 型记录锁。 ②间歇锁（Gap Locks） 幻读问题：当前事务读取了 一个范围的记录，这时另外的事务插入了新记录，此时当前事务再次读取记录时发现了新记录（但第一次读取时还不存在这条记录，无法为 幻影记录 加锁） 间歇锁：为 id 为 8 的记录添加间隙锁，意味着 不允许别的事务在 id 值为 8 的记录前边的间隙插入新记录 从而解决幻读问题 细节： 为 id 为 5 的记录添加间隙锁，由于 5 处于 3 - 8 之间，所以此时的间隙锁和为 8 添加间隙锁一样 为 id 为 20 的记录添加间隙锁，对 15 - 20 有效，对 20 到 +∞ 同样有效 当两个事务同时为 8 添加间隙锁后，又都想 insert 3 - 8 之间的数据，这样会报 Deadlock 错误 这是由于 A 事务控制着 B 事务的阻塞，B 事务控制着 A 事务的阻塞，当 AB 同时处于阻塞状态时就会出现 死锁 ③临键锁（Next-Key Locks） 当我们又想使用间隙锁锁住开区间 (3, 8) 又想同时为 8 添加行锁 (3, 8]，此时就可以使用临键锁 begin; select * from student where id \u003c=8 and id \u003e 3 for update; ④插入意向锁（Insert Intention Locks） 针对于被间隙锁阻塞的插入操作，会生成插入意向锁 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁，负责阻塞结束的插入操作的继续执行 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁 从对待锁的态度上划分\r悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上 锁， 阻塞 其它线程 SELECT ... FOR UPDATE 此语句执行过程中 所有扫描到的行 都会被锁上，在使用悲观锁时要确保语句使用到了索引，而不是全表扫描，否则会加表锁 乐观锁 乐观锁不使用数据库自身的锁机制实现，而是通过程序实现 适用于多读的应用类型， 这样可以提高吞吐量 Java 的 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁 版本号机制 为表添加版本号字段，第一次读的时候获取 version 字段，在更新或删除操作时会执行 version + 1 操作，此时其它事务对这条数据进行操作则不会成功 UPDATE ... SET version = version + 1 WHERE version = version 时间戳机制 和版本号类似，通过比对当前更新 当前数据的时间戳字段值 和 更新前的时间戳字段值 是否相同来判断是否存在版本冲突 当采用 读写分离、主从复制 架构时，由于两个数据库的同步问题可能会导致版本会不一致的情况，此时可以强制读取 master 的数据解决 当同一数据需要频繁的情况，可以采用库存作为乐观锁的实现字段，UPDATE ... WHERE 库存数量 - 购买数量 \u003e 0 解决超卖问题 从加锁的方式上划分\r显式锁 显式的使用了加锁的语句：lock in share mode for update 隐式锁 一般情况下 插入 一条数据是不需要加锁的，但是需要添加 隐式锁 对数据进行保护 在另一个事务的插入操作碰到了当前事务的插入操作时，才会触发隐式锁阻塞自己（延迟加锁） 全局锁 让整个库处于只读状态，阻塞其它 DML DDL 操作，应用场景：全库逻辑备份 Flush tables with read lock ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#全局锁"},{"categories":null,"content":"\r锁的内存结构 并不是每行数据都独立生成一个锁结构，复合条件的记录会被放到一个锁结构中 在同一个事务中进行加锁操作 被加锁的记录在同一个页面中 加锁的类型一致 等待状态一致 锁所在的事务信息 记录哪个事务生成的锁 是一个指针，指向关于该事务的更多信息，如 事务 id 等 索引信息 对于 行锁 ，记录加锁的记录是属于哪个索引的，也是一个指针 表锁／行锁信息 表锁： 记载着是对哪个表加的锁，还有其他的一些信息。 行锁： Space ID ：记录所在表空间 Page Number ：记录所在页号 n_bits ：对于行锁来说，一条记录就对应着一个比特位，一个页面中包含很多记录，用不同的比特位来区分到底是哪一条记录加了锁。为此在行锁结构的末尾放置了 一堆比特位，这个 n_bits 属性代表使用了多少比特位。n_bits 的值一般都比页面中记录条数多一些。主要是为了之后在页面中插入了新记录后也不至于重新分配锁结构 type_mode 锁的模式（ lock_mode ） LOCK_IS（十进制的 0 ）：表示共享意向锁，也就是 IS 锁 LOCK_IX（十进制的 1 ）：表示独占意向锁，也就是 IX 锁 LOCK_S （十进制的 2 ）：表示共享锁，也就是 S 锁 LOCK_X （十进制的 3 ）：表示独占锁，也就是 X 锁 LOCK_AUTO_INC （十进制的 4 ）：表示 AUTO-INC 锁 在InnoDB存储引擎中 LOCK_IS，LOCK_IX，LOCK_AUTO_INC 都算是表级锁的模式，LOCK_S 和 LOCK_X 既可以算是表级锁的模式，也可以是行级锁的模式。 锁的类型（ lock_type ）现阶段只有第5位和第6位被使用 LOCK_TABLE （十进制的 16 ），也就是当第 5 个比特位置为 1 时，表示表级锁 LOCK_REC （十进制的 32 ），也就是当第 6 个比特位置为 1 时，表示行级锁 行锁的具体类型（ rec_lock_type ） 只有在 lock_type 的值为 LOCK_REC 时，也就是只有在该锁为行级锁时，才会被细分为更多的类型： LOCK_ORDINARY （十进制的 0 ）：表示 next-key 锁 LOCK_GAP （十进制的 512 ）：也就是当第 10 个比特位置为 1 时，表示 gap 锁 LOCK_REC_NOT_GAP （十进制的 1024 ）：也就是当第 11 个比特位置为 1 时，表示正经记录锁 LOCK_INSERT_INTENTION （十进制的 2048 ）：也就是当第12个比特位置为1时，表示插入意向锁。 … … LOCK_WAIT （十进制的 256 ） ： 当 第 9 个比特位置 为 1 时，表示 is_waiting 为 true ，也就是当前事务尚未获取到锁，处在等待状态 当这个比特位为 0 时，表示 is_waiting 为 false ，也就是当前事务获取锁成功 其他信息 为了更好的管理系统运行过程中生成的各种 锁结构 而设计了各种哈希表和链表 一堆比特位 对于行锁来说，比特位的数量是由上边提到的 n_bits 属性表示的。InnoDB 数据页中的每条记录在 记录头信息 中都包含一个 heap_no 属性，伪记录 Infimum 的 heap_no 值为 0 ， Supremum 的 heap_no 值为 1 ，之后每插入一条记录， heap_no 值就增 1。 锁结构最后的一堆比特位就对应着一个页面中的记录，一个比特位映射一个 heap_no ，即一个比特位映射到页内的一条记录 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#锁的内存结构"},{"categories":null,"content":"\r锁监控 查看锁的监控情况 show status like 'innodb_row_lock%'; 查看锁的详细监控数据 # MySQL 5.7 只能看到正在阻塞的事务的信息, MySQL 8 可以看到所有事务信息 SELECT * FROM information_schema.INNODB_TRX\\G; ## 查看所有锁的信息 # MySQL 5.7 中 SELECT * FROM information_schema.INNODB_LOCKS\\G; # MySQL 8 中 SELECT * FROM performance_schema.data_locks\\G; ## 查看等待中的锁的信息 # MySQL 5.7 中 SELECT * FROM information_schema.INNODB_LOCK_WAITS\\G; # MySQL 8 中 SELECT * FROM performance_schema.data_lock_waits\\G; ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:17:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#锁监控"},{"categories":null,"content":"\r多版本并发控制","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#多版本并发控制"},{"categories":null,"content":"\rMVCC MVCC 即 多版本并发控制 （Multiversion Concurrency Control） 解决 读-写 / 写-读 并下情况下的 脏读、不可重复读、幻读 问题 MVCC 中的 读 / 写 不冲突，针对于 写 采用加锁的方式，针对于 读 采用 ReadView 管理记录版本的方式解决 快照读 快照读又叫 一致性读 ，读取的时快照数据【解决 读/写 问题中的 读】 不加锁的简单的 SELECT 语句就是快照读 由于是基于多版本，快照读 读到的数据不一定是最新的版本 快照读 的前提：不是串行的隔离级别，否则会退化成当前读 当前读 当前读 读的是最新版本最新数据【解决 读/写 问题中的 写】 加了锁的 SELECT 和 DML 操作都是当前读 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mvcc"},{"categories":null,"content":"\rMVCC MVCC 即 多版本并发控制 （Multiversion Concurrency Control） 解决 读-写 / 写-读 并下情况下的 脏读、不可重复读、幻读 问题 MVCC 中的 读 / 写 不冲突，针对于 写 采用加锁的方式，针对于 读 采用 ReadView 管理记录版本的方式解决 快照读 快照读又叫 一致性读 ，读取的时快照数据【解决 读/写 问题中的 读】 不加锁的简单的 SELECT 语句就是快照读 由于是基于多版本，快照读 读到的数据不一定是最新的版本 快照读 的前提：不是串行的隔离级别，否则会退化成当前读 当前读 当前读 读的是最新版本最新数据【解决 读/写 问题中的 写】 加了锁的 SELECT 和 DML 操作都是当前读 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#快照读"},{"categories":null,"content":"\rMVCC MVCC 即 多版本并发控制 （Multiversion Concurrency Control） 解决 读-写 / 写-读 并下情况下的 脏读、不可重复读、幻读 问题 MVCC 中的 读 / 写 不冲突，针对于 写 采用加锁的方式，针对于 读 采用 ReadView 管理记录版本的方式解决 快照读 快照读又叫 一致性读 ，读取的时快照数据【解决 读/写 问题中的 读】 不加锁的简单的 SELECT 语句就是快照读 由于是基于多版本，快照读 读到的数据不一定是最新的版本 快照读 的前提：不是串行的隔离级别，否则会退化成当前读 当前读 当前读 读的是最新版本最新数据【解决 读/写 问题中的 写】 加了锁的 SELECT 和 DML 操作都是当前读 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:1","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#当前读"},{"categories":null,"content":"\rReadView 由于 MVCC 的存在，可重复读 隔离级别还解决了 幻读 问题 MVCC 的实现依赖于：隐藏字段、Undo Log、Read View 由 隐藏字段 的 DB_ROLL_PTR 指向的 undo log 版本链 trx_id：此次修改的事务 ID rol_pointer：指向上一次修改的 undo 日志 Read View 就是一个事务在 MVCC 机制进行快照读操作时产生的读视图 creator_trx_id 创建这个 Read View 的事务 ID 事务 ID：SELECT 操作的事务 ID 为 0，INSERT、DELETE、UPDATE 操作的事务 ID 是递增的 trx_ids 表示在生成 ReadView 时当前系统中 活跃（启动但未提交的事务） 的读写事务的 事务 ID 列表 up_limit_id 活跃的事务中最小的事务 ID，也就是最早 begin 且没提交的事务 low_limit_id 系统最大的事务 ID 值 + 1（为下一个事务分配的 ID 值），注意并不是正在活跃的事务ID Read View 的规则，判断记录的某个版本是否可见 如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 相同 【可以访问】 就是说当前事务正在访问被自己修改过的数据 如果被访问版本的 trx_id 属性值 小于 ReadView 中的 up_limit_id 值【可以访问】 就是说当前正在访问的并不是活跃的事务是已经提交过的 如果被访问版本的 trx_id 属性值 大于或等于 ReadView 中的 low_limit_id 值【不能访问】 就是说当前正在访问的是后来事务修改的 如果被访问版本的 trx_id 属性值在 ReadView 的 up_limit_id 和 low_limit_id 之间 如果 trx_id 在 trx_ids 列表中，就是说这个事务还没提交【不能访问】 如果 trx_id 不在 trx_ids 列表中，就是说这个事务已经提交【可以访问】 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:2","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#readview"},{"categories":null,"content":"\rMVCC 执行流程 首先获取事务自己的版本号，也就是事务 ID 获取 ReadView 查询得到的数据，然后与 ReadView 中的事务版本号进行比较 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照 最后返回符合规则的数据（找到最后 已经提交的事务提交的 记录） 在隔离级别为 读已提交 时，每读取一次就获取一个 Read View 当隔离级别为 可重复读 的，只在事务开启时获取一个 Read View ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:3","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#mvcc-执行流程"},{"categories":null,"content":"\r幻读的解决 InnoDB 引擎的 可重复读 隔离级别下通过 MVCC 解决了幻读问题 由于可重复读的 Read View 只在事务开启时获取，根据 Read View 的事务版本号比较规则 可以实现：后来事务提交的数据不能访问、未提交事务的数据不能访问，从而解决幻读问题 ","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:18:4","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#幻读的解决"},{"categories":null,"content":"\r其它数据库日志","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:19:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#其它数据库日志"},{"categories":null,"content":"\r主从复制","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:20:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#主从复制"},{"categories":null,"content":"\r数据库备份与恢复","date":"2022-08-22","objectID":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/:21:0","series":null,"tags":null,"title":"MySQL自学笔记进阶md版","uri":"/mysql%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E8%BF%9B%E9%98%B6md%E7%89%88/#数据库备份与恢复"},{"categories":null,"content":"\rVue-Router 大连交通大学 信息学院 刘嘉宁 笔记摘自 表严肃 ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#vue-router"},{"categories":null,"content":"\r什么是 Vue 路由 是一个 Vue 的库，可以快速开发一个单页应用 指导网页层级、定位资源 避免后端通信整页刷新，做到不丢失状态、不丢失数据 ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#什么是-vue-路由"},{"categories":null,"content":"\r使用 Vue-Router 导入 Vue 和 Vue-Router 的 js 文件 \u003cscript src=\"vue.js\"\u003e\u003c/script\u003e \u003cscript src=\"vue-router..js\"\u003e\u003c/script\u003e 定义路由 js 文件 var routes = [ { path:'/', component:{ template:` \u003cdiv\u003e \u003ch1\u003e首页\u003c/h1\u003e \u003c/div\u003e ` } }, { path:'/about', component:{ template:` \u003cdiv\u003e \u003ch1\u003e关于\u003c/h1\u003e \u003c/div\u003e ` } } ]; // 这是 Vue-Router 暴露出来的构造器 var router = new VueRouter({ routes: routes }); // 创建 Vue 对象,指定 router 路由 new Vue({ el:'#app', router: router }); 设定路由链接及显示 \u003cdiv id=\"app\"\u003e \u003cdiv\u003e \u003c!-- 指定对应的路由地址 --\u003e \u003crouter-link to=\"/\"\u003e首页\u003c/router-link\u003e \u003crouter-link to=\"/about\"\u003e关于\u003c/router-link\u003e \u003c/div\u003e \u003cdiv\u003e \u003c!-- 路由显示的地方 --\u003e \u003crouter-view\u003e\u003c/router-view\u003e \u003c/div\u003e \u003c/div\u003e ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#使用-vue-router"},{"categories":null,"content":"\r传参 传递参数 \u003crouter-link to=\"/user/王梓良\"\u003e王梓良\u003c/router-link\u003e \u003crouter-link to=\"/user/沈斌\"\u003e沈斌\u003c/router-link\u003e 获取参数 { // 设置形参 name path:'/user/:name', component:{ template:` \u003cdiv\u003e \u003c!-- 获取 result风格 传递的参数 --\u003e \u003ch1\u003e关于 用户: {{$route.params.name}}\u003c/h1\u003e \u003c!-- 获取 ?age=18\u0026b=1 传递的参数: http://localhost/web/user/张三?age=18 --\u003e \u003ch1\u003e关于 用户: {{$route.query.age}}\u003c/h1\u003e \u003c/div\u003e ` } } ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#传参"},{"categories":null,"content":"\r子路由 在父级路显示界面由中添加子路由显示界面 // 设置形参 name path:'/user/:name', component:{ template:` \u003cdiv\u003e \u003c!-- 子路由方式1 --\u003e \u003c!--\u003crouter-link to=\"more\" append\u003e more \u003c/router-link\u003e--\u003e \u003c!--\u003crouter-view\u003e\u003c/router-view\u003e--\u003e \u003c!-- 子路由方式2 【推荐】 --\u003e \u003crouter-link :to=\"'/user/' + $route.params.name + '/more'\"\u003e more \u003c/router-link\u003e \u003crouter-view\u003e\u003c/router-view\u003e \u003c/div\u003e ` }, children:[ { path:'more', component:{ template:` \u003cdiv\u003e 用户 {{$route.params.name}} 的更多信息 \u003c/div\u003e ` } } ] ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#子路由"},{"categories":null,"content":"\r传参 , { // 设置形参 name path:'/user/:name', name:'user', //为路由指定名字 component:{ template:` \u003cdiv\u003e \u003c/div\u003e ` } } /*======================================================*/ // 创建 Vue 对象,指定 router 路由 new Vue({ el:'#app', router: router, methods:{ surf:function(){ this.router.push({ name:\"user\", // 同 为路由指定的名字 params:{ name:'沈斌' } }) } } }); ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#传参-1"},{"categories":null,"content":"\r命名视图 可以同时存在多个 \u003crouter-view\u003e \u003crouter-view name=\"sidebar\"\u003e\u003c/router-view\u003e \u003crouter-view name=\"content\"\u003e\u003c/router-view\u003e /*========================================================*/ , { path:'/about', component:{ sidebar:{ template:` \u003cdiv\u003e \u003ch1\u003esidebar\u003c/h1\u003e \u003c/div\u003e ` }, content:{ template:` \u003cdiv\u003e \u003ch1\u003econtent\u003c/h1\u003e \u003c/div\u003e ` } } } ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#命名视图"},{"categories":null,"content":"\r导航钩子 用来控制访问权限 略 ","date":"2022-05-19","objectID":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"VueRouter自学笔记","uri":"/vuerouter%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#导航钩子"},{"categories":null,"content":"\r校园智慧后勤管理系统 大连交通大学 信息学院 张箬晗、刘嘉宁 一个简易的校园后勤管理系统，学习、练习的项目笔记 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#校园智慧后勤管理系统"},{"categories":null,"content":"\r项目技术栈 前端 Vue Vue-router Element-ui axios 后端 SpringMVC Mybatis Shiro 数据库：MySQL、Redis 版本管理：git 项目管理：Maven ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#项目技术栈"},{"categories":null,"content":"\rVue 环境的配置 安装 Vue-cli 环境 链接：Vue 官网的 Vue Cli 安装教程 先安装 node.js 环境，在安装时会自动配置 node 和 npm 全局变量 链接：node.js 官网 使用 node -v npm -v 命令查看是否安装成功 在文件夹下打开 cmd 命令行执行 vue ui 命令开始创建 vue 项目 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-环境的配置"},{"categories":null,"content":"\rVue 项目环境介绍 使用 idea 打开刚刚创建的 vue 项目 node_modules：npm 加载的项目依赖模块， 存放项目的所有依赖 public：一些公共的内容 src：项目的源码，存放开发者写的代码 assets：存放图片 components：存放组件文件（一些可复用，非独立的页面） router： 存放了路由的 js 文件，index.js store：实现全局存储 views：存放界面 App.vue：项目入口文件，是一个 Vue 组件，也是项目的第一个 Vue 组件 main.js：核心文件，相当于 Java中的 main 方法，是整个项目的入口 js .xxxx：配置文件，包括git配置和语法配置等 package.json：项目配置文件，定义了项目的所有依赖，包括开发时依赖和发布时依赖 README.md：说明文档 在 idea 中添加 npm 的运行配置并设置 Script 为 serve 即可让 idea 一键启动 vue 项目 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-项目环境介绍"},{"categories":null,"content":"\relement-ui 环境安装 在 vue 项目下 执行命令 npm i element-ui -S 安装成功后在 package.json 中可以看到相应记录 在 main.js 中导入 elememt-ui import ElementUI from 'element-ui'; import 'element-ui/lib/theme-chalk/index.css'; Vue.use(ElementUI); ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#element-ui-环境安装"},{"categories":null,"content":"\raxios 环境安装 在 vue 项目下 执行命令 npm install axios -S 安装成功后在 package.json 中可以看到相应记录 在 main.js 中导入 axios import axios from 'axios'; Vue.prototype.$axios = axios ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#axios-环境安装"},{"categories":null,"content":"\r后端 Vue 跨域问题解决 在 spring 的配置文件中添加 \u003c!-- 允许所有请求通过, 解决 vue 跨域问题 --\u003e \u003cmvc:cors\u003e \u003cmvc:mapping path=\"/**\" allowed-origin-patterns=\"*\" allowed-methods=\"POST,GET,OPTIONS,DELETE,PUT,PATCH\" allowed-headers=\"Content-Type,Access-Control-Allow-Headers,Authorization,X-Requested-With\" allow-credentials=\"true\"/\u003e \u003c/mvc:cors\u003e 也可以使用精简写法 \u003cmvc:cors\u003e \u003cmvc:mapping path=\"/**\" /\u003e \u003c/mvc:cors\u003e ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端-vue-跨域问题解决"},{"categories":null,"content":"\r后端 Shiro 配置 在 config 包下创建配置类 @Configuration public class ShiroConfig { //1.创建 ShiroFilter 负责拦截所有请求 //将 name 设为与 web.xml 中 filter-name 一致, 让过滤器自动找到这个 bean @Bean(name = \"shiroFilter\") public ShiroFilterFactoryBean getShiroFilterFactoryBean(DefaultWebSecurityManager defaultWebSecurityManager){ //创建过滤工厂实例, 设置默认安全管理器 ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(defaultWebSecurityManager); Map\u003cString, String\u003e map = new HashMap\u003c\u003e(); //配置系统的受限资源: 所有请求 map.put(\"/test2.do\", \"authc\"); // authc 代表资源需要认证和授权 //配置系统的公共资源 map.put(\"/test1.do\", \"anon\"); shiroFilterFactoryBean.setFilterChainDefinitionMap(map); //设置被拦截时跳转的地址 shiroFilterFactoryBean.setLoginUrl(\"/login.do\"); return shiroFilterFactoryBean; } //2.创建安全管理器 @Bean public DefaultWebSecurityManager getDefaultWebSecurityManager(Realm realm){ DefaultWebSecurityManager defaultWebSecurityManager = new DefaultWebSecurityManager(); defaultWebSecurityManager.setRealm(realm); return defaultWebSecurityManager; } //3.创建自定义 Realm @Bean public Realm getRealm(){ return new CustomerRealm(); } } 在 shiro.realms 包下创建 Realm 实现类 public class CustomerRealm extends AuthorizingRealm { //验证是否使用的是自定义 token @Override public boolean supports(AuthenticationToken token) { return token instanceof JwtToken; } //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principal) { return null; } //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { return null; } } 在 web.xml 中配置启用 Shiro 过滤器 \u003c!-- shiro过虑器，DelegatingFilterProxy通过代理模式 关联spring容器中的bean和filter --\u003e \u003cfilter\u003e \u003cfilter-name\u003eshiroFilter\u003c/filter-name\u003e \u003cfilter-class\u003eorg.springframework.web.filter.DelegatingFilterProxy\u003c/filter-class\u003e \u003c!-- 设置true由servlet容器控制filter的生命周期 --\u003e \u003cinit-param\u003e \u003cparam-name\u003etargetFilterLifecycle\u003c/param-name\u003e \u003cparam-value\u003etrue\u003c/param-value\u003e \u003c/init-param\u003e \u003c!-- 设置spring容器filter的bean id，如果不设置则找与filter-name一致的bean--\u003e \u003c!-- \u003cinit-param\u003e--\u003e \u003c!-- \u003cparam-name\u003etargetBeanName\u003c/param-name\u003e--\u003e \u003c!-- \u003cparam-value\u003eshiroFilter\u003c/param-value\u003e--\u003e \u003c!-- \u003c/init-param\u003e--\u003e \u003c/filter\u003e \u003cfilter-mapping\u003e \u003cfilter-name\u003eshiroFilter\u003c/filter-name\u003e \u003curl-pattern\u003e/*\u003c/url-pattern\u003e \u003c/filter-mapping\u003e ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端-shiro-配置"},{"categories":null,"content":"\rShiro 认证配置 接收 token 解析 token 验证用户名密码：详见 后端 md5 配置 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { //向下转型 token 为自定义 token 类型 JwtToken jwtToken = (JwtToken) token; //获取 token 实例中的 token 信息 String jwt = (String) jwtToken.getPrincipal(); //使用工具类解析 token Claims claims = JwtUtil.parseJWT(jwt); //获取解析后的用户名 String username = claims.getId(); User user = userService.getUserByUsername(username); if (user == null){ return null; } return new SimpleAuthenticationInfo( username, //用户名 user.getPassword(), //密码 ByteSource.Util.bytes(user.getSalt()), //盐 this.getName()); } ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:1","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#shiro-认证配置"},{"categories":null,"content":"\rShiro 授权配置 在 com.djtu.config 下的 ShiroConfig 配置类中添加注解驱动 // 开启 @RequiresRoles、@RequiresPermissions 注解代理 @Bean public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() { DefaultAdvisorAutoProxyCreator app = new DefaultAdvisorAutoProxyCreator(); app.setProxyTargetClass(true); return app; } @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) { AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; } 获取当前用户角色信息 获取当前用户权限信息 设置授权信息 //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principal) { //这里只有在登录之后才会执行 String username = (String) principal.iterator().next(); Set\u003cString\u003e roles = roleService.getRoleByUsername(username); Set\u003cString\u003e permissions = permissionService.getPermissionByUsername(username); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); info.addRoles(roles); info.addStringPermissions(permissions); return info; } ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:2","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#shiro-授权配置"},{"categories":null,"content":"\rShiro 授权无效问题 问题： 在前后端分离场景下，产生跨域问题 cookie 无法存储到浏览器中，导致 Shiro 无法认定多次访问是否都是出自于同一个用户 所以在有授权注解标注的方法运行时，抛出 UnauthenticatedException 未登录异常 解决： 加入 Shiro 的 Session 管理器，并在每次请求时都带上一个识别身份信息的值：SessionId 每次请求都会经过 Session 管理器并判断 SessionId 的值是否为已登录用户后，再进入授权验证方法执行授权 在 com.djtu.shiro.session.ShiroSession 下创建 ShiroSession 类 /** * 目的: shiro 的 session 管理 * 自定义session规则，实现前后分离，在跨域等情况下使用token 方式进行登录验证才需要，否则没必须使用本类。 * shiro默认使用 ServletContainerSessionManager 来做 session 管理，它是依赖于浏览器的 cookie 来维护 session 的, * 调用 storeSessionId 方法保存sessionId 到 cookie中 * 为了支持无状态会话，我们就需要继承 DefaultWebSessionManager * 自定义生成sessionId 则要实现 SessionIdGenerator * */ public class ShiroSession extends DefaultWebSessionManager { /** * 定义的请求头中使用的标记key，用来传递 token */ private static final String AUTH_TOKEN = \"authToken\"; private static final String REFERENCED_SESSION_ID_SOURCE = \"Stateless request\"; public ShiroSession() { super(); //设置 shiro session 失效时间，默认为30分钟，这里现在设置为15分钟 setGlobalSessionTimeout(MILLIS_PER_MINUTE * 15); } /** * 获取sessionId，原本是根据sessionKey来获取一个sessionId * 重写的部分多了一个把获取到的token设置到request的部分。这是因为app调用登陆接口的时候，是没有token的，登陆成功后，产生了token,我们把它放到request中，返回结 * 果给客户端的时候，把它从request中取出来，并且传递给客户端，客户端每次带着这个token过来，就相当于是浏览器的cookie的作用，也就能维护会话了 * @param request ServletRequest * @param response ServletResponse * @return Serializable */ @Override protected Serializable getSessionId(ServletRequest request, ServletResponse response) { //获取请求头中的 AUTH_TOKEN 的值，如果请求头中有 AUTH_TOKEN 则其值为sessionId。shiro就是通过sessionId 来控制的 String sessionId = WebUtils.toHttp(request).getHeader(AUTH_TOKEN); if (StringUtils.isEmpty(sessionId)){ //如果没有携带id参数则按照父类的方式在cookie进行获取sessionId return super.getSessionId(request, response); } else { //请求头中如果有 authToken, 则其值为sessionId request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_SOURCE, REFERENCED_SESSION_ID_SOURCE); //sessionId request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID, sessionId); request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_IS_VALID, Boolean.TRUE); return sessionId; } } } 在 Shiro 配置类中添加 SessionManager 的 Bean // 必须使用session管理器，才能够解决前后端分离shiro的subject未认证的问题 @Bean public SessionManager sessionManager(){ //将我们继承后重写的shiro session 注册 ShiroSession shiroSession = new ShiroSession(); //如果后续考虑多tomcat部署应用，可以使用shiro-redis开源插件来做session 的控制，或者nginx 的负载均衡 shiroSession.setSessionDAO(new EnterpriseCacheSessionDAO()); return shiroSession; } 在 SecurityManager 的 Bean 方法中为安全管理器添加 SessionManager securityManager.setSessionManager(sessionManager); 在控制层登录方法中获取当前认证用户 SessionId 并传给前端 String sessionId = (String) subject.getSession().getId(); resultMap.put(\"sessionId\", sessionId); 在前端接收到 sessionId 后将其存储在 localStorage 中 localStorage.setItem(\"sessionId\", resp.data.data.sessionId); //向全局存储中中存值 在 Vue 的 axios.js 文件中添加 axios 的前置拦截，让除登录以外的请求在请求头上都加上 sessionId //前置拦截 axios.interceptors.request.use( config =\u003e { // 给每个请求都加上 authToken 请求头 if (config.url !== '/user/login.do') { config.headers.authToken = localStorage.getItem('sessionId'); } return config; }, error =\u003e { return Promise.reject(error); } ); 解决加了 authToken 的请求头的请求出现的跨域问题 在跨域配置文件中添加 authToken 到 allowed-headers \u003c!-- 允许所有请求通过, 解决 vue 跨域问题 --\u003e \u003cmvc:cors\u003e \u003cmvc:mapping path=\"/**\" allowed-origin-patterns=\"*\" allowed-methods=\"POST,GET,OPTIONS,DELETE,PUT,PATCH\" allowed-headers=\"Content-Type,Access-Control-Allow-Headers,Authorization,X-Requested-With,authToken\" allow-credentials=\"true\"/\u003e \u003c/mvc:cors\u003e ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:3","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#shiro-授权无效问题"},{"categories":null,"content":"\r后端 JWT 配置 在 com.djtu.utils 下创建 JwtUtil 类，用于 jwt 加密、解密、验证 jwt 是否过期 public class JwtUtil { //加密 public static String createJWT(String username, String issuer, String subject, long ttlMillis) { //The JWT signature algorithm we will be using to sign the token SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); //We will sign our JWT with our ApiKey secret byte[] apiKeySecretBytes = DatatypeConverter.parseBase64Binary(\"1sf12sds21ie1inecs078j\"); Key signingKey = new SecretKeySpec(apiKeySecretBytes, signatureAlgorithm.getJcaName()); //Let's set the JWT Claims JwtBuilder builder = Jwts.builder().setId(username) .setIssuedAt(now) .setSubject(subject) .setIssuer(issuer) .signWith(signatureAlgorithm, signingKey); //if it has been specified, let's add the expiration if (ttlMillis \u003e= 0) { long expMillis = nowMillis + ttlMillis; Date exp = new Date(expMillis); builder.setExpiration(exp); } //Builds the JWT and serializes it to a compact, URL-safe string return builder.compact(); } //解密 public static Claims parseJWT(String jwt) { //This line will throw an exception if // it is not a signed JWS (as expected) try { Claims claims = Jwts.parser() .setSigningKey(DatatypeConverter.parseBase64Binary(\"1sf12sds21ie1inecs078j\")) .parseClaimsJws(jwt) .getBody(); return claims; }catch (ExpiredJwtException e){ return null; } // System.out.println(\"ID: \" + claims.getId()); // System.out.println(\"Subject: \" + claims.getSubject()); // System.out.println(\"Issuer: \" + claims.getIssuer()); // System.out.println(\"Expiration: \" + claims.getExpiration()); } // 判断是否过期 public static boolean isTokenExpired(Date expiration) { return expiration.before(new Date()); } } 在 com.djtu.token 下创建 JwtToken 类，里面包装了加密后的 token 字符串、密码、等 package com.djtu.token; import com.djtu.utils.JwtUtil; import lombok.Data; import org.apache.shiro.authc.HostAuthenticationToken; import org.apache.shiro.authc.RememberMeAuthenticationToken; import org.springframework.stereotype.Component; import java.util.Arrays; /** * 自定义 token 类, 使用 jwt 传来的 token 进行身份验证 * 具体实现仿照了 UsernamePasswordToken 类 */ @Data @Component public class JwtToken implements HostAuthenticationToken, RememberMeAuthenticationToken { private String token; private char[] password; private boolean rememberMe; private String host; @Override public Object getPrincipal() { return token; } @Override public Object getCredentials() { return password; } public JwtToken() { this.rememberMe = false; } public JwtToken(String token) { this.token = token; } public JwtToken(String token, char[] password) { this(token, (char[])password, false, (String)null); } public JwtToken(String token, String password) { this(token, (char[])(password != null ? password.toCharArray() : null), false, (String)null); } public JwtToken(String token, char[] password, String host) { this(token, password, false, host); } public JwtToken(String token, String password, String host) { this(token, password != null ? password.toCharArray() : null, false, host); } public JwtToken(String token, char[] password, boolean rememberMe) { this(token, (char[])password, rememberMe, (String)null); } public JwtToken(String token, String password, boolean rememberMe) { this(token, (char[])(password != null ? password.toCharArray() : null), rememberMe, (String)null); } public JwtToken(String token, char[] password, boolean rememberMe, String host) { this.rememberMe = false; this.token = token; this.password = password; this.rememberMe = rememberMe; this.host = host; } public JwtToken(String username, String password, boolean rememberMe, String host) { this(username, password != null ? password.toCharArray() : null, rememberMe, host); } // @Override // public String toString() { // StringBuilder sb = new StringBuilder(); // sb.append(this.getClass().getName()); // sb.append(\" - \"); // sb.append(JwtUtil.parseJWT(this.token).getId()); // sb.append(\", rememberMe=\").append(this.rememberMe); // if (this.h","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端-jwt-配置"},{"categories":null,"content":"\r后端 md5 配置 在 com.djtu.shiro.matchers 下创建 MyHashedCredentialsMatcher 类 public class MyHashedCredentialsMatcher extends HashedCredentialsMatcher { @Override public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) { //如果没有 token , 那就是第一次访问或者访问的是登陆页面, 直接放行 if (((JwtToken) token).getPassword() == null){ return true; } //如果有 token 那就是有身份, 进行验证 md5 的密码... return super.doCredentialsMatch(token, info); } } 在 com.djtu.config 下的 ShiroConfig 配置类中为 Realm 设置自定义的密码验证器，并指定加密方式散列次数 @Configuration public class ShiroConfig { //1.创建 ShiroFilter 负责拦截所有请求 //将 name 设为与 web.xml 中 filter-name 一致, 让过滤器自动找到这个 bean //...... //2.创建安全管理器 @Bean public DefaultWebSecurityManager getDefaultWebSecurityManager(Realm realm){ //向下转型 realm 这样才可以设置密码验证器 CustomerRealm customerRealm = (CustomerRealm) realm; //设置密码验证器 //1. 创建 Shiro 提供的 CredentialsMatcher 密码验证器 MyHashedCredentialsMatcher matcher = new MyHashedCredentialsMatcher(); //2. 设置其加密方式 matcher.setHashAlgorithmName(\"md5\"); //3. 设置散列次数 matcher.setHashIterations(1024); //4. 为自定义的 Realm 设置 CredentialsMatcher customerRealm.setCredentialsMatcher(matcher); DefaultWebSecurityManager defaultWebSecurityManager = new DefaultWebSecurityManager(); defaultWebSecurityManager.setRealm(customerRealm); return defaultWebSecurityManager; } //3.创建自定义 Realm @Bean public Realm getRealm(){ return new CustomerRealm(); } @Bean public JwtFilter getJwtFilter(){ return new JwtFilter(); } } ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:9:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端-md5-配置"},{"categories":null,"content":"\r后端全局异常类 @RestControllerAdvice 注解实现 全局拦截异常 并 统一处理 @ExceptionHandler 拦截异常进入指定方法 在 com.djtu.exception 下创建 GlobalException 类 @Slf4j //lombok 提供的日志输出 @RestControllerAdvice public class GlobalException { @ExceptionHandler(value = UnauthorizedException.class) public Result handler(UnauthorizedException e){ log.error(\"运行时异常----------------{}\" + e.getMessage()); return new Result().setCode(401).setMessage(\"无权限访问\"); } @ExceptionHandler(value = ExpiredCredentialsException.class) public Result handler(ExpiredCredentialsException e) { log.error(\"运行时异常----------------{}\", e.getMessage()); return new Result().setCode(401).setMessage(\"登录已过期，请重新登录\"); } @ExceptionHandler(value = UnauthenticatedException.class) public Result handler(UnauthenticatedException e) { log.error(\"运行时异常----------------{}\", e.getMessage()); return new Result().setCode(401).setMessage(\"未登录\"); } } ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:10:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端全局异常类"},{"categories":null,"content":"\rMybatis 的缓存问题 在 Mabitas 的配置文件中开启缓存 \u003csetting name=\"cacheEnabled\" value=\"true\"/\u003e 在每个 mapper 中都添加标签 \u003ccache/\u003e 此时出现问题：Error serializing object. Cause: java.io.NotSerializableException: com.djtu.XXX...... 问题大意为 Mabatis 缓存的实体类不可序列化 解决：为所有加了缓存的mapper对应的实体类都实现 Serializable 接口，实现可序列化 为什么需要序列化？ 因为 \u003ccache/\u003e 默认 readOnly = false 如果开启 readOnly 只读的缓存会给所有调用者返回缓存对象的相同实例。 因此这些对象不能被修改。这就提供了可观的性能提升。 而可读写的缓存会（通过序列化）返回缓存对象的拷贝。 速度上会慢一些，但是更安全。 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:11:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#mybatis-的缓存问题"},{"categories":null,"content":"\r开启 Shiro 缓存 由于用户的权限信息是一个经常读取但不经常修改的数据，在每次调用需要授权的方法时都要读一遍数据库，所以将这部分授权数据存储在内存或者缓存服务器中提升查询速度 导入依赖 \u003c!-- shiro-ehcache --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.shiro\u003c/groupId\u003e \u003cartifactId\u003eshiro-ehcache\u003c/artifactId\u003e \u003cversion\u003e1.9.0\u003c/version\u003e \u003c/dependency\u003e 在 Shiro 配置类中添加 //4. 开启EH缓存 realm.setCacheManager(new EhCacheManager()); realm.setCachingEnabled(true); realm.setAuthenticationCachingEnabled(true); realm.setAuthenticationCacheName(\"authenticationCache\"); realm.setAuthorizationCachingEnabled(true); realm.setAuthorizationCacheName(\"authorizationCache\"); ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:12:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#开启-shiro-缓存"},{"categories":null,"content":"\r后端文件接收 在接口的形参中添加 MultipartFile file 用于解析文件 @RequestMapping(\"/uploadAvatar.do\") @ResponseBody public Result uploadAvatar(MultipartFile file){ System.out.println(file); return null; } 在 web.xml 中为 servlet 标签添加 multipart-config 配置，否则报错 java.lang.IllegalStateException: 由于没有提供multi-part配置，无法处理parts \u003cmultipart-config\u003e \u003cmax-file-size\u003e20848820\u003c/max-file-size\u003e \u003cmax-request-size\u003e418018841\u003c/max-request-size\u003e \u003cfile-size-threshold\u003e1048576\u003c/file-size-threshold\u003e \u003c/multipart-config\u003e ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:13:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#后端文件接收"},{"categories":null,"content":"\rTomcat 在 linux 中写入文件权限不足 linux 上部署的 Tomcat 在写入文件时，默认权限是 640 只能让所有者读取和写入 修改 Tomcat 的 bin 中 catalina.sh 文件第 290 行左右 #UMASK=“0027” 改为 #UMASK=“0000” 即可解决 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:14:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#tomcat-在-linux-中写入文件权限不足"},{"categories":null,"content":"\r关于MySQL的GROUP BY报错解决方案 原因：MySQL5.7版本之后使用Group by语句时报错，group by 违背了sql_mode=only_full_group_by。因为mysql版本5.7之后默认的模式是ONLY_FULL_GROUP_BY。拒绝选择列表、HAVING 条件或 ORDER BY 列表引用非聚合列的查询，这些列既不在 GROUP BY 子句中命名，也不在功能上依赖于（唯一确定的）GROUP BY 列。 解决： 1、先使用SQL查询sql_mode select @@global.sql_mode 2、重新设置sql_mode，删除ONLY_FULL_GROUP_BY set @@global.sql_mode ='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION' ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:15:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#关于mysql的group-by报错解决方案"},{"categories":null,"content":"\rPOI和easyExcel资料来源于：https://www.bilibili.com/video/BV1Ua4y1x7BK?spm_id_from=333.999.0.0 笔记记录者：@LittleHan：https://gitee.com/LittleHanQAQ ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#poi和easyexcel"},{"categories":null,"content":"\r一、常用场景 将用户信息导出为excel表格(导出数据…) 将Execl表中的信息录入到网站数据库 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:1","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#一常用场景"},{"categories":null,"content":"\r二、POI基本功能 HSSF-提供读写Microsoft Execl格式档案的功能 03年版本的xls XSSF-提供读写Microsoft Execl OOXML格式档案的功能 07年以后版本地xlsx HWPF-提供读写Microsoft Word格式档案的功能 HSLF-提供读写Microsoft PowerPoint格式档案的功能 HDGF-提供读写Microsoft Visio格式档案的功能 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:2","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#二poi基本功能"},{"categories":null,"content":"\r三、JAVA解析Excel工具EasyExcel(阿里巴巴) easyExcel 官网网址：https://github.com/alibaba/easyexcel easyExcel 官方文档：https://www.yuque.com/easyexcel/doc/easyexecl Apache POI官网：https://poi.apache.org/ java解析、生成Excel比较有名的框架有Apache poi、jxl，但他们都存在严重问题非常的消耗内存，EsayExcel 不会出现内存溢出，让使用者更加简单方便 。 POI与easyExcel对比： ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:3","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#三java解析excel工具easyexcel阿里巴巴"},{"categories":null,"content":"\r四、POI写入数据 导入相关依赖 \u003c!--导入依赖--\u003e \u003cdependencies\u003e \u003c!--xLs(03)--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.poi\u003c/groupId\u003e \u003cartifactId\u003epoi\u003c/artifactId\u003e \u003cversion\u003e3.9\u003c/version\u003e \u003c/dependency\u003e \u003c!--xLsx(07)--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.poi\u003c/groupId\u003e \u003cartifactId\u003epoi-ooxml\u003c/artifactId\u003e\u003cversion\u003e3.9\u003c/version\u003e \u003c/dependency\u003e \u003c!--日期格式化工具--\u003e \u003cdependency\u003e \u003cgroupId\u003ejoda-time\u003c/groupId\u003e \u003cartifactId\u003ejoda-time\u003c/artifactId\u003e \u003cversion\u003e2.10.1\u003c/version\u003e \u003c/dependency\u003e 需要注意:2003版本和2007版本存在兼容性问题！03最多只用65535行！ Excel中的几个对象 工作簿： 工作表： 行： 列： //1.创建工作簿 Workbook为一个接口 Workbook workbook=new HSSFWorkbook(); //2.创建工作表 Sheet sheet=workbook.createSheet(\"表名字\"); //3.创建一个行 Row row1=sheet.createRow(0); //4.创建一个单元格 Cell cell1=row1.createCell(0); cell1.setCellValue(\"姓名\"); Row row2=sheet.createRow(1); Cell cell2=row1.createCell(0); cell2.setCellValue(\"张三\"); //生成一张表（IO流） String path=\"E:\\\\\"; FileOutputStream fileOutputStream=new FileOutputStream(path+\"学生表.xls\"); workbook.write(fileOutputStream); fileOutputStream.close(); ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:4","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#四poi写入数据"},{"categories":null,"content":"\r五、大量数据的写入 大文件写HSSF 缺点：最多只能处理65536行，否则回抛出异常。 java.lang.IllegalArugmentException:Invalid row number(65536) outside allowable range(0..65535) 优点：过程中写入缓存，不操作磁盘，最后一次性写入磁盘，速度快。 大文件写XSSF 缺点：写数据时速度非常 慢，非常耗内存，也会发生内存溢出，如100万条 优点：可以写较大的数据量，如20万条 大文件写SXSSF 优点：可以写非常大的数据量，如100万条甚至更多条，写数据速度快，占用更少的内存 注意： 过程中会产生临时文件，需要清理临时文件 默认由100条记录被保存在内存中，如果超过这数量，则最前面的数据被写入临时文件 如果向自定义内存中数据的数量，可以使用new SXXSSFWorkbook(数量) 清除临时文件方法： ((SXSSFWorkbook)workbook).dispose(); ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:5","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#五大量数据的写入"},{"categories":null,"content":"\r六、POI读取数据 //1.获取文件流 FileInputStream inputStream=new FileInputStream(path+\"学生.xlsx\"); //2.创建工作簿 Workbook workbook=new HSSFWorkbook(inputStream); //3.获取工作表 Sheet sheet=workbook.getSheetAt(0); //获取行 Row row=sheet.getRow(0); //获取列(结合行就是一个单元格[0,0]) Cell cell=row.getCell(0); cell.getStringCellValue(); 注意：获取值的类型 Row类里的getPhysicalNunberOfCells()方法获取指定行有多少列 Sheet类里的getPhysicalNumberOfRows()方法获取表里有多少行 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:6","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#六poi读取数据"},{"categories":null,"content":"\r七、Easy Excel的使用 https://github.com/alibaba/easyexcel 导入依赖 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003eeasyexcel\u003c/artifactId\u003e \u003cversion\u003e3.0.5\u003c/version\u003e \u003c/dependency\u003e 注意：该依赖已经引用了xLs(03)和xLsx(07）,同时需要lombok依赖 三步走： 实体类 @Data public class DemoData{ @ExcepProperty(\"字符串标题\") private String str; /** * 忽略这个字段 */ @ExcelIgnore private String ignore; } 如果查到的数据已经时list封装好了，可以省略此步骤 private List\u003cDownloadData\u003e data() { List\u003cDownloadData\u003e list = ListUtils.newArrayList(); for (int i = 0; i \u003c 10; i++) { DownloadData data = new DownloadData(); data.setString(\"字符串\" + 0); data.setDate(new Date()); data.setDoubleData(0.56); list.add(data); } return list; } 写Excel String fileName = TestFileUtil.getPath() + \"write\" + System.currentTimeMillis() + \".xlsx\"; // 这里 需要指定写用哪个class去读，然后写到第一个sheet，名字为模板 然后文件流会自动关闭 // 如果这里想使用03 则 传入excelType参数即可 EasyExcel.write(fileName, DemoData.class).sheet(\"模板\").doWrite(data()); ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:7","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#七easy-excel的使用"},{"categories":null,"content":"\r八、遇到的问题以及解决方案 遇到的问题1：在web中，我们前端通过ajax发送导出Excel请求，当响应到浏览器是二进制码，并不会触发下载excel。 解决方案：我们可以采用form表单方式/超链接方式，而不是ajax方式发起请求。 遇到的问题2：根据row对象获取cell的值方法row.getCell( num)，返回值并不是String类型而是Cell类型，通过row.getCell( num).getStringCellValue()获取值 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:8","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#八遇到的问题以及解决方案"},{"categories":null,"content":"\r前端 Vue 中的 JWT 存储 在 src/store 下的 index.js 文件书写内容，在 state、 localStorage 中存储 token、userInfo 实现全局储存 import Vue from 'vue' import Vuex from 'vuex' Vue.use(Vuex) export default new Vuex.Store({ state: { token:localStorage.getItem(\"token\"), //将state中的token设为localStorage中的token值 userInfo:JSON.parse(localStorage.getItem(\"userInfo\")) //将state中的userInfo设为localStorage中的userInfo值 }, getters: { getUser: state =\u003e { //获取 state 中的 userInfo return state.userInfo; }, getToken: state =\u003e { //获取 state 中的 token if (state.token == null) { //是第一次登录 return ''; } return state.token; } }, mutations: { SET_TOKEN:(state, token)=\u003e{ //设置 state 中的 token state.token = token; localStorage.setItem(\"token\", token); }, SET_USERINFO:(state, userInfo)=\u003e{ //设置 state 中的 userInfo state.userInfo = userInfo; localStorage.setItem(\"userInfo\", userInfo); }, REMOVE_INFO:(state)=\u003e{ //删除 state 和 localStorage 中的 token 和 userInfo state.token = ''; state.userInfo = {}; localStorage.setItem(\"token\", ''); localStorage.setItem(\"userInfo\", JSON.stringify('')); } }, actions: { }, modules: { } }) ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:17:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前端-vue-中的-jwt-存储"},{"categories":null,"content":"\r前端 Vue 创建新页面流程 在 src/views 下创建 vue 页面文件, 并设置 name \u003ctemplate\u003e \u003c!--拷贝 饿了么 中的 组件代码--\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"login\", \u003c!--拷贝 饿了么 中的 data 和 methods--\u003e } \u003c/script\u003e \u003cstyle scoped\u003e /*拷贝饿了么中的内容*/ \u003c/style\u003e 在 src/router 下的 index.js 中填写路由信息 import Vue from 'vue' import VueRouter from 'vue-router' import test from \"@/views/test\"; import login from \"@/views/login\"; //导入 /views/ 下的对应文件 Vue.use(VueRouter) const routes = [ { path:\"/\", name:\"test\", component:test }, { //添加一个新的路由地址 path:\"/login\", //设置访问地址 name:\"login\", component: login //在这里设置 import 导入的对应文件 } ] 设置路由等等…略 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:18:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前端-vue-创建新页面流程"},{"categories":null,"content":"\r前端 Vue 的请求拦截配置 配置基础链接 在 src 下创建 axios.js import axios from \"axios\"; //配置 axios 每个链接的公共字符 axios.defaults.baseURL = \"http://localhost:8080/logisticsProject\"; 在 main.js 中导入刚刚创建好的文件 import \"./axios\" 在 src / axios.js 配置前置拦截和后置拦截，功能增强【没有过滤功能】 //前置拦截 axios.interceptors.request.use(config =\u003e { return config; //不进行前置拦截 }) //后置拦截: 根据后端给前端的状态码进行拦截, 这样在其他页面就只需要处理 200 状态码的情况了 axios.interceptors.response.use(resp =\u003e{ let res = resp.data; if (res.code == 200){ // 200 成功 不拦截 return resp; }else if(res.code == 401){ // 401 失败 显示失败信息, 跳转至 登录页面 ElementUI.Message.error(res.message, {duration:3*1000}); router.push(\"/login\"); return Promise.reject(res.message); }else { // 失败 显示失败信息 ElementUI.Message.error(res.message, {duration:3*1000}); return Promise.reject(res.message); } }) ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:19:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前端-vue-的请求拦截配置"},{"categories":null,"content":"\r前后端分离 cookie 问题 问题：前后端分离之后，后端的 cookie 无法存储到前端浏览器中 这是一个跨域问题 在后端跨域配置中添加 mapping 属性，允许接受 cookie allow-credentials=\"true\" 在前端 axios 的配置中添加默认配置，允许每次请求带上 cookie axios.defaults.withCredentials = true; 2022-04-30 ：这样并不能解决 Cookie 问题，Cookie 问题似乎不能轻易的解决，就算这么设置了也无法存储 Cookie ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:20:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前后端分离-cookie-问题"},{"categories":null,"content":"\r前后端传参思路 用户进入主页面时 向后端发送请求，获取该用户拥有的功能列表（父菜单、子菜单），并将其遍历在功能菜单上 向后端发送请求，获取该用户拥有的功能列表的目标地址（“/user/dorm”）绑定到按钮 :to=\"xxx\" 上，点击对应按钮 mian 栏就显示对应页面 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:21:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#前后端传参思路"},{"categories":null,"content":"\rVue el-dropdown-item 标签无法触发事件 使用 @click.native 替换 @click 即可 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:22:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-el-dropdown-item-标签无法触发事件"},{"categories":null,"content":"\rVue 如何跳转页面和刷新页面 this.$router.go(0) 刷新页面 this.$router.replace(\"/login\") 跳转页面 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:23:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-如何跳转页面和刷新页面"},{"categories":null,"content":"\rVue 表单 data 的规则验证 什么是 rules ? 是对 data 数据的验证，name 与表单中 prop 的值对应？ type：类型 required：是否必选项（此栏是否为空） message：报错信息 trigger：触发方式 blur ：失去焦点时进行验证（对 input 输入框的验证） change ：当值发生变化时进行验证（下拉框select，日期选择框date-picker，复选框checkbox，单选框radio） min / max：最小 / 最大 长度 name:[ {type: 'string', required: true, message: \"名称必填\", trigger: 'blur'}, {min: 3, max: 30, message: \"名称长度不能超过30位\"} ] 在 form 标签中指定 :rules 在 data 中添加 rules ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:24:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-表单-data-的规则验证"},{"categories":null,"content":"\rVue 如何动态生成表单 rules 起因：在 data 中写 this.xxx 无效 解决：在页面加载的回调方法 mounted / created 中加载 rules 中的内容 // 加载楼宇列表值 this.$axios.post(\"/building/getDormBuildingValueList.do\") .then(resp=\u003e{ // 设置楼宇 rules 验证枚举 var rulesEnum = []; for (let temp in resp.data.data) { rulesEnum.push(resp.data.data[temp].value); } var t = {type:'enum', enum: rulesEnum, message: '楼宇必须为楼宇列表中的值'}; this.rules.building.push(t); }, err=\u003e{ console.log(err); }) ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:25:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-如何动态生成表单-rules"},{"categories":null,"content":"\rVue 的路由拦截 七天免登录的实现 如果有七天免登录需求，后端在登录返回结果中他添加标记和时间戳 long timeStamp = System.currentTimeMillis()+1000*60*60*24*7; //设置过期时间为 7 天 if (!rememberMe) { timeStamp = System.currentTimeMillis()+1000*60*30; //如果没选七天免登录的话, 过期时间为 30 分钟 } resultMap.put(\"rememberMe\", rememberMe); //传递是否七天免登录的标记 resultMap.put(\"timestamp\", timeStamp); //传递过期时间戳 在前端的 main.js 中添加路由的 brforeEach 方法 /** * 每次路由前都验证 localStorage 是否过期 */ router.beforeEach((to, from, next)=\u003e { var rememberMe = store.getters.getRememberMe; var timeStamp = store.getters.getTimeStamp; var nowTimeStamp = new Date().getTime(); if (to.fullPath === '/login' || to.fullPath === '/register') { //如果访问的是 登录 / 注册 页面则 放行 next(); } else if (rememberMe == null) { // localStorage 为空 ElementUI.Message.error('您已退出登录, 请重新登录', {duration:3*1000}); next(\"/login\"); } else { var addTime = 0; if (rememberMe) { //勾选了 7 天免登录 addTime = 1000 * 60 * 60 * 24 * 7; } else { //未勾选 7 天免登录时 addTime = 1000 * 60 * 30; } if (nowTimeStamp \u003c timeStamp) { // 未过期 store.commit(\"SET_TIME_STAMP\", nowTimeStamp + addTime); next(); } else { //已过期 store.commit(\"REMOVE_INFO\"); ElementUI.Message.error('免登录时间已过或长时间未操作, 请重新登录', {duration:3*1000}); next(\"/login\"); } } }); 为登录界面添加时间戳验证 created() { if (this.$store.getters.getTimeStamp \u003e 0){ //页面打开时判断是否需要登录 this.$router.replace(\"/index\"); this.$notify({ title: '成功', message: '通过免登录验证, 进入主页', type: 'success' }); } } ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:26:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-的路由拦截"},{"categories":null,"content":"\rVue 打包发布 设置 Vue 的 base 路径（网站名），在 router 的 index.js 中修改 base 内容 const router = new VueRouter({ mode: 'history', // base: process.env.BASE_URL, base: 'DJTULogistics', routes }) npm run build 打包 Vue 项目到 dist 目录 复制到 nginx 或 tomcat 上部署 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:27:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-打包发布"},{"categories":null,"content":"\rVue 的深浅拷贝 Vue 中默认的 = 赋值为浅拷贝，拷贝对象的内存地址 深拷贝方法：由 JSON 包装在解析 深拷贝数据 = JSON.parse(JSON.stringify(原数据)); ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:28:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-的深浅拷贝"},{"categories":null,"content":"\rVue 不使用 axios 的时候如何修改 headers 问题来源：此项目是按照每次请求请求头中的自定义参数 authToken 来识别此次请求的用户是否有 session 当使用 axios 时，在 axios 的前置拦截中添加了 authToken 的 headers 请求头，但是在 Vue 其他 action 请求中无效 解决方法: 在 Vue 的 action 标签加上 :headers=\"{authToken: this.$store.getters.getSessionId}\" ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:29:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-不使用-axios-的时候如何修改-headers"},{"categories":null,"content":"\rVue watch 的使用 watch 可以做到在指定值发生改变后，执行回调方法 watch 写在 data 同级 watch: { '$route.params.floor'(newValue, oldValue) { alert(newValue + \", \" + oldValue); } } ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:30:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#vue-watch-的使用"},{"categories":null,"content":"\rGitee issues 的标签 标签解释： Bug - 错误 Duplicate - 重复 Enhancement - 加强，改善 Feature - 功能 Invalid - 非法 Question - 问题 WontFix - 不能修复 ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:31:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#gitee-issues-的标签"},{"categories":null,"content":"\r秒杀相关知识","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:0","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#秒杀相关知识"},{"categories":null,"content":"\rvalidation 为提高程序安全性、健壮度，对 HTTP 请求数据的校验需要在服务端再次校验 validation 实现用注解解决代码中大量数据校验而带来的冗余 SpringMVC 使用的是 Hibernate Validator 实现的 JSR-303 校验规范 使用方式： 导入依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.hibernate\u003c/groupId\u003e \u003cartifactId\u003ehibernate-validator\u003c/artifactId\u003e \u003cversion\u003e5.4.3.Final\u003c/version\u003e \u003c/dependency\u003e 在 Spring 配置文件中添加 数据校验器 \u003c!--校数校验--\u003e \u003cbean id=\"validator\" class=\"org.springframework.validation.beanvalidation.LocalValidatorFactoryBean\"\u003e \u003cproperty name=\"providerClass\" value=\"org.hibernate.validator.HibernateValidator\"/\u003e \u003c!-- 如果不加默认到 使用classpath下的ValidationMessages.properties --\u003e \u003cproperty name=\"validationMessageSource\" ref=\"messageSource\"/\u003e \u003c/bean\u003e \u003c!-- 国际化的消息资源文件（本系统中主要用于显示/错误消息定制） --\u003e \u003cbean id=\"messageSource\" class=\"org.springframework.context.support.ReloadableResourceBundleMessageSource\"\u003e \u003cproperty name=\"basenames\"\u003e \u003clist\u003e \u003c!-- 在web环境中一定要定位到classpath 否则默认到当前web应用下找--\u003e \u003cvalue\u003eclasspath:messages\u003c/value\u003e \u003c/list\u003e \u003c/property\u003e \u003cproperty name=\"useCodeAsDefaultMessage\" value=\"false\"/\u003e \u003cproperty name=\"defaultEncoding\" value=\"UTF-8\"/\u003e \u003cproperty name=\"cacheSeconds\" value=\"60\"/\u003e \u003c/bean\u003e \u003c!--添加数据校验器--\u003e \u003cmvc:annotation-driven validator=\"validator\"/\u003e 在 resources 中创建 messages.properties, 配置错误消息提示 username.null=用户不能为空 password.illegal=密码必须为5到20之间的大小写字符 age.illegal=年龄必须在18到60之间。 常用校验注解 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint @NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 在需要用到的地方配置 @Valid 在 @Valid 修饰的类中添加相关注解 自定义注解 在 validator 包下创建注解类，配置校验规则、自定义方法规则 @Target({ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented @Constraint( // 校验规则 validatedBy = {IsIdentValidator.class} ) public @interface IsIdent { // 自定义方法规则: 必填项 boolean required() default true; // 错误提示信息 String message() default \"{javax.validation.constraints.NotNull.message}\"; Class\u003c?\u003e[] groups() default {}; Class\u003c? extends Payload\u003e[] payload() default {}; } 在 validator 包下创建校验规则类，设置泛型为自定义的注解 public class IsIdentValidator implements ConstraintValidator\u003cIsIdent, String\u003e { private boolean required = false; @Override public void initialize(IsIdent isIdent) { boolean required = isIdent.required(); } @Override public boolean isValid(String s, ConstraintValidatorContext constraintValidatorContext) { if (required) { return ValidatorUtil.isIdent(s); }else { if (StringUtils.isEmpty(s)){ return true; }else { return ValidatorUtil.isIdent(s); } } } } 在 utils 包下创建 ValidatorUtil 工具类 public class ValidatorUtil { private static final Pattern ident_pattern = Pattern.compile(\"学生|导员|管理员\"); public static boolean isIdent(String ident){ if (StringUtils.isEmpty(ident)){ return false; } Matcher matcher = ident_pattern.matcher(ident); return matcher.matches(); } } 异常处理 异常处理类捕获 MethodArgumentNotValidException 获取定义的异常提示信息: e.getBindingResult().getAllErrors().get(0).getDefaultMessage() ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:1","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#validation"},{"categories":null,"content":"\rvalidation 为提高程序安全性、健壮度，对 HTTP 请求数据的校验需要在服务端再次校验 validation 实现用注解解决代码中大量数据校验而带来的冗余 SpringMVC 使用的是 Hibernate Validator 实现的 JSR-303 校验规范 使用方式： 导入依赖 org.hibernate hibernate-validator 5.4.3.Final 在 Spring 配置文件中添加 数据校验器 classpath:messages 在 resources 中创建 messages.properties, 配置错误消息提示 username.null=用户不能为空 password.illegal=密码必须为5到20之间的大小写字符 age.illegal=年龄必须在18到60之间。 常用校验注解 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint @NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 在需要用到的地方配置 @Valid 在 @Valid 修饰的类中添加相关注解 自定义注解 在 validator 包下创建注解类，配置校验规则、自定义方法规则 @Target({ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented @Constraint( // 校验规则 validatedBy = {IsIdentValidator.class} ) public @interface IsIdent { // 自定义方法规则: 必填项 boolean required() default true; // 错误提示信息 String message() default \"{javax.validation.constraints.NotNull.message}\"; Class\u003c?\u003e[] groups() default {}; Class\u003c? extends Payload\u003e[] payload() default {}; } 在 validator 包下创建校验规则类，设置泛型为自定义的注解 public class IsIdentValidator implements ConstraintValidator { private boolean required = false; @Override public void initialize(IsIdent isIdent) { boolean required = isIdent.required(); } @Override public boolean isValid(String s, ConstraintValidatorContext constraintValidatorContext) { if (required) { return ValidatorUtil.isIdent(s); }else { if (StringUtils.isEmpty(s)){ return true; }else { return ValidatorUtil.isIdent(s); } } } } 在 utils 包下创建 ValidatorUtil 工具类 public class ValidatorUtil { private static final Pattern ident_pattern = Pattern.compile(\"学生|导员|管理员\"); public static boolean isIdent(String ident){ if (StringUtils.isEmpty(ident)){ return false; } Matcher matcher = ident_pattern.matcher(ident); return matcher.matches(); } } 异常处理 异常处理类捕获 MethodArgumentNotValidException 获取定义的异常提示信息: e.getBindingResult().getAllErrors().get(0).getDefaultMessage() ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:1","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#常用校验注解"},{"categories":null,"content":"\rvalidation 为提高程序安全性、健壮度，对 HTTP 请求数据的校验需要在服务端再次校验 validation 实现用注解解决代码中大量数据校验而带来的冗余 SpringMVC 使用的是 Hibernate Validator 实现的 JSR-303 校验规范 使用方式： 导入依赖 org.hibernate hibernate-validator 5.4.3.Final 在 Spring 配置文件中添加 数据校验器 classpath:messages 在 resources 中创建 messages.properties, 配置错误消息提示 username.null=用户不能为空 password.illegal=密码必须为5到20之间的大小写字符 age.illegal=年龄必须在18到60之间。 常用校验注解 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint @NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 在需要用到的地方配置 @Valid 在 @Valid 修饰的类中添加相关注解 自定义注解 在 validator 包下创建注解类，配置校验规则、自定义方法规则 @Target({ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented @Constraint( // 校验规则 validatedBy = {IsIdentValidator.class} ) public @interface IsIdent { // 自定义方法规则: 必填项 boolean required() default true; // 错误提示信息 String message() default \"{javax.validation.constraints.NotNull.message}\"; Class\u003c?\u003e[] groups() default {}; Class\u003c? extends Payload\u003e[] payload() default {}; } 在 validator 包下创建校验规则类，设置泛型为自定义的注解 public class IsIdentValidator implements ConstraintValidator { private boolean required = false; @Override public void initialize(IsIdent isIdent) { boolean required = isIdent.required(); } @Override public boolean isValid(String s, ConstraintValidatorContext constraintValidatorContext) { if (required) { return ValidatorUtil.isIdent(s); }else { if (StringUtils.isEmpty(s)){ return true; }else { return ValidatorUtil.isIdent(s); } } } } 在 utils 包下创建 ValidatorUtil 工具类 public class ValidatorUtil { private static final Pattern ident_pattern = Pattern.compile(\"学生|导员|管理员\"); public static boolean isIdent(String ident){ if (StringUtils.isEmpty(ident)){ return false; } Matcher matcher = ident_pattern.matcher(ident); return matcher.matches(); } } 异常处理 异常处理类捕获 MethodArgumentNotValidException 获取定义的异常提示信息: e.getBindingResult().getAllErrors().get(0).getDefaultMessage() ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:1","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#自定义注解"},{"categories":null,"content":"\rvalidation 为提高程序安全性、健壮度，对 HTTP 请求数据的校验需要在服务端再次校验 validation 实现用注解解决代码中大量数据校验而带来的冗余 SpringMVC 使用的是 Hibernate Validator 实现的 JSR-303 校验规范 使用方式： 导入依赖 org.hibernate hibernate-validator 5.4.3.Final 在 Spring 配置文件中添加 数据校验器 classpath:messages 在 resources 中创建 messages.properties, 配置错误消息提示 username.null=用户不能为空 password.illegal=密码必须为5到20之间的大小写字符 age.illegal=年龄必须在18到60之间。 常用校验注解 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint @NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 在需要用到的地方配置 @Valid 在 @Valid 修饰的类中添加相关注解 自定义注解 在 validator 包下创建注解类，配置校验规则、自定义方法规则 @Target({ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented @Constraint( // 校验规则 validatedBy = {IsIdentValidator.class} ) public @interface IsIdent { // 自定义方法规则: 必填项 boolean required() default true; // 错误提示信息 String message() default \"{javax.validation.constraints.NotNull.message}\"; Class\u003c?\u003e[] groups() default {}; Class\u003c? extends Payload\u003e[] payload() default {}; } 在 validator 包下创建校验规则类，设置泛型为自定义的注解 public class IsIdentValidator implements ConstraintValidator { private boolean required = false; @Override public void initialize(IsIdent isIdent) { boolean required = isIdent.required(); } @Override public boolean isValid(String s, ConstraintValidatorContext constraintValidatorContext) { if (required) { return ValidatorUtil.isIdent(s); }else { if (StringUtils.isEmpty(s)){ return true; }else { return ValidatorUtil.isIdent(s); } } } } 在 utils 包下创建 ValidatorUtil 工具类 public class ValidatorUtil { private static final Pattern ident_pattern = Pattern.compile(\"学生|导员|管理员\"); public static boolean isIdent(String ident){ if (StringUtils.isEmpty(ident)){ return false; } Matcher matcher = ident_pattern.matcher(ident); return matcher.matches(); } } 异常处理 异常处理类捕获 MethodArgumentNotValidException 获取定义的异常提示信息: e.getBindingResult().getAllErrors().get(0).getDefaultMessage() ","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:1","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#异常处理"},{"categories":null,"content":"\r分布式 Session 问题 使用 nginx 做负载均衡服务器时，若使用默认轮询机制用户每次访问的服务器不同，导致偶现的 Session 丢失 解决方案： Session 复制：通过修改 Tomcat 的配置，A 服务器中 Session 修改时同时复制到 B 服务器中 优点：操作简单，只需修改 Tomcat 配置 缺点：Session 同步会占用内网带宽、由于同步造成性能下降、占用内存无法有效水平扩展 前端存储：直接将 Session 存储在浏览器中 优点：不占用服务器内存 缺点：存在安全风险、占用外网带宽 Session 粘滞：将同一用户请求都发往同一服务器 优点：无需修改代码、服务器可以水平扩展 缺点：添加新机器时、应用重启时 会重新 Hash 导致登录失效 后端集中存储：使用缓存服务器统一存储 Session 优点：安全、可以水平扩展 缺点：增加复杂度、需要修改代码 SpringMVC 中 配置 Redis 导入 redis jedis 依赖 \u003c!-- redis --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.data\u003c/groupId\u003e \u003cartifactId\u003espring-data-redis\u003c/artifactId\u003e \u003cversion\u003e2.7.0\u003c/version\u003e \u003c/dependency\u003e \u003c!-- jedis --\u003e \u003cdependency\u003e \u003cgroupId\u003eredis.clients\u003c/groupId\u003e \u003cartifactId\u003ejedis\u003c/artifactId\u003e \u003cversion\u003e3.8.0\u003c/version\u003e \u003c/dependency\u003e 在 resources 目录下创建 redis.properties 配置 redis 基础连接信息 # Redis Setting # Redis默认有16个库，序号是0-15，默认是选中的是0号数据库 spring.redis.database=0 # Redis服务器地址 spring.redis.host=47.113.216.124 # Redis服务器连接端口，默认是6379 spring.redis.port=6380 # Redis服务器连接密码（默认为空） spring.redis.password=redis # 连接池最大阻塞等待时间（使用负值表示没有限制），根据实际情况修改 spring.redis.pool.maxWaitMillis=-1 # 连接池中的最大空闲连接，根据实际情况修改 spring.redis.pool.maxIdle=8 # 连接池中的最小空闲连接，根据实际情况修改 spring.redis.pool.minIdle=0 # 连接超时时间（毫秒），根据实际情况修改 spring.redis.timeout=2000 在 resources 目录下创建 applicationContext-redis.xml 配置 redis \u003c!-- 载入redis.properties,这里要特别注意，如果有多个properties文件，必须用逗号分开，不能写成两个 \u003ccontext:property-placeholder/\u003e --\u003e \u003ccontext:property-placeholder location=\"classpath:redis.properties\" /\u003e \u003c!-- 配置JedisPoolConfig连接池--\u003e \u003cbean id=\"poolConfig\" class=\"redis.clients.jedis.JedisPoolConfig\"\u003e \u003cproperty name=\"maxIdle\" value=\"${spring.redis.pool.maxIdle}\"\u003e\u003c/property\u003e \u003cproperty name=\"minIdle\" value=\"${spring.redis.pool.minIdle}\"\u003e\u003c/property\u003e \u003cproperty name=\"maxWaitMillis\" value=\"${spring.redis.pool.maxWaitMillis}\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c!-- 配置jedis连接工厂 --\u003e \u003cbean id=\"connectionFactory\" class=\"org.springframework.data.redis.connection.jedis.JedisConnectionFactory\"\u003e \u003cproperty name=\"poolConfig\" ref=\"poolConfig\"\u003e\u003c/property\u003e \u003cproperty name=\"hostName\" value=\"${spring.redis.host}\"\u003e\u003c/property\u003e \u003cproperty name=\"port\" value=\"${spring.redis.port}\"\u003e\u003c/property\u003e \u003cproperty name=\"password\" value=\"${spring.redis.password}\"\u003e\u003c/property\u003e \u003cproperty name=\"database\" value=\"${spring.redis.database}\"\u003e\u003c/property\u003e \u003cproperty name=\"timeout\" value=\"${spring.redis.timeout}\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c!-- 配置RedisTemplate --\u003e \u003cbean id=\"stringRedisSerializer\" class=\"org.springframework.data.redis.serializer.StringRedisSerializer\" /\u003e \u003cbean id=\"cacheRedisTemplate\" class=\"org.springframework.data.redis.core.RedisTemplate\" \u003e \u003cproperty name=\"connectionFactory\" ref=\"connectionFactory\" /\u003e \u003cproperty name=\"keySerializer\" ref=\"stringRedisSerializer\" /\u003e \u003cproperty name=\"hashKeySerializer\" ref=\"stringRedisSerializer\" /\u003e \u003cproperty name=\"valueSerializer\" ref=\"stringRedisSerializer\" /\u003e \u003cproperty name=\"hashValueSerializer\" ref=\"stringRedisSerializer\" /\u003e \u003c/bean\u003e 在主 spring 配置文件中引入 redis 配置文件 \u003c!--引入redis配置文件--\u003e \u003cimport resource=\"applicationContext-redis.xml\"/\u003e 错误：Could not resolve placeholder ‘spring.redis.pool.maxIdle’ in value “${spring…… 错误大意为不能获取 properties 配置文件中定义的内容 原因：Spring 容器默认使用单例模式反射获取 \u003ccontext:property-placeholder location=\"classpath:......\" /\u003e 中的内容，由于是单例模式，在多次使用此标签时只会解析一个 解决：在每次使用 context:property-placeholder 标签中都添加 ignore-unresolvable=\"true\" 封装 redisTemplate 在 redis 包下创建 RedisService 类 @Component public final class RedisService { // 锁名称 public static final String LOCK_PREFIX = \"redis_lock:\"; @Resource private RedisTemplate\u003cString, String\u003e redisTemplate; /** * ---------------------------------通用--------------------------------- */ public void expire(String key, long l, TimeUnit timeUnit) { redisTemplate.expire(key, l, timeUnit); } public Long getExpire(String key) { return redisTemplate.getExpire(key); } public Long getExpire(String key, TimeUnit timeUnit) { return redisTemplate.getExpire(key, timeUnit); } public Boolean delete(String key) { return redisTemplate.delete(key); } public DataType type(String key) { return redisTemplate.type(key); } public Long deletes(Col","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:2","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#分布式-session-问题"},{"categories":null,"content":"\r分布式 Session 问题 使用 nginx 做负载均衡服务器时，若使用默认轮询机制用户每次访问的服务器不同，导致偶现的 Session 丢失 解决方案： Session 复制：通过修改 Tomcat 的配置，A 服务器中 Session 修改时同时复制到 B 服务器中 优点：操作简单，只需修改 Tomcat 配置 缺点：Session 同步会占用内网带宽、由于同步造成性能下降、占用内存无法有效水平扩展 前端存储：直接将 Session 存储在浏览器中 优点：不占用服务器内存 缺点：存在安全风险、占用外网带宽 Session 粘滞：将同一用户请求都发往同一服务器 优点：无需修改代码、服务器可以水平扩展 缺点：添加新机器时、应用重启时 会重新 Hash 导致登录失效 后端集中存储：使用缓存服务器统一存储 Session 优点：安全、可以水平扩展 缺点：增加复杂度、需要修改代码 SpringMVC 中 配置 Redis 导入 redis jedis 依赖 org.springframework.data spring-data-redis 2.7.0 redis.clients jedis 3.8.0 在 resources 目录下创建 redis.properties 配置 redis 基础连接信息 # Redis Setting # Redis默认有16个库，序号是0-15，默认是选中的是0号数据库 spring.redis.database=0 # Redis服务器地址 spring.redis.host=47.113.216.124 # Redis服务器连接端口，默认是6379 spring.redis.port=6380 # Redis服务器连接密码（默认为空） spring.redis.password=redis # 连接池最大阻塞等待时间（使用负值表示没有限制），根据实际情况修改 spring.redis.pool.maxWaitMillis=-1 # 连接池中的最大空闲连接，根据实际情况修改 spring.redis.pool.maxIdle=8 # 连接池中的最小空闲连接，根据实际情况修改 spring.redis.pool.minIdle=0 # 连接超时时间（毫秒），根据实际情况修改 spring.redis.timeout=2000 在 resources 目录下创建 applicationContext-redis.xml 配置 redis 在主 spring 配置文件中引入 redis 配置文件 错误：Could not resolve placeholder ‘spring.redis.pool.maxIdle’ in value “${spring…… 错误大意为不能获取 properties 配置文件中定义的内容 原因：Spring 容器默认使用单例模式反射获取 中的内容，由于是单例模式，在多次使用此标签时只会解析一个 解决：在每次使用 context:property-placeholder 标签中都添加 ignore-unresolvable=\"true\" 封装 redisTemplate 在 redis 包下创建 RedisService 类 @Component public final class RedisService { // 锁名称 public static final String LOCK_PREFIX = \"redis_lock:\"; @Resource private RedisTemplate redisTemplate; /** * ---------------------------------通用--------------------------------- */ public void expire(String key, long l, TimeUnit timeUnit) { redisTemplate.expire(key, l, timeUnit); } public Long getExpire(String key) { return redisTemplate.getExpire(key); } public Long getExpire(String key, TimeUnit timeUnit) { return redisTemplate.getExpire(key, timeUnit); } public Boolean delete(String key) { return redisTemplate.delete(key); } public DataType type(String key) { return redisTemplate.type(key); } public Long deletes(Col","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:2","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#springmvc-中-配置-redis"},{"categories":null,"content":"\r分布式 Session 问题 使用 nginx 做负载均衡服务器时，若使用默认轮询机制用户每次访问的服务器不同，导致偶现的 Session 丢失 解决方案： Session 复制：通过修改 Tomcat 的配置，A 服务器中 Session 修改时同时复制到 B 服务器中 优点：操作简单，只需修改 Tomcat 配置 缺点：Session 同步会占用内网带宽、由于同步造成性能下降、占用内存无法有效水平扩展 前端存储：直接将 Session 存储在浏览器中 优点：不占用服务器内存 缺点：存在安全风险、占用外网带宽 Session 粘滞：将同一用户请求都发往同一服务器 优点：无需修改代码、服务器可以水平扩展 缺点：添加新机器时、应用重启时 会重新 Hash 导致登录失效 后端集中存储：使用缓存服务器统一存储 Session 优点：安全、可以水平扩展 缺点：增加复杂度、需要修改代码 SpringMVC 中 配置 Redis 导入 redis jedis 依赖 org.springframework.data spring-data-redis 2.7.0 redis.clients jedis 3.8.0 在 resources 目录下创建 redis.properties 配置 redis 基础连接信息 # Redis Setting # Redis默认有16个库，序号是0-15，默认是选中的是0号数据库 spring.redis.database=0 # Redis服务器地址 spring.redis.host=47.113.216.124 # Redis服务器连接端口，默认是6379 spring.redis.port=6380 # Redis服务器连接密码（默认为空） spring.redis.password=redis # 连接池最大阻塞等待时间（使用负值表示没有限制），根据实际情况修改 spring.redis.pool.maxWaitMillis=-1 # 连接池中的最大空闲连接，根据实际情况修改 spring.redis.pool.maxIdle=8 # 连接池中的最小空闲连接，根据实际情况修改 spring.redis.pool.minIdle=0 # 连接超时时间（毫秒），根据实际情况修改 spring.redis.timeout=2000 在 resources 目录下创建 applicationContext-redis.xml 配置 redis 在主 spring 配置文件中引入 redis 配置文件 错误：Could not resolve placeholder ‘spring.redis.pool.maxIdle’ in value “${spring…… 错误大意为不能获取 properties 配置文件中定义的内容 原因：Spring 容器默认使用单例模式反射获取 中的内容，由于是单例模式，在多次使用此标签时只会解析一个 解决：在每次使用 context:property-placeholder 标签中都添加 ignore-unresolvable=\"true\" 封装 redisTemplate 在 redis 包下创建 RedisService 类 @Component public final class RedisService { // 锁名称 public static final String LOCK_PREFIX = \"redis_lock:\"; @Resource private RedisTemplate redisTemplate; /** * ---------------------------------通用--------------------------------- */ public void expire(String key, long l, TimeUnit timeUnit) { redisTemplate.expire(key, l, timeUnit); } public Long getExpire(String key) { return redisTemplate.getExpire(key); } public Long getExpire(String key, TimeUnit timeUnit) { return redisTemplate.getExpire(key, timeUnit); } public Boolean delete(String key) { return redisTemplate.delete(key); } public DataType type(String key) { return redisTemplate.type(key); } public Long deletes(Col","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:2","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#shiro-中使用-redis-存储-session"},{"categories":null,"content":"\r秒杀思路","date":"2022-04-16","objectID":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:32:3","series":null,"tags":null,"title":"校园后勤管理系统项目笔记","uri":"/%E6%A0%A1%E5%9B%AD%E5%90%8E%E5%8B%A4%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#秒杀思路"},{"categories":null,"content":"\rVue JavaScript框架 简化Dom操作 响应式数据驱动 ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#vue"},{"categories":null,"content":"\r使用Vue 导入开发版本的Vue.js \u003cscript src=\"https://cdn.jsdelivr.net/npm/vue@2/dist/vue.js\"\u003e\u003c/script\u003e 创建Vue实例对象，设置el属性和data属性 将id为app的标签内的信息改为message对应的信息 \u003cdiv id=\"app\"\u003e {{message}} \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"#app\", \u003c!-- el 就是 element --\u003e data:{ message:\"Hello Vue!\" } }) \u003c/script\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#使用vue"},{"categories":null,"content":"\rel：挂载点 通过 css 选择器 设置 Vue 管理的元素 在el命中的元素内部嵌套的标签也会被Vue所管理 \u003cdiv id=\"app\"\u003e {{message}} \u003c!--支持表达式: {{ message + \"123\" }}--\u003e \u003cspan\u003e{{message}}\u003c/span\u003e \u003c/div\u003e 也可以使用其他css选择器来设置Vue管理的元素，建议使用id选择器 不能使用HTML或BODY的双标签 el 挂载点的作用域： el 命中的元素 el 命中的元素内部的元素 el 无法命中 html 和 body 标签 ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#el挂载点"},{"categories":null,"content":"\rdata：数据对象 定义Vue用到的数据 data中可以写复杂类型的数据，使用时遵守js的语法即可 \u003cdiv id=\"app\" class=\"app\"\u003e \u003ch2\u003e{{message}}\u003c/h2\u003e \u003ch2\u003e{{people.name}}\u003c/h2\u003e \u003ch2\u003e{{array[1]}}\u003c/h2\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"#app\", data:{ message:\"Hello Vue!\", people:{ name:\"唐僧\" }, array:[123, 12, 1] } }) \u003c/script\u003e data 数据对象的类型 字符串：{{ 字符串名 }} 对象：{{ 对象名 . 属性名 }} 数组：{{ 数组名 [ 下标 ] }} ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#data数据对象"},{"categories":null,"content":"\rmethods：方法 定义 Vue 用到的方法 在 methods 中定义的方法中，可使用 this 获取到 data 中的数据 \u003cdiv id=\"app\"\u003e \u003cbutton @click=\"sub\"\u003e-\u003c/button\u003e \u003cspan\u003e{{num}}\u003c/span\u003e \u003cbutton @click=\"add\"\u003e+\u003c/button\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"#app\", data:{ num : 0 }, methods:{ add:function(){ if(this.num \u003c 10){ this.num++; }else{ alert(\"满了，别点了\") } }, sub:function(){ if(this.num \u003e 0){ this.num--; }else{ alert(\"无了，别点了\") } } } }) \u003c/script\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#methods方法"},{"categories":null,"content":"\rVue指令 不同于传统获 DOM 元素操作它们的形式，Vue 采用一系列 v- 开头的特殊语法来实现 Vue 的页面由数据生成，数据改变页面会同步跟着改变 ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#vue指令"},{"categories":null,"content":"\r1. 内容绑定、事件绑定\rv-text：设置文本值 设置元素的 textContent 支持表达式：\u003cdiv v-text=\"message+'!'\"\u003e \u003c/div 使用 v-text=\"\" 或 {{}} 插值表达式 \u003cdiv\u003e \u003c!-- {{xxx}} 插值表达式 --\u003e \u003c!-- {{xxx + “123”}} 插值表达式拼接字符串 --\u003e \u003ch2 v-text=\"message\"\u003e{{\"使用默认写法会替换掉全部内容\"}}\u003c/h2\u003e \u003ch2 v-text=\"info\"\u003e\u003c/h2\u003e \u003ch2 \u003e{{message+\"123\"}}\u003c/h2\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"div\", data:{ message:\"Hello World!\", info:\"qwerdf\" } }) \u003c/script\u003e v-html：设置HTML 与 v-text 相同，不过可以解析 HTML 指令 设置元素的 innerHTML 使用 v-html=\"\" 解析html字符串 \u003cdiv id=\"app\"\u003e \u003cp v-html=\"content\"\u003e\u003c/p\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"#app\", data:{ content:\"\u003ca href='#'\u003e测试链接\u003c/a\u003e\" } }) \u003c/script\u003e v-on：绑定事件 设置元素的绑定事件 onXXX 定义在 methods 属性中 使用 v-on:click 或 @click v-on:keyup.enter 限制触发的修饰符 enter 按回车时 方法内部可以通过 this 关键字访问 data 属性中的数据 \u003cdiv id=\"app\"\u003e \u003cbutton v-on:click=\"doit\"\u003e测试\u003c/button\u003e \u003cbutton @click=\"doit\"\u003e{{content}}\u003c/button\u003e \u003cbutton @dblclick=\"doit\"\u003e测试\u003c/button\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"#app\", data:{ content:\"\u003ca href='#'\u003e测试链接\u003c/a\u003e\" }, methods:{ doit:function(){ this.content = \"testLink\"; alert(this.content); } } }) \u003c/script\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:1","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#1-内容绑定事件绑定"},{"categories":null,"content":"\r1. 内容绑定、事件绑定\rv-text：设置文本值 设置元素的 textContent 支持表达式： ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:1","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-text设置文本值"},{"categories":null,"content":"\r1. 内容绑定、事件绑定\rv-text：设置文本值 设置元素的 textContent 支持表达式： ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:1","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-html设置html"},{"categories":null,"content":"\r1. 内容绑定、事件绑定\rv-text：设置文本值 设置元素的 textContent 支持表达式： ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:1","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-on绑定事件"},{"categories":null,"content":"\r2. 显式切换、属性绑定\rv-show：切换显示状态 切换元素的 style=\"display:none\" 使用 v-show=\"true\" 布尔、引用、表达式，数据改变后显示状态会同步刷新 \u003cdiv\u003e \u003cimg v-show=\"isShow\" src=\"/image.jpg\" /\u003e \u003cbutton @click=\"show\"\u003e显示/隐藏\u003c/button\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"div\", data:{ isShow : true }, methods:{ show:function(){ this.isShow = !this.isShow; } } }) \u003c/script\u003e v-if：切换显示状态 操纵Dom树（对性能消耗较v-show大） 使用v-if=\"true\" 其他同v-show \u003cdiv\u003e \u003cimg v-if=\"isShow\u003e=18\" src=\"/image.jpg\" /\u003e \u003cbutton @click=\"show\"\u003e显示\u003c/button\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"div\", data:{ isShow : 17 }, methods:{ show:function(){ this.isShow++; } } }) \u003c/script\u003e v-bind：设置元素属性 完整写法 v-bind:属性名=\"值\" 可简写 :属性名，使用三元表达式、{active:isActive} 根据 isActive 的值判断是否填入 “active” \u003cdiv\u003e \u003cimg v-bind:style=\"css\" src=\"/image.jpg\" /\u003e \u003cbr\u003e \u003cimg :src=\"imgSrc\" /\u003e \u003cbr\u003e \u003cimg :class=\"isActive?'active':''\" :src=\"imgSrc\" @click=\"toggleActive\" /\u003e \u003cbr\u003e \u003cimg :class={active:isActive} :src=\"imgSrc\" @click=\"toggleActive\" /\u003e \u003cbr\u003e \u003c/div\u003e \u003cscript\u003e var app = new Vue({ el:\"div\", data:{ css:\"border:1px solid red\", imgSrc:\"/image.jpg\", isActive:false }, methods:{ toggleActive:function(){ this.isActive = !this.isActive; } } }) \u003c/script\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:2","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#2-显式切换属性绑定"},{"categories":null,"content":"\r2. 显式切换、属性绑定\rv-show：切换显示状态 切换元素的 style=\"display:none\" 使用 v-show=\"true\" 布尔、引用、表达式，数据改变后显示状态会同步刷新 显示/隐藏 v-if：切换显示状态 操纵Dom树（对性能消耗较v-show大） 使用v-if=\"true\" 其他同v-show 显示 v-bind：设置元素属性 完整写法 v-bind:属性名=\"值\" 可简写 :属性名，使用三元表达式、{active:isActive} 根据 isActive 的值判断是否填入 “active” ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:2","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-show切换显示状态"},{"categories":null,"content":"\r2. 显式切换、属性绑定\rv-show：切换显示状态 切换元素的 style=\"display:none\" 使用 v-show=\"true\" 布尔、引用、表达式，数据改变后显示状态会同步刷新 显示/隐藏 v-if：切换显示状态 操纵Dom树（对性能消耗较v-show大） 使用v-if=\"true\" 其他同v-show 显示 v-bind：设置元素属性 完整写法 v-bind:属性名=\"值\" 可简写 :属性名，使用三元表达式、{active:isActive} 根据 isActive 的值判断是否填入 “active” ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:2","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-if切换显示状态"},{"categories":null,"content":"\r2. 显式切换、属性绑定\rv-show：切换显示状态 切换元素的 style=\"display:none\" 使用 v-show=\"true\" 布尔、引用、表达式，数据改变后显示状态会同步刷新 显示/隐藏 v-if：切换显示状态 操纵Dom树（对性能消耗较v-show大） 使用v-if=\"true\" 其他同v-show 显示 v-bind：设置元素属性 完整写法 v-bind:属性名=\"值\" 可简写 :属性名，使用三元表达式、{active:isActive} 根据 isActive 的值判断是否填入 “active” ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:2","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-bind设置元素属性"},{"categories":null,"content":"\r3. 列表循环、表单元素绑定\rv-for：列表循环 完整写法 v-for=\"item in arr\" 、v-for=\"(item,index) in arr\" 循环的次数由数组的长度决定，可响应式同步更新数据 \u003cdiv id=\"app\"\u003e \u003cul\u003e \u003cli v-for=\"(item,index) in arr\"\u003e {{index+1 + \" -\u003e \" + item}} \u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003cscript\u003e new Vue({ el:\"#app\", data:{ arr:[\"a\", 'b', 3, { name:\"mike\", tel:\"12233334444\" }] } }) \u003c/script\u003e v-model：双向数据绑定 完整写法 v-model=\"data中元素\" 获取和设置表单元素的值，为表单元素设置默认 value 值为 data 中元素值，当表单中值改变时也会同步到 data 元素中 \u003cdiv id=\"app\"\u003e \u003cinput type=\"text\" v-model=\"message\" \u003e {{message}} \u003c/div\u003e \u003cscript\u003e new Vue({ el:\"#app\", data:{ message:\"刘嘉宁\" } }) \u003c/script\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:3","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#3-列表循环表单元素绑定"},{"categories":null,"content":"\r3. 列表循环、表单元素绑定\rv-for：列表循环 完整写法 v-for=\"item in arr\" 、v-for=\"(item,index) in arr\" 循环的次数由数组的长度决定，可响应式同步更新数据 {{index+1 + \" -\u003e \" + item}} v-model：双向数据绑定 完整写法 v-model=\"data中元素\" 获取和设置表单元素的值，为表单元素设置默认 value 值为 data 中元素值，当表单中值改变时也会同步到 data 元素中 {{message}} ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:3","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-for列表循环"},{"categories":null,"content":"\r3. 列表循环、表单元素绑定\rv-for：列表循环 完整写法 v-for=\"item in arr\" 、v-for=\"(item,index) in arr\" 循环的次数由数组的长度决定，可响应式同步更新数据 {{index+1 + \" -\u003e \" + item}} v-model：双向数据绑定 完整写法 v-model=\"data中元素\" 获取和设置表单元素的值，为表单元素设置默认 value 值为 data 中元素值，当表单中值改变时也会同步到 data 元素中 {{message}} ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:3","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#v-model双向数据绑定"},{"categories":null,"content":"\r网络应用\raxios 网络请求库 内部封装了 Ajax，容量小，易与 Vue 结合 get axios.get(\"请求地址?k1=v1\u0026k2=v2\") .then(function(resp){ //成功响应的回调方法 },function(err){ //报错之后的回调方法 }) post axios.post(\"请求地址\",{k1:v1,k2:v2}) .then(function(resp){ //成功响应的回调方法 },function(err){ //报错之后的回调方法 }) vue 中的使用 \u003cdiv id=\"app\"\u003e \u003cinput type=\"button\" value=\"getJoke\" @click=\"getJoke\"\u003e {{ joke }} \u003c/div\u003e \u003cscript\u003e new Vue({ el:\"#app\", data:{ joke:\"这是一条笑话\" }, methods:{ getJoke:function(){ //因为 ajax 是异步的, 在 ajax 代码中的 this 是 whindow 对象而不是 vue 对象 //所以要将当前 vue 对象存起来, 以便方法内 ajax 代码中进行调用 var that = this; axios.get(\"https://autumnfish.cn/api/joke\") .then(function(resp){ that.joke = resp.data; console.log(this); },function(err){ console.log(err); }) } } }) \u003c/script\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#网络应用"},{"categories":null,"content":"\r网络应用\raxios 网络请求库 内部封装了 Ajax，容量小，易与 Vue 结合 get axios.get(\"请求地址?k1=v1\u0026k2=v2\") .then(function(resp){ //成功响应的回调方法 },function(err){ //报错之后的回调方法 }) post axios.post(\"请求地址\",{k1:v1,k2:v2}) .then(function(resp){ //成功响应的回调方法 },function(err){ //报错之后的回调方法 }) vue 中的使用 {{ joke }} ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#axios-网络请求库"},{"categories":null,"content":"\r跨域问题 浏览器的 同源策略 是由 NetScape 提出的一个著名的安全策略，是浏览器最核心最基本的安全功能。 同源就是指 协议、域名、端口都要相同 跨域的解决方案： JSONP 由前端解决跨域问题，只能解决 GET 请求 CORS 是一个 W3C 标准，提供了 Web 服务从不同网域传来沙盒脚本的方法，避开浏览器的同源策略 后端解决方案 在 类 / 方法 上加注解 @CrossOrigin(origins = \"*\") 标识此 类 / 方法 接收所有域发来的请求 @Controller @RequestMapping(\"/user\") @CrossOrigin(origins = \"*\") public class TestController { @RequestMapping(\"/get.do\") @ResponseBody //@CrossOrigin(origins = \"*\") public User getUser(){ return new User(\"mike\", \"123\"); } } 也可以使用配置类实现 略 也可以使用 xml 配置解决 \u003cmvc:cors\u003e \u003cmvc:mapping path=\"/**\"/\u003e \u003c/mvc:cors\u003e ","date":"2022-04-12","objectID":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"VUE自学笔记","uri":"/vue%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#跨域问题"},{"categories":null,"content":"\rShiro 大连交通大学 信息学院 刘嘉宁 笔记摘自 编程不良人 小陈 ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro"},{"categories":null,"content":"\r权限管理 权限管理属于系统安全的范畴，实现 对用户访问系统的控制 按照 安全规则 或 安全策略 控制用户只能访问自己被授权的资源 身份认证：判断当前访问的用户是否具有访问系统的权限（用户名、口令） 授权：判断通过认证的用户是否具有访问系统资源的权限（访问控制） ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#权限管理"},{"categories":null,"content":"\rShiro 是一款 Java 权限管理框架，由 Apache 公司开发 相比 SpringSecurity 框架没有其功能强大，但相对简单、易用 ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-1"},{"categories":null,"content":"\rShiro 核心架构 Security Manager：安全管理器 Autheniticator：认证器 Authorizer：授权器 Session Manager：会话管理器 Session Dao：会话 Dao（对会话数据进行增删改查持久化和内存的存储） Cache Manager：缓存管理器（存储用户认证授权数据） Pluggable Realms：可扩展的域（获取认证授权数据，完成认证授权操作） Cryptography：算法匹配器（提供一些常用算法、工具类） ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-核心架构"},{"categories":null,"content":"\rShiro 认证判断用户是否为系统的合法用户，判断用户的用户名和口令是否和系统中的一致 Shiro 认证的关键对象 Subject 主体：进行认证的都称为主体（用户、程序） Principal 身份信息：主体进行认证的标识，要具有唯一性，可以有多个身份但必须有一个主身份（用户名、ID 号等） Credential 凭证信息：只有主体知道的安全信息（密码、证书） 认证流程 将用户的身份信息和凭证信息生成 Token 令牌，验证 Token 是否正确，做处理 ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-认证"},{"categories":null,"content":"\rShiro 使用\r导入依赖 \u003c!-- https://mvnrepository.com/artifact/org.apache.shiro/shiro-core --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.shiro\u003c/groupId\u003e \u003cartifactId\u003eshiro-core\u003c/artifactId\u003e \u003cversion\u003e1.9.0\u003c/version\u003e \u003c/dependency\u003e 在 resources 目录下创建 Shiro 的配置文件 shiro.ini [users] xiaochen:123 zhangsan:123456 lisi:789 创建测试类 public static void main(String[] args) { //创建安全管理器对象 DefaultSecurityManager securityManager = new DefaultSecurityManager(); //为安全管理器设置 realm securityManager.setRealm(new IniRealm(\"classpath:shiro.ini\")); //使用安全工具类设置安全管理器 SecurityUtils.setSecurityManager(securityManager); //获得当前登录的主体对象 Subject subject = SecurityUtils.getSubject(); //创建用户名密码的令牌 UsernamePasswordToken token = new UsernamePasswordToken(\"xiaochen\", \"123\"); try { //(boolean) 判断是否认证成功 System.out.println(subject.isAuthenticated()); //用户认证, 认证失败会抛出异常 subject.login(token); System.out.println(subject.isAuthenticated()); } catch (UnknownAccountException e) { System.out.println(\"未知的账号: 用户名不存在\"); } catch (IncorrectCredentialsException e) { System.out.println(\"无效的凭证信息: 密码错误\"); } } 认证流程： 进入 DelegatingSubject 验证是否有会话 调用内部的 securityManager 的 login 方法 进入 ModularRealmAuthenticator 的内部验证是否配了 Realm 验证是否支持 token 进入其内部代理的 AuthenticatingRealm 类的 doGetAuthenticationInfo 方法查看缓存中是否存在 token 调用子类 SimpleAccountRealm 类的 doGetAuthenticationInfo 方法开始校验 调用 getUser 方法通过用户名查询账户（会抛出 UnknownAccountException 账户不存在异常） doGetAuthenticationInfo 方法继续验证是否锁定，验证密码是否过期 回到 AuthenticatingRealm 类的 assertCredentialsMatch 方法使用内部代理的 CredentialsMatch 验证密码是否匹配 由 SimpleAccountRealm 类的 doGetAuthenticationInfo 方法完成对用户名的校验 由 SimpleAccountRealm 的父类 AuthenticatingReam 类的 assertCredentialsMatch 方法完成对密码的校验 由 SimpleAccountRealm 类的 doGetAuthorizationInfo 方法完成授权 ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-使用"},{"categories":null,"content":"\r自定义 Realm 自定义 Realm 类继承 AuthorizingRealm 授权是 每次查询权限 时调用，在授权方法中查询用户的权限信息 认证中的用户名由此类来判断，密码由 SimpleAuthenticationInfo 的父类判断、抛出异常 public class CustomerRealm extends AuthorizingRealm { //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { return null; } //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { //获取token中的身份信息 String principal = (String) token.getPrincipal(); //从数据库中获取用户名密码信息做判断 if (\"xiaochen\".equals(principal)){ //用户名 密码 当前Realm名字 return new SimpleAuthenticationInfo(principal, \"123\", this.getName()); } return null; } } ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#自定义-realm"},{"categories":null,"content":"\rShiro 的加密算法 MD5 算法 MD5 算法不可逆，一个明文对应一个密文( 16进制，32位长度的字符串 ) 一般用来加密、签名( 校验和 ) MD5 加盐：就是在明文加上随机的字符后再进行加密 // 明文 + 盐 + hash散列次数 Md5Hash md5Hash = new Md5Hash(\"123\", \"X*1oq\", 1024); //默认盐加在明文前 System.out.println(md5Hash.toHex()); Shiro 中的密码校验机制使用的是 AuthenticatingReam 类的 assertCredentialsMatch 方法的底层调用的是自身代理的 CredentialsMatcher 对象，所以在创建自定义的 Realm 类时，可以为其 set 一个 CredentialsMatcher ：HashedCredentialsMatcher 自定义 Realm 类 public class CustomerRealm extends AuthorizingRealm { //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { return null; } //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { //获取token中的用户名 String principal = (String) token.getPrincipal(); //从数据库中获取用户名密码信息做判断 if (\"xiaochen\".equals(principal)){ //用户名 return new SimpleAuthenticationInfo(principal, //加salt后的密码 \"1846940e9a8bf8560e2311ec98a55a43\", //账户对应的随机盐 ByteSource.Util.bytes(\"X*1oq\"), //当前Realm名字 this.getName()); } return null; } } 测试使用 DefaultSecurityManager securityManager = new DefaultSecurityManager(); //创建自定义的 Realm 实例 CustomerRealm realm = new CustomerRealm(); //创建 Shiro 提供的 CredentialsMatcher HashedCredentialsMatcher hashedCredentialsMatcher = new HashedCredentialsMatcher(); //设置其加密方式 hashedCredentialsMatcher.setHashAlgorithmName(\"md5\"); //设置散列次数 hashedCredentialsMatcher.setHashIterations(1024); //为自定义的 Realm 设置 CredentialsMatcher realm.setCredentialsMatcher(hashedCredentialsMatcher); securityManager.setRealm(realm); SecurityUtils.setSecurityManager(securityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"xiaochen\", \"123\"); try { subject.login(token); System.out.println(\"成功登录\"); } catch (AuthenticationException e) { e.printStackTrace(); } ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-的加密算法"},{"categories":null,"content":"\rShiro 授权判断用户是否为系统的合法用户，判断用户的用户名和口令是否和系统中的一致 Shiro 授权的关键对象 Subject 主体：主体要访问的系统中的资源（页面、图片） Resource 资源：资源类型（商品信息） 与 资源实例（编号为 001 的商品信息） Permission 权限/许可：主体对资源的操作权限，通过权限可知对哪些资源有哪些操作许可（查询权限、修改权限） 授权流程 为用户授对应权限，当用户操作资源时，判断其是否有权限 授权方式： 基于角色的访问控制：RBAC（Role-Based Access Control）以角色为中心进行访问控制 基于资源的访问控制：RBAC（Resource-Based Access Control）已资源为中心进行访问控制 权限字符串： 资源标识符 : 操作 : 资源实例标识符 意思是对哪个资源的哪个实例具有什么操作 用户创建：user:create 用户修改实例 001 的权限：user:update:001 用户对实例 001 的所有权限：user:*:001 ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-授权"},{"categories":null,"content":"\rShiro 授权的使用 doGetAuthorizationInfo 授权方法在每次 查询权限信息时 被调用 public class CustomerRealm extends AuthorizingRealm { //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { //获取身份信息 String primaryPrincipal = (String) principals.getPrimaryPrincipal(); System.out.println(primaryPrincipal); //将数据库中查询出的角色信息赋给权限对象 SimpleAuthorizationInfo simpleAuthorizationInfo = new SimpleAuthorizationInfo(); simpleAuthorizationInfo.addRole(\"user\"); simpleAuthorizationInfo.addRole(\"admin\"); //将数据库中查询出的权限信息赋给权限对象 simpleAuthorizationInfo.addStringPermission(\"user:*:01\"); simpleAuthorizationInfo.addStringPermission(\"order:create\"); return simpleAuthorizationInfo; } //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { return null; } } 测试使用 public static void main(String[] args) { DefaultSecurityManager securityManager = new DefaultSecurityManager(); //创建自定义的 Realm 实例 CustomerRealm realm = new CustomerRealm(); //创建 Shiro 提供的 CredentialsMatcher HashedCredentialsMatcher hashedCredentialsMatcher = new HashedCredentialsMatcher(); //设置其加密方式 hashedCredentialsMatcher.setHashAlgorithmName(\"md5\"); //设置散列次数 hashedCredentialsMatcher.setHashIterations(1024); //为自定义的 Realm 设置 CredentialsMatcher realm.setCredentialsMatcher(hashedCredentialsMatcher); securityManager.setRealm(realm); SecurityUtils.setSecurityManager(securityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"xiaochen\", \"123\"); try { subject.login(token); System.out.println(\"成功登录\"); } catch (AuthenticationException e) { e.printStackTrace(); } //如果成功认证 if (subject.isAuthenticated()){ //该用户是否有 admin 的权限(boolean) System.out.println(subject.hasRole(\"admin\")); //该用户是否分别有 列表中 的权限(boolean[]) boolean[] booleans = subject.hasRoles(Arrays.asList(\"admin\", \"super\")); for (boolean b : booleans) { System.out.print(b+\" \"); } //该用户是否有所有 列表中 的权限(boolean) System.out.println(subject.hasAllRoles(Arrays.asList(\"admin\", \"user\"))); System.out.println(); System.out.println(\"=============================\"); //该用户是否有 字符串 中的权限 System.out.println(\"所有权限\"+subject.isPermitted(\"user:*:*\")); System.out.println(\"创建01权限\"+subject.isPermitted(\"user:create:01\")); //该用户分别具有这些权限? boolean[] permitted = subject.isPermitted(\"user:*:02\", \"order:*:02\", \"order:update:01\"); for (boolean b : permitted) { System.out.print(b+\" \"); } System.out.println(); //该用户是否同时具有这些权限? System.out.println(subject.isPermittedAll(\"user:create:01\", \"order:create:02\")); } } ","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#shiro-授权的使用"},{"categories":null,"content":"\r实战补充 Shiro 提供了 ShiroFilter 过滤器，实现对每次请求的认证操作 设置 SpringMVC 及 Shiro 的依赖 \u003c!-- https://mvnrepository.com/artifact/javax.servlet/javax.servlet-api --\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003cversion\u003e4.0.1\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-webmvc\u003c/artifactId\u003e \u003cversion\u003e5.3.18\u003c/version\u003e \u003c/dependency\u003e \u003c!-- https://mvnrepository.com/artifact/org.apache.shiro/shiro-spring --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.shiro\u003c/groupId\u003e \u003cartifactId\u003eshiro-spring\u003c/artifactId\u003e \u003cversion\u003e1.9.0\u003c/version\u003e \u003c/dependency\u003e 编写 web.xml 文件内容 \u003c!-- shiro过虑器，DelegatingFilterProxy通过代理模式 关联spring容器中的bean和filter --\u003e \u003cfilter\u003e \u003cfilter-name\u003eshiroFilter\u003c/filter-name\u003e \u003cfilter-class\u003eorg.springframework.web.filter.DelegatingFilterProxy\u003c/filter-class\u003e \u003c!-- 设置true由servlet容器控制filter的生命周期 --\u003e \u003cinit-param\u003e \u003cparam-name\u003etargetFilterLifecycle\u003c/param-name\u003e \u003cparam-value\u003etrue\u003c/param-value\u003e \u003c/init-param\u003e \u003c!-- 设置spring容器filter的bean id，如果不设置则找与filter-name一致的bean--\u003e \u003c!-- \u003cinit-param\u003e--\u003e \u003c!-- \u003cparam-name\u003etargetBeanName\u003c/param-name\u003e--\u003e \u003c!-- \u003cparam-value\u003eshiroFilter\u003c/param-value\u003e--\u003e \u003c!-- \u003c/init-param\u003e--\u003e \u003c/filter\u003e \u003cfilter-mapping\u003e \u003cfilter-name\u003eshiroFilter\u003c/filter-name\u003e \u003curl-pattern\u003e/*\u003c/url-pattern\u003e \u003c/filter-mapping\u003e 编写 Spring 配置文件内容 \u003c!-- 设置自动注入依赖 --\u003e \u003ccontext:component-scan base-package=\"com.test\" /\u003e \u003c!-- 设置视图解析器, 将默认前缀设为项目根目录, 默认后缀为 .html --\u003e \u003cbean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" \u003e \u003cproperty name=\"prefix\" value=\"/\" /\u003e \u003cproperty name=\"suffix\" value=\".html\" /\u003e \u003c/bean\u003e 编写 Shiro 的配置类 @Configuration public class ShiroConfig { //1.创建 ShiroFilter 负责拦截所有请求 //将 name 设为与 web.xml 中 filter-name 一致, 让过滤器自动找到这个 bean @Bean(name = \"shiroFilter\") public ShiroFilterFactoryBean getShiroFilterFactoryBean(DefaultWebSecurityManager defaultWebSecurityManager){ //创建过滤工厂实例, 设置默认安全管理器 ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(defaultWebSecurityManager); Map\u003cString, String\u003e map = new HashMap\u003c\u003e(); //配置系统的受限资源: 所有请求 map.put(\"/index.html\", \"authc\"); // authc 代表资源需要认证和授权 //配置系统的公共资源 map.put(\"/user/login\", \"anon\"); shiroFilterFactoryBean.setFilterChainDefinitionMap(map); //设置被拦截时重定向的页面 shiroFilterFactoryBean.setLoginUrl(\"/login.html\"); return shiroFilterFactoryBean; } //2.创建安全管理器 @Bean public DefaultWebSecurityManager getDefaultWebSecurityManager(Realm realm){ DefaultWebSecurityManager defaultWebSecurityManager = new DefaultWebSecurityManager(); defaultWebSecurityManager.setRealm(realm); return defaultWebSecurityManager; } //3.创建自定义 Realm @Bean public Realm getRealm(){ return new CustomerRealm(); } } 配置 受限、公共 资源时设置的简称（Shiro默认的过滤器） 配置缩写 对应的过滤器 功能 anon AnonymousFilter 指定 url 可以未认证时访问 authc FormAuthenticationFilter 指定 url 需要认证 username password rememberMe 等参数。但一般不用这个，自定义逻辑可以更好的定制出错的返回信息 authcBasic BasicHttpAuthenticationFilter 指定 url 需要 basic 登录 logout LogoutFilter 配置指定 url 即可, 退出, 登出过滤器 noSessionCreation NoSessionCreationFilter 禁止创建会话 perms PermissionsAuthorizationFilter 需要指定权限才能访问 port PortFilter 需要指定端口才能访问 rest HttpMethodPermissionFilter 将 http 请求方法转化成相应的动词来构造一个权限字符串 roles RolesAuthorizationFilter 需要指定角才能访问 ssl SslFilter 需要 https 请求才能访问 user UserFilter 需要已登录或 ‘记住我’ 的用户才能访问 编写认证授权的 Realm 类内容 public class CustomerRealm extends AuthorizingRealm { @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { return null; } @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String username = (String) token.getPrincipal(); if (\"xiaochen\".equals(username)) { return new SimpleAuthenticationInfo(username, \"123\", this.getName()); } return null; } } 编写控制层内容 @Controller @RequestMapping(\"/test\") public class MainController { //http://localhost:8080/springMVCWithShiro/test/login.do @RequestMapping(\"/","date":"2022-04-11","objectID":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:0","series":null,"tags":null,"title":"Shiro自学笔记md版","uri":"/shiro%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#实战补充"},{"categories":null,"content":"\rJava 多线程笔记 大连交通大学 信息学院 刘嘉宁 笔记摘自 西部开源 秦疆 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#java-多线程笔记"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#多线程基础"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#进程与线程"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#thread-类常用方法"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的五大步骤"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的相关方法"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的停止"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的阻塞"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的礼让"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的插队"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的优先级"},{"categories":null,"content":"\r多线程基础\r进程与线程 进程（Process）：进程就是程序的一次执行过程，是系统分配的单位，操作系统在执行时里面有很多进程 线程（Thread）：一个进程中可以有一至多个线程，是 CPU 调度和执行的单位，真正的线程是多个核心每个核心处理一个线程 Thread 类常用方法 Thread.currentThread() 获取当前线程 Thread.currentThread().getName() 获取当前线程 name new Thread(t1, \"张三\") 创建线程对象时，为线程设置 name Thread.sleep(200); 设置阻塞，单位 ms 线程的五大步骤 新建 就绪 运行 阻塞 终止 线程的相关方法 final void setPriority(int newPriority) 更改线程的优先级 static void sleep(long millis) 【休眠】 void join() 等待该线程终止，【插队】 static void yield() 暂停当前正在执行的线程对象，【礼让】 void interrupt() 中断线程（勿用） boolean isAlive() 测试线程是否处于活动状态 Thread.state getState() 获取线程的状态（NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED） 线程的停止 stop()、destory() 已经被标识过时不建议使用 让线程自己停下来【推荐】 设置一个标记位，当其值为 flase 时，终止其循环 class MyThread implements Runnable{ boolean flag = true; @Override public void run() { int i = 1; while (flag){ System.out.println(i++); } } public void stop(){ this.flag = false; } } 线程的阻塞 Thread.sleep(1000ms) 【静态方法】 每个线程都有一把锁，sleep 不会释放锁 wait() 同步锁定时 线程的礼让 Thread.yield()【静态方法】 让当前线程从运行状态变为就绪状态，暂停一下 cpu 会重新调度线程，不一定会礼让成功 线程的插队 t.join() 让 t 线程强制执行，其它线程阻塞，执行结束后其他线程才可继续 线程的优先级 getPriority().setPriority(5) 线程的优先级由 1 ~ 10 表示，优先级越高权重就越大，但调度器未必完全按优先级来执行 守护线程 daemon 线程 线程分为用户线程和守护线程 JVM 不会等待守护线程执行完毕 setDaemon(true) 设置一个线程为守护线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#守护线程-daemon-线程"},{"categories":null,"content":"\r线程的实现 run 方法：线程执行的内容 start 方法：开启线程的方法，线程开启不一定立即执行，由 CPU 调度执行 继承 Thead 类 OOP 单继承局限性 创建一个类，继承 Thread 类 class 线程对象 extends Thread 重写 run 方法 调用其 start 方法开启线程 实现 Runnable 接口 避免单继承的局限性，灵活方便，方便同一个对象被多个线程使用 创建一个类，实现 Runnable 接口 class 线程对象 implements Runnable 重写 run 方法 创建 Thread 代理类实例 Thread 代理对象 = new Thread(线程对象) 调用代理类 srart 方法开启线程 实现 Callable 接口 可以定义返回值，可以抛出异常，实现较为复杂 创建一个类，实现 Callable 接口 class 线程对象 implements Callable\u003c返回值类型\u003e 重写 call 方法（需要抛出异常）public Boolean call() throws Exception 创建线程对象 创建执行服务 // 线程池数量（也就是想要创建几个线程） ExecutorService service = Executors.newFixedThreadPool(1); 提交执行 //想要创建几个线程就写多少行 Future\u003cBoolean\u003e r = service.submit(线程对象); 获取结果 //创建了几个线程就写多少行 返回值类型 res = r.get(); 关闭服务 service.shutdown(); 小问题 使用 Runnable 实现多线程的时候，为什么说 Thread 是代理类？ 因为此时的 Thread 充当的就是静态代理中的代理类 在 new Thread(线程对象) 后，Thread 类会将线程对象作为其成员变量 private Runnable target; 在启动线程后，调用 Thread 类的 run 方法实际上调用的是 target.run(); 并对其进行访问控制、功能增强 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程的实现"},{"categories":null,"content":"\r线程的实现 run 方法：线程执行的内容 start 方法：开启线程的方法，线程开启不一定立即执行，由 CPU 调度执行 继承 Thead 类 OOP 单继承局限性 创建一个类，继承 Thread 类 class 线程对象 extends Thread 重写 run 方法 调用其 start 方法开启线程 实现 Runnable 接口 避免单继承的局限性，灵活方便，方便同一个对象被多个线程使用 创建一个类，实现 Runnable 接口 class 线程对象 implements Runnable 重写 run 方法 创建 Thread 代理类实例 Thread 代理对象 = new Thread(线程对象) 调用代理类 srart 方法开启线程 实现 Callable 接口 可以定义返回值，可以抛出异常，实现较为复杂 创建一个类，实现 Callable 接口 class 线程对象 implements Callable\u003c返回值类型\u003e 重写 call 方法（需要抛出异常）public Boolean call() throws Exception 创建线程对象 创建执行服务 // 线程池数量（也就是想要创建几个线程） ExecutorService service = Executors.newFixedThreadPool(1); 提交执行 //想要创建几个线程就写多少行 Future r = service.submit(线程对象); 获取结果 //创建了几个线程就写多少行 返回值类型 res = r.get(); 关闭服务 service.shutdown(); 小问题 使用 Runnable 实现多线程的时候，为什么说 Thread 是代理类？ 因为此时的 Thread 充当的就是静态代理中的代理类 在 new Thread(线程对象) 后，Thread 类会将线程对象作为其成员变量 private Runnable target; 在启动线程后，调用 Thread 类的 run 方法实际上调用的是 target.run(); 并对其进行访问控制、功能增强 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#继承-thead-类"},{"categories":null,"content":"\r线程的实现 run 方法：线程执行的内容 start 方法：开启线程的方法，线程开启不一定立即执行，由 CPU 调度执行 继承 Thead 类 OOP 单继承局限性 创建一个类，继承 Thread 类 class 线程对象 extends Thread 重写 run 方法 调用其 start 方法开启线程 实现 Runnable 接口 避免单继承的局限性，灵活方便，方便同一个对象被多个线程使用 创建一个类，实现 Runnable 接口 class 线程对象 implements Runnable 重写 run 方法 创建 Thread 代理类实例 Thread 代理对象 = new Thread(线程对象) 调用代理类 srart 方法开启线程 实现 Callable 接口 可以定义返回值，可以抛出异常，实现较为复杂 创建一个类，实现 Callable 接口 class 线程对象 implements Callable\u003c返回值类型\u003e 重写 call 方法（需要抛出异常）public Boolean call() throws Exception 创建线程对象 创建执行服务 // 线程池数量（也就是想要创建几个线程） ExecutorService service = Executors.newFixedThreadPool(1); 提交执行 //想要创建几个线程就写多少行 Future r = service.submit(线程对象); 获取结果 //创建了几个线程就写多少行 返回值类型 res = r.get(); 关闭服务 service.shutdown(); 小问题 使用 Runnable 实现多线程的时候，为什么说 Thread 是代理类？ 因为此时的 Thread 充当的就是静态代理中的代理类 在 new Thread(线程对象) 后，Thread 类会将线程对象作为其成员变量 private Runnable target; 在启动线程后，调用 Thread 类的 run 方法实际上调用的是 target.run(); 并对其进行访问控制、功能增强 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#实现-runnable-接口"},{"categories":null,"content":"\r线程的实现 run 方法：线程执行的内容 start 方法：开启线程的方法，线程开启不一定立即执行，由 CPU 调度执行 继承 Thead 类 OOP 单继承局限性 创建一个类，继承 Thread 类 class 线程对象 extends Thread 重写 run 方法 调用其 start 方法开启线程 实现 Runnable 接口 避免单继承的局限性，灵活方便，方便同一个对象被多个线程使用 创建一个类，实现 Runnable 接口 class 线程对象 implements Runnable 重写 run 方法 创建 Thread 代理类实例 Thread 代理对象 = new Thread(线程对象) 调用代理类 srart 方法开启线程 实现 Callable 接口 可以定义返回值，可以抛出异常，实现较为复杂 创建一个类，实现 Callable 接口 class 线程对象 implements Callable\u003c返回值类型\u003e 重写 call 方法（需要抛出异常）public Boolean call() throws Exception 创建线程对象 创建执行服务 // 线程池数量（也就是想要创建几个线程） ExecutorService service = Executors.newFixedThreadPool(1); 提交执行 //想要创建几个线程就写多少行 Future r = service.submit(线程对象); 获取结果 //创建了几个线程就写多少行 返回值类型 res = r.get(); 关闭服务 service.shutdown(); 小问题 使用 Runnable 实现多线程的时候，为什么说 Thread 是代理类？ 因为此时的 Thread 充当的就是静态代理中的代理类 在 new Thread(线程对象) 后，Thread 类会将线程对象作为其成员变量 private Runnable target; 在启动线程后，调用 Thread 类的 run 方法实际上调用的是 target.run(); 并对其进行访问控制、功能增强 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#实现-callable-接口"},{"categories":null,"content":"\r线程的实现 run 方法：线程执行的内容 start 方法：开启线程的方法，线程开启不一定立即执行，由 CPU 调度执行 继承 Thead 类 OOP 单继承局限性 创建一个类，继承 Thread 类 class 线程对象 extends Thread 重写 run 方法 调用其 start 方法开启线程 实现 Runnable 接口 避免单继承的局限性，灵活方便，方便同一个对象被多个线程使用 创建一个类，实现 Runnable 接口 class 线程对象 implements Runnable 重写 run 方法 创建 Thread 代理类实例 Thread 代理对象 = new Thread(线程对象) 调用代理类 srart 方法开启线程 实现 Callable 接口 可以定义返回值，可以抛出异常，实现较为复杂 创建一个类，实现 Callable 接口 class 线程对象 implements Callable\u003c返回值类型\u003e 重写 call 方法（需要抛出异常）public Boolean call() throws Exception 创建线程对象 创建执行服务 // 线程池数量（也就是想要创建几个线程） ExecutorService service = Executors.newFixedThreadPool(1); 提交执行 //想要创建几个线程就写多少行 Future r = service.submit(线程对象); 获取结果 //创建了几个线程就写多少行 返回值类型 res = r.get(); 关闭服务 service.shutdown(); 小问题 使用 Runnable 实现多线程的时候，为什么说 Thread 是代理类？ 因为此时的 Thread 充当的就是静态代理中的代理类 在 new Thread(线程对象) 后，Thread 类会将线程对象作为其成员变量 private Runnable target; 在启动线程后，调用 Thread 类的 run 方法实际上调用的是 target.run(); 并对其进行访问控制、功能增强 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#小问题"},{"categories":null,"content":"\r线程同步 线程同步就是一种等待机制，多个需要同时访问此对象的线程进入线程的等待池形成队列，等待前一个线程执行完毕，后面的才能执行 锁机制，为当前线程设置排它锁，独占资源 synchronized lock 使用 Lock 对象充当同步锁，Lock 接口的实现类 ReentrantLock 【可重入锁】可以显式的加锁、释放锁 是显式锁，需要手动关闭锁 只有代码块锁，没有方法锁 使用 Lock 锁减少 JVM 调度线程的时间，性能更好 优先使用：Lock \u003e 同步代码块 \u003e 同步方法 class MyThread1 implements Runnable { private ReentrantLock lock = new ReentrantLock(); @Override public void run() { try { lock.lock(); ... //}catch (Exception e){ }finally { lock.unlock(); } } } 锁机制会存在的问题： 当一个线程持有锁，其他线程都要挂起等待 多线程竞争时，加锁、释放锁，会导致较多的上下文切换、调度延时，引起性能问题 如果一个优先级高的线程在等待优先级低的线程释放锁，导致性能倒置 为方法加锁 锁的是同步监视器 也就是 this class Blank{ int money; synchronized void buy(){ ... } } 添加锁方法块 锁的同步监视器是括号中的对象 this：锁 this 就是给当前这个对象整个锁起来了，相等于给银行锁起来，但是人们还在里面取钱 变量：锁 变化的量 ，锁的是进行业务操作的对象，也就是账户这个类而不是银行这个类 class Account{ ... } class Blank{ Account account; //如果此时将fun方法上锁，就是错误的锁 fun(){ sybchronized (account) { ... } } } ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程同步"},{"categories":null,"content":"\r死锁 多个线程都在等待对方释放资源，都停止执行的情形 互斥条件：一个资源每次只能被一个进程使用 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系 class DLTest extends Thread { static Integer a = new Integer(0); static Integer b = new Integer(1); int flag; public DLTest(int flag) { this.flag = flag; } @Override public void run() { makeup(); } private void makeup() { if (flag == 0){ synchronized (a){ System.out.println(Thread.currentThread().getName()+\" 拿到了a\"); synchronized (b){ System.out.println(Thread.currentThread().getName()+\" 拿到了b\"); } } }else { synchronized (b){ System.out.println(Thread.currentThread().getName()+\" 拿到了b\"); synchronized (a){ System.out.println(Thread.currentThread().getName()+\" 拿到了a\"); } } } } public static void main(String[] args) { DLTest dl1 = new DLTest(0); DLTest dl2 = new DLTest(1); dl1.start(); dl2.start(); } } 使用命令行查看是否死锁： jps //查看当前用户下的java进程的pid及基本信息 jstack 进程号 //查看指定进程（pid）的堆栈信息，用以分析线程情况 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#死锁"},{"categories":null,"content":"\r生产者和消费者问题 生产者和消费者问题 假设仓库中只能存放一件产品, 生产者将生产出来的产品放入仓库, 消费者将仓库中产品取走消费. 如果仓库中没有产品, 则生产者将产品放入仓库, 否则停止生产并等待, 直到仓库中的产品被消费者取走为止. 如果仓库中放有产品, 则消费者可以将产品取走消费, 否则停止消费并等待, 直到仓库中再次放入产品为止. 只能在同步代码块中使用 wait() 让线程处于等待状态，直到其他线程通知【会释放锁】 notify() 唤醒一个处于等待状态的线程 notityAll() 唤醒一个对象上所有调用 wait 的线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#生产者和消费者问题"},{"categories":null,"content":"\r线程池 经常创建、销毁线程对性能影响比较大 使用多线程可以 提高相应速度 降低资源消耗 便于线程管理 ExecutorService 线程池接口 Executors 工具类、工厂类，用于创建并返回不同类型的线程池 import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolTest { public static void main(String[] args) { //创建一个线程池，池大小为 10 ExecutorService service = Executors.newFixedThreadPool(10); //执行 service.execute(new MyThread2()); service.execute(new MyThread2()); service.execute(new MyThread2()); service.execute(new MyThread2()); service.execute(new MyThread2()); //关闭线程池 service.shutdown(); } } class MyThread2 implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName()); } } Callable 就是使用的线程池创建的线程 ","date":"2022-04-05","objectID":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"Java多线程复习笔记md版","uri":"/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0md%E7%89%88/#线程池"},{"categories":null,"content":"\rJUC 大连交通大学 信息学院 刘嘉宁 笔记摘自 尚硅谷 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#juc"},{"categories":null,"content":"\r什么是 JUC 是 java.util.concurrent 工具包的简称 是一个线程处理工具包，从 JDK 1.5 开始出现 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-juc"},{"categories":null,"content":"\r进程与线程 进程（Process）：指系统中正在运行的一个应用程序，程序一旦运行就是进程【资源分配的最小单位】 线程（Thread）：系统分配处理器时间资源的基本单元，是进程之内独立执行的一个单元执行流【程序执行的最小单位】 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:1","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#进程与线程"},{"categories":null,"content":"\r进程的状态 线程中的枚举类：Thread.state NEW 新建 RUNNABLE 准备就绪 BLOCKED 阻塞 WAITING 不见不散（wait() / join() 没有指定超时值时） TIMED_WAITING 过时不候 （wait() / join() 指定了超时值时） TERMINATED 终结 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:2","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#进程的状态"},{"categories":null,"content":"\rwait 与 sleep 区别不同点： 声明的位置不同：Thread 类中声明 sleep , Object 类中声明 wait 需求不同：sleep 可以在任何需要的场景下调用，wait 必须使用在同步代码块或同步方法中 是否释放同步锁：wait 会释放锁，sleep 不会 结束阻塞的方式：wait 需要 notify / notifyAll 结束阻塞，sleep 等自身结束就好 相同点： 都会被 interrupted 方法中断 都是在哪里睡就在哪里醒 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:3","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#wait-与-sleep-区别"},{"categories":null,"content":"\r并发与并行 串行：多个任务排队执行，一次只能取一个执行一个 并行：同一时间点，可以同时取多个任务，同时执行多个任务，多个 CPU 核心独立同时执行 并发：同一时间段内，同一时间只能执行一个任务，但是这段时间内看起来像是同时执行的 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:4","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#并发与并行"},{"categories":null,"content":"\r其他概念 管程：Monitor 监视器，就是锁，锁住的对象（每个对象都有一个管程对象） 锁的进入、退出就是使用管程对象实现的 守护线程：t.setDaemon(true) 将一个线程设为守护线程，守护线程的生命周期和一个程序的生命周期相同 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:5","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#其他概念"},{"categories":null,"content":"\rLock 接口 什么是可重入？ 可重入性表现在同一个线程可以多次获得锁，而不同线程依然不可多次获得锁，借助 AQS 同步器来实现 Lock 与 synchronized 的区别 Lock 不是 java 语言内置的 Lock 需要手动上锁和释放锁 synchronized 发生异常时会自动释放锁，Lock 在发生异常时不会释放锁，需要在 finally 中释放锁 Lock 可以让等待锁的线程响应中断，synchronized 不行 Lock 可以知道有没有成功获取锁，synchronized 不行 Lock 在锁竞争激烈时效率较高 Lock 接口的实现类 ReentrantLock 可重入锁 class MyThread{ Lock lock = new ReentrantLock(); void fun(){ lock.lock(); try{ //业务代码 }finally{ lock.unlock(); } } } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#lock-接口"},{"categories":null,"content":"\r线程间通信 即 生产者与消费者 的问题 用到的 Object 方法 wait() 在其他线程调用此对象的 notify() 方法前，导致当前线程等待【会释放锁】 notify() 唤醒在此对象监视器上等待的一个线程 notifyAll() 唤醒在此对象监视器上等待的所有线程 用到的 Condition 方法 用法：使用 Lock 锁时，用下面方法进行等待和唤醒 Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); condition.await(); condition.signal(); condition.signalAll(); await() 同 wait() signal() 同 notify() signalAll() 同 notifyAll() 生产者和消费者例子之 synchronized public class ShareIncrDecr { public static void main(String[] args) { Share share = new Share(); new Thread(()-\u003e{ for (int i = 0; i \u003c 10; i++) { try { //这是生产者线程，负责 +1 share.incr(); } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); new Thread(()-\u003e{ for (int i = 0; i \u003c 10; i++) { try { //这是消费者线程，负责 -1 share.decr(); } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); } } /** * Share 类就是一个带控制的共享对象 * 仓库空时，就允许生产者生产，不允许消费者消费 * 仓库满时，就允许消费者消费，不允许生产者生产 */ class Share{ private int number = 0; void incr() throws InterruptedException { synchronized(this){ if (number != 0){ //非空就等待 this.wait(); } //生产 number++; System.out.println(Thread.currentThread().getName()+\" 目前 \"+number); //唤醒等待着的所有线程 this.notifyAll(); } } void decr() throws InterruptedException { synchronized(this){ if (number != 1){ //不满就等待 this.wait(); } //消费 number--; System.out.println(Thread.currentThread().getName()+\" 目前 \"+number); //唤醒等待着的所有线程 this.notifyAll(); } } } 遇到的问题： 虚假唤醒 就是当有多个生产者多个消费者时，一个生产者在等待的时候，另一个生产者改变了标记值，但是第一个生产者结束等待之后没有再次判断标记值。因为 wait 方法会释放锁，第一个生产者释放了锁，第二个生产者就有可能改变其标记值 解决：if 变 while synchronized(this){ while (number != 1){ //wait 的特点：在哪里睡，就在哪里醒 this.wait(); } number++ / --; this.notifyAll(); } 为什么推荐使用 notifyAll 而不是 notify , notifyAll 岂不是会唤醒所有线程导致 资源竞争 降低性能? 正因为notify只随机唤醒一个阻塞线程，如果一个线程执行完+1之后执行notify，而唤醒的线程不满足执行条件的线程，此时线程就都阻塞了。而使用notifyAll，会唤醒所有阻塞线程，只要有一个线程符合条件就可以继续执行，就不会出现这种情况了。 线程的定制化通信 public class ShareDiy { public static void main(String[] args) { ShareResource shareResource = new ShareResource(); new Thread(()-\u003e{ for (int i = 0; i \u003c 10; i++) { try { shareResource.print5(i); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"AA\").start(); new Thread(()-\u003e{ for (int i = 0; i \u003c 10; i++) { try { shareResource.print10(i); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"BB\").start(); new Thread(()-\u003e{ for (int i = 0; i \u003c 10; i++) { try { shareResource.print15(i); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"CC\").start(); } } class ShareResource{ private int flag = 1; Lock lock = new ReentrantLock(); //每一个 condition 对应了一个线程，让线程依次执行也就是让 condition 依次执行 Condition c1 = lock.newCondition(); Condition c2 = lock.newCondition(); Condition c3 = lock.newCondition(); public void print5(int loop) throws InterruptedException { lock.lock(); try { while (flag != 1){ //如果当前抢到执行的线程不是指定的线程：等待 c1.await(); } for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName()+\" :: \"+i+\"在轮数\"+loop); } //指定下次执行的线程 flag = 2; //唤醒下一线程 c2.signal(); } finally { lock.unlock(); } } public void print10(int loop) throws InterruptedException { lock.lock(); try { while (flag != 2){ //如果当前抢到执行的线程不是指定的线程：等待 c2.await(); } for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName()+\" :: \"+i+\"在轮数\"+loop); } //指定下次执行的线程 flag = 3; //唤醒下一线程 c3.signal(); } finally { lock.unlock(); } } public void print15(int loop) throws InterruptedException { lock.lock(); try { while (flag != 3){ //如果当前抢到执行的线程不是指定的线程：等待 c3.await(); } for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName()+\" :: \"+i+\"在轮数\"+loop); } //指定下次执行的线程 flag = 1; //唤醒下一线程 c1.signal(); } finally { lock.unlock(); } } } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#线程间通信"},{"categories":null,"content":"\r集合的线程安全 ArrayList：当多个线程同时添加、获取元素时，会发生并发修改异常 List list = new ArrayList(); for (int i = 0; i \u003c 10000; i++) { new Thread(()-\u003e{ list.add(1); System.out.println(list); }).start(); } //Exception in thread \"Thread-xx\" java.util.ConcurrentModificationException 解决方案 Vector：是 List 接口的实现类，通过 synchronized 修饰方法实现线程安全，效率较低（JDK 1.0） List list = new Vector(); Collections：通过 Collections 工具类的 synchronizedList 方法返回一个线程安全的 list，效率较低较古老 List list = Collections.synchronizedList(new ArrayList\u003c\u003e()); CopyOnWriteArrayList：是 JUC 包中线程安全 list 使用写时复制技术，就是在并发读的时候处理写的安全 独立写 先复制出一份新集合，向新的集合中写入数据，写完再覆盖合并原有内容，读取新的集合空间中的内容 List list = new CopyOnWriteArrayList(); HashSet：当多个线程同时添加、获取元素时，会发生并发修改异常 Set set = new HashSet(); for (int i = 0; i \u003c 100; i++) { new Thread(()-\u003e{ set.add(UUID.randomUUID().toString().substring(0, 4)); System.out.println(set); }).start(); } //Exception in thread \"Thread-xx\" java.util.ConcurrentModificationException 解决方案 CopyOnWriteArraySet：是 JUC 包中线程安全 set 使用写时复制技术，就是在并发读的时候处理写的安全 独立写 先复制出一份新集合，向新的集合中写入数据，写完再覆盖合并原有内容，读取新的集合空间中的内容 Set set = new CopyOnWriteArraySet(); HashMap：当多个线程同时添加、获取元素时，会发生并发修改异常 Map\u003cString, String\u003e map = new HashMap\u003c\u003e(); for (int i = 0; i \u003c 100; i++) { new Thread(()-\u003e{ map.put(UUID.randomUUID().toString().substring(0, 4), \"1\"); System.out.println(map); }).start(); } //Exception in thread \"Thread-xx\" java.util.ConcurrentModificationException 解决方案 ConcurrentHashMap：是 JUC 包中线程安全 map Map\u003cString, String\u003e map = new ConcurrentHashMap\u003c\u003e(); ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#集合的线程安全"},{"categories":null,"content":"\r多线程锁","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#多线程锁"},{"categories":null,"content":"\rsynchronized 锁的八种情况 class Test{ public static void main(String[] args) throws InterruptedException { Phone phone1 = new Phone(); Phone phone2 = new Phone(); new Thread(()-\u003e{ // phone.sayHello(); phone1.sendSMS(); }).start(); Thread.sleep(100); new Thread(()-\u003e{ phone1.sendEmail(); }).start(); } } class Phone { synchronized void sendSMS() throws InterruptedException { TimeUnit.SECONDS.sleep(4); System.out.println(\"发送短信\"); } synchronized void sendEmail(){ System.out.println(\"发送邮件\"); } void sayHello(){ System.out.println(\"你好\"); } } 标准访问,先短信还是先邮件：是同一把锁，锁的范围是 this 发送短信 发送邮件 在短信方法内停四秒,先短信还是先邮件：是同一把锁，锁的范围是 this 发送短信 发送邮件 普通的 hello 方法,先短信还是先邮件：hello 方法与锁无关，先执行 hello 你好 发送邮件 有两部手机,先短信还是先邮件：不是同一把锁，锁的范围是各自的 this 发送邮件 发送短信 同一部手机,都是静态同步方法,先短信还是先邮件：是同一把锁，锁的范围是 Class 发送短信 发送邮件 有两部手机,都是静态同步方法,先短信还是先邮件：是同一把锁，锁的范围是 Class 发送短信 发送邮件 同一部手机,短信静态同步、邮件同步：不是同一把锁，锁的范围不同 发送邮件 发送短信 有两部手机,短信静态同步、邮件同步：不是同一把锁，锁的范围不同 发送邮件 发送短信 锁的三种表现形式： 对于普通同步方法，锁是当前实例对象 对于静态同步方法，锁是当前类的 Class 对象 对于同步方法块，锁是 Synchronized 括号里的配置的对象 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:1","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#synchronized-锁的八种情况"},{"categories":null,"content":"\r公平锁与非公平锁 非公平锁 synchronized、无参的 ReentrantLock 容易有线程饿死，效率高 不需要排队，直接抢 公平锁 ReentrantLock(true) 阳光普照，效率低 会先判断是否有排队队列，如果有则排队，如果没有则执行 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:2","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#公平锁与非公平锁"},{"categories":null,"content":"\r可重入锁 可重入锁也称递归锁，即进入了第一层之后内层的都可以随意进入 synchronized 是隐式的可重入锁，ReentrantLock 是显式的可重入锁 lock 锁在嵌套 lock 锁时会记录锁的 state 数量，在嵌套中不解锁不会影响运行，但会影响嵌套外的锁上锁 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:3","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#可重入锁"},{"categories":null,"content":"\rCallable \u0026 Future 接口 Callable 实现有返回值的 call 方法 call 方法可以引发异常 不能直接替换 Runnable，因为 Thread 的构造方法不支持 Callable 类型 FutureTask 是 Runnable 接口的实现类，构造器中可以传递 Callable ，实现让 Thread 代理 FutureTask 代理 Callable 实现类 未来任务 FutureTask 原理 单独开辟一个线程，等线程运行结束总结返回其返回值 由于 Callable 是函数式接口，可以用 lambda 表达式简写 FutureTask\u003cInteger\u003e futureTask1 = new FutureTask\u003c\u003e(()-\u003e{ return 1024; }); new Thread(futureTask1).start(); //isDone() 方法，返回线程是否运行结束有返回值 while (!futureTask1.isDone()){ System.out.println(\"等待线程运行\"); } try { //get() 会阻塞线程直到运行完毕 System.out.println(futureTask1.get()); //此时多次 get() 不需要多次执行线程, FutureTask 会记录结果 } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } //线程执行完毕后 main 线程才会结束 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#callable--future-接口"},{"categories":null,"content":"\rJUC 三大辅助类","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#juc-三大辅助类"},{"categories":null,"content":"\r减少计数 CountDownlatch CountDownlatch 类可以设置一个计数器，通过 countDown 方法来进行 -1 操作，当计数器值为 0 时唤醒 await 继续执行 await() 阻塞当前线程 countDown() 将计数器 -1 //创建计数器同时设置值 CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i \u003c 6; i++) { new Thread(()-\u003e { System.out.println(Thread.currentThread().getName()+\"离开了教室\"); //每次执行 countDown 方法计数器的值都 -1 countDownLatch.countDown(); }, String.valueOf(i)).start(); } //阻塞当前线程直到计数器值为 0 countDownLatch.await(); System.out.println(\"班长关门了\"); ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:1","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#减少计数-countdownlatch"},{"categories":null,"content":"\r循环栅栏 CyclicBarrier CyclicBarrier 类允许一组线程互相等待，直到达到某个公共屏障点，这些线程必须不时地等待 CyclicBarrier(int n, Runnable act) n: 到达屏障点的数，act: 执行的功能 await() 让参与者在所有线程执行结束之前，一直等待 //创建循环栅栏, 指定线程数量, 执行成功后的操作 CyclicBarrier cyclicBarrier = new CyclicBarrier(NUMBER, ()-\u003e{ System.out.println(\"七颗龙珠已经集齐, 神龙来喽\"); }); for (int i = 0; i \u003c 7; i++) { new Thread(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"龙珠收集了\"); try { //让参与者等待，直至所有线程运行结束 cyclicBarrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }, String.valueOf(i)).start(); } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:2","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#循环栅栏-cyclicbarrier"},{"categories":null,"content":"\r信号灯 Semaphore Semaphore 类相当一个信号灯，控制同一时间阻塞的线程的数量 acquire() 获取一个许可，其他线程阻塞 release() 释放一个许可，其他阻塞的线程被唤醒 //设置许可数量 Semaphore semaphore = new Semaphore(3); for (int i = 0; i \u003c 6; i++) { new Thread(()-\u003e{ try { //获得一个许可, 阻塞其他线程 semaphore.acquire(); System.out.println(Thread.currentThread().getName()+\"抢到了车位\"); TimeUnit.SECONDS.sleep(new Random().nextInt(5)); System.out.println(Thread.currentThread().getName()+\"------离开了车位\"); } catch (InterruptedException e) { e.printStackTrace(); }finally { //释放这个许可, 唤醒其他线程 semaphore.release(); } }).start(); } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:3","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#信号灯-semaphore"},{"categories":null,"content":"\rReentrantReadWriteLock 读写锁","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#reentrantreadwritelock-读写锁"},{"categories":null,"content":"\r悲观锁与乐观锁 悲观锁：总是假设最坏的情况，每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程 乐观锁：总是假设最好的情况，每次去拿数据的时候不会上锁，但是在更新的时候会判断一下在此期间有没有人去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:1","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#悲观锁与乐观锁"},{"categories":null,"content":"\r表锁与行锁 是数据库中的概念 表锁：对表中数据操作时，对整个表进行上锁，同一时间别人不能操作这个表 行锁：对表中数据操作时，只对这一行进行上锁，同一时间别人还可以操作表中其他字段（会引发死锁） ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#表锁与行锁"},{"categories":null,"content":"\r共享锁与独占锁 共享锁与排它锁都是通过 AQS 实现的 共享锁：共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据 独占锁：也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排他锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:3","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#共享锁与独占锁"},{"categories":null,"content":"\r读锁与写锁 为何要使用读写锁？ 如果未加锁，多个线程可能同时读写，导致写还没结束就开始读 //读写锁的实质是 Lock 锁 ReadWriteLock rwLock = new ReentrantReadWriteLock(); //为代码加写锁 rwLock.writeLock().lock(); rwLock.writeLock().unlock(); //为代码加读锁 rwLock.readLock().lock(); rwLock.readLock().unlock(); /** * 得到的效果就是在写的时候，写锁独占写完这个写下一个，读也不能抢占锁 * 读的时候可以让别的读线程同时读，但是此时不能写 */ 读锁：是共享锁，一个线程读的时候别的线程也可以读，但是不能写 ReentrantReadWriteLock 类的 ReadLock 方法 写锁：是独占锁，一个线程写的时候别的线程不能对其进行任何操作 ReentrantReadWriteLock 类的 WriteLock 方法 读锁写锁都有可能造成死锁，当一线程改的时候要等二线程读，而线程改的时候要等一线程读，发生死锁 锁降级： 将写锁降级为读锁 先获取写锁，再获取读锁，释放写锁，释放读锁 当线程获取读锁的时候，可能有其他线程同时也在持有读锁，因此不能把获取读锁的线程“升级”为写锁 而对于获得写锁的线程，它一定独占了读写锁，因此可以继续让它获取读锁 当它同时获取了写锁和读锁后，还可以先释放写锁继续持有读锁，这样一个写锁就“降级”为了读锁 读写锁的缺点： 造成饥饿锁：一直写没法读，一直读没法写 读的同时不可以写，要等待读完，写的同时可以读 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:4","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#读锁与写锁"},{"categories":null,"content":"\rvolatile 修饰符 确保其修饰的变量在多线程间的可见性 //设置线程停止的标志 private volatile boolean stop = false; //...... public void stop(){ flag = true; //这里推荐使用 interrupt 否则不会立即停止线程，会等待此次线程完成才会停止 monitorThread.interrupt(); } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:5","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#volatile-修饰符"},{"categories":null,"content":"\rBlockingQueue 阻塞队列 阻塞：当队列中元素满的时候 Thread 1 处于阻塞状态，当队列空的时候 Thread 2 处于阻塞状态。就是在某些情况下会挂起线程，一旦满足某些条件，被挂起线程又会自动被唤起 BlockingQueue 阻塞队列一手包办了合适线程的阻塞与唤醒操作，实现类： ArrayBlockingQueue 是基于数组的定长的（有界的）阻塞队列 LinkedblockingQueue 是由链表结构组成的有界阻塞队列，默认大小：Integer.MAX_VALUE DelayQueue 是由优先级队列实现的延迟无界阻塞队列（指定的延迟到了才能从中获取数据） PrionrityBlockingQueue 是支持优先级排序的无界阻塞队列 SynchronousQueue 是单个元素的阻塞队列 LinkedTransferQueue 是链表组成的无界的阻塞队列 LinkedBlockingQueue 是由链表组成的双向阻塞队列 核心方法 通过几组不同的方法实现不同的阻塞处理 抛出异常（ArrayBlockingQueue 为例）： add：当队列满时，继续添加则抛出异常：java.lang.IllegalStateException: Queue full remove：当队列空时，继续移出则抛出异常：java.util.NoSuchElementException elememt：抛出异常：java.util.NoSuchElementException 特殊值（ArrayBlockingQueue 为例）： offer：当队列满时，false poll：当队列空时，null peek：null 阻塞（ArrayBlockingQueue 为例）： put：当队列满时，阻塞队列，直至队列不为满 take：当队列空时，阻塞队列，直至队列不为空 超时（ArrayBlockingQueue 为例）： offer：当队列满时，阻塞队列，直至队列不为满或达到超时时间 pool：当队列空时，阻塞队列，直至队列不为空或达到超时时间 ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#blockingqueue-阻塞队列"},{"categories":null,"content":"\r==ThreadPool 线程池== 创建线程的方式： 继承 Thread 类 实现 Runnable 接口 实现 Callable 接口 使用线程池 什么是线程池 一种线程使用模式。线程过多会带来调度开销， 进而影响缓存局部性和整体性能。 而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。 避免了在处理短时间任务时创建与销毁线程的代价。 线程池不仅能够保证内核的充分利用，还能防止过分调度。 线程池的特点 降低资源消耗：通过重复利用已创建好的线程降低线程创建和销毁造成的销毁 提高响应速度：任务到达时，可以不需要等待就能立即执行 提高线程的可管理性：可以对线程统一分配，调优和监控 线程池的架构 Java 中的线程池通过 Executor 框架实现 线程池的使用方式 三大常用线程池 底层都是通过实例 ThreadPoolExecutor 不同的构造方法实现的线程池 Executors.newFixedThreadPool(int 池大小); 一池多线程 线程定量，方便控制线程的并发量 线程可以重复利用，在显式关闭之前一直都在 超出的线程被提交时需在队列中等待 //创建线程池 池的大小为 5 ExecutorService threadPool1 = Executors.newFixedThreadPool(5); try { //循环 10 次，让每个线程运行两次 for (int i = 0; i \u003c 10; i++) { threadPool1.execute(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"来了啊 \"); }); } } finally { //关闭线程池 threadPool1.shutdown(); } /* pool-1-thread-3来了啊 pool-1-thread-4来了啊 pool-1-thread-5来了啊 pool-1-thread-2来了啊 pool-1-thread-1来了啊 pool-1-thread-2来了啊 pool-1-thread-5来了啊 pool-1-thread-4来了啊 pool-1-thread-3来了啊 pool-1-thread-1来了啊 Executors.newSingleThreadExecutor(); 一池一线程，一个任务一个任务执行 线程池中最多执行 1 个线程，之后提交的线程活动将会排在队列中以此执行 //创建一池一线程的线程池 ExecutorService threadPool2 = Executors.newSingleThreadExecutor(); try { //循环 10 次，让这个线程运行 10 次 for (int i = 0; i \u003c 10; i++) { threadPool2.execute(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"来了啊 \"); }); } } finally { //关闭线程池 threadPool2.shutdown(); } /* pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 pool-1-thread-1来了啊 Executors.newCachedThreadPool(); 遇强则强，根据需求创建线程，可扩容 线程池中数量没有固定，可达到最大值（Interger. MAX_VALUE） 线程池中的线程可进行缓存重复利用和回收（回收默认时间为 1 分钟） 当线程池中，没有可用线程，会重新创建一个线程 //创建一池可扩容的线程池 ExecutorService threadPool3 = Executors.newCachedThreadPool(); try { //循环 20 次，线程池自动判断需要的线程数 for (int i = 0; i \u003c 20; i++) { threadPool3.execute(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"来了啊 \"); }); } } finally { //关闭线程池 threadPool3.shutdown(); } /* pool-1-thread-2来了啊 pool-1-thread-6来了啊 pool-1-thread-7来了啊 pool-1-thread-3来了啊 pool-1-thread-9来了啊 pool-1-thread-5来了啊 pool-1-thread-10来了啊 pool-1-thread-1来了啊 pool-1-thread-8来了啊 pool-1-thread-12来了啊 pool-1-thread-4来了啊 pool-1-thread-13来了啊 pool-1-thread-11来了啊 pool-1-thread-5来了啊 pool-1-thread-1来了啊 pool-1-thread-12来了啊 pool-1-thread-8来了啊 pool-1-thread-4来了啊 pool-1-thread-11来了啊 pool-1-thread-13来了啊 线程池的七个参数 以上线程池实现类的底层都是调用了 ThreadPoolExecutor 类的实例，ThreadPoolExecutor 类的构造参数有七个 int corePoolSize 常驻线程数量 int maximumPoolSize 最大线程数量 long keepAliveTime 线程存活时间 TimeUnit unit 存活时间的单位 BlockingQueue\u003cRunnable\u003e workQueue 阻塞队列，用于存储超出最大线程数量的线程 ThreadFactory threadFactory 线程工程，用于创建线程 RejectedExecutionHandler handler 拒绝策论 线程池的底层工作流程 在线程池被创建后，线程池中无线程 在调用线程池 execute 方法后： 如果 corePool 常驻池未满，则进入常驻池 如果 corePool 常驻池满了，则进入阻塞队列等待 如果阻塞队列满了，在最大线程数范围内，则为其开辟新的线程优先处理 如果当前线程进入后最大线程数，则执行拒绝策略 当一个线程完成任务后，会从阻塞队列中取任务执行 当一个线程无事可做超过 keepAliveTime 时，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉 线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小 线程池的拒绝策略 AbortPolicy：直接抛出异常，爱咋咋地【默认】 CallerRunsPolicy：将任务退回至调用者，哪来的回哪去 DiscardOldestPolicy：抛弃当代队列中等待最久的任务，撵走老头 DiscardPolicy：不错任何处理，无视它 自定义线程池 阿里巴巴开发手册中不允许使用 Executors 创建线程池 因为这些默认线程池的最大线程数为 Interger. MAX_VALUE：2147483647 ，非常大 可能会堆积大量的请求，导致 OOM ExecutorService myThreadPool = new ThreadPoolExecutor( 2,//常驻线程数量 5,//最大线程数量 2L,//线程存活时间 TimeUnit.SECONDS,//存活时间单位 new ArrayBlockingQueue\u003c\u003e(3),//阻塞队列 Executors.defaultThreadFactory(),//线程工厂 new ThreadPoolExecutor.AbortPolicy()//拒绝策略 ); try { //循环创建执行线程 8 次 for (int i = 0; i \u003c 8; i++) { myThreadPool.execute(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"来了啊 \"); }); } } finally { //关闭线程池 myThreadPool.shutdown(); } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#threadpool-线程池"},{"categories":null,"content":"\rFork / Join 分支合并框架将一个大任务拆分成多个小任务进行并行处理最终将子任务结果合并成最后处理结果，Fork：拆分，Join：合并 任务分割：Fork/Join 框架会把大的任务分为足够小的小任务，如果子任务比较大还会继续分割 执行任务：分割的子任务放到双端队列中，几个启动线程分别从双端队列中获取执行任务 合并结果：子任务执行完的结果都放在一个队列里，启动一个线程读取队列中的数据并合并 /** * 计算 1+2+3+ ... +100, 先将 1-100 拆分为 1-50 51-100 * 再向下拆分 1-25 26-50 51-75 76-100 直至拆分插值小于 10 * 计算后依次向上合并最后合并出 1-100 的值 */ public class MyTask extends RecursiveTask\u003cInteger\u003e { private static final int VALUE = 10; private int begin; private int end; private int result; public MyTask(int begin, int end) { this.begin = begin; this.end = end; } @Override protected Integer compute() { if ((end - begin) \u003c= VALUE){ for (int i = begin; i \u003c= end; i++) { result += i; } }else{ //获取中间值 int middle = (begin + end) / 2; //拆分左边 MyTask myTask1 = new MyTask(begin, middle); myTask1.fork(); //拆分右边 MyTask myTask2 = new MyTask(middle+1, end); myTask2.fork(); //合并结果 result = myTask1.join() + myTask2.join(); } return result; } public static void main(String[] args) throws ExecutionException, InterruptedException { //创建 MyTask 对象 MyTask myTask = new MyTask(0, 100); //创建分支合并池对象 ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask\u003cInteger\u003e forkJoinTask = forkJoinPool.submit(myTask); //获取最终合并结果 System.out.println(forkJoinTask.get()); //关闭池对象 forkJoinPool.shutdown(); } } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#fork--join-分支合并框架"},{"categories":null,"content":"\rCompletableFuture 异步回调CompletableFuture 类实现 Future 接口 异步：异步通常意味着非阻塞， 可以使得我们的任务单独运行在与主线程分离的其他线程中，并且通过回调可 以在主线程中得到异步任务的执行状态，是否完成，和是否异常等信息 没有返回值的异步调用 CompletableFuture\u003cVoid\u003e 当泛型无返回值时，可以写 Void 标识 runAsync() 实现 Runnable 设置线程执行的内容 get() 获得线程执行结果 //没有返回值的异步调用 //实现一个Runnable接口 CompletableFuture\u003cVoid\u003e completableFuture = CompletableFuture.runAsync(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"是没有返回值的异步通信\"); }); try { //获取其执行结果 completableFuture.get(); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } 有返回值的异步调用 supplyAsync() 实现 Supplier 设置线程执行的内容 whenComplete() 实现 BiConsumer 可通过方法形参获取线程执行完毕的返回值及错误信息 get() 获得线程执行结果 //有返回值的异步调用 实现一个Supplier接口的get方法 CompletableFuture\u003cInteger\u003e integerCompletableFuture = CompletableFuture.supplyAsync(()-\u003e{ System.out.println(Thread.currentThread().getName()+\"是有返回值的异步通信\"); //int i = 1/0; return 1024; }); // 实现一个BiConsumer接口的accept方法 integerCompletableFuture.whenComplete((t, u)-\u003e{ System.out.println(\"t = \"+t); //返回值 System.out.println(\"u = \"+u); //异常信息 }); try { //获得线程执行结果 integerCompletableFuture.get(); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } ","date":"2022-04-05","objectID":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:0","series":null,"tags":null,"title":"JUC自学笔记md版","uri":"/juc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#completablefuture-异步回调"},{"categories":null,"content":"\rJVM 大连交通大学 信息学院 刘嘉宁 2022-01-21 笔记摘自：尚硅谷 宋红康 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm"},{"categories":null,"content":"\rJVM Java虚拟机基础 JVM : Java HotSpot Virtual Machine 是程序虚拟机，就是二进制字节码的运行环境 JVM 是 Java 语言的基石，负责硬件和操作系统的独立性，编译文件的小尺寸 如果将 Java API 比作数学公式的话，那么 JVM 就是好比公式的推导过程 基础知识才是 重点 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-java虚拟机基础"},{"categories":null,"content":"\rJVM 的特点 一次编译到处运行 自动内存管理 自动垃圾回收功能 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-的特点"},{"categories":null,"content":"\rJVM 的位置JVM 是运行在操作系统之上，它与硬件没有直接的交互 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-的位置"},{"categories":null,"content":"\rJVM 的整体结构HotSpot 虚拟机的整体结构：三层 类装载器(类加载器)子系统 将字节码文件加载至内存中生成 class 对象 加载、链接、初始化 运行时数据区 方法区、堆：==多个线程共享的== 虚拟机栈、本都方法栈、程序计数器：==每个线程独有的== 执行引擎 解释器、JIT编译器(后端编译器(即时编译器))、垃圾回收器 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:3","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-的整体结构"},{"categories":null,"content":"\r指令集架构 栈式指令集架构：Java… 入栈出栈实现简单，适用资源受限的系统 零地址指令 指令集小，指令多 不需要硬件支持，跨平台性 寄存器式指令集架构：Android… 性能优秀，高效 一地址、二地址、三地址指令 指令集多，指令少 完全依赖硬件，可移植性差 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:4","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#指令集架构"},{"categories":null,"content":"\rJVM 的生命周期 启动 通过引导类加载器(bootstrap class loader)创建一个初始类(initial class)来完成的，这个类是由虚拟机的具体实现指定的 执行 在执行 Java 程序的时候虚拟机运行，程序结束后停止 执行 Java 程序的时候，真正在执行的是一个叫做 Java 虚拟机的进程 销毁 程序正常执行结束 异常或错误而终止 操作系统出现错误 调用了 exit \\ halt 方法 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-的生命周期"},{"categories":null,"content":"\rJVM 与 JDK 的区别 JVM 目的是在不同平台上使用相同的字节码，它们能给出相同的结果 JVM 不止一种，只要满足 JVM 规范即可，如 HotSpot VM 等 在 Java SE Specifications (opens new window) 上可以找到各个版本的 JDK 对应的 JVM 规范 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:6","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-与-jdk-的区别"},{"categories":null,"content":"\rJava 语言 编译与解释共存Java 语言一次编写到处运行，编写的 .java 文件由编译器编译为 JVM 可以理解的字节码文件 .class 后再由解释器 \u0026 JIT 解释执行 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:7","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#java-语言-编译与解释共存"},{"categories":null,"content":"\rOracle JDK vs OpenJDK Oriacle JDK 为长期维护版本，不是开源的，更为稳定，商用需要付费 OpenJDK 大概每三个月发布一次，开源，与 Oracle JDK 的代码几乎相同 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:8","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#oracle-jdk-vs-openjdk"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jvm-发展历程"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#sun-classic-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#exact-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#hotspot-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#eba-jrockit-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ibm-j9-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#kvmcdccldc"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#azul-vm--bea-liquid-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#apache-harmony"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#microsoft-jvm--taobao-jvm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#daivik-vm"},{"categories":null,"content":"\rJVM 发展历程冷知识: java 之父 詹姆斯高斯林 目前就职于谷歌 SUN Classic VM 世界上第一款商用的虚拟机 HptSpot内置此虚拟机 虚拟机内部只有解释器 可以外挂 JIT 即时编译器，但会接管解释器工作 (启动暂停时间变长) Exact VM 准确式内存管理 虚拟机知道内存中某个数据的类型 支持解释器和 JIT 编译器同时工作 热点探测功能(雏形) HotSpot VM JDK 1.3 至今一直默认使用 加入方法区概念 热点探测功能: 通过计数器找到最具编译价值的代码，触发即时编译或栈上替换 支持解释器和 JIT 编译器同时工作 EBA JRockit VM BEA 团队开发，后被 Oracle 收购 是世界上最快的 JVM 内部不包含解释器，全靠 JIT 拥有全面的 Java 运行时解决方案组合 (主要用于服务器端) IBM J9 VM IBM 公司开发，也简称 IT4J IBM 公司常用 KVM、CDC、CLDC 针对于 Java ME 产品 KVM 简单、轻量、高度可移植，老人机等低端设备还在使用 Azul VM \u0026 BEA Liquid VM Azul 虚拟机被称为高性能虚拟机中的战斗机，可以管理至少数十个 CPU 和数百 G 内存… Liquid 虚拟机可以越过操作系统直接控制硬件，高性能… Apache Harmony 是 IBM 和 Intel 联合开发的开源 JVM 由于受到 SUN 公司 OpenJDK 的压制，被放弃 Microsoft JVM \u0026 Taobao JVM Microsoft JVM 在 WindowsXP SP3 之前存在于 Windows 系统中，后被 SUN 公司指控 GG… Taobao JVM 由阿里发布的一个深度定制且开源的高性能服务器，淘宝、天猫在用 Daivik VM 采用寄存器架构，执行的是 dex 文件(可由 class 文件转换来) 应用于 Android 5.0 前 Graal VM 增强 HotSpot 虚拟机，可以作为 “任何语言” 的运行平台 支持不同语言间混用接口和对象，支持这些语言的本地库文件 原理是将不同语言通过解释器转换为能接受的中间格式，还可以即时编译 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:9","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#graal-vm"},{"categories":null,"content":"\r内存与垃圾回收HotSpot 虚拟机的整体结构分为三层：类加载子系统、运行时数据区、执行引擎 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#内存与垃圾回收"},{"categories":null,"content":"\r1. 类加载器子系统类加载器子系统负责: 加载Class文件 类加载子系统分为三个阶段：加载阶段、链接阶段、初始化阶段 1. 加载阶段 Loading 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 2. 链接阶段 Linking 验证 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 准备 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 解析 将常量池内的符号引用转换为直接引用的过程 3. 初始化阶段 Initialization 执行类构造器\u003cclinit\u003e()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 类加载器的分类从上到下 为 包含关系 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 ==双亲委派机制==Java 虚拟机对 class 文件采用的是 按需加载 方式，采用 双亲委派模式 双亲委派模式：把请求交给父类处理，是一种任务委派模式 一个类加载器收到请求，会先把这个请求委托给父类执行 如果父类加载器还存在父类，则进一步向上委托 直至引导类加载器 如果父类加载器可以完成类的加载，就成功返回，否则才自己尝试 双亲委派机制的优点： 避免类的重复加载 确保程序安全，防止核心 API 被随意篡改 (沙箱安全机制) 打破双亲委派机制： 打破双亲委派机制 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#1-类加载器子系统"},{"categories":null,"content":"\r1. 类加载器子系统类加载器子系统负责: 加载Class文件 类加载子系统分为三个阶段：加载阶段、链接阶段、初始化阶段 1. 加载阶段 Loading 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 2. 链接阶段 Linking 验证 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 准备 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 解析 将常量池内的符号引用转换为直接引用的过程 3. 初始化阶段 Initialization 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 类加载器的分类从上到下 为 包含关系 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 ==双亲委派机制==Java 虚拟机对 class 文件采用的是 按需加载 方式，采用 双亲委派模式 双亲委派模式：把请求交给父类处理，是一种任务委派模式 一个类加载器收到请求，会先把这个请求委托给父类执行 如果父类加载器还存在父类，则进一步向上委托 直至引导类加载器 如果父类加载器可以完成类的加载，就成功返回，否则才自己尝试 双亲委派机制的优点： 避免类的重复加载 确保程序安全，防止核心 API 被随意篡改 (沙箱安全机制) 打破双亲委派机制： 打破双亲委派机制 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#1-加载阶段-loading"},{"categories":null,"content":"\r1. 类加载器子系统类加载器子系统负责: 加载Class文件 类加载子系统分为三个阶段：加载阶段、链接阶段、初始化阶段 1. 加载阶段 Loading 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 2. 链接阶段 Linking 验证 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 准备 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 解析 将常量池内的符号引用转换为直接引用的过程 3. 初始化阶段 Initialization 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 类加载器的分类从上到下 为 包含关系 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 ==双亲委派机制==Java 虚拟机对 class 文件采用的是 按需加载 方式，采用 双亲委派模式 双亲委派模式：把请求交给父类处理，是一种任务委派模式 一个类加载器收到请求，会先把这个请求委托给父类执行 如果父类加载器还存在父类，则进一步向上委托 直至引导类加载器 如果父类加载器可以完成类的加载，就成功返回，否则才自己尝试 双亲委派机制的优点： 避免类的重复加载 确保程序安全，防止核心 API 被随意篡改 (沙箱安全机制) 打破双亲委派机制： 打破双亲委派机制 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#2-链接阶段-linking"},{"categories":null,"content":"\r1. 类加载器子系统类加载器子系统负责: 加载Class文件 类加载子系统分为三个阶段：加载阶段、链接阶段、初始化阶段 1. 加载阶段 Loading 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 2. 链接阶段 Linking 验证 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 准备 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 解析 将常量池内的符号引用转换为直接引用的过程 3. 初始化阶段 Initialization 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 类加载器的分类从上到下 为 包含关系 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 ==双亲委派机制==Java 虚拟机对 class 文件采用的是 按需加载 方式，采用 双亲委派模式 双亲委派模式：把请求交给父类处理，是一种任务委派模式 一个类加载器收到请求，会先把这个请求委托给父类执行 如果父类加载器还存在父类，则进一步向上委托 直至引导类加载器 如果父类加载器可以完成类的加载，就成功返回，否则才自己尝试 双亲委派机制的优点： 避免类的重复加载 确保程序安全，防止核心 API 被随意篡改 (沙箱安全机制) 打破双亲委派机制： 打破双亲委派机制 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#3-初始化阶段-initialization"},{"categories":null,"content":"\r1. 类加载器子系统类加载器子系统负责: 加载Class文件 类加载子系统分为三个阶段：加载阶段、链接阶段、初始化阶段 1. 加载阶段 Loading 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 2. 链接阶段 Linking 验证 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 准备 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 解析 将常量池内的符号引用转换为直接引用的过程 3. 初始化阶段 Initialization 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 类加载器的分类从上到下 为 包含关系 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 ==双亲委派机制==Java 虚拟机对 class 文件采用的是 按需加载 方式，采用 双亲委派模式 双亲委派模式：把请求交给父类处理，是一种任务委派模式 一个类加载器收到请求，会先把这个请求委托给父类执行 如果父类加载器还存在父类，则进一步向上委托 直至引导类加载器 如果父类加载器可以完成类的加载，就成功返回，否则才自己尝试 双亲委派机制的优点： 避免类的重复加载 确保程序安全，防止核心 API 被随意篡改 (沙箱安全机制) 打破双亲委派机制： 打破双亲委派机制 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#类加载器的分类"},{"categories":null,"content":"\r1. 类加载器子系统类加载器子系统负责: 加载Class文件 类加载子系统分为三个阶段：加载阶段、链接阶段、初始化阶段 1. 加载阶段 Loading 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 2. 链接阶段 Linking 验证 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 准备 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 解析 将常量池内的符号引用转换为直接引用的过程 3. 初始化阶段 Initialization 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 类加载器的分类从上到下 为 包含关系 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 ==双亲委派机制==Java 虚拟机对 class 文件采用的是 按需加载 方式，采用 双亲委派模式 双亲委派模式：把请求交给父类处理，是一种任务委派模式 一个类加载器收到请求，会先把这个请求委托给父类执行 如果父类加载器还存在父类，则进一步向上委托 直至引导类加载器 如果父类加载器可以完成类的加载，就成功返回，否则才自己尝试 双亲委派机制的优点： 避免类的重复加载 确保程序安全，防止核心 API 被随意篡改 (沙箱安全机制) 打破双亲委派机制： 打破双亲委派机制 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#双亲委派机制"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#2-运行时数据区"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#程序计数器pc寄存器"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#虚拟机栈-java-栈"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#栈顶缓存区"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#方法的调用"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#多态性的前提"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#栈的相关面试题"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#本地方法栈"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#本地方法接口"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#本地方法栈-1"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#堆"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#新生区"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#养老区"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#元空间"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#关于-oom"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#关于-gc"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#关于-tlab"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#堆空间相关面试题"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#方法区"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#存储的内容"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#方法区的垃圾回收"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#方法区的常见面试题"},{"categories":null,"content":"\r2. 运行时数据区\r方法区 Method Area 、堆空间 Heap Area ：进程私有 虚拟机栈 Stack Area 、PC寄存器 PC Register 、本地方法栈 Native Method Stack：每个线程私有 程序计数器(PC寄存器) 程序计数器是线程私有的 是对物理 PC 寄存器的一种抽象模拟 用于存储指向下一条指令的地址 是 JVM 规范中唯一没有规定任何 GC / OOM 的区域 虚拟机栈( Java 栈) 虚拟机栈是线程私有的 栈中存储着栈帧，栈帧对应着方法 用于存储方法的局部变量、部分结果，参与方法的调用和返回 Java 指令都是根据栈来设计的，栈的优点…，栈存在 OOM 栈帧： 局部变量表 是一个数字数组，用于存储方法参数和定义在方法体内的局部变量 不存在数据安全问题 在编译期就确定了大小 slot：变量槽。32位数据占一个 slot，64位数据占两个 slot ( long、double ) 在命令行界面使用反编译指令：javap -v -p HeapTest.class \u003e HeapTestClass.txt 将详细的 class 文件反编译结果转存在文件中 操作数栈(表达式栈) 用于保存计算过程的中间结果、计算过程中的变量、返回值 执行引擎根据字节码指令出入栈 在编译期就确定了大小 32位数据占一个栈单位深度，64位数据占两个栈单位深度( long、double ) 动态链接(指向运行时常量池的方法引用) 将 Class 文件常量池符号引用转换为在运行时常量池中调用方法的直接引用 方法返回地址(方法正常退出或异常退出的定义) 存储该方法 PC 寄存器的值 作为返回地址 一些附加消息 对程序调试提供支持的信息 栈顶缓存区 由于 JVM 虚拟机使用的是栈式虚拟机，指令集小意味着需要使用更多的指令，对内存的读写也更频繁 HotSpot 将栈顶的元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率 方法的调用 静态链接 在编译期间就可以确定其符号引用和直接引用的绑定关系的 【早期绑定】目标方法结构在编译器就确定了，运行期保持不变 C++ 中的【非虚方法】: 静态方法、私有方法、final 方法、实例构造器、父类方法 动态链接 在程序运行期间才能确定其符号引用和直接引用的绑定关系的 【晚期绑定】目标方法结构在编译器无法被确定，只能在程序运行期根据实际的 传入类型 绑定相关的方法 (多态) C++ 中的【虚方法】: 不是非虚方法的方法 虚方法表：存储在方法区中，为避免每次都去寻找对应引用，提高性能 多态性的前提 类的继承关系 方法的重写 非虚方法：不能被重写的方法，不能实现多态的方法 栈的相关面试题 调整栈的大小，就能保证不出现溢出吗？ 不能保证，可以通过 -Xss 设置栈的大小，也可以设置栈的自动扩展，但当数据量足够多时依旧无法避免 StackOverflow 甚至 OOM 垃圾回收会涉及到虚拟机栈吗？ 不会 方法中定义的局部变量是否线程安全？ 何为线程安全 如果只有一个线程操作此数据，则是线程安全的 如果多个线程同时操作此数据，则此数据为共享数据。如果不考略同步机制，则会存在线程安全问题 分具体情况 如果局部变量只在自己方法内创建使用并销毁，则不存在线程安全问题 如果局部变量是被传进来的或会当作返回值返回，则存在线程安全问题 Error（错误） GC（垃圾回收器） 程序计数器 F F 本地方法栈 T F 虚拟机栈 T F 方法区 T T 堆 T T 本地方法栈\r本地方法接口 Java 调用非 Java 代码的接口，为融合不同的编程语言为 Java 所用 使用本地方法实现 jre 与底层系统的交互 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，本地方法栈用于管理本地方法的调用 本地方法栈是线程私有的 本地方法通常是由 C / C++ 编写 本地方法直接使用本地的寄存器，堆内存，脱离虚拟机内部的运行时数据区。其不受 JVM 虚拟机控制，有同虚拟机相同的权限 在 HotSpot JVM 中：本地方法栈与虚拟机栈合二为一 堆 堆区在 JVM 启动时被创建，是 JVM 中最大的一块区域 JVM 中，堆在物理上不连续，逻辑上连续 ==几乎所有==的对象实例和数组都分配在堆空间中 栈中存放着对堆中的引用，方法运行结束后，堆中的内存并不会立即被回收，而是等待垃圾回收器 JDK 8 之后的对空间逻辑上分为：新生区、养老区、元空间 默认新生代和老年代的比例为 1 : 2 （可以通过 -XX:NewRatio=2 调节） 默认新生代中伊甸园区和幸存者0区1区的比例为 8 : 1 : 1（可以通过 -XX:SurvivorRatio=8 调节, 默认有自适应内存分配策略） 新生区存储生命周期较短的对象 伊甸园区 Eden 几乎所有的 Java 对象，都是在伊甸园区中被 new 出来的 绝大部分的 Java 对象，都是在新生代销毁的 当伊甸园区满时，程序又需要创建对象，此时垃圾回收 GC 开始工作，将不再被引用的对象销毁（包括幸存者区），将未被销毁的幸存对象放至幸存者 0 / 1 区（此时为空的幸存者区） 幸存者0区 Survivor0 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 幸存者1区 Survivor1 存放伊甸园区未被垃圾回收器回收的对象 每次 GC 工作，都会将未达到限制的对象存放在另一幸存者区 当循环次数到达限制（15次）时，将对象放至养老区 养老区存储生命周期较长的对象、新生代（伊甸园区 / 幸存者区）放不下的超大对象 元空间存储不会被垃圾回收的对象（元空间旧称永久代，永久代在 JDK 1.8 之后是 HotSpot 虚拟机特有的） 关于 OOM OutOfMemoryError 堆空间溢出 常见于对象创建次数过多且都不会被回收的情况 关于 GC 频繁在新生代收集，很少在老年代收集，几乎不再元空间收集 Minor GC ≈ Young GC 新生代（伊甸园区）的垃圾回收【STW：会暂停用户线程，等垃圾回收结束，用户线程恢复】 Major GC ≈ Old GC老年代的垃圾回收【速度慢 Minor GC 10倍以上，STW 时间更长】 Full GC 整个 Java 堆和方法区的垃圾回收（老年代 / 方法区空间不足时触发，调用 System.gc( ) 时可能触发）【开发时尽量避免】 关于 TLAB TLAB：Thread Local Allocation Buffer 线程私有分配缓冲区 在伊甸园区中，每个线程都有一块私有的缓冲区名为 TLAB，与 Java API 中 Thread Local 没有关系 TLAB 默认占伊甸园区的 1% 内存 JVM 会优先向 TLAB 空间中分配对象，一旦对象在 TLAB 空间中分配失败，JVM 会尝试使用加锁机制保证数据原子性（为创建对象时的地址加锁） TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 堆空间常用调节参数 -XX:+PrintFlagsInitial 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal 查看所有参数的最终值（修改过的不会和初始值一致） 具体查看某个参数的指令： jps 查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id -Xmn 用来设置新生代的内存大小 -Xms 用来设置新生代和老年代的初始大小（默认为物理内存的 1/64） -Xmx 用来设置新生代和老年代的最大大小（默认为物理内存的 1/4） 在开发时推荐将初始大小和最大大小设置相同的数值，避免自动扩容时处理器资源浪费 -XX:NewRatio 设置新生代和老年代的在堆结构中的占比 -XX:SurvivorRatio 设置新生代中 Eden 和 s0 / s1 区的占比， 默认有自适应内存分配策略 -XX:MaxTenuringThreshold 设置新生代垃圾的最大年龄 -XX:+PrintGCDetails 输出详细的 GC 处理日志 堆空间相关面试题 为什么需要有两块幸存者区来回倒腾？ 因为要解决内存碎片问题，在 Minor GC 之后幸存者区会出现内存占用不连续的情况，有大对象进来时会出现有空间但无处安放的问题，此时如果向另一幸存者区转移压缩一次即可解决。这是一种空间换时间的思路【复制算法】。 堆是分配对象的唯一选择嘛？ 不是，==几乎所有==的对象实例和数组都分配在堆空间中。发生逃逸的对象存在堆中，没有发生逃逸的对象存在栈中。 逃逸分析：方法内创建的对象如果有可能在方法外被调用，则发生了逃逸（ JDK 8 中使用标量替换优化而来）。 逃逸方法为代码做的优化： 方法区 是各个线程共享的一块区域 用于存储 类的信息、运行时常量池、即时编译器编译后的代码缓存（字符串常量池、静态变量存储、引用在堆） 和堆一样，在物理内存中可以不连续，逻辑上连续 在 JDK 7 方法区称作为永久代，在 JDK 8 方法区称作为元空间 元空间和永久代的区别：元空间不在虚拟机设置的内存中","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#补充对象的创建详情"},{"categories":null,"content":"\r3. 执行引擎 区别于物理机的概念，虚拟机的执行引擎是由软件自行实现的，可以执行那些不被硬件支持的指令集 主要任务是将字节码解释/编译为对应平台上的本地机器能够识别的指令【后端编译】 执行引擎根据 PC 寄存器 的指令地址运行，通过局部变量表对应堆中的对象实例，通过对象头中的元数据对应到方法区的类型信息 前端编译原理图： 后端编译原理图： 解释器 对字节码 逐行解释 逐条执行 优点：上来可以直接解释执行，响应速度快 缺点：较为低效 JIT 即时编译器 将源代码直接全部编译为机器语言 缺点：响应时间较长 优点：使用热点探测功能 缓存热点代码不必重复编译，效率高速度快 HotSpot 的 C1 C2 编译器 热点代码 一段时间内被调用次数较多的方法，方法中循环次数较多的循环体【栈上替换 （OSR编译）】 热点探测功能：基于计数器热点探测 方法调用计数器：统计方法调用的次数 回边计数器：统计循环体循环次数 热度衰减：每经历一个 半衰周期 调用的计数器中的值都会 衰减 一半 编译器常用调节参数 -XX:CompileThreshold 设置热点代码的方法调用次数 -XX:-UseCounterDecay 关闭热度衰减 -XX:CounterHalfLifeTime 调整半衰期时间（秒） ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:3","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#3-执行引擎"},{"categories":null,"content":"\r3. 执行引擎 区别于物理机的概念，虚拟机的执行引擎是由软件自行实现的，可以执行那些不被硬件支持的指令集 主要任务是将字节码解释/编译为对应平台上的本地机器能够识别的指令【后端编译】 执行引擎根据 PC 寄存器 的指令地址运行，通过局部变量表对应堆中的对象实例，通过对象头中的元数据对应到方法区的类型信息 前端编译原理图： 后端编译原理图： 解释器 对字节码 逐行解释 逐条执行 优点：上来可以直接解释执行，响应速度快 缺点：较为低效 JIT 即时编译器 将源代码直接全部编译为机器语言 缺点：响应时间较长 优点：使用热点探测功能 缓存热点代码不必重复编译，效率高速度快 HotSpot 的 C1 C2 编译器 热点代码 一段时间内被调用次数较多的方法，方法中循环次数较多的循环体【栈上替换 （OSR编译）】 热点探测功能：基于计数器热点探测 方法调用计数器：统计方法调用的次数 回边计数器：统计循环体循环次数 热度衰减：每经历一个 半衰周期 调用的计数器中的值都会 衰减 一半 编译器常用调节参数 -XX:CompileThreshold 设置热点代码的方法调用次数 -XX:-UseCounterDecay 关闭热度衰减 -XX:CounterHalfLifeTime 调整半衰期时间（秒） ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:3","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#解释器"},{"categories":null,"content":"\r3. 执行引擎 区别于物理机的概念，虚拟机的执行引擎是由软件自行实现的，可以执行那些不被硬件支持的指令集 主要任务是将字节码解释/编译为对应平台上的本地机器能够识别的指令【后端编译】 执行引擎根据 PC 寄存器 的指令地址运行，通过局部变量表对应堆中的对象实例，通过对象头中的元数据对应到方法区的类型信息 前端编译原理图： 后端编译原理图： 解释器 对字节码 逐行解释 逐条执行 优点：上来可以直接解释执行，响应速度快 缺点：较为低效 JIT 即时编译器 将源代码直接全部编译为机器语言 缺点：响应时间较长 优点：使用热点探测功能 缓存热点代码不必重复编译，效率高速度快 HotSpot 的 C1 C2 编译器 热点代码 一段时间内被调用次数较多的方法，方法中循环次数较多的循环体【栈上替换 （OSR编译）】 热点探测功能：基于计数器热点探测 方法调用计数器：统计方法调用的次数 回边计数器：统计循环体循环次数 热度衰减：每经历一个 半衰周期 调用的计数器中的值都会 衰减 一半 编译器常用调节参数 -XX:CompileThreshold 设置热点代码的方法调用次数 -XX:-UseCounterDecay 关闭热度衰减 -XX:CounterHalfLifeTime 调整半衰期时间（秒） ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:3","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#jit-即时编译器"},{"categories":null,"content":"\r3. 执行引擎 区别于物理机的概念，虚拟机的执行引擎是由软件自行实现的，可以执行那些不被硬件支持的指令集 主要任务是将字节码解释/编译为对应平台上的本地机器能够识别的指令【后端编译】 执行引擎根据 PC 寄存器 的指令地址运行，通过局部变量表对应堆中的对象实例，通过对象头中的元数据对应到方法区的类型信息 前端编译原理图： 后端编译原理图： 解释器 对字节码 逐行解释 逐条执行 优点：上来可以直接解释执行，响应速度快 缺点：较为低效 JIT 即时编译器 将源代码直接全部编译为机器语言 缺点：响应时间较长 优点：使用热点探测功能 缓存热点代码不必重复编译，效率高速度快 HotSpot 的 C1 C2 编译器 热点代码 一段时间内被调用次数较多的方法，方法中循环次数较多的循环体【栈上替换 （OSR编译）】 热点探测功能：基于计数器热点探测 方法调用计数器：统计方法调用的次数 回边计数器：统计循环体循环次数 热度衰减：每经历一个 半衰周期 调用的计数器中的值都会 衰减 一半 编译器常用调节参数 -XX:CompileThreshold 设置热点代码的方法调用次数 -XX:-UseCounterDecay 关闭热度衰减 -XX:CounterHalfLifeTime 调整半衰期时间（秒） ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:3","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#热点代码"},{"categories":null,"content":"\rStringTable String 在 JDK 8 中是由 char 数组构成，在 JDK 9 及之后是由 byte 数组加标记构成，节约了一些空间 String 具有不可变性【引用类型】 字符串常量池中是不会存储相同的字符串的 String 去重（G1垃圾回收器操作） 可通过 UserStringDeduplication (bool) 开启 String 去重（默认关闭） 可通过 PrintStringDeduplicationStatistics (bool) 打印详细的去重信息 可通过 StringDeduplicationAgeThreshold (uintx) 指定去重候选的年龄 StringTableSize StringTableSize 即 String 常量池大小，过小时容易发生 hash 碰撞，需要补齐链表 增加搜索难度，导致性能降低 在 JDK 6 中 StringTableSize 的值为 1009，JDK 7 及之后 StringTableSize 的值为 60013 可通过 -XX:StringTableSize 修改 StringTableSize 的值（JDK 8 只能修改为 1009 以上的值） intern( ) 方法 当字符串==常量==与字符串==常量==拼接时，结果直接存储在字符串常量池中，【编译期优化】（包括 final 修饰的常量） 当字符串拼接时，其中有一个为==变量==，结果就存储在堆中，底层为 new StringBuilder 后 append( ) 进去后返回 toString( ) JDK 5 之前为 StringBuffer ，线程安全但效率较低 补充： 使用 ”+” 拼接字符串时底层会调用 StringBuilder 和 String 对象，当大量拼接字符串时效率低，占用高 如果确定经常拼接的字符串长度不会高于某个值时，可以将此值在 StringBuilder 的有参构造器中指定 拼接的结果对象调用 intern( ) 方法后，如果字符串常量池中没有当前字符串的话，则在常量池中生成 String 常量池常见面试题 new String(\"ab\") 会创建几个对象？ 两个，一个是 new 出来的 String 对象，一个是常量池中的 “ab” new String(\"a\") + new String(\"b\") 会创建几个对象？ 六个对象 使用 + 连接字符串 new StringBuilder() new String(“a”) 常量池中的 “a” new String(“b”) 常量池中的 “b” Stringbuilder 的返回值为其 toString 方法的返回值 String 对象【此时常量池中并没有 “ab” 】 如图，为何在 JDK 7/8 中 s3 == s4 的值为 true ? 因为在 JDK 7 之后，字符串常量池存储在堆空间中。s3 在定义时字符串常量池中并没有 “11” , 所以在执行 intern 方法时将 s3 的引用地址放置在了字符串常量池中，定义 s4 时将字符串常量池中 s3 的地址赋给 s4 , 所以 s3 == s4 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:4","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#stringtable"},{"categories":null,"content":"\rStringTable String 在 JDK 8 中是由 char 数组构成，在 JDK 9 及之后是由 byte 数组加标记构成，节约了一些空间 String 具有不可变性【引用类型】 字符串常量池中是不会存储相同的字符串的 String 去重（G1垃圾回收器操作） 可通过 UserStringDeduplication (bool) 开启 String 去重（默认关闭） 可通过 PrintStringDeduplicationStatistics (bool) 打印详细的去重信息 可通过 StringDeduplicationAgeThreshold (uintx) 指定去重候选的年龄 StringTableSize StringTableSize 即 String 常量池大小，过小时容易发生 hash 碰撞，需要补齐链表 增加搜索难度，导致性能降低 在 JDK 6 中 StringTableSize 的值为 1009，JDK 7 及之后 StringTableSize 的值为 60013 可通过 -XX:StringTableSize 修改 StringTableSize 的值（JDK 8 只能修改为 1009 以上的值） intern( ) 方法 当字符串==常量==与字符串==常量==拼接时，结果直接存储在字符串常量池中，【编译期优化】（包括 final 修饰的常量） 当字符串拼接时，其中有一个为==变量==，结果就存储在堆中，底层为 new StringBuilder 后 append( ) 进去后返回 toString( ) JDK 5 之前为 StringBuffer ，线程安全但效率较低 补充： 使用 ”+” 拼接字符串时底层会调用 StringBuilder 和 String 对象，当大量拼接字符串时效率低，占用高 如果确定经常拼接的字符串长度不会高于某个值时，可以将此值在 StringBuilder 的有参构造器中指定 拼接的结果对象调用 intern( ) 方法后，如果字符串常量池中没有当前字符串的话，则在常量池中生成 String 常量池常见面试题 new String(\"ab\") 会创建几个对象？ 两个，一个是 new 出来的 String 对象，一个是常量池中的 “ab” new String(\"a\") + new String(\"b\") 会创建几个对象？ 六个对象 使用 + 连接字符串 new StringBuilder() new String(“a”) 常量池中的 “a” new String(“b”) 常量池中的 “b” Stringbuilder 的返回值为其 toString 方法的返回值 String 对象【此时常量池中并没有 “ab” 】 如图，为何在 JDK 7/8 中 s3 == s4 的值为 true ? 因为在 JDK 7 之后，字符串常量池存储在堆空间中。s3 在定义时字符串常量池中并没有 “11” , 所以在执行 intern 方法时将 s3 的引用地址放置在了字符串常量池中，定义 s4 时将字符串常量池中 s3 的地址赋给 s4 , 所以 s3 == s4 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:4","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#stringtablesize"},{"categories":null,"content":"\rStringTable String 在 JDK 8 中是由 char 数组构成，在 JDK 9 及之后是由 byte 数组加标记构成，节约了一些空间 String 具有不可变性【引用类型】 字符串常量池中是不会存储相同的字符串的 String 去重（G1垃圾回收器操作） 可通过 UserStringDeduplication (bool) 开启 String 去重（默认关闭） 可通过 PrintStringDeduplicationStatistics (bool) 打印详细的去重信息 可通过 StringDeduplicationAgeThreshold (uintx) 指定去重候选的年龄 StringTableSize StringTableSize 即 String 常量池大小，过小时容易发生 hash 碰撞，需要补齐链表 增加搜索难度，导致性能降低 在 JDK 6 中 StringTableSize 的值为 1009，JDK 7 及之后 StringTableSize 的值为 60013 可通过 -XX:StringTableSize 修改 StringTableSize 的值（JDK 8 只能修改为 1009 以上的值） intern( ) 方法 当字符串==常量==与字符串==常量==拼接时，结果直接存储在字符串常量池中，【编译期优化】（包括 final 修饰的常量） 当字符串拼接时，其中有一个为==变量==，结果就存储在堆中，底层为 new StringBuilder 后 append( ) 进去后返回 toString( ) JDK 5 之前为 StringBuffer ，线程安全但效率较低 补充： 使用 ”+” 拼接字符串时底层会调用 StringBuilder 和 String 对象，当大量拼接字符串时效率低，占用高 如果确定经常拼接的字符串长度不会高于某个值时，可以将此值在 StringBuilder 的有参构造器中指定 拼接的结果对象调用 intern( ) 方法后，如果字符串常量池中没有当前字符串的话，则在常量池中生成 String 常量池常见面试题 new String(\"ab\") 会创建几个对象？ 两个，一个是 new 出来的 String 对象，一个是常量池中的 “ab” new String(\"a\") + new String(\"b\") 会创建几个对象？ 六个对象 使用 + 连接字符串 new StringBuilder() new String(“a”) 常量池中的 “a” new String(“b”) 常量池中的 “b” Stringbuilder 的返回值为其 toString 方法的返回值 String 对象【此时常量池中并没有 “ab” 】 如图，为何在 JDK 7/8 中 s3 == s4 的值为 true ? 因为在 JDK 7 之后，字符串常量池存储在堆空间中。s3 在定义时字符串常量池中并没有 “11” , 所以在执行 intern 方法时将 s3 的引用地址放置在了字符串常量池中，定义 s4 时将字符串常量池中 s3 的地址赋给 s4 , 所以 s3 == s4 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:4","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#intern--方法"},{"categories":null,"content":"\rStringTable String 在 JDK 8 中是由 char 数组构成，在 JDK 9 及之后是由 byte 数组加标记构成，节约了一些空间 String 具有不可变性【引用类型】 字符串常量池中是不会存储相同的字符串的 String 去重（G1垃圾回收器操作） 可通过 UserStringDeduplication (bool) 开启 String 去重（默认关闭） 可通过 PrintStringDeduplicationStatistics (bool) 打印详细的去重信息 可通过 StringDeduplicationAgeThreshold (uintx) 指定去重候选的年龄 StringTableSize StringTableSize 即 String 常量池大小，过小时容易发生 hash 碰撞，需要补齐链表 增加搜索难度，导致性能降低 在 JDK 6 中 StringTableSize 的值为 1009，JDK 7 及之后 StringTableSize 的值为 60013 可通过 -XX:StringTableSize 修改 StringTableSize 的值（JDK 8 只能修改为 1009 以上的值） intern( ) 方法 当字符串==常量==与字符串==常量==拼接时，结果直接存储在字符串常量池中，【编译期优化】（包括 final 修饰的常量） 当字符串拼接时，其中有一个为==变量==，结果就存储在堆中，底层为 new StringBuilder 后 append( ) 进去后返回 toString( ) JDK 5 之前为 StringBuffer ，线程安全但效率较低 补充： 使用 ”+” 拼接字符串时底层会调用 StringBuilder 和 String 对象，当大量拼接字符串时效率低，占用高 如果确定经常拼接的字符串长度不会高于某个值时，可以将此值在 StringBuilder 的有参构造器中指定 拼接的结果对象调用 intern( ) 方法后，如果字符串常量池中没有当前字符串的话，则在常量池中生成 String 常量池常见面试题 new String(\"ab\") 会创建几个对象？ 两个，一个是 new 出来的 String 对象，一个是常量池中的 “ab” new String(\"a\") + new String(\"b\") 会创建几个对象？ 六个对象 使用 + 连接字符串 new StringBuilder() new String(“a”) 常量池中的 “a” new String(“b”) 常量池中的 “b” Stringbuilder 的返回值为其 toString 方法的返回值 String 对象【此时常量池中并没有 “ab” 】 如图，为何在 JDK 7/8 中 s3 == s4 的值为 true ? 因为在 JDK 7 之后，字符串常量池存储在堆空间中。s3 在定义时字符串常量池中并没有 “11” , 所以在执行 intern 方法时将 s3 的引用地址放置在了字符串常量池中，定义 s4 时将字符串常量池中 s3 的地址赋给 s4 , 所以 s3 == s4 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:4","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#string-常量池常见面试题"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference\u003cUser\u003e usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference\u003cUser\u003e uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue\u003cUser\u003e rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference\u003cUser\u003e pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收garbage-collection"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收相关算法"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#标记算法"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#finalization-机制"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#清除算法"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收相关概念补充"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器garbage-collector"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器分类"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器的性能指标"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器的发展史"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器与分代的关系"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#serial-回收器"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#parnew-回收器"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#parallel-scavenge回收器jdk-8-默认"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#concurrent-mark-sweep-回收器"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#garbage-first-回收器jdk-9-默认"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#gc-日志分析"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器的未来"},{"categories":null,"content":"\r垃圾回收（Garbage Collection） 什么是垃圾：运行程序中再没有任何指针指向的对象 为什么要进行垃圾回收： 需要释放没用的对象，整理内存碎片以便于分配给新的对象。 如果没有 GC 那么内存总有一天会用完，无法保证程序的正常进行。 降低内存泄露和溢出的风险，程序员可以更专注于业务处理 垃圾回收相关算法\r标记算法标记出已经死亡的对象（不再被任何存活对象引用的对象） 引用计数算法【 python 使用】 记录对象被引用的情况，引用就 +1，引用失效就 -1，如果计数器为 0，则可回收 优点：实现简单，效率高 缺点：存储空间的开销，计数时间的开销，无法处理循环引用（造成内存泄漏） 可达性分析算法【 Java 使用】 根对象：一组必须活跃的引用 （栈中引用的，本地方法栈中的，方法区中静态属性引用的，常量池中的，同步锁持有的，虚拟机内部的对象） 一个指针里面保存了堆中的对象，但自己又不存储在堆中，它就是一个 Root 对象 以一组根对象集合为起始点，从上到下搜索根对象集合所连接的对象是否可达，引用链上的对象都不是垃圾回收对象 虚拟机中对象可能的三种状态： 可触及的：从根节点能够直接或间接的访问这个对象（就不是垃圾） 可复活的：从根节点不可达，但是有可能在 fnalize 方法中复活（刀下留人） 不可触及的：对象的 finalize 方法被调用过并且没有被复活（死定了） finalization 机制 可由程序员提供对象被销毁前的处理逻辑 在 GC 回收一个对象前，总是要调用 finalize( ) 方法（Object 类自带的方法） 判定一个对象是否可回收，会经过==两次标记==： 如果这个对象是根节点不可达的，第一次标记 这个对象有必要执行 finalize 方法，进行二次标记 如果在 finalize 方法中与引用链上的对象建立了联系，则移出即将回收集合，直到再次出现没有引用存在的情况，此时这个对象就是 不可触及的 （finalize 方法只会被执行一次） 清除算法 标记 - 清除算法（Mark - Sweep） 标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象 清除：Collector 对堆内存从头到尾进行现行的遍历，如果发现某个对象 Header 中没有标记为可达对象，则 ‘清除’ 优点：易于理解 缺点：效率不算高、GC 时会发生 STW、清除后内存不连续，会产生内存碎片，需要维护一个空闲列表（并不会真正的把对象置空，而是把 ‘清除’ 的对象地址记录在空闲列表中，下次分配对象优先在空闲列表中记录的内存分配） 复制算法（Copying） 复制：将内存分为 A B 两区，每次垃圾回收都将存活对象复制到另一未被使用的内存块中，交换两个内存块角色 优点：没有标记和清除过程，简单高效、不会出现内存碎片 缺点：需要两倍的内存空间、内存中存活对象较少时才行（新生代中大多数对象朝生夕死，适合复制算法）、在 G1 垃圾回收器中需要维护 region 引用，因为每次复制都会导致内存地址变化，栈中对堆内存的的引用发生变化 标记 - 压缩算法（Mark - Compact） 是对 标记 - 清除 算法的一种优化，相当于 标记 - 清除 - 压缩 算法 标记：从引用根节点开始遍历，标记所有被引用的对象 压缩：将所有存活的对象压缩到内存的一端，之后清除此外的空间 优点：解决了 标记 - 清除 算法中内存碎片的问题、解决了 复制算法 占用两倍内存的高额代价 缺点：效率低于复制算法、也需要调整引用的地址、移动过程中也需要 STW 三种算法比较 分代收集算法 针对不同的代采用不同的垃圾回收算法 新生代：复制算法，新生代区域较老年代小，对象生命周期短，存活率低，回收频繁 老年代：标记 - 清除 + 标记 - 压缩，老年代区域较大，对象生命周期长，存活率高，回收不及新生代频繁 HotSpot 中使用 CMS 回收器，CMS 回收器是基于 标记 - 清除 实现的，效率较高，对于碎片问题，使用 标记 - 压缩 的 Serial Old 回收器做补偿 增量收集算法 每次垃圾收集线程都只收集一小块区域，与用户线程交替执行，直到垃圾收集完成。 优点：有效减少单次 STW 延迟，提高用户体验、系统稳定 缺点：造成系统吞吐量的下降 分区算法 将堆空间划分为连续的小空间 region，每个小区间独立使用独立回收，好处是可以控制每次回收多少小空间 垃圾回收相关概念补充 System.gc( ); 显示的调用 full gc ，对堆空间及元空间进行垃圾回收 实际上调用的是 Runtime.getRuntime().gc(); 是一个本地方法 无法保证对垃圾收集器的调用（需等待安全点） 可以使用 System.runFinalization(); 确保 finalze 方法的执行 Slot 槽的复用：为什么声明了一个 bytes 变量，局部变量表的槽数也是 2 ，但是局部变量表中只有一条 args 呢？ 因为 bytes 实际存储在序号 1 的位置，栈中有引用 GC 不会回收 bytes 但是当下方声明 byte b = 127 之后局部变量表序号 1 的位置被复用，此时 bytes 将会被 GC 回收 内存溢出与内存泄漏 跳转至方法区内存泄漏相关内容 STW：Stop The World 为确保标记时以及清除时的数据一致性，发生的停顿，停止整个程序 如果分析过程中引用关系不断变化，则分析结果准确性无法保证 因为 STW 的存在，Thread 的 sleep 时间不一定十分准确 垃圾回收的并行与并发 并发：单个处理器在同一时间段中，几个程序快速的交替执行，会互相抢占资源【某一时间段内同时发生】 并行：多个处理器同时执行多个程序时，一个处理器执行一个程序，不会互相抢占资源【某一时间点同时发生】 垃圾回收的并发、并行、串行 并发：同一段时间内，用户线程与垃圾回收线程同时执行，有效减少单次 STW 时长 并行：用户线程 STW 的时候，多条垃圾回收线程并行工作 串行：用户线程 STW 的时候，同一时间点只有一条垃圾回收线程工作 垃圾回收的安全点与安全区域 安全点（SafePoint） 多线程环境下 GC 能够安全、可控的回收对象的时间点，安全点的选择以 是否具有让程序长时间执行的特征 为标准 安全点的选择方式 抢先式中断：中断所有线程，如果有线程不在安全点，则恢复线程跑到安全点（没有 JVM 用这种） 主动式中断：各线程在安全点时轮询一个中断标记，当这个标记为真时，主动将自己中断挂起 例如（执行较慢的指令：方法调用、循环跳转、异常跳转等） 安全区域（Safe Region） 当线程处于 Sleep 或者 Blocked 状态，JVM 无法中断时 代码在一段片段中，对象的引用关系不会发生变化，这个区域中任意 GC 都是安全的 当线程处于安全区时，需等待 GC 完成才能退出安全区 关于引用 强引用（StrongReference） 最传统的引用 Object obj = new Object(); 是可达的，可触及的 只要强引用关系还在，对象就不会被垃圾回收器回收 软引用（SoftReference） 被置空的强引用、传参时 new 出来的对象 构造软引用 SoftReference usr = new SoftReference\u003c\u003e(new User()); 是可达的，可触及的 高速缓存会使用到软引用，软引用在内存溢出前回收 弱引用（WeakReference） 被置空的强引用、传参时 new 出来的对象 构造弱引用 User user = new User(); WeakReference uwr = new WeakReference\u003c\u003e(new User()); user = null; 是可达的，可触及的 只要垃圾回收器工作，弱引用就被回收 虚引用（PhantomReference） 构造虚引用 User user = new User(); ReferenceQueue rq = new ReferenceQueue\u003c\u003e(); //引用队列 PhantomReference pr = new PhantomReference\u003c\u003e(user,rq); user = null; 使用虚引用为了在这个对象被回收时收到一个系统通知，对象回收跟踪 终结器引用 在 GC 时，终结器引用入队，finalizer线程通过终结器引用来找到被引用对象并调用 finalze 方法，在第二次 GC 时回收对象 垃圾回收器（Garbage Collector）\r垃圾回收器分类 按照线程数分类 串行垃圾回收器：单 cpu 平台、硬件资源受限平台【Serial、Serial Old】 并行垃圾回收器：并发能力比较强的 cpu 【ParNew、Parallel、Scavenge、Parallel Old】 按照工作模式分类 并发式垃圾回收：用户线程与垃圾回收线程快速交替执行，延迟时间段【CMS、G1】 独占式垃圾回收：垃圾回收时独占一整段时间，用户线程等待垃圾回收线程执行 按照碎片处理分类 压缩式垃圾回收器：采用了带有压缩算法的垃圾回收器 非压缩式垃圾回收器：不进行内存空间压缩的垃圾回收器 按照工作的内存区间分类 年轻代的垃圾回收 老年代的垃圾回收 垃圾回收器的性能指标 吞吐量：运行用户代码的时间占用总运行时间的比例【a/a+b】 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例【b/a+b】 暂","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:5","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#垃圾回收器相关面试题"},{"categories":null,"content":"\r字节码与类的加载","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#字节码与类的加载"},{"categories":null,"content":"\r关于字节码内容略 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#关于字节码内容"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器\u003cclinit\u003e()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 \u003cclinit\u003e 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 \u003cclinit\u003e 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行\u003cclinit\u003e方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行\u003cclinit\u003e方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行\u003cclinit\u003e方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行\u003cclinit\u003e方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的\u003cclinit\u003e方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#类的加载"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#过程1loading-加载阶段"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#过程2linking-链接阶段"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#过程3initialization-初始化阶段"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#哪些场景下不需要生成-clinit-方法"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#clinit-的多线程安全性问题"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#类的主动使用与被动使用的问题"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#过程4using-使用阶段"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#过程5unloading-卸载阶段"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#类的卸载"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#再谈类加载器"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#类的显式加载与隐式加载"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#命名空间"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#类加载器的三大特征"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#classloader-类加载器"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#classloader-与现有类加载器的关系"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#双亲委派机制-1"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#打破双亲委派机制-a-name打破双亲委派机制-a"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#沙箱安全机制"},{"categories":null,"content":"\r类的加载\r过程1：Loading 加载阶段 获取类的二进制字节流 将其代表的静态存储结构 (元数据: 类的方法代码，变量名，方法名，访问权限，返回值等) 转化为方法区的运行时数据结构 在内存中生成此类的 java.lang.Class 实例，作为方法区这个类的访问入口 ==类加载器的工作就只在加载阶段，链接、初始化都是由 JVM 完成的== 就是将 Java 类的字节码文件加载到机器内存中，并在内存中构建出 Java 类的原型 – 类模板对象 通过类的全限定名，获取类的二进制数据流 解析类的二进制数据流生成方法区内的 Java 类模板 堆中创建 java.lang.Class 类的实例，表示该类型，指向方法区这个类的各种数据（模板） 数组类型本身并不是由类加载器负责创建，而是在运行时创建，但数组的元素类型需要由类加载器创建。 基础数据类型：由虚拟机预先定义，权限为 Public 引用数据类型：需要类加载器加载，权限看具体类的访问权限 获取类二进制数据流的方式 读入 class 文件 读入 jar、zip 等数据包，提取类文件 存在数据库中的类的二进制数据 类似于 HTTP 之类的协议通过网络加载 在运行时生成的 Class 的二进制信息 如果数据不是 ClassFile 的结构，抛出 ClassFormatError 过程2：Linking 链接阶段 Verification 验证阶段 确保 class 文件的字节流中包含信息符合当前虚拟机要求，正确性、无危险性 java 虚拟机中 class 文件必须以 CA FE BA BE 开头 保证加载的字节码是合法、合理并符合规范的 格式验证： 会与加载阶段一起执行，验证之后才会加载相关二进制数据。 验证是否 CAFEBABE 开头（魔数） 验证主版本与副版本是否在当前虚拟机的支持范围内 验证数据中每一项的长度是否正确 语义检查： 验证是否所有类都有父类存在 验证 final 的方法或者类是否被重写或重载了 验证非抽象类是否实现了所有抽象方法或接口方法 验证是否存在不兼容的方法（重复方法，final / static 的抽象方法） 字节码验证： 验证字节码执行过程中是否会跳转到一个不存在的指令 验证函数的调用是否传递了正确的类型参数 验证变量的赋值类型是否正确 栈映射帧：尽可能的检测在特定字节码处，其局部变量表和操作数栈是否有着正确的数据类型（无法做到 100% 准确） 符号引用验证： 在解析阶段才会执行 验证常量池中符号引用的这些类或者方法是否确实存在 Preparation 准备阶段 为类变量分配内存，并赋初始值: 零值 常量（final 修饰）在编译阶段就已经被赋值了，准备阶段只会显式的初始化 不会为实例变量初始化，因为这里是类的加载过程，类在实例化时才会初始化实例变量 为类的静态变量分配内存，并将其初始化为默认值。没有代码执行 会为 final 修饰的基本数据类型类变量赋其字面量值 不会为常量赋值，因为 final 在编译期就已经被赋值了 Resolution 解析阶段 将常量池内的符号引用转换为直接引用的过程 将类、接口、字段、方法的符号引用转为直接引用，直接引用到方法区真实的地址 过程3：initialization 初始化阶段 执行类构造器()的过程 clinit: 是类中的所有类变量的赋值和静态代码块的语句合并而来 虚拟机会保证子类的 clinit 执行前，父类的 clinit 执行完毕 clinit 在多线程下会被同步加锁 (保证只加载一次) 为类的静态变量赋予正确的初始值，包括 final 修饰的有方法调用 / 实例化 赋值的类变量 执行静态代码块中的代码 由父及子，静态先行 哪些场景下，不需要生成 方法 没有类变量的类 类变量不用显式的赋值的类 类变量都是有 final 修饰的不需要方法调用 / 实例化的类 的多线程安全性问题 clinit 方法是加锁线程安全的，保证一个类只有一次初始化，其他线程阻塞后直接返回已经准备好的信息 死锁：如果加载类 A 需要加载类 B ，加载类 B 需要加载类 A ，那么在多线程同时加载时，就会造成死锁 类的主动使用与被动使用的问题 主动使用时会调用 clinit 方法，被动使用时不会调用 clinit 方法 主动使用： 创建一个类的实例时，new、反射、克隆、反序列化 /*反序列化例子*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"序列化后的类文件\")); 类名 类 = (类名)ois.readObject(); //此时会执行方法进行初始化 调用类的静态方法时 类名.方法名(); //此时会执行方法进行初始化 当使用类、接口的静态字段时（ final 特殊） 如果是 static 加 final 修饰时，具体要看显式赋值有没有方法的调用或者类的实例化 System.out.print(类名.静态字段名); //此时会执行方法进行初始化 当使用 java.lang.reflect 包中的方法反射类的方法时，比如：Class.forName(“com.Test”) Class.forName(\"com.mysql.cj.jdbc.Driver\"); //此时会执行方法进行初始化 当初始化子类时，如果发现父类还没初始化，会先初始化父类 在一个类初始化时，并不会先初始化它实现的接口 在一个接口初始化时，也不会先初始化它的父接口 只有在首次使用接口的静态字段时，才会导致接口的初始化 如果一个接口定义了 default 方法，那么直接或间接的实现接口的类的初始化，都要先初始化接口 JDK 8 新特性：可以在接口中定义方法体，但必须是 default 修饰的 class Father implements InterfClass{ public static void main(String[] args) { //运行时会先加载初始化 main 主类，此时会执行接口InterfClass的方法进行初始化 } } interface InterfClass{ public default void fun (){ sout... } } 当虚拟机启动时，用户需要指定一个要执行的主类，（main 方法） 如 6 所示 当依次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的放方法所在的类 JDK 7 中 Java 语言对动态性的支持加入的… 测试类加载的相关参数 -XX:+TraceClassLoading 显示类加载详情 被动使用： 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 例子：访问父类的静态字段时，子类不会初始化 通过数组定义类引用，不会触发类的初始化 Father[] father = new Father[10]; //这个时候 Father 类不会被初始化 调用常量不会触发此类或接口的初始化。因为常量在连接阶段已经被显式赋值了 static final int a = 1; //这样定义的不会 static final int b = Integer.valueOf(2); //这样定义的会 调用 ClassLoader 类的 loadClass( ) 方法加载一个类，并不是对类的主动使用，不会导致类的初始化 自定义类加载器时，可能会用到这个方法 ClassLoader.getSystemClassLoader().loadClass(\"com.mysql.cj.jdbc.Driver\"); //不会导致类的初始化 过程4：Using 使用阶段 访问类的静态变量，new 出实例对象… 过程5：Unloading 卸载阶段 一个类在被类加载器加载【加载阶段】时，会创建其对应的 Class 实例，由类加载器实例对象根据这个实例在方法区中创建类的信息 ==一个类何时结束生命周期，取决于它的 Class 对象合适结束生命周期== 需要其所有实例对象都被回收 需要其 Class 引用变量被回收 需要其类加载器的引用变量及对象被回收 当这个类 Class 对象被回收之后，方法区内容才可以被回收 类的卸载 启动类加载器加载的类型在整个运行期间是不可能被卸载的（ JVM 规范，jls 规范） 扩展类加载器和系统类加载器在运行期间不太可能被卸载，因为系统类加载器实例或扩展类的实例基本上弄能被直接或间接的加载到 自定义类加载器只有在简单的上下文环境中才能被卸载，调用 System.gc( ) 强制垃圾回收时才会被卸载 再谈类加载器 引导类加载器 Bootstrap ClassLoader 使用 C / C++ 实现的 用来加载 Java 的核心类库 只加载包名为 java、javax、sun 等开头的类 扩展类加载器 Extension ClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 ext 子目录 (扩展目录) 加载类库 系统类加载器 (应用程序类加载器) ApplicationClassLoader Java 语言编写，派生于 ClassLoader 类，属于用户自定义类加载器 从 path 路径下加载类库 是程序中默认的类加载器，Java 应用的类都由它加载 用户自定义类加载器 需要继承于 ClassLoader 实现绝妙的插件机制：OS","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#自定义类加载器"},{"categories":null,"content":"\r性能监控与调优","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#性能监控与调优"},{"categories":null,"content":"\r关于性能监控与调优略 ","date":"2022-01-21","objectID":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:1","series":null,"tags":null,"title":"JVM自学笔记md版","uri":"/jvm%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#关于性能监控与调优"},{"categories":null,"content":"\rRabbitMQ 大连交通大学 信息学院 刘嘉宁 2021-11-21 笔记摘自 bjpwernode 秦世国 ","date":"2021-11-21","objectID":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"RabbitMQ自学笔记md版","uri":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#rabbitmq"},{"categories":null,"content":"\r什么是消息队列 消息队列 MQ ( Message Queue ) 解耦 生产者负责将数据写入到队列中，谁想不想要这个数据，与生产者无关 消费者直接从消息队列中取数据，即便消费者宕机超时，与生产者无关 异步 生产者执行完主要功能后，将后续需要处理的功能存入消息队列即可返回 异步化调用其他系统接口，消费者处理速度不影响生产者性能 削锋 / 限流 生产者们根据自己的能力从消息队列中取数据，即便系统同时有再多请求都不至于崩溃 ","date":"2021-11-21","objectID":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"RabbitMQ自学笔记md版","uri":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是消息队列"},{"categories":null,"content":"\rRabbitMQ消息队列 Erlang 语言开发的 AMQP 的开源实现 AMQP：高级消息队列协议（应用层） AMQP 协议本身包括三层： Module Layer: 位于协议最高层，主要定义了一些供客户端调用的命令，客户端可以利用这些命令实现自己的业务逻辑。例如，客户端可以使用Queue . Declare 命令声明一个队列或者使用Basic.Consume 订阅消费一个队列中的消息。 Session Layer: 位于中间层，主要负责将客户端的命令发送给服务器，再将服务端的应答返回给客户端，主要为客户端与服务器之间的通信提供可靠性同步机制和错误处理。 Transport Layer: 位于最底层，主要传输二进制数据流，提供帧的处理、信道复用、错误检测和数据表示等。 ","date":"2021-11-21","objectID":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"RabbitMQ自学笔记md版","uri":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#rabbitmq消息队列"},{"categories":null,"content":"\rRabbitMQ 特点 可靠性：持久化、传输确认、发布确认 灵活的路由：Exchange 消息集群：集群组成Broker 高可用：宕机解决 多种协议：支持多种协议 多语言客户端：支持常用编程语言 管理界面：提供可视化界面 跟踪机制：消息异常时可追踪维护 ","date":"2021-11-21","objectID":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"RabbitMQ自学笔记md版","uri":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#rabbitmq-特点"},{"categories":null,"content":"\rRabbitMQ常用命令 启动 RabbitMQ：rabbitmq-server start \u0026 关闭 RabbitMQ：rabbitmqctl stop ","date":"2021-11-21","objectID":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"RabbitMQ自学笔记md版","uri":"/rabbitmq%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#rabbitmq常用命令"},{"categories":null,"content":"\rSpringBoot 大连交通大学 信息学院 刘嘉宁 2021-11-15 笔记摘自 bjpwernode 秦世国 SpringBoot 框架，整合了 Spring + SpringMVC + MyBatis 框架，简化开发 SpringBoot 抛弃了繁琐的 xml 配置过程，采用大量默认配置，简化开发 使用 SpringBoot 可以非常容易和快速的创建基于 Spring 框架的应用程序 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot"},{"categories":null,"content":"\rSpringBoot 的特性 能够快速创建基于 Spring 的应用程序 能够直接使用 java main 方法启动内嵌的 Tomcat 服务器运行 SpringBoot 程序，不需要外置 Tomcat 再部署 war 包文件 提供约定的 starter POM（起步依赖）简化 Maven 配置，引入相关依赖包，消除版本冲突问题 自动化配置，根据项目的 Maven 依赖配置，Spring boot 自动配置整合 ssm 提供了程序的健康检查等功能 基本可以抛弃XML配置文件，采用注解配置 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-的特性"},{"categories":null,"content":"\rSpringBoot 的四大核心 起步依赖 根据需要的功能自动配置 Maven 依赖 自动配置 根据起步依赖自动提供相关配置 Actuator 健康检查机制，可以看到 SpringBoot 运行状态信息 命令行界面 主要针对 Groovy（一种基于 JVM 的敏捷开发语言）使用 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-的四大核心"},{"categories":null,"content":"\r搭建 SpringBoot 项目 在创建 SpringBoot 模块时确保电脑联网，确认 Server URL 为：start.springboot.io 选择起步依赖 项目结构 编写控制器 因为这里控制器类使用的不是 @Controller 注解，所以其中方法返回值为页面的输出流信息，并不是对页面的请求转发 @RestController 是一个复合注解，相当于为所有方法加上了 @ResponseBody 启动 SpringBoot 自带的 Tomcat 服务器 成果 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-springboot-项目"},{"categories":null,"content":"\r@SpringBootApplication 注解 该注解为 SpringBoot 的==核心注解== 该注解标注的类为 SpringBoot 的程序入口类 SpringBoot 会扫描当前类 同级路径 以及 子孙路径 中所有标注了 SpringBoot 注解的类 主要作用是开启 SpringBoot 自动配置 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:1","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springbootapplication-注解"},{"categories":null,"content":"\r分析 主方法内容SpringApplication.run(SpringBootTestApplication.class, args); : 启动 SpringBoot 应用 运行此 run 方法后，会返回 Spring 的应用上下文 ApplicationContext 由于启动的是 WEB 应用，因此启动时会同时启动内嵌的 Tomcat 服务器 默认端口号为 8080，默认应用上下文路径为 ’ ‘（访问时无项目名） ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#分析-主方法内容"},{"categories":null,"content":"\r分析 pom.xml 文件内容pom.xml 中的依赖： \u003cdependencies\u003e \u003c!--web项目环境的起步依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!--测试环境的起步依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e 在 \u003cparent\u003e 标签中可以查看当前项目父项目 spring-boot-starter-parent-2.5.6.pom 的配置信息： \u003cproperties\u003e \u003c!--指定项目JDK版本--\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003c!--指定输入的字符集编码格式--\u003e \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e \u003c!--指定输出的字符集编码格式--\u003e \u003cproject.reporting.outputEncoding\u003eUTF-8\u003c/project.reporting.outputEncoding\u003e \u003c/properties\u003e \u003cbuild\u003e \u003c!--资源文件的路径、命名规范格式--\u003e \u003cresources\u003e \u003cresource\u003e \u003cdirectory\u003e${basedir}/src/main/resources\u003c/directory\u003e \u003cfiltering\u003etrue\u003c/filtering\u003e \u003cincludes\u003e \u003cinclude\u003e**/application*.yml\u003c/include\u003e \u003cinclude\u003e**/application*.yaml\u003c/include\u003e \u003cinclude\u003e**/application*.properties\u003c/include\u003e \u003c/includes\u003e \u003c/resource\u003e \u003cresource\u003e \u003cdirectory\u003e${basedir}/src/main/resources\u003c/directory\u003e \u003cexcludes\u003e \u003cexclude\u003e**/application*.yml\u003c/exclude\u003e \u003cexclude\u003e**/application*.yaml\u003c/exclude\u003e \u003cexclude\u003e**/application*.properties\u003c/exclude\u003e \u003c/excludes\u003e \u003c/resource\u003e \u003c/resources\u003e \u003c/build\u003e 在父项目的 \u003cparent\u003e 标签中可以查看父项目父项目 spring-boot-dependencies-2.5.6.pom 的配置信息： \u003c!--依赖的版本控制--\u003e \u003cproperties\u003e \u003c!--mysql数据库版本--\u003e \u003cmysql.version\u003e8.0.27\u003c/mysql.version\u003e \u003c!--Spring框架版本--\u003e \u003cspring-framework.version\u003e5.3.12\u003c/spring-framework.version\u003e ..... \u003c/properties\u003e 这些都可以在当前项目的 pom.xml 中覆盖修改 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:3","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#分析-pomxml-文件内容"},{"categories":null,"content":"\r属性配置文件 用于改变 SpringBoot 的默认运行行为 可以通过这个文件改变 SpringBoot 的默认行为，例如 Tomcat 的默认端口号、上下文访问路径 application.properties # 这里是 SpringBoot 的配置文件，可以通过这个文件改变 SpringBoot 的默认行为，例如 Tomcat 的默认端口号、上下文访问路径 # 设置 Tomcat 服务器端口号为 9100 server.port=9100 # 设置人下文访问路径(项目名)为 boot server.servlet.context-path=/boot application.yml # yml/yaml 和 properties 一样，也是 SpringBoot 的配置文件，不过 yml 文件更具层次感 server: port: 9100 servlet: context-path: /boot properties 和 yml 文件同时存在时，properties 文件的优先级更高 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#属性配置文件"},{"categories":null,"content":"\r多环境配置 # 激活配置文件，相当于把 dev 中的内容拷贝到这（多文件可以逗号分割） spring.profiles.active=online ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:1","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#多环境配置"},{"categories":null,"content":"\r自定义属性 @Value 在 application 类可识别的任何类中都可以使用 @Value(${属性名}) 为变量赋值 # 注意：不能使用中文，不能使用敏感词如 name... stuName = zhangsan stuAge = 24 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:2","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#自定义属性-value"},{"categories":null,"content":"\r为对象注入属性 @ConfigurationProperties 在类上方标注注解 @ConfigurationProperties(prefix = \"前缀\") 此类必须有 get / set 方法，必须由 Spring 容器管理 @ConfigurationProperties(prefix = \"stu\") @Component public class Student { private String name; private Integer age; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } stu.name = zhangsan stu.age = 24 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:3","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#为对象注入属性-configurationproperties"},{"categories":null,"content":"\r中文乱码问题 当属性值为中文时会产生乱码问题，例： stu.name = 张三 stu.age = 24 解决方案：使用unicode编码的中文：百度一下 “中文转unicode” # 张三 =\u003e \\u5f20\\u4e09 stu.name = \\u5f20\\u4e09 stu.age = 24 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:4","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#中文乱码问题"},{"categories":null,"content":"\rSpringBoot 使用 JSP 文件 SpringBoot 默认不推荐 JSP，想使用 JSP 需要在 pom.xml 手动导入相关依赖 \u003c!--引入Spring Boot内嵌的Tomcat对JSP的解析包，不加解析不了jsp页面--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.tomcat.embed\u003c/groupId\u003e \u003cartifactId\u003etomcat-embed-jasper\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- servlet依赖的jar包start ，可选--\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- servlet依赖的jar包end --\u003e \u003c!-- jsp依赖jar包start ，可选--\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet.jsp\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet.jsp-api\u003c/artifactId\u003e \u003cversion\u003e2.3.1\u003c/version\u003e \u003c/dependency\u003e \u003c!-- jsp依赖jar包end --\u003e \u003c!--jstl标签依赖的jar包start ，可选--\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejstl\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!--jstl标签依赖的jar包end --\u003e \u003cresources\u003e \u003cresource\u003e \u003c!--源文件位置 --\u003e \u003cdirectory\u003esrc/main/webapp\u003c/directory\u003e \u003c!--编译到 META-INF/resourece 目录下不能随便写 这个路径表示编译后的根路径 --\u003e \u003ctargetPath\u003eMETA-INF/resources\u003c/targetPath\u003e \u003cincludes\u003e \u003c!--要那些文件编译过去，**表示 webapp 目录下以及子孙目录，*.* 表示所有文件 --\u003e \u003cinclude\u003e**/*.*\u003c/include\u003e \u003c/includes\u003e \u003c/resource\u003e \u003c/resources\u003e 在 application.properties 文件中加入视图解析器 #视图解析器， / 相当于 src/main/webapp 目录 spring.mvc.view.prefix=/ spring.mvc.view.suffix=.jsp ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-使用-jsp-文件"},{"categories":null,"content":"\rSpringBoot 整合 MyBatis 在创建项目时勾选 SQL 中的 MyBatis Framework 和 MySQL Driver，基础整合 SSM 在 pom.xml 中修改 MySQL 版本 \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cscope\u003eruntime\u003c/scope\u003e \u003c!--指定MySQL驱动版本--\u003e \u003cversion\u003e8.0.27\u003c/version\u003e \u003c/dependency\u003e 添加 MyBatis 逆向工程插件 \u003cplugin\u003e \u003cgroupId\u003eorg.mybatis.generator\u003c/groupId\u003e \u003cartifactId\u003emybatis-generator-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e1.3.6\u003c/version\u003e \u003cconfiguration\u003e \u003c!--配置文件的位置--\u003e \u003cconfigurationFile\u003eGeneratorMapper.xml\u003c/configurationFile\u003e \u003cverbose\u003etrue\u003c/verbose\u003e \u003coverwrite\u003etrue\u003c/overwrite\u003e \u003c/configuration\u003e \u003c/plugin\u003e 在项目根目录下创建 GeneratorMapper.xml 逆向工程映射文件，并配置信息 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"\u003e \u003cgeneratorConfiguration\u003e \u003c!-- 指定连接数据库的JDBC驱动包所在位置，指定到你本机的完整路径 --\u003e \u003cclassPathEntry location=\"D:\\Document\\JDBC\\mysql-connector-java-8.0.27.jar\"/\u003e \u003c!-- 配置table表信息内容体，targetRuntime指定采用MyBatis3的版本 --\u003e \u003ccontext id=\"tables\" targetRuntime=\"MyBatis3\"\u003e \u003c!-- 抑制生成注释，由于生成的注释都是英文的，可以不让它生成 --\u003e \u003ccommentGenerator\u003e \u003cproperty name=\"suppressAllComments\" value=\"true\" /\u003e \u003c/commentGenerator\u003e \u003c!-- 配置数据库连接信息 --\u003e \u003cjdbcConnection driverClass=\"com.mysql.cj.jdbc.Driver\" connectionURL=\"jdbc:mysql://127.0.0.1:3306/springbootdb\" userId=\"root\" password=\"129807\"\u003e \u003c/jdbcConnection\u003e \u003c!-- 生成model类，targetPackage指定model类的包名， targetProject指定生成的model放在eclipse的哪个工程下面--\u003e \u003cjavaModelGenerator targetPackage=\"com.bjpn.springbootmybatis.model\" targetProject=\"src/main/java\"\u003e \u003cproperty name=\"enableSubPackages\" value=\"false\" /\u003e \u003cproperty name=\"trimStrings\" value=\"false\" /\u003e \u003c/javaModelGenerator\u003e \u003c!-- 生成MyBatis的Mapper.xml文件，targetPackage指定mapper.xml文件的包名， targetProject指定生成的mapper.xml放在eclipse的哪个工程下面 --\u003e \u003csqlMapGenerator targetPackage=\"com.bjpn.springbootmybatis.mapper\" targetProject=\"src/main/java\"\u003e \u003cproperty name=\"enableSubPackages\" value=\"false\" /\u003e \u003c/sqlMapGenerator\u003e \u003c!-- 生成MyBatis的Mapper接口类文件,targetPackage指定Mapper接口类的包名， targetProject指定生成的Mapper接口放在eclipse的哪个工程下面 --\u003e \u003cjavaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.bjpn.springbootmybatis.mapper\" targetProject=\"src/main/java\"\u003e \u003cproperty name=\"enableSubPackages\" value=\"false\" /\u003e \u003c/javaClientGenerator\u003e \u003c!-- 数据库表名及对应的Java模型类名 --\u003e \u003ctable tableName=\"t_user\" domainObjectName=\"User\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"/\u003e \u003c/context\u003e \u003c/generatorConfiguration\u003e 在 application.properties 中配置数据库基本信息 # 指定 MySQL 驱动位置 spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://127.0.0.1:3306/springbootdb?useUnicode=true\u0026characterEncoding=utf8\u0026useSSL=false spring.datasource.username=root spring.datasource.password=129807 双击 Maven 工具中的 mybatis-generator:generate 生成 mapper 包（mapper接口和mapper映射文件）及 model 包（实体类） 自动生成的默认 mapper 接口包含的功能 ==指定 MyBatis 的 mapper 映射文件位置== 在每一个 mapper 接口上标注 @Mapper 注解 在 SpringBoot 的主方法上标注 @MapperScan(basePackages = {\"mapper 包的 source root 路径\"}) 【推荐】 在 application.properties 中指定 Mybatis 映射文件的路径 mybatis.mapper-locations=classpath:mapper/*.xml 在 pom.xml 中添加指定资源路径，让java下所有 .xml 文件都参与编译 \u003cresources\u003e \u003cresource\u003e \u003cdirectory\u003esrc/main/java\u003c/directory\u003e \u003cincludes\u003e \u003cinclude\u003e**/*.xml\u003c/include\u003e \u003c/includes\u003e \u003c/resource\u003e \u003c/resources\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-整合-mybatis"},{"categories":null,"content":"\r事务支持 在 SpringBoot 的主方法上标注注解 @EnableTransactionManagement 开启事务 在需要事务的 service 方法上标注注解 @Transactional 在开启了事务的方法中抛出异常就会自动 rollback 回滚 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:1","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#事务支持"},{"categories":null,"content":"\rSpringBoot 整合Redis 在创建项目时勾选 NoSQL 中的 Spring Data Redis 在 application.properties 中配置 Redis 连接基本信息 #配置redis连接信息 spring.redis.host=192.168.30.128 spring.redis.port=6379 spring.redis.password=129807 在业务层定义 RedisTemplate 类变量，让 Spring 容器自动导入 @Resource private RedisTemplate redisTemplate; redisTemplate.opsForValue().set(\"userAll\", list); redisTemplate.opsForValue().get(\"userAll\"); ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-整合redis"},{"categories":null,"content":"\rRedis 的缓存穿透问题 Redis 作为数据库的缓存数据库时，多线程并发同时请求一条数据时，Redis 中并没有这条数据就会同时从数据库中读取数据。 解决方案： 为业务方法添加 synchronized 锁，只有第一次访问数据库，第二次时 Redis 中已经有缓存，其余都访问 Redis 会使并发失效，降低运行速度 为业务代码块添加 synchronized 锁，在第一批次并发请求中，第一个请求到数据并存到缓存服务器后，第二个请求能直接读取到缓存数据 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:1","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#redis-的缓存穿透问题"},{"categories":null,"content":"\rRedis 集群、哨兵模式 Redis 作为数据库的缓存数据库时，一旦宕机项目可能无法正常运行，这时就用到了集群 多台 Redis 数据库做集群时，通常由一台主服务器多台从服务器组成，当主节点数据改变时，从节点自动依照改变 配置主从节点： 主节点 从节点 配置哨兵节点： 哨兵：类似于 Dubbo 的注册中心，Java 程序与哨兵交互，由哨兵管理节点的主从（依照宕机情况）。实现高可用 和 Dubbo 的 Zookeeper 注册中心一样，并不是每次都访问哨兵，当主节点不可用时才会由哨兵管理 sentinel.conf * 节点数量 启动哨兵 * 节点数量 配置 application.properties 配置 #配置redis哨兵连接信息：哨兵地址们，哨兵名称，密码 spring.redis.sentinel.nodes=192.168.235.128:26380,192.168.235.128:26382,192.168.235.128:26384 spring.redis.sentinel.master=mymaster spring.redis.password=123456 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:2","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#redis-集群哨兵模式"},{"categories":null,"content":"\rSpringBoot 热部署插件： 热部署插件可以在代码修改后自动重新加载修改内容，避免重启服务器反复编译未修改代码 在 pom.xml 中引入热部署插件依赖 \u003c!--SpringBoot热部署插件--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-devtools\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e Recompile 选中的文件，避免重新编译所有文件。 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-热部署插件"},{"categories":null,"content":"\rSpringBoot 启动非 WEB 工程 在创建模块时，不勾选起步依赖 在主入口 run 方法前接收返回值：Spring 容器，调用 getBean 获取实例对象 @SpringBootApplication public class SpringBootjavaApplication { public static void main(String[] args) { ApplicationContext context = SpringApplication.run(SpringBootjavaApplication.class, args); DoSomeService doSomeService = (DoSomeService) context.getBean(\"doSomeService\"); doSomeService.sayHello(); } } 让主入口类实现 CommandLineRunner 接口，并重写 run 方法 程序启动后会调用 run 方法，此时的 Spring 容器已经启动完成 @SpringBootApplication public class SpringBootjavaApplication implements CommandLineRunner { @Resource private DoSomeService doSomeService; public static void main(String[] args) { SpringApplication.run(SpringBootjavaApplication.class, args); } @Override public void run(String... args) throws Exception { doSomeService.sayHello(); } } ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-启动非-web-工程"},{"categories":null,"content":"\rSpringBoot 使用拦截器 创建拦截器类 @Component public class MyInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"拦截器成功拦截\"); return false; } } 创建配置类 @Configuration 注解为标记此类为 Spring 的配置类 实现 WebMvcConfigurer 接口相当于将此类添加到 MVC 的命名空间中 通过重写 addInterceptors 方法，添加自定义的拦截器类，配置拦截规则 @Configuration public class MyConfig implements WebMvcConfigurer { @Resource private MyInterceptor myInterceptor; /** * 注册拦截器，相当于 \u003cmvc:interceptors\u003e\u003c/mvc:interceptors\u003e * @param registry 拦截器的注册对象 */ @Override public void addInterceptors(InterceptorRegistry registry) { //添加拦截器 InterceptorRegistration interceptorRegistration = registry.addInterceptor(myInterceptor); //配置拦截规则 interceptorRegistration.addPathPatterns(\"/private/**\"); //配置请求忽略规则 interceptorRegistration.excludePathPatterns(\"/private/test02\"); } } 使用拦截器，在访问 test01 时拦截，访问 test02 时忽略 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-使用拦截器"},{"categories":null,"content":"\rSpringBoot 字符编码 添加 application.properties 配置 # 指定编码格式 spring.http.encoding.charset=UTF-8 # 激活HttpSpringBoot编码 spring.http.encoding.enabled=true # 强制Request和Response都是用这种编码格式 spring.http.encoding.force=true ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-字符编码"},{"categories":null,"content":"\rSpringBoot 打包 war 包 在创建模块时就选择 war，pom.xml 中默认打包方式就会变成 war 包，在打包时内嵌 Tomcat 不参与打包 点击 Maven 工具中的 package 即可在 target 目录中生成 war 包 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-打包-war-包"},{"categories":null,"content":"\rSpringBoot 打包 jar 包 打包 jar 包并上传至 linux 服务器，使用 java -jar jar包文件名.jar 启动 SpringBoot 内嵌Tomcat 封装 shell 脚本 touch 一个 run.sh 文件，在文件内写入 java -jar jar包文件名.jar 命令 chmod 777 run.sh 修改文件权限 ./run.sh 启动 Tomcat 服务器 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-打包-jar-包"},{"categories":null,"content":"\rSpringBoot 使用 Servlet，FilterServlet：【已被控制器替代，不必掌握】 在入口类上标注 @ServletComponentScan(basePackage = \"Servlet包路径\") 在 Servlet 类上方标注 WebServlet(\"/项目名\") 注解，即可让 SpringBoot 扫描到 通过 @Configuration 配置类获取 Bean /** * @Bean标记当前方法是一个Spring的Bean配置方法 * 方法名就是Bean的ID，返回值就是Bean的Class */ @Bean public ServletRegistrationBean heServletRegistrationBean(TestServlet testServlet){ //获取Servlet注册Bean ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(); //注册Servlet servletRegistrationBean.setServlet(testServlet); //返回class return servletRegistrationBean; } Filter：【已被拦截器替代，不必掌握】 在入口类上标注 @ServletComponentScan(basePackage = \"Filter包路径\") 在 Filter类上方标注 @WebFilter(urlPatterns=\"/*\") 注解，即可让 SpringBoot 扫描到 通过 @Configuration 配置类获取 Bean @Bean public FilterRegistrationBean heFilterRegistration(TestFilter testFilter) { //获取Filter注册Bean FilterRegistrationBean filterRegistration = new FilterRegistrationBean(); //注册Filter filterRegistration.setFilter(testFilter); //设置过滤路径 filterRegistration.addUrlPatterns(\"/*\"); //返回class return filterRegistration; } ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:14:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-使用-servletfilter"},{"categories":null,"content":"\rSprintBoot 健康检查机制 在创建模块时勾选 Ops 中的Spring Boot Actuator 【不必掌握】 GET /env 查看所有环境变量 HTTP方法 路径 描述 GET /configprops 查看配置属性，包括默认配置 http://www.haojson.com对json进行格式化 GET /beans 查看Spring容器目前初始化的bean及其关系列表 GET /mappings 查看所有url映射 GET /health 查看应用健康指标 GET /info 查看应用信息 GET /metrics 查看应用基本指标 GET /metrics/{name} 查看具体指标 JMX /shutdown 关闭应用 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#sprintboot-健康检查机制"},{"categories":null,"content":"\rSpringBoot 中的 Thymeleaf 模板 Thymeleaf 是用来开发 Web 和独立环境项目的服务器端的 Java 模版引擎 SpringBoot 并不支持 JSP 但完美整合了 Thymeleaf ，甚至集成了 Thymeleaf 的自动化配置、视图解析器 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-中的-thymeleaf-模板"},{"categories":null,"content":"\rThymeleaf 的特点 动静结合：Thymeleaf 在有网络和无网络的环境下皆可运行，即能直接显示模板上的静态数据；也能像 Jsp 一样动态的从后台接收数据并替换掉模板上的静态数据。这是由于以 HTML 标签为载体，要寄托在 HTML 标签下实现。 开箱即用：它提供标准和 spring 标准两种方言，可以直接套用模板实现 JSTL、 OGNL 表达式效果，避免每天套模板、该jstl、改标签的困扰。同时开发人员也可以扩展和创建自定义的方言。 多方言支持：Thymeleaf 提供spring标准方言和一个与 SpringMVC 完美集成的可选模块，可以快速的实现表单绑定、属性编辑器、国际化等功能。 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:1","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的特点"},{"categories":null,"content":"\r使用 Thymeleaf 创建项目时，勾选 Boot DevTools 热部署、Spring Web 后端、Thymeleaf 百里香叶 起步依赖。 在 application.properties 属性配置文件中，关闭 thymeleaf 的缓存，方便调试 #开发阶段，建议关闭thymeleaf的缓存，不然没有办法看到实时页面 spring.thymeleaf.cache=false 在 application.properties 属性配置文件中，配置 Thymeleaf 的视图解析器 ( 同指向 WEB-INF 中的 JSP 的视图解析器一样 ) #默认视图视图前缀 spring.thymeleaf.prefix=classpath:/templates/ #默认视图后缀 spring.thymeleaf.suffix=.html 在 templates 路径下创建 html 文件，在 html 标签中添加属性 \u003chtml lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"\u003e 使用、效果 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:2","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用-thymeleaf"},{"categories":null,"content":"\rThymeleaf 的变量表达式 ${变量名} 获取变量值 ${变量名.属性名} 获取对象中属性名 ${变量名.方法名()} 获取对象方法的返回值 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:3","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的变量表达式"},{"categories":null,"content":"\rThymeleaf 的选择变量表达式 需配合 th:object 使用 *{变量名} 获取变量值 *{变量名.属性名} 获取对象中属性名 *{变量名.方法名()} 获取对象方法的返回值 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:4","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的选择变量表达式"},{"categories":null,"content":"\rThymeleaf 的 URL 表达式 @{路径} 用于 script、link、a、form、img 标签的地址属性中获取动态数据 \u003c!--互联网绝对路径--\u003e \u003ca th:href=\"@{'https://www.baidu.com/s?wd='+${user.name}}\" target=\"_blank\"\u003e百度\u003c/a\u003e\u003cbr/\u003e \u003c!--项目相对的路径--\u003e \u003ca th:href=\"@{/bb/test02}\" target=\"_blank\"\u003etest02\u003c/a\u003e\u003cbr/\u003e \u003c!--项目的相对路径【不推荐，当项目层次结构复杂时，有可能会丢失地址路径】--\u003e \u003ca th:href=\"@{bb/test02}\" target=\"_blank\"\u003etest02\u003c/a\u003e\u003cbr/\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:5","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的-url-表达式"},{"categories":null,"content":"\rThymeleaf 的常见属性 th:value = \"${...}\" 将动态数据设置到表单元素的 value 属性中 th:attr = \"属性名=${...}\" 可以修改指定属性的值，可以自定义属性 th:onclick = \"js代码\" 可以实现事件处理，在 js 代码中可以拼接 Thymeleaf 的变量表达式（只支持数字和布尔类型） ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:6","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的常见属性"},{"categories":null,"content":"\rThymeleaf 的 each 迭代 List 集合 用法 th:each = \"item,itemStat:${itemList}\" item：每次的迭代对象 itemStat：迭代对象的信息（省略时默认名为 item名+Stat） itemStat.index：0开始下标 itemStat.count：1开始下标 itemStat.size：迭代对象的大小 itemStat.even / odd：当前迭代对象下标的奇偶，0开始 itemStat.first：是否是第一个 itemStat.last：是否是最后一个 itemStat.current：当前迭代对象，等价于 item itemList：后台传过来的数据 \u003ctr th:each=\"user,itemStat:${userList}\"\u003e \u003ctd th:text=\"${itemStat.count}\"\u003e序号\u003c/td\u003e \u003ctd th:text=\"${user.name}\"\u003e姓名\u003c/td\u003e \u003ctd th:text=\"${user.sex}\"\u003e性别\u003c/td\u003e \u003ctd th:text=\"${user.age}\"\u003e年龄\u003c/td\u003e \u003ctd\u003e\u003ca th:href=\"@{'/modify?id='+${user.id}+'xxxxx'}\"\u003e修改\u003c/a\u003e\u003c/td\u003e \u003ctd\u003e\u003ca th:href=\"@{'/delete?id='+${user.id}}\"\u003e删除\u003c/a\u003e\u003c/td\u003e \u003c/tr\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:7","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的-each-迭代-list-集合"},{"categories":null,"content":"\rThymeleaf 的 each 迭代 Map 集合 直接对 Map 的 key，value 进行迭代 用法：th:each = \"node:${itemMap}\" node：itemMap 每次的迭代对象 node.key：获取当前键值对中的 key node.value：活动当前键值对中的 value \u003ctr th:each=\"node:${userMap}\"\u003e \u003ctd th:text=\"${nodeStat.count}\"\u003e序号\u003c/td\u003e \u003ctd th:text=\"${node.key}\"\u003ekey\u003c/td\u003e \u003ctd th:text=\"${node.value}\"\u003evalue\u003c/td\u003e \u003ctd th:text=\"${node.value.id}\"\u003eid\u003c/td\u003e \u003ctd th:text=\"${node.value.name}\"\u003e姓名\u003c/td\u003e \u003ctd th:text=\"${node.value.age}\"\u003e年龄\u003c/td\u003e \u003ctd th:text=\"${node.value.sex}\"\u003e性别\u003c/td\u003e \u003c/tr\u003e 将 Map 转换成 keySet 后，通过遍历 key 获取 value 进行迭代 用法：th:each = \"key:${itemMap.keySet()}\" key：每次迭代的 key 对象 itemMap.get(key)：取当前 key 对应的 value \u003ctr th:each=\"key:${userMap.keySet()}\"\u003e \u003ctd th:text=\"${keyStat.count}\"\u003e序号\u003c/td\u003e \u003ctd th:text=\"${key}\"\u003ekey\u003c/td\u003e \u003ctd th:text=\"${userMap.get(key)}\"\u003evalue\u003c/td\u003e \u003ctd th:text=\"${userMap.get(key).id}\"\u003eid\u003c/td\u003e \u003ctd th:text=\"${userMap.get(key).name}\"\u003e姓名\u003c/td\u003e \u003ctd th:text=\"${userMap.get(key).age}\"\u003e年龄\u003c/td\u003e \u003ctd th:text=\"${userMap.get(key).sex}\"\u003e性别\u003c/td\u003e \u003c/tr\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:8","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的-each-迭代-map-集合"},{"categories":null,"content":"\rThymeleaf 的 if、unless 表达式 th:if = \"${表达式}\" 如果表达式为 false 则删除所在标签 \u003ctd th:if=\"${user.sex == '1'}\"\u003e男\u003c/td\u003e \u003ctd th:if=\"${user.sex == '0'}\"\u003e女\u003c/td\u003e th:unless = \"${表达式}\" 如果表达式为 true 则删除所在标签【不推荐使用】 \u003ctd th:unless=\"${user.sex == '1'}\"\u003e女\u003c/td\u003e \u003ctd th:unless=\"${user.sex == '0'}\"\u003e男\u003c/td\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:9","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的-ifunless-表达式"},{"categories":null,"content":"\rThymeleaf 的 switch case 表达式 th:case=\"*\" 当所有 case 都不匹配时执行 \u003ch3 th:switch=\"${week}\"\u003e \u003cspan th:case=\"1\"\u003e星期一\u003c/span\u003e \u003cspan th:case=\"2\"\u003e星期二\u003c/span\u003e \u003cspan th:case=\"3\"\u003e星期三\u003c/span\u003e \u003cspan th:case=\"4\"\u003e星期四\u003c/span\u003e \u003cspan th:case=\"5\"\u003e星期五\u003c/span\u003e \u003cspan th:case=\"6\"\u003e星期六\u003c/span\u003e \u003cspan th:case=\"7\"\u003e星期日\u003c/span\u003e \u003cspan th:case=\"*\"\u003e错误数据\u003c/span\u003e \u003c/h3\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:10","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的-switch-case-表达式"},{"categories":null,"content":"\rThymeleaf 的内敛文本、内敛脚本 内敛：inline [[${动态数据}]] 将文本直接显示在页面中 [[${动态数据}]] 将文本直接用在 js 代码中 为父标签添加 th:inline = \"javascript\" 后，会自动为内嵌文本添加双引号。 ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:11","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的内敛文本内敛脚本"},{"categories":null,"content":"\rThymeleaf 的字符串拼接 | | 中写的文本和变量表达式会被 Thymeleaf 自动解析拼接（优雅，永不过时） \u003ctd\u003e\u003ca th:href=\"@{|/modify?id=${user.id}\u0026xx=xxx|}\"\u003e修改\u003c/a\u003e\u003c/td\u003e \u003ctd\u003e\u003ca th:href=\"@{'/delete?id='+${user.id}}\"\u003e删除\u003c/a\u003e\u003c/td\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:12","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的字符串拼接"},{"categories":null,"content":"\rThymeleaf 的三元运算符 男:\u003cinput type=\"radio\" name=\"sex\" th:checked=\"*{sex=='1'?true:false}\"\u003e 女:\u003cinput type=\"radio\" name=\"sex\" th:checked=\"*{sex=='0'?true:false}\"\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:13","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的三元运算符"},{"categories":null,"content":"\rThymeleaf 的表达式基本对象 #request 对象、session 对象 \u003cp th:text=\"${#request.getSession().getAttribute('week')}\"\u003e\u003c/p\u003e \u003cp th:text=\"${#httpSession.getAttribute('week')}\"\u003e\u003c/p\u003e \u003cp th:text=\"${session.week}\"\u003e\u003c/p\u003e ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:14","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#thymeleaf-的表达式基本对象"},{"categories":null,"content":"\rSpringBoot 的 REST 接口架构风格 REST: 表述性状态传递，是一组客户端和服务器交互时架构理念和设计原则 架构风格：api 的组织方式 传统：https://www.bilibili.com/video/BVxxx?p=57 RESTful 风格：https://www.bilibili.com/video/BVxxx/p/57 REST 风格的增删改查 查：GET 增：POST 删：DELETE 改：PUT \u003cform action=\"xxx\" method=\"post\"\u003e 姓名：\u003cinput type=\"text\" name=\"username\"\u003e 密码：\u003cinput type=\"password\" name=\"password\"\u003e \u003cinput type=\"hidden\" name=\"_method\" value=\"PUT\"\u003e \u003c!--真实的提交方式--\u003e \u003c/form\u003e 常用注解： @PathVariable：路径变量，从 url 中获取数据 当形参名和路径变量名相同时，value 可省略 @GetMapping(\"/test/{page}\") public String test(@PathVariable Integer page){ return \"test/\"+page; } @GetMapping 查询时用，相当于在 RequestMapping 基础上指定 method 参数必须为 get @PostMapping 添加时用 @PutMapping 修改时用 @DeleteMapping 删除时用 在 application.properties 启用对 put ，delete 请求方式的支持 # 启用 hiddenmethod 过滤器 spring.mvc.hiddenmethod.filter.enabled=true ","date":"2021-11-15","objectID":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:17:0","series":null,"tags":null,"title":"SpringBoot自学笔记md版","uri":"/springboot%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-的-rest-接口架构风格"},{"categories":null,"content":"\rDubbo 大连交通大学 信息学院 刘嘉宁 2021-11-12 笔记摘自 bjpwernode 秦世国 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#dubbo"},{"categories":null,"content":"\r什么是Dubbo 高性能的 RPC 框架, 解决了分布式中的调用问题 不同于HTTP需要进行7步走(三次握手和四次挥手)，Dubbo采用Socket（TCP）通信机制，一步到位 可直接将实例化（实现 Serializable 接口）的数据以二进制流形式传输 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是dubbo"},{"categories":null,"content":"\r什么是分布式 分布式系统是若干独立系统的集合, 但是用户使用起来像是在使用一套系统 解决高并发问题 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是分布式"},{"categories":null,"content":"\r应用架构的发展 单一架构：将所有业务放到一台服务器中 性能差 垂直应用架构：将大应用拆分成为小应用(一般按业务纬度拆分), 根据访问频率决定部署的服务器数量 页面更改难 应用间不能相互调用 分布式架构：将业务拆分后, 用某种（RPC（Dubbo））方式实现各个业务模块的远程调用和复用 RPC模式（远程过程调用模式） 应用间客户相互调用 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#应用架构的发展"},{"categories":null,"content":"\rDubbo的三大核心能力 面向接口的远程方法调用：A项目中的接口可让B项目实现（由Dubbo实现） 智能容错负载均衡 服务自动注册和发现 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#dubbo的三大核心能力"},{"categories":null,"content":"\rDubbo的基本架构\r==服务提供者（Provider）==：暴露服务的服务提供方，服务提供者在启动时向注册中心注册自己提供的服务。 ==服务消费者（Consumer）==: 调用远程服务的服务消费方，在启动时向注册中心订阅自己所需的服务，从提供者地址列表中基于软负载均衡算法选一台提供者进行调用，如果调用失败再选另一台调用。 ==注册中心（Registry）==：注册中心返回服务提供者地址列表给消费者，如果有变更将基于长连接推送变更数据给消费者 ==监控中心（Monitor）==：监控服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#dubbo的基本架构"},{"categories":null,"content":"\r协议 Dubbo支持多种协议：dubbo, hessian , rmi , http, webservice , thrift , memcached , redis Dubbo官方推荐使用 dubbo 协议，默认端口 20880 在 Spring 配置文件加入 \u003cdubbo:protocol name=\"dubbo\" port=\"20880\" /\u003e ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#协议"},{"categories":null,"content":"\r使用Dubbo\r一、创建服务提供者 在 pom.xml 中添加依赖 \u003c!--Spring --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-context\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c!--Dubbo依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edubbo\u003c/artifactId\u003e \u003cversion\u003e2.6.2\u003c/version\u003e \u003c/dependency\u003e 在 pom.xml 中添加编译插件 \u003c!--JDK1.8编译插件--\u003e \u003cplugin\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cversion\u003e3.1\u003c/version\u003e \u003cconfiguration\u003e \u003csource\u003e1.8\u003c/source\u003e \u003ctarget\u003e1.8\u003c/target\u003e \u003c/configuration\u003e \u003c/plugin\u003e 创建实体类实现 Serializable 接口 创建接口及实现类 在 实现类名-privider.xml（ spring 配置文件） 中添加 \u003c!--服务提供者的唯一标识--\u003e \u003cdubbo:application name=\"01-link-orderservice-provider\"/\u003e \u003c!--指定dubbo使用的协议及端口号--\u003e \u003cdubbo:protocol name=\"dubbo\" port=\"20880\"/\u003e \u003c!--暴露服务接口 interface:暴露的接口的全限定名 ref:暴露的接口的实现类 registry:不使用注册中心 N/A --\u003e \u003cdubbo:service interface=\"com.bjpn.service.OrderService\" ref=\"orderService\" registry=\"N/A\"/\u003e \u003c!--将接口实现类创建在Spring容器中--\u003e \u003cbean name=\"orderService\" class=\"com.bjpn.service.impl.OrderServiceImpl\"/\u003e 测试运行 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"orderservce-provider.xml\"); //启动 Spring 容器 context.start(); //阻塞运行 System.in.read(); } 二、创建服务消费者 创建新项目，添加依赖、插件 创建接口及实现类，编写组合接口的实现类，并创建 set 方法（由 Spring 容器注入） 在 实现类名-consume.xml （ spring 配置文件） 中添加 \u003c!--服务消费者的唯一标识--\u003e \u003cdubbo:application name=\"link-main-web\" /\u003e \u003c!--引用远程接口服务: 类似于Bean标签，用于创建来自另一台服务器中的对象 Dubbo为其接口创建动态代理对象，通过获取到的这个代理对象调用远程服务器中的具体方法 id 远程服务代理对象名 interface 远程接口全限定名 url 服务提供者地址 registry N/A不使用注册中心 --\u003e \u003cdubbo:reference id=\"remoteShopService\" interface=\"com.bjpn.service.OrderService\" url=\"dubbo://localhost:20880\" registry=\"N/A\"/\u003e \u003c!--为组合了远程接口实现类的类实例化--\u003e \u003cbean name=\"shopService\" class=\"com.bjpn.service.impl.ShopServiceImpl\"\u003e \u003cproperty name=\"orderService\" ref=\"remoteShopService\"/\u003e \u003c/bean\u003e 测试运行 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"shop-consume.xml\"); ShopService shopService = (ShopService) context.getBean(\"shopService\"); Order order = shopService.buyGoods(10001, \"零食\", 20.0, 2); System.out.println(order); } ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用dubbo"},{"categories":null,"content":"\r使用Dubbo\r一、创建服务提供者 在 pom.xml 中添加依赖 org.springframework spring-context 4.3.16.RELEASE com.alibaba dubbo 2.6.2 在 pom.xml 中添加编译插件 maven-compiler-plugin 3.1 1.8 1.8 创建实体类实现 Serializable 接口 创建接口及实现类 在 实现类名-privider.xml（ spring 配置文件） 中添加 测试运行 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"orderservce-provider.xml\"); //启动 Spring 容器 context.start(); //阻塞运行 System.in.read(); } 二、创建服务消费者 创建新项目，添加依赖、插件 创建接口及实现类，编写组合接口的实现类，并创建 set 方法（由 Spring 容器注入） 在 实现类名-consume.xml （ spring 配置文件） 中添加 测试运行 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"shop-consume.xml\"); ShopService shopService = (ShopService) context.getBean(\"shopService\"); Order order = shopService.buyGoods(10001, \"零食\", 20.0, 2); System.out.println(order); } ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#一创建服务提供者"},{"categories":null,"content":"\r使用Dubbo\r一、创建服务提供者 在 pom.xml 中添加依赖 org.springframework spring-context 4.3.16.RELEASE com.alibaba dubbo 2.6.2 在 pom.xml 中添加编译插件 maven-compiler-plugin 3.1 1.8 1.8 创建实体类实现 Serializable 接口 创建接口及实现类 在 实现类名-privider.xml（ spring 配置文件） 中添加 测试运行 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"orderservce-provider.xml\"); //启动 Spring 容器 context.start(); //阻塞运行 System.in.read(); } 二、创建服务消费者 创建新项目，添加依赖、插件 创建接口及实现类，编写组合接口的实现类，并创建 set 方法（由 Spring 容器注入） 在 实现类名-consume.xml （ spring 配置文件） 中添加 测试运行 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"shop-consume.xml\"); ShopService shopService = (ShopService) context.getBean(\"shopService\"); Order order = shopService.buyGoods(10001, \"零食\", 20.0, 2); System.out.println(order); } ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#二创建服务消费者"},{"categories":null,"content":"\rDubbo服务化最近实践 分包 将服务接口、服务模型、服务异常等均放在公共包中 将需要重复编写的接口、类等 install 在 maven 仓库中 粒度 服务接口尽可能大粒度（高内聚） 接口以业务场景划分，而不是某功能的某一步骤 版本 为接口定义版本号，区分同一接口的不同实现 可为\u003cdubbo:service \u003cdubbo:reference 标签指定相同 version 属性，绑定暴露的接口实现类和引用远程的 “ 接口实现类 ” ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#dubbo服务化最近实践"},{"categories":null,"content":"\rDubbo常用标签 公用标签 \u003cdubbo:application name=”服务的名称”/\u003e 配置应用信息，唯一标识服务 \u003cdubbo:registry address=”ip:port” protocol=”协议”/\u003e 配置注册中心 check=\"false\" 启动时是否检查注册中心是否可用 服务提供者标签 \u003cdubbo:service interface=”服务接口名” ref=”服务实现对象bean”\u003e 配置暴露的服务 retries=\"2\" 自动重试次数 timeout=\"2000\" 超时时间，2000毫秒内没有响应则不再重试 version=\"1.0.0\" / version=\"1.0.1\"定义版本号，在提供相同接口的实现类时 用版本号区分 服务消费者标签 \u003cdubbo:reference id=”服务引用bean的id” interface=”服务接口名”/\u003e 引用远程服务 check=\"false\" 启动时是否检查注册中心是否可用 retries=\"2\" 自动重试次数 timeout=\"2000\" 超时时间，2000毫秒内没有响应则不再重试 version=\"1.0.0\" 定义版本号，在提供相同接口的实现类时 用版本号区分 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#dubbo常用标签"},{"categories":null,"content":"\r注册中心 服务提供者将服务的唯一标识（接口的全限定名）和基本信息（IP、端口、版本号…）登记到注册中心 服务消费者向注册中心查找服务的唯一标识，返回服务的清单列表，然后拿到服务的基本信息向服务提供者索要服务 注册中心用于将服务统一管理 注册中心的类型 Multicast注册中心：组播方式 Redis注册中心：使用Redis作为注册中心 Simple注册中心：就是一个dubbo服务。作为注册中心。提供查找服务的功能。 Zookeeper注册中心：使用Zookeeper作为注册中心【推荐使用】 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#注册中心"},{"categories":null,"content":"\rZookeeper Zookeeper是一个高性能的，分布式的，开放源码的分布式应用程序协调服务 Zookeeper 使用： 配置安装目录 conf 下的 zoo.cfg 在安装目录 bin 目录下启动 Zookeeper 为项目添加 Zookeeper 依赖 \u003c!-- zookeeper客户端依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-framework\u003c/artifactId\u003e \u003cversion\u003e4.1.0\u003c/version\u003e \u003c/dependency\u003e 在项目 spring.xml 配置文件中添加, 并删除 registry=\"N/A\" 、url=\"dubbo://localhost:20880\" \u003c!--指定注册中心--\u003e \u003cdubbo:registry address=\"zookeeper://192.168.30.128:2181\"/\u003e ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:1","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#zookeeper"},{"categories":null,"content":"\rDubbo 中 Zookeeper 的高可用 高可用：通常来描述一个系统经过专门的设计，从而减少不能提供服务的时间，而保持其服务的高度可用性。 健壮性：Dubbo 会将 Zookeeper 中服务信息存储在内存中，即使宕机也可以保证注册中心提供服务列表查询，但不能注册新服务 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:2","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#dubbo-中-zookeeper-的高可用"},{"categories":null,"content":"\r监控中心 Dubbo 提供的简陋的管理控制台 监控服务提供者和消费者的运行状态 ","date":"2021-11-12","objectID":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:0","series":null,"tags":null,"title":"Dubbo自学笔记md版","uri":"/dubbo%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#监控中心"},{"categories":null,"content":"\rCRM：客户关系管理系统 大连交通大学 信息学院 刘嘉宁 2021-10-19 – 2022-01 笔记摘自：bjpowernode 李宁 项目使用手册： 修改 pom.xml 中 MySQL 驱动等依赖版本 创建 crm2 库并导入 crm2.sql 在 crm/utils/RedisUtil.java 中配置 Jedis 连接信息 项目演示： 演示地址 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#crm客户关系管理系统"},{"categories":null,"content":"\rJSP的base标签 basePath为拼接的url连接 base标签href引入了basePath变量 在页面使用相对路径的地方可以使用basePath前缀 自动拼接出：http://localhost:8080/crm/ \u003c%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %\u003e \u003c% String basePath = request.getScheme() + \"://\" + request.getServerName() + \":\" + request.getServerPort() + request.getContextPath() + \"/\"; %\u003e \u003chtml\u003e \u003chead\u003e \u003cbase href=\"\u003c%=basePath%\u003e\"\u003e ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#jsp的base标签"},{"categories":null,"content":"\r1. applicationContext-web.xml 注解扫描, 扫描 ontroller 包下的注解 注解驱动, 加载处理器适配器和处理器映射器 视图解析器, 前缀和后缀加载视图 ( Jsp ) 前缀 : /WEB-INF/jsp 后缀 : .jsp 控制器返回的资源 : return \"/index\"; /WEB-INF/jsp/index.jsp 拦截器配置 权限校验: 除了访问登录页面和登录操作外, 其余必须要求当前用户登录才可以访问 文件上传解析器 文件上传操作 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#1-applicationcontext-webxml"},{"categories":null,"content":"\r2. applicationContext-service .xml 注解扫描, 扫描 service 包下的注解 加载 spring 的声明式事务控制 aop = 切面 + 切入点 声明式事务控制 = 切入点 + 切面 + 事务管理器 save, update , delete开头的方法需要开启事务 其他方法只读事务 加载 applicationContext-dao.xml 配置文件 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#2-applicationcontext-service-xml"},{"categories":null,"content":"\r3. applicationContext-dao.xml 数据库连接池配置 driver, url, username, password mybatis 的整合 sqlSessionFactoryBean 生成sqlSessionFactory 加载 mybatis 的配置文件 mapperScanner 生成sqlSession 扫描 mybatis 的 dao 接口, 将接口创建对应的代理对象, 交给 spring 容器进行管理 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#3-applicationcontext-daoxml"},{"categories":null,"content":"\r项目搭建流图\rexception包：异常包 interceptor包：拦截器包 setting包：代表setting业务模块，以后还有workbench等 dao包：处理持久层的接口和mapper文件 domain包：存放实体类，也有命名为entity、pojo service包：处理业务逻辑层事务业务等 web包：web项目 controller包：存放Servlet文件 utils包：工具包，其中放的工具也会被其他业务使用 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#项目搭建流图"},{"categories":null,"content":"\rUUID 什么是UUID：共36位由字母和数字和 ’ - ’ 生成的随机串，全世界唯一。 UUID组成：随机数 + 时间戳 + 硬件编码 UUID uuid = UUID.randomUUID(); String id = uuid.toString(); id = id.replaceAll(\"-\", \"\"); ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#uuid"},{"categories":null,"content":"\rAjax路径URL 相对路径：settings/user/login.do 相对路径会自动拼接项目名称 http://localhost:8080/crm/settings/user/login.do 绝对路径：/settings/user/login.do 绝对路径不会自动拼接项目名称 http://localhost:8080/settings/user/login.do ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#ajax路径url"},{"categories":null,"content":"\rAjax返回值resp约定定义 code：返回值的编码 0：操作成功 1：操作失败 2：用户名或密码错误 … msg：日志信息 data：具体数据 resp{ code: \"0/1/...\", msg: \"respInfo\", data: { null, [\"abcd\", \"efgh\", \"jklm\"], [ {name: \"admin\", pswd: \"123\"}, {name: \"admin1\", pswd: \"1234\"}, ] } } ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:8:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#ajax返回值resp约定定义"},{"categories":null,"content":"\r实体类序列化与反序列化 实现 Serializable 接口 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:9:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#实体类序列化与反序列化"},{"categories":null,"content":"\rIDEA 的 Free mybatis plugins 插件 可以根据 DAO 类方法名自动生成 Mapper映射文件的对应标签 find =\u003e \u003cselect\u003e delete =\u003e \u003cdelete\u003e update =\u003e \u003cupdate\u003e insert =\u003e \u003cinsert\u003e ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:10:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#idea-的-free-mybatis-plugins-插件"},{"categories":null,"content":"\rCookie的设置 //将Cookie设置为根路径下，让所有模块都能访问到这个Cookie cookie.setPath(\"/\"); //设置Cookie存放在硬盘中，60*60*24为一天 cookie.setMaxAge(60*60*24*10); ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:11:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#cookie的设置"},{"categories":null,"content":"\r清除Session中的数据 session.removeAttribute(“数据名”); //2. 清除Session中的数据 HttpSession session = request.getSession(); session.removeAttribute(\"user\"); ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:12:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#清除session中的数据"},{"categories":null,"content":"\r灵活运用JSTL \u003cc:forEach items=\"${typeList}\" var=\"t\" varStatus=\"i\"\u003e \u003c%-- varStatus: 相当于index i.index从0开始 i.count从1开始 --%\u003e \u003c%--灵活运用三目表达式--%\u003e \u003ctr class=\"${i.count%2 == 0? \"\": \"active\"}\"\u003e \u003ctd\u003e\u003cinput type=\"checkbox\" /\u003e\u003c/td\u003e \u003ctd\u003e${i.count}\u003c/td\u003e \u003ctd\u003e${t.code}\u003c/td\u003e \u003ctd\u003e${t.name}\u003c/td\u003e \u003ctd\u003e${t.description}\u003c/td\u003e \u003c/tr\u003e \u003c/c:forEach\u003e ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:13:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#灵活运用jstl"},{"categories":null,"content":"\r全选与反选 jsp传统实现方式 //全选 function SelectAllAndUnSelectAll(){ var select = $(\"#checkAll\").prop(\"checked\"); for (var i = 0; i \u003c $(\"input[name=ck]\").length; i++) { $(\"input[name=ck]\")[i].checked = select; } } //反选 function reSelectAll(){ if($(\"input[name=ck]\").length == $(\"input[name=ck]:checked\").length){ $(\"#checkAll\").prop(\"checked\", true); }else{ $(\"#checkAll\").prop(\"checked\", false); } } ajax异步刷新的方式 使用异步刷新加载出来的代码不能使用 $(\"input[name=ck]\") jQuery 方式绑定DOM对象 // 不是由 ajax 异步出来的 html 标签 事件名 子容器对象 回调方法 $(\"#dictionaryValueListBody\").on(\"click\", \"input[name=ck]\", function (){ $(\"#checkAll\").prop(\"checked\", $(\"input[name=ck]:checked\").length == $(\"input[name=ck]\").length) }) ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:14:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#全选与反选"},{"categories":null,"content":"\r封装返回值类型实体类 每次 ajax 请求都要返回一些固定格式的 MAP 将使用频率高相似度高的 MAP 内容包装成实体类 返回时就可以返回这个类 ajax 在前端也可以向解析 MAP 一样解析这个类中的内容、 通过实体类进行封装 通过 MAP 集合基础上进行封装 对分页查询进行封装 略 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:15:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#封装返回值类型实体类"},{"categories":null,"content":"\r当前方法已过时标记 @Deprecated ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:16:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#当前方法已过时标记"},{"categories":null,"content":"\r在mybatis动态查询的if标签中 \u003c \u003e 会被解析成标签的开始和结束 应使用 \u0026lt; \u0026gt;转义 模糊查询 ‘%’ 左右都要加上空格 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:17:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#在mybatis动态查询的if标签中"},{"categories":null,"content":"\rHTML：设置select标签默认option 设置 select 标签 value 属性即可 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:18:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#html设置select标签默认option"},{"categories":null,"content":"\rPOI: Office 文档的 Java 处理包 POI 对 Excel 文件的坐标 HSSFWorkbook : Excel工作簿对象 HSSFSheet: Excel页码对象 HSSFRow : Excel行对象 HSSFCell: Excel列/单元格对象 使用 MultipartFile 获取到前端传入的对象，然后通过 HSSFWorkbook 等对象转换提取后，存入数据库 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:19:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#poi-office-文档的-java-处理包"},{"categories":null,"content":"\r文件 input 框的使用 为文件 input 框添加 Form 表单 为 Form 表单添加 enctype 属性为 multipart/form-data application/x-www-form-urlencoded【默认】只能上传文本格式的文件 multipart/form-data 以二进制形式上传，可以上传所有类型文件 再后端使用 MultipartFile 类型接收文件 String originalFilename = activityFile.getOriginalFilename(); 获取文件名 activityFile.transferTo(new File(url+\"/\"+fileName)); 将文件写入到指定文件中 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:20:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#文件-input-框的使用"},{"categories":null,"content":"\r调用浏览器的文件下载功能 利用 response 对象创建输出流，POI 就可以通过这个输出流输出文件 //声明返回类型 response.setContentType(\"octets/stream\"); response.setHeader(\"Content-Disposition\",\"attachment;filename=Activity-\"+DateTimeUtil.getSysTime()+\".xls\"); //创建输出流 OutputStream out = response.getOutputStream(); //通过输出流输出workbook的内容 workbook.write(out); ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:21:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#调用浏览器的文件下载功能"},{"categories":null,"content":"\r为异步加载出的标签绑定事件 使用异步刷新加载出来的代码不能使用 $(\"...\") jQuery 方式绑定DOM对象 解决方式： // 不是由 ajax 异步出来的 html 标签 事件名 子容器对象 回调方法 $(\"#dictionaryValueListBody\").on(\"click\", \"input[name=ck]\", function (){ $(\"#checkAll\").prop(\"checked\", $(\"input[name=ck]:checked\").length == $(\"input[name=ck]\").length) }) ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:22:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#为异步加载出的标签绑定事件"},{"categories":null,"content":"\r服务器缓存 使用全局作用域 ServletContext 作为缓存区域，将常用字典值存在全局作用域中，需要时直接从缓存中取 需要注意： 当持久化数据库的值增删改时，缓存数据应及时更新 需要处理缓存穿透、缓存击穿、缓存雪崩的问题 ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:23:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#服务器缓存"},{"categories":null,"content":"\r如何将对象存至Redis中？ Redis 中只支持 String 类型，但是 String 类型是二进制安全的，这意味着 String 类型可以存储任意类型数据。 任何图片、视频等等格式文件，只要可以序列化与反序列化，那么它都可以保存至 Redis 中。 Redis 的 String 类型最大可以存储 512MB 内容。 在 Java 中，一个类实现了 Serializable 接口，那么这个类就是可以序列化的。 序列化工具类： import java.io.*; public class SerializableUtil { //序列化 public static byte [] serialize(Object obj){ ObjectOutputStream obi=null; ByteArrayOutputStream bai=null; try { bai=new ByteArrayOutputStream(); obi=new ObjectOutputStream(bai); obi.writeObject(obj); byte[] byt=bai.toByteArray(); return byt; } catch (IOException e) { e.printStackTrace(); } return null; } //反序列化 public static Object unserizlize(byte[] byt){ ObjectInputStream oii=null; ByteArrayInputStream bis=null; bis=new ByteArrayInputStream(byt); try { oii=new ObjectInputStream(bis); Object obj=oii.readObject(); return obj; } catch (Exception e) { e.printStackTrace(); } return null; } } ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:24:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#如何将对象存至redis中"},{"categories":null,"content":"\rJQuery中，获取键盘事件 在相应的事件回调方法上加 event 形参，JQuery 会自动将事件对象传入 $(\"#searchActivity\").keydown(function (event){ console.log(event.keyCode); if (event.keyCode == 13){ alert(\"敲击了回车\"); return false; } }); ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:25:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#jquery中获取键盘事件"},{"categories":null,"content":"\r关闭输入框自动提示 为输入框添加属性 autocomplete 值为 off \u003cinput type=\"text\" autocomplete=\"off\"\u003e ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:26:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#关闭输入框自动提示"},{"categories":null,"content":"\rBootstrap 自动补全插件 typeahead 插件 //source: 输入框内容变化时,自动回调的方法 // query: 输入的关键字 // process: 解析数据的方法(需按规则对内容解析) //delay: 等待多久发送一次请求(毫秒) $(\"#create-customerName\").typeahead({ source: function (query, process) { $.post( \"workbench/transaction/getCustomerName.do\", { \"name\" : query }, function (data) { //data格式: data[\"张三有限责任公司\", \"法外狂徒张三\", \"思阁张三\"] process(data); }, \"json\" ); }, delay: 500 }); ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:27:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#bootstrap-自动补全插件"},{"categories":null,"content":"\recharts 图表插件 导入插件 \u003cscript type=\"text/javascript\" src=\"jquery/ECharts/echarts.min.js\"\u003e\u003c/script\u003e 为插件提供显示区域 \u003c!-- 为 ECharts 准备一个定义了宽高的 DOM --\u003e \u003cdiv id=\"main\" style=\"width: 600px;height:400px;\"\u003e\u003c/div\u003e 初始化插件，指定显示区域、指定配置和数据、显示 option：图表的配置和数据 legend：图表的数据种类 xAxis：图表 x 轴坐标显示内容 yAxis：图表 y 轴坐标显示内容（默认自动） series：显示内容列表 name：对应的数据种类 type：显示的图的类型 data：图的数据 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('main')); // 指定图表的配置项和数据 var option = { title: { text: 'ECharts 入门示例' }, tooltip: {}, legend: { data: ['销量'] }, xAxis: { data: ['衬衫', '羊毛衫', '雪纺衫', '裤子', '高跟鞋', '袜子'] }, yAxis: {}, series: [ { name: '销量', // type: 'bar',//柱状图 // type: 'pie',//饼状图 type: 'line',//折线图 data: [5, 20, 36, 10, 10, 20] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); 效果： 交易历史图表效果： ","date":"2021-10-17","objectID":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/:28:0","series":null,"tags":null,"title":"CRM客户关系管理系统项目笔记","uri":"/crm%E5%AE%A2%E6%88%B7%E5%85%B3%E7%B3%BB%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/#echarts-图表插件"},{"categories":null,"content":"\rGIT 大连交通大学 信息学院 刘嘉宁 2021-10-17 笔记摘自链接：bjpowernode 李宁 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#git"},{"categories":null,"content":"\rGIT：版本控制工具 一个开源的分布式版本控制系统，可以有效，高速的管理项目版本。 用于存储，追踪目录和文件的修改历史 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#git版本控制工具"},{"categories":null,"content":"\rGIT的作用 协同开发 版本控制 数据备份 权限控制 分支管理 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#git的作用"},{"categories":null,"content":"\rGIT的优点 适合分布式，强调个体。 公共服务器压力和数据量都不大。 速度快，灵活。 相对容易的解决冲突。 大部分操作在本地完成，不需要联网。 以快照流的方式工作。 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#git的优点"},{"categories":null,"content":"\rGIT的目录 工作目录 保存代码的文件夹 暂存区 类似于回收站，暂时保存代码用 本地仓库 git init 创建出来的 .git 隐藏目录 远程仓库 代码的托管平台 Github / Gitee ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#git的目录"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#git常用命令"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#查看版本号-git---version"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建本地仓库-git-init"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#工作目录添加到暂存区-add"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#暂存区还原到工作目录--reset"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#暂存区提交到本地仓库-commit"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#查看暂存区文件状态-git-status"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#设置签名config"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#查看日志信息-log"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#版本切换-reset"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#文件删除-rm"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#文件找回-restore"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#分支管理"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建分支branch"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#查看分支branch"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#切换分支checkout"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建并切换分支checkout--b"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#删除分支branch--d"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#强制删除分支branch--d"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#分支合并merge"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#远程仓库"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#本地仓库关联远程仓库remote"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#查看关联的远程仓库信息remote--v"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#删除与远程仓库的关联关系remote-remove"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#将本地仓库推送到远程仓库push"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#删除远程仓库分支push--d"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#克隆代码到本地仓库clone"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#拉取分支到本地仓库pull"},{"categories":null,"content":"\rGIT 大连交通大学 信息学院 刘嘉宁 2021-10-17 笔记摘自链接：bjpowernode 李宁 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:0:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#git"},{"categories":null,"content":"\rGIT：版本控制工具 一个开源的分布式版本控制系统，可以有效，高速的管理项目版本。 用于存储，追踪目录和文件的修改历史 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:1:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#git版本控制工具"},{"categories":null,"content":"\rGIT的作用 协同开发 版本控制 数据备份 权限控制 分支管理 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:2:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#git的作用"},{"categories":null,"content":"\rGIT的优点 适合分布式，强调个体。 公共服务器压力和数据量都不大。 速度快，灵活。 相对容易的解决冲突。 大部分操作在本地完成，不需要联网。 以快照流的方式工作。 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:3:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#git的优点"},{"categories":null,"content":"\rGIT的目录 工作目录 保存代码的文件夹 暂存区 类似于回收站，暂时保存代码用 本地仓库 git init 创建出来的 .git 隐藏目录 远程仓库 代码的托管平台 Github / Gitee ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:4:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#git的目录"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#git常用命令"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#查看版本号-git---version"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#创建本地仓库-git-init"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#工作目录添加到暂存区-add"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#暂存区还原到工作目录--reset"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#暂存区提交到本地仓库-commit"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#查看暂存区文件状态-git-status"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#设置签名config"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#查看日志信息-log"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#版本切换-reset"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#文件删除-rm"},{"categories":null,"content":"\rGIT常用命令移动到Git中test文件夹：cd D:/Document/Git/test ==git是不会管理空文件夹的== 查看版本号 git --version 创建本地仓库 git init 本地仓库创建后会出现一个隐藏的 .git 文件夹 工作目录添加到暂存区 add git add 文件 git add . 提交当前目录所有文件 暂存区还原到工作目录 reset git reset 文件 删除暂存区中的该文件 暂存区提交到本地仓库 commit git commit git commit -m \"日志信息\" git commit --amend -m \"日志信息\" 重新提交日志信息 查看暂存区文件状态 git status 已跟踪文件：绿色，已经添加到暂存区【以跟踪】 未跟踪文件：红色，未添加到暂存区【未跟踪】 git restore HEAD 文件名 让文件变为【未跟踪】状态 设置签名config 设置签名（用户名，邮箱） ​ git config user.name \"LiuJN\" ​ git config user.email \"LiuJaNing@163.com\" 设置全局签名（用户名，邮箱） ​ git config --global user.name \"LiuJN\" ​ git config --global user.email \"LiuJaNing@163.com\" git config --list 查看当前所有 config 信息 查看日志信息 log git log 查看当前日志信息，当前时间节点的日志信息 git reflog 查看本地仓库更新历史记录 版本切换 reset git reset --hard 版本的Hash值 文件删除 rm 文件被删除之后，还需要 添加、提交 操作让本地仓库知道文件已经被删除 通过 git 命令删除文件 rm git rm 文件名 删除工作目录、缓存区中的文件，直接提交即可 文件找回 restore ==删除的文件如果已经提交则无法找回== git restore 文件名 找回添加到暂存区后被删除的文件 git restore --staged 文件名 找回使用 git rm 命令删除的文件到暂存区，然后 git restore 文件名 找回文件到工作目录 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:5:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#文件找回-restore"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#分支管理"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#创建分支branch"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#查看分支branch"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#切换分支checkout"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#创建并切换分支checkout--b"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#删除分支branch--d"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#强制删除分支branch--d"},{"categories":null,"content":"\r分支管理\r创建分支branch git branch 分支名 创建出来的分支基于当前分支的代码，创建之后分支的操作互不影响 查看分支branch git branch 切换分支checkout git checkout 分支名 创建并切换分支checkout -b git checkout -b 分支名称 删除分支branch -d 无法删除当前所处的分支 git branch -d 分支名 强制删除分支branch -D 如果分支已经被修改过，必须使用强制删除 git branch -D 分支名 分支合并merge git merge 目标分支的名称 将目标分支的内容合并到当前分支 ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:6:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#分支合并merge"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#远程仓库"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#本地仓库关联远程仓库remote-add"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#查看关联的远程仓库信息remote--v"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#删除与远程仓库的关联关系remote-remove"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#将本地仓库推送到远程仓库push"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#删除远程仓库分支push--d"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#克隆代码到本地仓库clone"},{"categories":null,"content":"\r远程仓库\r本地仓库关联远程仓库remote add git remote add 远程仓库名 远程仓库地址 查看关联的远程仓库信息remote -v git remote -v 删除与远程仓库的关联关系remote remove git remote remove 远程仓库名 将本地仓库推送到远程仓库push git push 远程仓库名 本地分支名 第一支推送的分支就是远程仓库的默认分支，无法删除 删除远程仓库分支push -d git push -d 远程仓库名 远程仓库分支名 克隆代码到本地仓库clone git clone 远程仓库地址 克隆到当前文件夹下，默认放在远程仓库名称 git clone 远程仓库地址 本地文件夹名称 自己指定本地文件夹名称 git clone -b 远程仓库分支 远程仓库地址 本地文件夹名称 克隆远程仓库的分支到本地 拉取分支到本地仓库pull 拉取本地仓库不存在的分支 git pull 远程仓库名 远程仓库分支名:本地仓库分支名 拉取本地仓库已经存在的分支【本地已有同名分支】 git pull 远程仓库名称 远程仓库分支名 强制拉取远程仓库的内容到不同版本的本地仓库中 git pull origin master --allow-unrelated-histories ","date":"2021-10-17","objectID":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/:7:0","series":null,"tags":null,"title":"GIT自学笔记md版mini版","uri":"/git%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88mini%E7%89%88/#拉取分支到本地仓库pull"},{"categories":null,"content":"\rNginx自学笔记 大连交通大学 信息学院 刘嘉宁 2021-10-17 笔记摘自：bjpowernode 杨震 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nginx自学笔记"},{"categories":null,"content":"\rNginx服务器 静态网站部署 负载均衡 虚拟主机 反向代理，正向代理 代理对象是客户端，反向代理 代理对象是服务端。 动静分离 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nginx服务器"},{"categories":null,"content":"\rNginx服务器特点 占用内存少 并发处理能力强 高性能 低系统资源消耗 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nginx服务器特点"},{"categories":null,"content":"\r在Linux中的部署配置Nginx 安装依赖编译器与依赖的类库：gcc编译器、openssl库、pcre库、zlib库 yum install gcc openssl openssl-devel pcre pcre-devel zlib zlib-devel -y 上传安装包并解压 在nginx解压路径下执行 ./configure --prefix=/usr/local/nginx 编译 make 安装 make install ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#在linux中的部署配置nginx"},{"categories":null,"content":"\rNginx常用命令 启动Nginx：在Nginx安装目录/sbin 下执行命令 ./nginx master 进程读取配置文件，并维护 worker 进程 worker 进程则对请求进行实际处理 关闭Nginx 优雅关闭：处理完请求后再关闭 kill -quit 主pid 暴力关闭：不管请求是否处理完成，直接关闭 kill -term 主pid 重启Nginx：./nginx -s reload ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nginx常用命令"},{"categories":null,"content":"\r一、在Nginx中部署静态网站 在 nginx安装目录/conf/nginx.conf 中修改配置 server：虚拟主机 location：处理的网站，/开头 root：网站根目录 index：首页文件名 重启服务器，访问 127.0.0.1/myWeb ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#一在nginx中部署静态网站"},{"categories":null,"content":"\r二、Nginx常用负载均衡策略\r1. 轮询 为每个访问的url生成hash值，按照访问url的hash结果来分配请求到哪台服务器 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址 在 server 中添加 location 并让proxy_pass 对应到 upstream名 2. 权重 请求按照一定的权重分发到不同的服务器。weight值越大访问的比例越大，用于后端服务器性能不均的情况 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址，并声明对应的 weight 权重值 3. ip绑定 ip绑定也叫ip_hash，按照ip的hash值对应服务器，可以解决session丢失问题 4. 最少连接 哪台服务器最空闲就分配到哪台服务器 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#二nginx常用负载均衡策略"},{"categories":null,"content":"\r二、Nginx常用负载均衡策略\r1. 轮询 为每个访问的url生成hash值，按照访问url的hash结果来分配请求到哪台服务器 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址 在 server 中添加 location 并让proxy_pass 对应到 upstream名 2. 权重 请求按照一定的权重分发到不同的服务器。weight值越大访问的比例越大，用于后端服务器性能不均的情况 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址，并声明对应的 weight 权重值 3. ip绑定 ip绑定也叫ip_hash，按照ip的hash值对应服务器，可以解决session丢失问题 4. 最少连接 哪台服务器最空闲就分配到哪台服务器 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#1-轮询"},{"categories":null,"content":"\r二、Nginx常用负载均衡策略\r1. 轮询 为每个访问的url生成hash值，按照访问url的hash结果来分配请求到哪台服务器 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址 在 server 中添加 location 并让proxy_pass 对应到 upstream名 2. 权重 请求按照一定的权重分发到不同的服务器。weight值越大访问的比例越大，用于后端服务器性能不均的情况 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址，并声明对应的 weight 权重值 3. ip绑定 ip绑定也叫ip_hash，按照ip的hash值对应服务器，可以解决session丢失问题 4. 最少连接 哪台服务器最空闲就分配到哪台服务器 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#2-权重"},{"categories":null,"content":"\r二、Nginx常用负载均衡策略\r1. 轮询 为每个访问的url生成hash值，按照访问url的hash结果来分配请求到哪台服务器 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址 在 server 中添加 location 并让proxy_pass 对应到 upstream名 2. 权重 请求按照一定的权重分发到不同的服务器。weight值越大访问的比例越大，用于后端服务器性能不均的情况 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址，并声明对应的 weight 权重值 3. ip绑定 ip绑定也叫ip_hash，按照ip的hash值对应服务器，可以解决session丢失问题 4. 最少连接 哪台服务器最空闲就分配到哪台服务器 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#3-ip绑定"},{"categories":null,"content":"\r二、Nginx常用负载均衡策略\r1. 轮询 为每个访问的url生成hash值，按照访问url的hash结果来分配请求到哪台服务器 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址 在 server 中添加 location 并让proxy_pass 对应到 upstream名 2. 权重 请求按照一定的权重分发到不同的服务器。weight值越大访问的比例越大，用于后端服务器性能不均的情况 在 nginx安装目录/conf/nginx.conf 中修改配置，在http 中添加 upstream 并对应每个服务器的地址，并声明对应的 weight 权重值 3. ip绑定 ip绑定也叫ip_hash，按照ip的hash值对应服务器，可以解决session丢失问题 4. 最少连接 哪台服务器最空闲就分配到哪台服务器 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#4-最少连接"},{"categories":null,"content":"\r三、在Nginx中部署动静分离网站略 ","date":"2021-10-17","objectID":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"Nginx自学笔记md版","uri":"/nginx%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#三在nginx中部署动静分离网站"},{"categories":null,"content":"\rRedis自学笔记 大连交通大学 信息学院 刘嘉宁 2021-10-11 笔记摘自：bjpowernode 杨震 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis自学笔记"},{"categories":null,"content":"\rNoSQL（Not Only SQL） 解决大规模数据集合多重数据种类带来的挑战，特别是超大规模数据的存储。 非关系型数据库，数据之间一旦没有关系，扩展性、读写性能都大大提高。 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#nosqlnot-only-sql"},{"categories":null,"content":"\rRedis和MySQL数据库的区别 MySQL 关系型数据库 易于维护 易于向用户展示具有隶属关系的信息 查询时需要从硬盘读取数据，查询效率相对低 Redis：Remote Dictionary Server(远程字典服务器) 非关系型数据库 数据以MAP集合形式存储在内存中 不适于长期存储，适于频繁快速的查询 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis和mysql数据库的区别"},{"categories":null,"content":"\rRedis的特点 支持数据持久化：可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 支持多种数据结构：key-value类型、list、set、zset、hash 等数据结构的存储。 支持数据备份：Redis支持数据的备份，即master-slave模式的数据备份。 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis的特点"},{"categories":null,"content":"\rRedis基础知识 Redis默认使用16个数据库 可以在安装目录/redis.conf文件中修改 port值 启动Redis数据库 Redis默认端口：6379 在安装目录下执行命令：redis-server 后台启动Redis服务：redis-server \u0026 根据配置文件启动Redis：redis-server 配置文件 \u0026 如果修改了redis的配置文件redis.conf，必须在启动时指定配置文件，否则修改无效！ 关闭Redis数据库 执行命令：redis-cli shutdown 执行命令： ps -ef | grep redis 查询出redis进程的PID kill pid 或者 kill -9 pid 杀掉进程 连接redis 在任意位置执行命令：redis-cli 使用ping命令测试是否连通 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis基础知识"},{"categories":null,"content":"\rRedis常用命令 切换数据库： select 数据库编号 查看当前数据库有哪些key： keys * 删除当前数据库中的数据： flushdb 删除所有库中的所有数据： flushall 查看库中有多少条数据： dbsize String字符串类型 最大值512MB 向MAP中存放键值对：set key值 value值 获取key值对应的value值：get key值 空为：nil 为原value值后追加字符：append key值 value值 返回追加后的字符串 类型 长度 返回对应的字符串字符个数：strlen key值 不存在返回 0 截取字符串：getrange key值 开始下标 结束下标 正负下标同pathon ==左右都同时包含== 临时向MAP中存放键值对：setex key值 秒数 value值 List列表类型 在列表左边压入键值对：lpush key值 值... 返回追加后的列表 长度 在指定下标区间中取值：lrange key值 开始下标 结束下标 ==左右同时包含== 在列表右边压入键值对：rpush key值 值... 返回追加后的列表 长度 移除左侧第一个元素：lpop key值 返回删除掉的value值 移除右侧第一个元素：rpop key值 返回删除掉的value值 取指定下标上的值：lindex key值 下标 返回列表中有多少个数据：llen key值 更换列表中指定下标位的值：lset key值 下标 value值 Hash哈希类型 在哈希列表key中添加 field域和value值 对：hset key值 field值 value值 [field value …] 返回当前哈希列表中域值对的数量 获取哈希列表中指定field域的value值：hget key值 field值 获取哈希列表中所有 域和值 ：getall key值 获取哈希列表中所有field域列表：hkeys key值 删除哈希列表中的一个 域值对 ：hdel key值 field值 获取哈希列表中所有value值列表：hvals key值 查看哈希列表中 是否存在对应的field域：hexists key值 field值 Set集合类型 向集合中添加元素：sadd key值 元素值 [元素值...] 返回追加后的集合 长度 显示集合中所有元素：smembers key值 判断集合中是否存在对应的member值：sismember key值 member值 获取集合中元素的个数：scard key值 移除一个或多个元素：srem key值 member值 [member值...] 返回移除的集合 长度 返回指定集合的差集，第一个集合有，其他集合没有的值：sdiff key值 [key值...] 返回指定集合的交集，第一个集合有，其他集合也有的值：sinter key值 [key值...] 返回指定集合的并集，所有集合中的元素并在一起：sunion key值 [key值...] Zset有序集合类型 通过每个元素的分数来确定元素 向有序集合中添加元素：zadd key值 score值 value值 返回追加后的有序集合 长度 查询有序集合指定空间内的元素：zrange key值 开始下标 结束下标 其值按照score分数升序排序，最小为下标0 按分数查询有序集合指定空间内的元素：zrangebyscore key值 min分数 max分数 移除一个或多个元素：zrem key值 member值 [member值...] 返回移除的有序集合 长度 获取有序集合中元素的个数：zcard key值 获取有序集合中成员的排名：zrank key值 member值 获取有序集合中元素的分数：zscore key值 member值 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis常用命令"},{"categories":null,"content":"\rRedis常用命令 切换数据库： select 数据库编号 查看当前数据库有哪些key： keys * 删除当前数据库中的数据： flushdb 删除所有库中的所有数据： flushall 查看库中有多少条数据： dbsize String字符串类型 最大值512MB 向MAP中存放键值对：set key值 value值 获取key值对应的value值：get key值 空为：nil 为原value值后追加字符：append key值 value值 返回追加后的字符串 类型 长度 返回对应的字符串字符个数：strlen key值 不存在返回 0 截取字符串：getrange key值 开始下标 结束下标 正负下标同pathon ==左右都同时包含== 临时向MAP中存放键值对：setex key值 秒数 value值 List列表类型 在列表左边压入键值对：lpush key值 值... 返回追加后的列表 长度 在指定下标区间中取值：lrange key值 开始下标 结束下标 ==左右同时包含== 在列表右边压入键值对：rpush key值 值... 返回追加后的列表 长度 移除左侧第一个元素：lpop key值 返回删除掉的value值 移除右侧第一个元素：rpop key值 返回删除掉的value值 取指定下标上的值：lindex key值 下标 返回列表中有多少个数据：llen key值 更换列表中指定下标位的值：lset key值 下标 value值 Hash哈希类型 在哈希列表key中添加 field域和value值 对：hset key值 field值 value值 [field value …] 返回当前哈希列表中域值对的数量 获取哈希列表中指定field域的value值：hget key值 field值 获取哈希列表中所有 域和值 ：getall key值 获取哈希列表中所有field域列表：hkeys key值 删除哈希列表中的一个 域值对 ：hdel key值 field值 获取哈希列表中所有value值列表：hvals key值 查看哈希列表中 是否存在对应的field域：hexists key值 field值 Set集合类型 向集合中添加元素：sadd key值 元素值 [元素值...] 返回追加后的集合 长度 显示集合中所有元素：smembers key值 判断集合中是否存在对应的member值：sismember key值 member值 获取集合中元素的个数：scard key值 移除一个或多个元素：srem key值 member值 [member值...] 返回移除的集合 长度 返回指定集合的差集，第一个集合有，其他集合没有的值：sdiff key值 [key值...] 返回指定集合的交集，第一个集合有，其他集合也有的值：sinter key值 [key值...] 返回指定集合的并集，所有集合中的元素并在一起：sunion key值 [key值...] Zset有序集合类型 通过每个元素的分数来确定元素 向有序集合中添加元素：zadd key值 score值 value值 返回追加后的有序集合 长度 查询有序集合指定空间内的元素：zrange key值 开始下标 结束下标 其值按照score分数升序排序，最小为下标0 按分数查询有序集合指定空间内的元素：zrangebyscore key值 min分数 max分数 移除一个或多个元素：zrem key值 member值 [member值...] 返回移除的有序集合 长度 获取有序集合中元素的个数：zcard key值 获取有序集合中成员的排名：zrank key值 member值 获取有序集合中元素的分数：zscore key值 member值 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#string字符串类型"},{"categories":null,"content":"\rRedis常用命令 切换数据库： select 数据库编号 查看当前数据库有哪些key： keys * 删除当前数据库中的数据： flushdb 删除所有库中的所有数据： flushall 查看库中有多少条数据： dbsize String字符串类型 最大值512MB 向MAP中存放键值对：set key值 value值 获取key值对应的value值：get key值 空为：nil 为原value值后追加字符：append key值 value值 返回追加后的字符串 类型 长度 返回对应的字符串字符个数：strlen key值 不存在返回 0 截取字符串：getrange key值 开始下标 结束下标 正负下标同pathon ==左右都同时包含== 临时向MAP中存放键值对：setex key值 秒数 value值 List列表类型 在列表左边压入键值对：lpush key值 值... 返回追加后的列表 长度 在指定下标区间中取值：lrange key值 开始下标 结束下标 ==左右同时包含== 在列表右边压入键值对：rpush key值 值... 返回追加后的列表 长度 移除左侧第一个元素：lpop key值 返回删除掉的value值 移除右侧第一个元素：rpop key值 返回删除掉的value值 取指定下标上的值：lindex key值 下标 返回列表中有多少个数据：llen key值 更换列表中指定下标位的值：lset key值 下标 value值 Hash哈希类型 在哈希列表key中添加 field域和value值 对：hset key值 field值 value值 [field value …] 返回当前哈希列表中域值对的数量 获取哈希列表中指定field域的value值：hget key值 field值 获取哈希列表中所有 域和值 ：getall key值 获取哈希列表中所有field域列表：hkeys key值 删除哈希列表中的一个 域值对 ：hdel key值 field值 获取哈希列表中所有value值列表：hvals key值 查看哈希列表中 是否存在对应的field域：hexists key值 field值 Set集合类型 向集合中添加元素：sadd key值 元素值 [元素值...] 返回追加后的集合 长度 显示集合中所有元素：smembers key值 判断集合中是否存在对应的member值：sismember key值 member值 获取集合中元素的个数：scard key值 移除一个或多个元素：srem key值 member值 [member值...] 返回移除的集合 长度 返回指定集合的差集，第一个集合有，其他集合没有的值：sdiff key值 [key值...] 返回指定集合的交集，第一个集合有，其他集合也有的值：sinter key值 [key值...] 返回指定集合的并集，所有集合中的元素并在一起：sunion key值 [key值...] Zset有序集合类型 通过每个元素的分数来确定元素 向有序集合中添加元素：zadd key值 score值 value值 返回追加后的有序集合 长度 查询有序集合指定空间内的元素：zrange key值 开始下标 结束下标 其值按照score分数升序排序，最小为下标0 按分数查询有序集合指定空间内的元素：zrangebyscore key值 min分数 max分数 移除一个或多个元素：zrem key值 member值 [member值...] 返回移除的有序集合 长度 获取有序集合中元素的个数：zcard key值 获取有序集合中成员的排名：zrank key值 member值 获取有序集合中元素的分数：zscore key值 member值 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#list列表类型"},{"categories":null,"content":"\rRedis常用命令 切换数据库： select 数据库编号 查看当前数据库有哪些key： keys * 删除当前数据库中的数据： flushdb 删除所有库中的所有数据： flushall 查看库中有多少条数据： dbsize String字符串类型 最大值512MB 向MAP中存放键值对：set key值 value值 获取key值对应的value值：get key值 空为：nil 为原value值后追加字符：append key值 value值 返回追加后的字符串 类型 长度 返回对应的字符串字符个数：strlen key值 不存在返回 0 截取字符串：getrange key值 开始下标 结束下标 正负下标同pathon ==左右都同时包含== 临时向MAP中存放键值对：setex key值 秒数 value值 List列表类型 在列表左边压入键值对：lpush key值 值... 返回追加后的列表 长度 在指定下标区间中取值：lrange key值 开始下标 结束下标 ==左右同时包含== 在列表右边压入键值对：rpush key值 值... 返回追加后的列表 长度 移除左侧第一个元素：lpop key值 返回删除掉的value值 移除右侧第一个元素：rpop key值 返回删除掉的value值 取指定下标上的值：lindex key值 下标 返回列表中有多少个数据：llen key值 更换列表中指定下标位的值：lset key值 下标 value值 Hash哈希类型 在哈希列表key中添加 field域和value值 对：hset key值 field值 value值 [field value …] 返回当前哈希列表中域值对的数量 获取哈希列表中指定field域的value值：hget key值 field值 获取哈希列表中所有 域和值 ：getall key值 获取哈希列表中所有field域列表：hkeys key值 删除哈希列表中的一个 域值对 ：hdel key值 field值 获取哈希列表中所有value值列表：hvals key值 查看哈希列表中 是否存在对应的field域：hexists key值 field值 Set集合类型 向集合中添加元素：sadd key值 元素值 [元素值...] 返回追加后的集合 长度 显示集合中所有元素：smembers key值 判断集合中是否存在对应的member值：sismember key值 member值 获取集合中元素的个数：scard key值 移除一个或多个元素：srem key值 member值 [member值...] 返回移除的集合 长度 返回指定集合的差集，第一个集合有，其他集合没有的值：sdiff key值 [key值...] 返回指定集合的交集，第一个集合有，其他集合也有的值：sinter key值 [key值...] 返回指定集合的并集，所有集合中的元素并在一起：sunion key值 [key值...] Zset有序集合类型 通过每个元素的分数来确定元素 向有序集合中添加元素：zadd key值 score值 value值 返回追加后的有序集合 长度 查询有序集合指定空间内的元素：zrange key值 开始下标 结束下标 其值按照score分数升序排序，最小为下标0 按分数查询有序集合指定空间内的元素：zrangebyscore key值 min分数 max分数 移除一个或多个元素：zrem key值 member值 [member值...] 返回移除的有序集合 长度 获取有序集合中元素的个数：zcard key值 获取有序集合中成员的排名：zrank key值 member值 获取有序集合中元素的分数：zscore key值 member值 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#hash哈希类型"},{"categories":null,"content":"\rRedis常用命令 切换数据库： select 数据库编号 查看当前数据库有哪些key： keys * 删除当前数据库中的数据： flushdb 删除所有库中的所有数据： flushall 查看库中有多少条数据： dbsize String字符串类型 最大值512MB 向MAP中存放键值对：set key值 value值 获取key值对应的value值：get key值 空为：nil 为原value值后追加字符：append key值 value值 返回追加后的字符串 类型 长度 返回对应的字符串字符个数：strlen key值 不存在返回 0 截取字符串：getrange key值 开始下标 结束下标 正负下标同pathon ==左右都同时包含== 临时向MAP中存放键值对：setex key值 秒数 value值 List列表类型 在列表左边压入键值对：lpush key值 值... 返回追加后的列表 长度 在指定下标区间中取值：lrange key值 开始下标 结束下标 ==左右同时包含== 在列表右边压入键值对：rpush key值 值... 返回追加后的列表 长度 移除左侧第一个元素：lpop key值 返回删除掉的value值 移除右侧第一个元素：rpop key值 返回删除掉的value值 取指定下标上的值：lindex key值 下标 返回列表中有多少个数据：llen key值 更换列表中指定下标位的值：lset key值 下标 value值 Hash哈希类型 在哈希列表key中添加 field域和value值 对：hset key值 field值 value值 [field value …] 返回当前哈希列表中域值对的数量 获取哈希列表中指定field域的value值：hget key值 field值 获取哈希列表中所有 域和值 ：getall key值 获取哈希列表中所有field域列表：hkeys key值 删除哈希列表中的一个 域值对 ：hdel key值 field值 获取哈希列表中所有value值列表：hvals key值 查看哈希列表中 是否存在对应的field域：hexists key值 field值 Set集合类型 向集合中添加元素：sadd key值 元素值 [元素值...] 返回追加后的集合 长度 显示集合中所有元素：smembers key值 判断集合中是否存在对应的member值：sismember key值 member值 获取集合中元素的个数：scard key值 移除一个或多个元素：srem key值 member值 [member值...] 返回移除的集合 长度 返回指定集合的差集，第一个集合有，其他集合没有的值：sdiff key值 [key值...] 返回指定集合的交集，第一个集合有，其他集合也有的值：sinter key值 [key值...] 返回指定集合的并集，所有集合中的元素并在一起：sunion key值 [key值...] Zset有序集合类型 通过每个元素的分数来确定元素 向有序集合中添加元素：zadd key值 score值 value值 返回追加后的有序集合 长度 查询有序集合指定空间内的元素：zrange key值 开始下标 结束下标 其值按照score分数升序排序，最小为下标0 按分数查询有序集合指定空间内的元素：zrangebyscore key值 min分数 max分数 移除一个或多个元素：zrem key值 member值 [member值...] 返回移除的有序集合 长度 获取有序集合中元素的个数：zcard key值 获取有序集合中成员的排名：zrank key值 member值 获取有序集合中元素的分数：zscore key值 member值 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#set集合类型"},{"categories":null,"content":"\rRedis常用命令 切换数据库： select 数据库编号 查看当前数据库有哪些key： keys * 删除当前数据库中的数据： flushdb 删除所有库中的所有数据： flushall 查看库中有多少条数据： dbsize String字符串类型 最大值512MB 向MAP中存放键值对：set key值 value值 获取key值对应的value值：get key值 空为：nil 为原value值后追加字符：append key值 value值 返回追加后的字符串 类型 长度 返回对应的字符串字符个数：strlen key值 不存在返回 0 截取字符串：getrange key值 开始下标 结束下标 正负下标同pathon ==左右都同时包含== 临时向MAP中存放键值对：setex key值 秒数 value值 List列表类型 在列表左边压入键值对：lpush key值 值... 返回追加后的列表 长度 在指定下标区间中取值：lrange key值 开始下标 结束下标 ==左右同时包含== 在列表右边压入键值对：rpush key值 值... 返回追加后的列表 长度 移除左侧第一个元素：lpop key值 返回删除掉的value值 移除右侧第一个元素：rpop key值 返回删除掉的value值 取指定下标上的值：lindex key值 下标 返回列表中有多少个数据：llen key值 更换列表中指定下标位的值：lset key值 下标 value值 Hash哈希类型 在哈希列表key中添加 field域和value值 对：hset key值 field值 value值 [field value …] 返回当前哈希列表中域值对的数量 获取哈希列表中指定field域的value值：hget key值 field值 获取哈希列表中所有 域和值 ：getall key值 获取哈希列表中所有field域列表：hkeys key值 删除哈希列表中的一个 域值对 ：hdel key值 field值 获取哈希列表中所有value值列表：hvals key值 查看哈希列表中 是否存在对应的field域：hexists key值 field值 Set集合类型 向集合中添加元素：sadd key值 元素值 [元素值...] 返回追加后的集合 长度 显示集合中所有元素：smembers key值 判断集合中是否存在对应的member值：sismember key值 member值 获取集合中元素的个数：scard key值 移除一个或多个元素：srem key值 member值 [member值...] 返回移除的集合 长度 返回指定集合的差集，第一个集合有，其他集合没有的值：sdiff key值 [key值...] 返回指定集合的交集，第一个集合有，其他集合也有的值：sinter key值 [key值...] 返回指定集合的并集，所有集合中的元素并在一起：sunion key值 [key值...] Zset有序集合类型 通过每个元素的分数来确定元素 向有序集合中添加元素：zadd key值 score值 value值 返回追加后的有序集合 长度 查询有序集合指定空间内的元素：zrange key值 开始下标 结束下标 其值按照score分数升序排序，最小为下标0 按分数查询有序集合指定空间内的元素：zrangebyscore key值 min分数 max分数 移除一个或多个元素：zrem key值 member值 [member值...] 返回移除的有序集合 长度 获取有序集合中元素的个数：zcard key值 获取有序集合中成员的排名：zrank key值 member值 获取有序集合中元素的分数：zscore key值 member值 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#zset有序集合类型"},{"categories":null,"content":"\rRedis持久化将Redis数据库中的数据以二进制形式存储在硬盘中 一、RDB持久化 根据数据更新频率决定是否持久化 Redis服务器默认开启RDB持久化方式 持久化文件存储在数据库 安装目录 / dump.rdb 配置规则 可以在安装目录/redis.conf文件中修改 save值是否开启RDB持久化 单位之间内达到被修改次数就会被持久化 save 900 1 #900秒内被修改1次就会被持久化 save 300 10 #300秒内被修改10次就会被持久化 save 60 10000 #60秒内被修改10000次就会被持久化 可以在安装目录/redis.conf文件中修改 dbfilename值修改持久化文件存放位置 可以在安装目录/redis.conf文件中修改 rdbcompression值修改持久化文件是否需要压缩 【yes】开启压缩，默认开启 可以在安装目录/redis.conf文件中修改 stop-writes-on-bgsave-error值修改持久化时发生错误是否阻止其他命令执行 【yes】之后的所有数据都不再持久化 【no】之后数据更改不受影响 手动将数据持久化 使用bgsave命令：直接将当前数据库中所有数据存储在dump.rdb中 RDB的缺点：无法保证dump.rdb中存储的数据与数据库中的数据保持一致 二、ROF持久化 根据指定的时间间隔持久化数据库数据 Append Only File（AOF） 持久化文件存储在数据库 安装目录 / appendonly.aof 配置规则 可以在安 装目录/redis.conf文件中修改 appendonly值是否开启AOF持久化 可以在安装目录/redis.conf文件中修改 appendfilename值修改持久化文件存放位置 可以在安装目录/redis.conf文件中修改 appendfsync值修改持久化方式 【always】每次数据修改都进行持久化，会增大服务器压力 【everysec】每隔一秒对数据进行持久化一次 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis持久化"},{"categories":null,"content":"\rRedis持久化将Redis数据库中的数据以二进制形式存储在硬盘中 一、RDB持久化 根据数据更新频率决定是否持久化 Redis服务器默认开启RDB持久化方式 持久化文件存储在数据库 安装目录 / dump.rdb 配置规则 可以在安装目录/redis.conf文件中修改 save值是否开启RDB持久化 单位之间内达到被修改次数就会被持久化 save 900 1 #900秒内被修改1次就会被持久化 save 300 10 #300秒内被修改10次就会被持久化 save 60 10000 #60秒内被修改10000次就会被持久化 可以在安装目录/redis.conf文件中修改 dbfilename值修改持久化文件存放位置 可以在安装目录/redis.conf文件中修改 rdbcompression值修改持久化文件是否需要压缩 【yes】开启压缩，默认开启 可以在安装目录/redis.conf文件中修改 stop-writes-on-bgsave-error值修改持久化时发生错误是否阻止其他命令执行 【yes】之后的所有数据都不再持久化 【no】之后数据更改不受影响 手动将数据持久化 使用bgsave命令：直接将当前数据库中所有数据存储在dump.rdb中 RDB的缺点：无法保证dump.rdb中存储的数据与数据库中的数据保持一致 二、ROF持久化 根据指定的时间间隔持久化数据库数据 Append Only File（AOF） 持久化文件存储在数据库 安装目录 / appendonly.aof 配置规则 可以在安 装目录/redis.conf文件中修改 appendonly值是否开启AOF持久化 可以在安装目录/redis.conf文件中修改 appendfilename值修改持久化文件存放位置 可以在安装目录/redis.conf文件中修改 appendfsync值修改持久化方式 【always】每次数据修改都进行持久化，会增大服务器压力 【everysec】每隔一秒对数据进行持久化一次 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#一rdb持久化"},{"categories":null,"content":"\rRedis持久化将Redis数据库中的数据以二进制形式存储在硬盘中 一、RDB持久化 根据数据更新频率决定是否持久化 Redis服务器默认开启RDB持久化方式 持久化文件存储在数据库 安装目录 / dump.rdb 配置规则 可以在安装目录/redis.conf文件中修改 save值是否开启RDB持久化 单位之间内达到被修改次数就会被持久化 save 900 1 #900秒内被修改1次就会被持久化 save 300 10 #300秒内被修改10次就会被持久化 save 60 10000 #60秒内被修改10000次就会被持久化 可以在安装目录/redis.conf文件中修改 dbfilename值修改持久化文件存放位置 可以在安装目录/redis.conf文件中修改 rdbcompression值修改持久化文件是否需要压缩 【yes】开启压缩，默认开启 可以在安装目录/redis.conf文件中修改 stop-writes-on-bgsave-error值修改持久化时发生错误是否阻止其他命令执行 【yes】之后的所有数据都不再持久化 【no】之后数据更改不受影响 手动将数据持久化 使用bgsave命令：直接将当前数据库中所有数据存储在dump.rdb中 RDB的缺点：无法保证dump.rdb中存储的数据与数据库中的数据保持一致 二、ROF持久化 根据指定的时间间隔持久化数据库数据 Append Only File（AOF） 持久化文件存储在数据库 安装目录 / appendonly.aof 配置规则 可以在安 装目录/redis.conf文件中修改 appendonly值是否开启AOF持久化 可以在安装目录/redis.conf文件中修改 appendfilename值修改持久化文件存放位置 可以在安装目录/redis.conf文件中修改 appendfsync值修改持久化方式 【always】每次数据修改都进行持久化，会增大服务器压力 【everysec】每隔一秒对数据进行持久化一次 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#二rof持久化"},{"categories":null,"content":"\rRedis事务管理 在MySQL中事务是通过临时备份表来实现的，开启事务时生成备份表，如果rollback就用备份表覆盖原表 在Redis中事务是通过将命令存入一个栈来实现的，如果exec提交就执行栈中所有命令 触发事务的错误： 语法错误:Redis事务管理对象销毁栈，所有的命令都无效 set key1 100 sets key2 200 # 语法错误，就是命令书写错误 执行错误: 不会影响事务中其他命令的执行 set key1 100 set key2 200 # key2关联的数据是string lpush key2 300 # 语法没有错误/命令没有拼写错误，但是将key2的类型错误理解为列表 这个错误只有在Redis执行这个命令时才会爆发，所以并不会影响其他命令 事务相关命令： multi 要求Redis服务器提供一个事务管理对象, 相当于 start transaction exec 要求事务管理对象执行栈中所有的命令, 相当于commit discard 要求事务管理对象销毁栈, 相当于rollback watch 通过watch监控某一个数据，如果在事务执行过程中这个被监控的数据被修改了则取消本次事务中所有的操作 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis事务管理"},{"categories":null,"content":"\rRedis消息订阅“ 消息订阅 “ ：一种数据共享的服务，便于redis客户端之间数据共享。 通 道：redis信息订阅提供的存放共享数据的平台 发布者：写入共享数据的redis客户端 订阅者：读取共享数据的redis客户端 消息订阅相关命令： 1. `subscribe 通道名1 [通道名2]`：订阅（自动接收）通道信息\r2. `publish 通道名 信息`：向通道发布信息\r","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:8:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis消息订阅"},{"categories":null,"content":"\rRedis的主从复制和哨兵模式略 ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:9:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#redis的主从复制和哨兵模式"},{"categories":null,"content":"\r使用Jedis操作RedisJedis：Redis作者使用 Java 写的工具类，用于连接Redis数据库 需要关闭linux防火墙，让非本地客户端可以连接到redis。否则可能会抛出连接超时异常 导入依赖 \u003c!-- jedis依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eredis.clients\u003c/groupId\u003e \u003cartifactId\u003ejedis\u003c/artifactId\u003e \u003cversion\u003e3.7.0\u003c/version\u003e \u003c/dependency\u003e 在redis.conf中 关闭Redis的保护模式 在redis.conf中 取消服务器与客户端IP的绑定 在redis.conf中 设置访问Redis服务器的密码 按照redis.conf 的配置文件启动Redis数据库 测试ping数据库 @Test public void testJedis() { //1. 创建Jedis对象, 打开连接通道 Jedis jedis = new Jedis(\"192.168.50.128\", 6379); //2. 提供登录密码，验证 jedis.auth(\"123\"); //3. 发送ping命令, 测试通道否建立成功 String result = jedis.ping(); System.out.println(\"result = \" + result); } 操作String字符串 @Test public void testJedisString() { //1. 创建Jedis对象, 打开连接通道 Jedis jedis = new Jedis(\"192.168.50.128\", 6379); //2. 提供登录密码，验证 jedis.auth(\"123\"); //操作String字符串 jedis.select(0); jedis.set(\"key1\", \"Hello\"); jedis.set(\"key2\", \"World\"); String key1 = jedis.get(\"key1\"); System.out.println(key1); String key2 = jedis.get(\"key2\"); System.out.println(key2); jedis.flushDB(); Long aLong = jedis.dbSize(); System.out.println(aLong); } 操作list列表 @Test public void testJedisList() { //1. 创建Jedis对象, 打开连接通道 Jedis jedis = new Jedis(\"192.168.50.128\", 6379); //2. 提供登录密码，验证 jedis.auth(\"123\"); //操作list列表 jedis.lpush(\"key1\", \"Hello\", \"World\"); List\u003cString\u003e key1 = jedis.lrange(\"key1\", 0, 2); System.out.println(key1); jedis.flushDB(); } 操作Set集合 @Test public void testJedisSet() { //1. 创建Jedis对象, 打开连接通道 Jedis jedis = new Jedis(\"192.168.50.128\", 6379); //2. 提供登录密码，验证 jedis.auth(\"123\"); //操作Set集合 Long num = jedis.sadd(\"key1\", \"10\", \"20\", \"10\"); System.out.println(\"当前key1中数据数量\" + num); Boolean is10 = jedis.sismember(\"key1\", \"10\"); System.out.println(\"key1中是否有10\" + is10); Set\u003cString\u003e key1 = jedis.smembers(\"key1\"); System.out.println(key1); jedis.flushDB(); } 操作hash哈希 @Test public void testJedisHash() { //1. 创建Jedis对象, 打开连接通道 Jedis jedis = new Jedis(\"192.168.50.128\", 6379); //2. 提供登录密码，验证 jedis.auth(\"123\"); //操作hash哈希 jedis.hset(\"key1\", \"deptNo\", \"10\"); jedis.hset(\"key1\", \"dName\", \"sales\"); jedis.hset(\"key1\", \"loc\", \"beijing\"); String hget = jedis.hget(\"key1\", \"deptNo\"); System.out.println(hget); hget = jedis.hget(\"key1\", \"dName\"); System.out.println(hget); hget = jedis.hget(\"key1\", \"loc\"); System.out.println(hget); jedis.flushDB(); } 操作ZSet有序集合 @Test public void testJedisZSet() { //1. 创建Jedis对象, 打开连接通道 Jedis jedis = new Jedis(\"192.168.50.128\", 6379); //2. 提供登录密码，验证 jedis.auth(\"123\"); //操作ZSet有序集合 jedis.zadd(\"key1\", 80, \"mike\"); jedis.zadd(\"key1\", 60, \"smith\"); jedis.zadd(\"key1\", 40, \"tom\"); Set\u003cString\u003e key1 = jedis.zrange(\"key1\", 0, -1); System.out.println(key1); jedis.flushDB(); } ","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:10:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#使用jedis操作redis"},{"categories":null,"content":"\r在 SpringMVC 中使用 Redis 在 pom.xml 中添加依赖 \u003c!-- spring-data-redis --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.data\u003c/groupId\u003e \u003cartifactId\u003espring-data-redis\u003c/artifactId\u003e \u003cversion\u003e2.6.4\u003c/version\u003e \u003c/dependency\u003e \u003c!-- jedis --\u003e \u003cdependency\u003e \u003cgroupId\u003eredis.clients\u003c/groupId\u003e \u003cartifactId\u003ejedis\u003c/artifactId\u003e \u003cversion\u003e4.2.2\u003c/version\u003e \u003c/dependency\u003e 在 resources 路径下创建 redis.properties 文件 redis.host=Redis的host redis.port=Redis的端口号 redis.password=\"Redis的密码\" redis.maxIdle=400 redis.maxTotal=6000 redis.maxWaitMillis=1000 redis.blockWhenExhausted=true redis.testOnBorrow=true redis.db=1 创建 RedisService 类 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.*; import java.io.Serializable; import java.util.List; import java.util.Set; import java.util.concurrent.TimeUnit; public class RedisService { @Autowired private RedisTemplate redisTemplate; public void setRedisTemplate(RedisTemplate redisTemplate) { this.redisTemplate = redisTemplate; } /** * 写入缓存 * @param key * @param value * @return */ public boolean set(final String key, Object value) { boolean result = false; try { ValueOperations\u003cSerializable, Object\u003e operations = redisTemplate.opsForValue(); operations.set(key, value); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 写入缓存设置时效时间 * @param key * @param value * @return */ public boolean set(final String key, Object value, Long expireTime) { boolean result = false; try { ValueOperations\u003cSerializable, Object\u003e operations = redisTemplate.opsForValue(); operations.set(key, value); redisTemplate.expire(key, expireTime, TimeUnit.SECONDS); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 批量删除对应的value * @param keys */ public void remove(final String... keys) { for (String key : keys) { remove(key); } } /** * 批量删除key * @param pattern */ public void removePattern(final String pattern) { Set\u003cSerializable\u003e keys = redisTemplate.keys(pattern); if (keys.size() \u003e 0) redisTemplate.delete(keys); } /** * 删除对应的value * @param key */ public void remove(final String key) { if (exists(key)) { redisTemplate.delete(key); } } /** * 判断缓存中是否有对应的value * @param key * @return */ public boolean exists(final String key) { return redisTemplate.hasKey(key); } /** * 读取缓存 * @param key * @return */ public Object get(final String key) { Object result = null; ValueOperations\u003cSerializable, Object\u003e operations = redisTemplate.opsForValue(); result = operations.get(key); return result; } /** * 哈希 添加 * @param key * @param hashKey * @param value */ public void hmSet(String key, Object hashKey, Object value){ HashOperations\u003cString, Object, Object\u003e hash = redisTemplate.opsForHash(); hash.put(key,hashKey,value); } /** * 哈希 删除 * @param key * @param hashKey */ public void hmDel(String key, Object hashKey){ HashOperations\u003cString, Object, Object\u003e hash = redisTemplate.opsForHash(); hash.delete(key,hashKey); } /** * 哈希获取数据 * @param key * @param hashKey * @return */ public Object hmGet(String key, Object hashKey){ HashOperations\u003cString, Object, Object\u003e hash = redisTemplate.opsForHash(); return hash.get(key,hashKey); } /** * 列表添加 * @param k * @param v */ public void lPush(String k,Object v){ ListOperations\u003cString, Object\u003e list = redisTemplate.opsForList(); list.rightPush(k,v); } /** * 列表获取 * @param k * @param l * @param l1 * @return */ public List\u003cObject\u003e lRange(String k, long l, long l1){ ListOperations\u003cString, Object\u003e list = redisTemplate.opsForList(); return list.range(k,l,l1); } /** * 集合添加 * @param key * @param value */ public void add(String key,Object value){ SetOperations\u003cString, Object\u003e set = redisTemplate.opsForSet(); set.add(key,value); } /** * 集合获取 * @param key * @return */ public Set\u003cObject\u003e setMembers(String key){ SetOperations\u003cString, Object\u003e set = redisTemplate.opsForSet(); return set.members(key); } /** * 有序集合添加 * @param key * @param value * @param scoure */ public void zAdd(String key,Object value,double scoure){ ZSetOperations\u003cString, Object\u003e zset = redisTemplat","date":"2021-10-11","objectID":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:11:0","series":null,"tags":null,"title":"Redis自学笔记","uri":"/redis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#在-springmvc-中使用-redis"},{"categories":null,"content":"\rLinux自学笔记 大连交通大学 信息学院 刘嘉宁 2021-10-10 笔记摘自：bjpowernode 杨震 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#linux自学笔记"},{"categories":null,"content":"\rLinux文件目录 ==root== : 系统管理员 root用户（拥有超级权限）的目录。 ==bin 或 usr/bin== : 存放系统预装的可执行程序，相当于windows中的环境变量。 usr : 系统资源目录，一些系统可执行文件或者系统的一些文件库。 usr/local/bin : 用户自己的可执行文件，相当于windows中的用户环境变量。 lib 或 usr/lib : 存放着系统最基本的动态连接共享库，相当于windows里的DLL文件，几乎所有的应用程序都需要用到这些共享库。 boot : 存放启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 dev : (Device)存放Linux的外部设备，Linux中的设备也是以文件的形式存在。 ==etc== : 存放所有的系统管理所需要的配置文件。 ==home== : 普通用户的主目录，每个用户都有一个以用户的账号命名的根目录，用户登录后默认打开自己的根目录。 var : 存放着在不断扩充着的东西，我们习惯将那些经常被修改的文件存放在该目录下，比如运行的各种日志文件。 mnt : 让用户临时挂载别的文件系统，可以将光驱挂载在/mnt/上，进入该目录就可以查看光驱里的内容。 opt : 额外安装软件所存放的目录。相当于windows中Programe files目录。 tmp : 存放一些临时文件。 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#linux文件目录"},{"categories":null,"content":"\r远程操作Linux XShell工具：用于推送Linux命令 XFTP工具：用于文件数据传输 使用XShell链接Linux系统 使用ifconfig获取Linux的IP地址 在XShell中建立连接：填写名称、主机 填写用户名：Linux的用户名root 填写密码：Linux中root账户的密码129807 XFTP同理 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#远程操作linux"},{"categories":null,"content":"\rLinux常用命令","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#linux常用命令"},{"categories":null,"content":"\r一、文件相关操作 pwd：查看当前所在的文件夹目录 ls：列出当前目录下的所有文件和目录 ls -a：同时列出隐藏与非隐藏的文件和目录 ls -l：以列表的方式列出当前目录下的所有文件和目录 cd：切换到指定目录 cd 文件夹的uri路径 cd.. ：返回上一级目录 mkdir：创建单个目录 mkdir 路径 mkdir -p：创建多级目录 mkdir -p 路径 touch：创建 一个/多个 文件 touch 文件名.后缀 touch 路径/文件名.后缀 cp：复制文件 cp 来源文件 目标目录 cp -r：递归复制目录及目录中所有内容 rm：删除文件或目录 rm 目录路径/文件 rm -r：递归删除目录及目录中的所有内容 rm -r 目录路径 rm -f：强制删除不提示 rm -rf 目录路径 mv：移动文件或目录 mv 来源文件/目录 目标目录 mv 来源文件 同级目标文件：重命名文件 mv 来源文件/目录 . ：移动到上一级目录中 cat：查看文件内容 cat 文件 cat -n：带行号 查看文件内容 more：使用VI编辑器显示文本内容 more 文件 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:1","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#一文件相关操作"},{"categories":null,"content":"\r二、VI及VIM文本编辑器 vi 文件：使用VI文本编辑器打开文件 一般模式：只能看 按 i 或 a(光标在下一个字符处) 进入编辑模式 按 / 或 : 进入命令行模式 编辑模式：能修改 按 esc 退回一般模式 命令行模式： :wq：保存并退出 :q!：不保存并退出 :q：未改动时退出 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:2","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#二vi及vim文本编辑器"},{"categories":null,"content":"\r三、用户管理 id：查看用户信息 id 用户名 useradd：添加用户 useradd 用户名 useradd -d /home/用户的文件夹名 用户名 passwd用户名 ：为用户设置密码 userdel：删除用户 userdel 用户名：删除用户但不删除用户在 /home中的文件夹 userdel -r 用户名：删除用户及其文件夹 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:3","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#三用户管理"},{"categories":null,"content":"\r四、进程管理\r什么是Linux的进程： Linux进程的概念和windows一样 Linux中每个进程都有一个ID编号 Linux中每个进程都会对应一个父进程（调用这个进程的进程） 进程的分类： 前台进程，在前台可见 后台进程，前台不可见 进程相关常用命令： ps显示当前进程的状态 ps –a：显示当前终端下的所有进程信息 ps –u：以用户的格式显示进程信息 ps –x：显示后台进程运行的参数 ps –e：显示所有进程信息 ps –f：以全格式显示进程信息 USER：用户名称 PID：进程号 %CPU：进程占用CPU的百分比 %MEM：进程占用物理内存的百分比 VSZ：进程占用的虚拟内存大小（单位：KB） RSS：进程占用的物理内存大小（单位：KB） TT：终端名称,缩写. STAT：进程状态，其中S-睡眠，s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 STARTED：进程的启动时间 TIME：CPU时间，即进程使用CPU的总时间 COMMAND：启动进程所用的命令和参数，如果过长会被截断显示 PPID 父进程的ID C CPU使用的资源百分比 PRI指进程的执行优先权(Priority的简写)，其值越小越早被执行 SZ 使用掉的内存大小 kill终止进程 kill 进程ID：终止进程 kill -9 进程ID：强迫进程立即停止 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:4","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#四进程管理"},{"categories":null,"content":"\r四、进程管理\r什么是Linux的进程： Linux进程的概念和windows一样 Linux中每个进程都有一个ID编号 Linux中每个进程都会对应一个父进程（调用这个进程的进程） 进程的分类： 前台进程，在前台可见 后台进程，前台不可见 进程相关常用命令： ps显示当前进程的状态 ps –a：显示当前终端下的所有进程信息 ps –u：以用户的格式显示进程信息 ps –x：显示后台进程运行的参数 ps –e：显示所有进程信息 ps –f：以全格式显示进程信息 USER：用户名称 PID：进程号 %CPU：进程占用CPU的百分比 %MEM：进程占用物理内存的百分比 VSZ：进程占用的虚拟内存大小（单位：KB） RSS：进程占用的物理内存大小（单位：KB） TT：终端名称,缩写. STAT：进程状态，其中S-睡眠，s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 STARTED：进程的启动时间 TIME：CPU时间，即进程使用CPU的总时间 COMMAND：启动进程所用的命令和参数，如果过长会被截断显示 PPID 父进程的ID C CPU使用的资源百分比 PRI指进程的执行优先权(Priority的简写)，其值越小越早被执行 SZ 使用掉的内存大小 kill终止进程 kill 进程ID：终止进程 kill -9 进程ID：强迫进程立即停止 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:4","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是linux的进程"},{"categories":null,"content":"\r四、进程管理\r什么是Linux的进程： Linux进程的概念和windows一样 Linux中每个进程都有一个ID编号 Linux中每个进程都会对应一个父进程（调用这个进程的进程） 进程的分类： 前台进程，在前台可见 后台进程，前台不可见 进程相关常用命令： ps显示当前进程的状态 ps –a：显示当前终端下的所有进程信息 ps –u：以用户的格式显示进程信息 ps –x：显示后台进程运行的参数 ps –e：显示所有进程信息 ps –f：以全格式显示进程信息 USER：用户名称 PID：进程号 %CPU：进程占用CPU的百分比 %MEM：进程占用物理内存的百分比 VSZ：进程占用的虚拟内存大小（单位：KB） RSS：进程占用的物理内存大小（单位：KB） TT：终端名称,缩写. STAT：进程状态，其中S-睡眠，s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 STARTED：进程的启动时间 TIME：CPU时间，即进程使用CPU的总时间 COMMAND：启动进程所用的命令和参数，如果过长会被截断显示 PPID 父进程的ID C CPU使用的资源百分比 PRI指进程的执行优先权(Priority的简写)，其值越小越早被执行 SZ 使用掉的内存大小 kill终止进程 kill 进程ID：终止进程 kill -9 进程ID：强迫进程立即停止 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:4","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#进程的分类"},{"categories":null,"content":"\r四、进程管理\r什么是Linux的进程： Linux进程的概念和windows一样 Linux中每个进程都有一个ID编号 Linux中每个进程都会对应一个父进程（调用这个进程的进程） 进程的分类： 前台进程，在前台可见 后台进程，前台不可见 进程相关常用命令： ps显示当前进程的状态 ps –a：显示当前终端下的所有进程信息 ps –u：以用户的格式显示进程信息 ps –x：显示后台进程运行的参数 ps –e：显示所有进程信息 ps –f：以全格式显示进程信息 USER：用户名称 PID：进程号 %CPU：进程占用CPU的百分比 %MEM：进程占用物理内存的百分比 VSZ：进程占用的虚拟内存大小（单位：KB） RSS：进程占用的物理内存大小（单位：KB） TT：终端名称,缩写. STAT：进程状态，其中S-睡眠，s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 STARTED：进程的启动时间 TIME：CPU时间，即进程使用CPU的总时间 COMMAND：启动进程所用的命令和参数，如果过长会被截断显示 PPID 父进程的ID C CPU使用的资源百分比 PRI指进程的执行优先权(Priority的简写)，其值越小越早被执行 SZ 使用掉的内存大小 kill终止进程 kill 进程ID：终止进程 kill -9 进程ID：强迫进程立即停止 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:4","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#进程相关常用命令"},{"categories":null,"content":"\r压缩与解压缩 gzip：压缩文件 gzip 文件 压缩格式为.gz 会自动删除原文件 gunzip：解压缩.gz格式文件 gunzip 文件 解压为原本格式 会自动删除.gz文件 zip：压缩文件 zip 压缩后的目录和文件名 要压缩的目录 zip -r：递归压缩目录及目录下的所有文件 zip -r 压缩后的目录和文件名 要压缩的目录或文件 unzip：解压缩.zip格式文件 unzip 要解压的目录和文件名（小心覆盖原文件） unzip -d 解压后文件的存放位置：指定解压位置 tar：压缩/解压缩文件 -c：产生.tar.gz打包文件 -v：显示详细信息 -f：指定压缩后的文件名 -z：打包同时压缩 -x：解压.tar.gz文件 -C: 指定解压到哪个目录 tar -zcvf 压缩包文件名.tar.gz 目录名 tar -zxvf 压缩包文件名 -C 存放的目录 ","date":"2021-10-10","objectID":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:5","series":null,"tags":null,"title":"Linux自学笔记md版","uri":"/linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#压缩与解压缩"},{"categories":null,"content":"\rSpringMVC自学笔记 大连交通大学 信息学院 刘嘉宁 2021-9-23 笔记摘自：bjpowernode 杨震 ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springmvc自学笔记"},{"categories":null,"content":"\rSpringMVC 是Spring框架的衍生版 简化了Servlet的使用 ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springmvc"},{"categories":null,"content":"\r解决了Servlet规范的问题: 存在大量的Servlet接口实现类 需要手动写大量获取请求参数的代码 需要手动获取输出流：PrintWriter out = response.getWriter( ) … 需要手动重定向和请求转发 ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:1","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#解决了servlet规范的问题"},{"categories":null,"content":"\r使用SpringMVC框架 SpringMVC认为：一个网站中有一个 Servlet（ DispatcherServlet中央调度器 ） 就够了 由这个 Servlet 调用多个处理器类（Controller控制器） 再由 Controller 处理器类调用 Service（ 调用DAO … ） 添加 spring-webmvc 的依赖 \u003c!-- servlet依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003cversion\u003e4.0.1\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c!--spring-webmvc --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-webmvc\u003c/artifactId\u003e \u003cversion\u003e5.3.10\u003c/version\u003e \u003c/dependency\u003e 配置web.xml 让tomcat来创建DispatcherServlet的实例对象（Servlet规范：不能使用Spring创建Servlet对象） DispatcherServlet会自动==创建spring容器对象并保存在服务器全局作用域对象中== 使用init-param标签指定（ 创建spring容器对象需要用到的 ）spring.xml文件位置 通知tomcat在启动时创建spring容器的实例对象 \u003c!-- dispatcherServlet会自动创建spring容器对象， 并调用spring容器中web-inf下的xxx-servlet.xml（key-servlet.xml）文件， 并将spring容器对象保存到网站的全局作用域对象中 --\u003e \u003cservlet\u003e \u003cservlet-name\u003ekey\u003c/servlet-name\u003e \u003cservlet-class\u003eorg.springframework.web.servlet.DispatcherServlet\u003c/servlet-class\u003e \u003c!--配置spring.xml文件路径，让DispatcherServlet按照这个文件创建spring容器对象--\u003e \u003cinit-param\u003e \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e \u003cparam-value\u003eclasspath:spring.xml\u003c/param-value\u003e \u003c/init-param\u003e \u003c!--通知tomcat在启动时创建spring容器的实例对象：非0整数即可--\u003e \u003cload-on-startup\u003e1\u003c/load-on-startup\u003e \u003c/servlet\u003e \u003c!--SpringMVC推荐所有请求以 .do 结尾，让所有 .do 结尾的请求由DispatcherServlet处理--\u003e \u003cservlet-mapping\u003e \u003cservlet-name\u003ekey\u003c/servlet-name\u003e \u003curl-pattern\u003e*.do\u003c/url-pattern\u003e \u003c/servlet-mapping\u003e 编写Controller类 @Controller声明让spring容器创建这个Controller类 @component 、@Service 、@Controller 均是让spring容器创建其声明的实例对象 @RequestMapping(value = \"/one\")设置 类 / 方法 的请求地址 /** * @component * @Service * @Controller * * 均是让spring容器创建实例对象 * 按需使用 * * * @RequestMapping(Value=\"\") 设置处理器类的请求地址 * 也可以放在方法上，设置方法的请求地址 */ @Controller @RequestMapping(value = \"/one\") public class OneController { //这个类的调用地址 http://locoalhost:8080/myWeb/one/method2.do @RequestMapping(value = \"/method1.do\") public String method1(){ return \"/info.jsp\"; } } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用springmvc框架"},{"categories":null,"content":"\r遇到的问题 报错：java.lang.ClassNotFoundException: org.springframework.web.context.ContextLoaderListener 似乎的IDEA/Tomcat没有将需要的jar包放到位 解决方式： 在Artifacts中在使用的项目包上点击Put into Output Root，左侧lib文件夹出现内容则成功 ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#遇到的问题"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 \u003c!-- jackson-core --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.fasterxml.jackson.core\u003c/groupId\u003e \u003cartifactId\u003ejackson-core\u003c/artifactId\u003e \u003cversion\u003e2.13.0-rc2\u003c/version\u003e \u003c/dependency\u003e \u003c!-- jackson-databind --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.fasterxml.jackson.core\u003c/groupId\u003e \u003cartifactId\u003ejackson-databind\u003c/artifactId\u003e \u003cversion\u003e2.13.0-rc2\u003c/version\u003e \u003c/dependency\u003e 在spring.xml中注册MVC的注解驱动 \u003c!--注册MVC的注解驱动--\u003e \u003cmvc:annotation-driven /\u003e 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#处理器方法"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#按照处理器方法的返回值学习"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#一modelandview类型返回值保存到请求作用域"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#二string类型返回值资源文件请求转发"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#三void类型返回值手写输出流"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#四自定义类型对象使用ajax时自动解析成json返回"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#按照处理器方法的接收参数学习"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#一httpservletrequest类型参数request请求包"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#二httpservletresponse类型参数response响应包"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#三httpsession类型参数session作用域"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#四自定义参数类型基本类型引用类型"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#按照处理器方法间调用方式学习"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#一重定向"},{"categories":null,"content":"\r处理器方法\r按照处理器方法的返回值学习： ModelAndView String void 自定义类型对象 一、ModelAndView类型返回值：保存到请求作用域 ModelAndView是SpringMVC提供一个工具类 ModelAndView用于存储Controller类运行的结果 ModelAndView存储需要申请 调用的资源文件 的地址 使用方式： 存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 @RequestMapping(value = \"/method3.do\") public ModelAndView method3() throws Exception{ ModelAndView mv = new ModelAndView(); //存储在ModelAndView中的内容会自动被DispatcherServlet保存到请求作用域中 mv.addObject(\"tt\", \"这是我自己定的info信息\"); mv.setViewName(\"/jsp/test.jsp\"); return mv; } 二、String类型返回值：资源文件请求转发 其String类型返回值是一个资源文件请求地址 这个资源文件默认情况下将会交给DispatcherServlet通过请求转发来向Http服务器索要资源文件 这个资源文件可以是 jsp / html / 处理器其他方法 使用方式： 默认通过请求转发方式 @RequestMapping(value = \"/method1.do\") public String method1(){ //使用请求转发打开“ ”中的网页 return \"/info.jsp\"; } 调用处理器中其他方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"method2.do\"; } 调用其他处理器中方法 @RequestMapping(value = \"/method6.do\") public String method6(){ return \"/two/method1.do\"; } 三、void类型返回值：手写输出流 处理器方法在运行完毕后，是不需要将结果交给DispatcherServlet 处理器方法借助于响应对象，自行将结果写入到响应体 此时处理器方法在声明时，需要申请一个HttpServletResponse参数。这个参数由DispatcherServlet负责提供 使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试1111111111\"); } 四、自定义类型对象：使用Ajax时，自动解析成JSON返回 使用自定义类型对象：说明使用ajax技术发送请求 返回对象交给DispatcherServlet负责将返回的对象解析为JSON格式字符串写入到响应体 使用方式： 添加依赖 com.fasterxml.jackson.core jackson-core 2.13.0-rc2 com.fasterxml.jackson.core jackson-databind 2.13.0-rc2 在spring.xml中注册MVC的注解驱动 在处理器类方法上声明@ResponseBody注解，让此方法的返回值由DispatcherServlet扫描到并交给响应体中 @RequestMapping(value = \"/test1.do\") @ResponseBody public Dept test1(){ return new Dept(\"10\", \"王五\", \"东北\"); } 按照处理器方法的接收参数学习： HttpServletRequest HttpServletResponse HttpSession 自定义参数（基本类型/引用类型） ​ 1）基本类型: 必须与浏览器发送的请求参数名相同 ​ 2）引用类型: 必须与浏览器发送的请求参数名相同 一、HttpServletRequest类型参数：Request请求包使用方式： @RequestMapping(value = \"/method7.do\") public void method7(HttpServletRequest request){ String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); System.out.println(\"name = \"+name+\", age = \"+age); } 二、HttpServletResponse类型参数：Response响应包使用方式： @RequestMapping(value = \"/method2.do\") public void method2(HttpServletResponse response) throws Exception{ PrintWriter out = response.getWriter(); out.print(\"测试测试使用相应对象的输出流向浏览器输出内容\"); } 三、HttpSession类型参数：Session作用域使用方式： @RequestMapping(value = \"/method8.do\") public String method8(HttpSession session){ session.setAttribute(\"info\", \"测试使用SpringMVC的session作用域\"); return \"/info.jsp\"; } 四、自定义参数类型：基本类型、引用类型 基本类型: 变量名 必须与浏览器发送的请求参数名相同 引用类型: 属性名 必须与浏览器发送的请求参数名相同 使用方式： @RequestMapping(value = \"/method9.do\") public void method9(String deptNo, String dName, String loc){ System.out.println(\"deptNo = \" + deptNo); System.out.println(\"dName = \" + dName); System.out.println(\"loc = \" + loc); } @RequestMapping(value = \"/method10.do\") public void method10(Dept dept){ System.out.println(\"deptNo = \" + dept.getDeptNo()); System.out.println(\"dName = \" + dept.getDName()); System.out.println(\"loc = \" + dept.getLoc()); } 按照处理器方法间调用方式学习：\r一、重定向 原地址格式： 如果要求浏览器访问其他网站的地址，使用url 如果要求浏览器访问当前网站的地址，使用 uri (/myWeb/one/method1.do) 现地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method4.do\") public String method4() throws Exception{ return \"redirect:/one/method1.do\"; } 二、请求转发 地址格式： 简化版 uri 不写网站名 (/one/method1.do) @RequestMapping(value = \"/method5.do\") public String method5() throws Exception{ return \"forward:/one/method1.do\"; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#二请求转发"},{"categories":null,"content":"\r视图解析器 SpringMVC为避免资源路径的冗余，加入了视图解析器来自动补全拼接文件路径和文件扩展名 使用方式： 在spring.xml中加入 \u003c!--帮助处理文件的路径和扩展名，生成视图对象--\u003e \u003cbean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\u003e \u003cproperty name=\"prefix\" value=\"/jsp/\" /\u003e \u003cproperty name=\"suffix\" value=\".jsp\" /\u003e \u003c/bean\u003e 测试使用 @RequestMapping(value = \"/method12.do\") public ModelAndView method12(Dept dept){ ModelAndView mv = new ModelAndView(); mv.addObject(\"tt\", \"使用了视图解析器自动补全路径和后缀\"); //mv.setViewName(\"/jsp/test.jsp\"); mv.setViewName(\"test\"); return mv; } ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#视图解析器"},{"categories":null,"content":"\r拦截器过滤器：characterEncodingFilter…… servlet规范中的一部分，任何java web工程都可以使用 在url-pattern中配置了/*之后，可以对所有要访问的资源进行拦截 拦截器：是AOP思想的具体应用 拦截器是SpringMVC框架自己的，只有使用了SpringMVC框架的工程才能使用 拦截器只会拦截访问的控制器方法， 如果访问的是.jsp/.html/.css/.image/.js是不会进行拦截的 使用方式： 创建HandlerInterceptor的实现类config.MyInterceptor public class MyInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { HttpSession session = request.getSession(); //访问登陆页面，放行 if (request.getRequestURL().toString().contains(\"login\")){ System.out.println(request.getRequestURL().toString()+\"正在登录\"); return true; } //用户登录成功过，放行 if (session.getAttribute(\"userLoginInfo\") != null){ System.out.println(\"登陆过，存在session\"); return true; } //不通过，重定向到初始页面 response.sendRedirect(\"/myWeb/index.jsp\"); return false; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"处理后\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"清理\"); } } 在spring.xml中注册拦截器 \u003cmvc:interceptors\u003e \u003cmvc:interceptor\u003e \u003c!-- /** 为拦截所有路径及其子路径 --\u003e \u003cmvc:mapping path=\"/**\"/\u003e \u003cbean class=\"com.bjpn.config.MyInterceptor\"/\u003e \u003c/mvc:interceptor\u003e \u003c/mvc:interceptors\u003e ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#拦截器"},{"categories":null,"content":"\rSpringMVC执行原理 ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springmvc执行原理"},{"categories":null,"content":"\r✔✔ SSM项目用到的依赖汇总： \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003cversion\u003e4.0.1\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-context\u003c/artifactId\u003e \u003cversion\u003e5.3.9\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-jdbc\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis\u003c/artifactId\u003e \u003cversion\u003e3.5.1\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis-spring\u003c/artifactId\u003e \u003cversion\u003e1.3.1\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e8.0.26\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edruid\u003c/artifactId\u003e \u003cversion\u003e1.1.12\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-aspects\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-web\u003c/artifactId\u003e \u003cversion\u003e5.3.9\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-webmvc\u003c/artifactId\u003e \u003cversion\u003e5.3.10\u003c/version\u003e \u003cscope\u003ecompile\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.fasterxml.jackson.core\u003c/groupId\u003e \u003cartifactId\u003ejackson-core\u003c/artifactId\u003e \u003cversion\u003e2.13.0-rc2\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.fasterxml.jackson.core\u003c/groupId\u003e \u003cartifactId\u003ejackson-databind\u003c/artifactId\u003e \u003cversion\u003e2.13.0-rc2\u003c/version\u003e \u003c/dependency\u003e ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#-ssm项目用到的依赖汇总"},{"categories":null,"content":"\r遇到问题\r1. 中文参数乱码问题 原因：post请求默认使用ISO-8859-01东欧字符集 解决：添加SpringMVC提供的过滤器接口实现类 在web.xml中添加 \u003c!--添加过滤器--\u003e \u003cfilter\u003e \u003cfilter-name\u003echaracterEncodingFilter\u003c/filter-name\u003e \u003cfilter-class\u003eorg.springframework.web.filter.CharacterEncodingFilter\u003c/filter-class\u003e \u003c!--设置字符集--\u003e \u003cinit-param\u003e \u003cparam-name\u003eencoding\u003c/param-name\u003e \u003cparam-value\u003eutf-8\u003c/param-value\u003e \u003c/init-param\u003e \u003c/filter\u003e \u003cfilter-mapping\u003e \u003cfilter-name\u003echaracterEncodingFilter\u003c/filter-name\u003e \u003curl-pattern\u003e*.do\u003c/url-pattern\u003e \u003c/filter-mapping\u003e ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#遇到问题"},{"categories":null,"content":"\r遇到问题\r1. 中文参数乱码问题 原因：post请求默认使用ISO-8859-01东欧字符集 解决：添加SpringMVC提供的过滤器接口实现类 在web.xml中添加 characterEncodingFilter org.springframework.web.filter.CharacterEncodingFilter encoding utf-8 characterEncodingFilter *.do ","date":"2021-09-23","objectID":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"SpringMVC自学笔记md版","uri":"/springmvc%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#1-中文参数乱码问题"},{"categories":null,"content":"\rSpring框架自学笔记 大连交通大学 信息学院 刘嘉宁 2021-9-14 笔记摘自：bjpowernode 杨震 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#spring框架自学笔记"},{"categories":null,"content":"\r框架： 一组工具类 框架是针对某一个技术进行封装，目的降低被封装的技术的使用难度 框架这个工具类都是存储在jar包文件 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#框架"},{"categories":null,"content":"\rSpring框架(优点)： Spring：简化java开发，整合了现有的技术框架。是一个轻量级的控制反转和面向切面的框架。 开源的免费的容器（框架） 轻量级的，非入侵式的框架 控制反转（IOC），面向切面编程（AOP） 支持事务处理，对框架整合的支持 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#spring框架优点"},{"categories":null,"content":"\rSpring的七大模块：\r","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#spring的七大模块"},{"categories":null,"content":"\rSpring容器，使用： Spring容器对象（ApplicationContext）特点： 由Spring容器管理的类需要提供一个无参数的构造方法 一个bean标签描述的类在Spring容器对象只有一个对应实例对象 如果某个类在Spring容器对象需要存在多个实例对象，可以借助于多个bean标签 使用Spring容器对象 通过xml文件或注解 创建并保存 一个类 开发人员可以直接向容器 索要 对象 创建maven项目，添加spring-context的依赖 \u003c!-- 这里添加的是spring-webmvc的依赖 maven会自动导入spring用到的相关依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-webmvc\u003c/artifactId\u003e \u003cversion\u003e5.3.10\u003c/version\u003e \u003c/dependency\u003e 在resources路径下创建spring.xml文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!--通知spring容器，Student类需要由spring负责创建并在开发时对外提供--\u003e \u003cbean class=\"com.bjpn.Student\" id=\"student\"\u003e\u003c/bean\u003e \u003c/beans\u003e 在spring.xml文件内部声明bean标签 class：需要被spring容器创建的类的全限定名 id：bean标签的唯一标识 name：别名 Spring容器内部有一个Map\u003cid, class\u003e相等于：map.put(id, new Student) 测试使用Spring容器对象创建类 @Test public void appTest1() { /* context:Spring容器对象 ApplicationContext的重要实现类： 1. ClassPathXmlApplicationContext：相对路径获取配置文件 2. FileSystemXmlApplicationContext：绝对路径获取配置文件 */ ApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); //向容器索要对象 Studnet stu = (Studnet) context.getBean(\"student\"); //通过反射声明类型就可以不用强转 //Studnet stu = context.getBean(\"student\", Studnet.class); //调用类中的方法测试 stu.say(); } ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#spring容器使用"},{"categories":null,"content":"\r补: 使用JavaConfig实现配置 在Config类上声明@Configuration，它会被spring容器托管创建 在Config类上声明@ComponentScan（xxx.xxxx），可以将包下所有有@Component声明的类绑定为Config类 在其方法上声明@Bean，它的方法名就是id属性、返回值就是class属性 使用AnnotationConfigApplicationContext获取上下文容器对象 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#补-使用javaconfig实现配置"},{"categories":null,"content":"\rSpring框架提供的服务： IOC和DI服务：提供对象的创建 DI服务：提供对象的初始化 AOP服务：提供动态代理设计模式，简化其使用难度 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#spring框架提供的服务"},{"categories":null,"content":"\r1. IOC：控制反转服务 IOC是一种控制反转的思想 控制反转就是获得依赖对象的方式反转了：将所有会用到的对象统一保存在spring容器中，使用的时候调用需要的对象即可，避免有写死了依赖对象的代码，大大提高了解耦合性。 IOC的实现方式： 通过xml文件或注解 创建并保存 一个类 一、通过xml文件描述： 在spring.xml文件中添加bean标签： \u003c!--通知spring容器，Student类需要由spring负责创建并在开发时对外提供--\u003e \u003cbean class=\"com.bjpn.Student\" id=\"student\"\u003e\u003c/bean\u003e 在spring.xml文件内部声明bean标签 class：需要被spring容器创建的类信息 id：bean标签的唯一标识 Spring容器内部有一个Map\u003cid, class\u003e相等于：map.put(id, new Student) 测试使用Spring容器对象创建类 @Test public void appTest1() { /* context:Spring容器对象 ApplicationContext的重要实现类： 1. ClassPathXmlApplicationContext：相对路径获取配置文件 2. FileSystemXmlApplicationContext：绝对路径获取配置文件 */ ApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); //向容器索要对象 Studnet stu = (Studnet) context.getBean(\"student\"); //调用类中的方法测试 stu.say(); } 二、通过Annotation注解描述： @Component声明要被spring创建实例对象的类 ==必须存在无参构造方法== 默认id：小驼峰类名 手动设置id：@Component(value=\"id名\") 在类上方声明@Component注解 在spring配置文件中添加component-scan标签，并绑定到包 \u003ccontext:component-scan base-package=\"org.example\"\u003e\u003c/context:component-scan\u003e ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:1","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#1-ioc控制反转服务"},{"categories":null,"content":"\r2. DI：依赖注入服务依赖注入服务：IOC的一个扩展，负责对象中属性的初始化 依赖：bean对象的创建依赖于容器 注入：bean对象中的所有属性由容器来注入 DI服务分类： 基本属性初始化 引用类型属性初始化 有参构造方法属性初始化 DI的实现方式： 通过xml文件或注解 初始化 一个类 一、通过xml文件描述： 在spring.xml文件的bean标签中添加： property标签：通过set方法为实例对象进行赋值 name：属性名 value：基本属性值 ref：引用类型属性的bean标签id \u003cbean class=\"java.util.ArrayList\" id=\"arrayList\"\u003e\u003c/bean\u003e \u003cbean class=\"org.example.App\" id=\"app2\"\u003e \u003c!--通过set方法为实例对象进行赋值--\u003e \u003c!--普通类型注入--\u003e \u003cproperty name=\"name\" value=\"毛桑\"\u003e\u003c/property\u003e \u003c!--引用类型注入--\u003e \u003cproperty name=\"list\" ref=\"arrayList\"\u003e\u003c/property\u003e \u003c!--数组的注入--\u003e \u003cproperty name=\"array\"\u003e \u003carray\u003e \u003cvalue\u003e1\u003c/value\u003e \u003cvalue\u003e2\u003c/value\u003e \u003cvalue\u003e3\u003c/value\u003e \u003cvalue\u003e4\u003c/value\u003e \u003c/array\u003e \u003c/property\u003e \u003c!--List集合的注入--\u003e \u003cproperty name=\"arraylist\"\u003e \u003clist\u003e \u003cvalue\u003e听歌\u003c/value\u003e \u003cvalue\u003e看电影\u003c/value\u003e \u003cvalue\u003e吹牛逼\u003c/value\u003e \u003c/list\u003e \u003c/property\u003e \u003c!--Map集合的注入--\u003e \u003cproperty name=\"map\"\u003e \u003cmap\u003e \u003centry key=\"\" value=\"\"\u003e \u003centry key=\"\" value=\"\"\u003e \u003centry key=\"\" value=\"\"\u003e \u003c/map\u003e \u003c/property\u003e \u003c!--Set集合的注入--\u003e \u003cproperty name=\"set\"\u003e \u003cset\u003e \u003cvalue\u003e听歌\u003c/value\u003e \u003cvalue\u003e看电影\u003c/value\u003e \u003cvalue\u003e吹牛逼\u003c/value\u003e \u003c/set\u003e \u003c/property\u003e \u003c!--Null空值的注入--\u003e \u003cproperty name=\"nullValue\"\u003e \u003cnull/\u003e \u003c/property\u003e \u003c!--properties文件的注入--\u003e \u003cproperty\u003e \u003cprops\u003e \u003cprop key=\"username\"\u003eroot\u003c/prop\u003e \u003cprop key=\"password\"\u003e129807\u003c/prop\u003e \u003c/props\u003e \u003c/property\u003e \u003c/bean\u003e \u003c!-- p 命名空间的使用--\u003e \u003cbean class=\"org.example.App\" id=\"app4\" p:name=\"毛嘉\"\u003e constructor-arg标签：通过有参构造方法为实例对象进行赋值 name：属性名 value：基本属性值 ref：引用类型属性的bean标签id \u003cbean class=\"java.util.ArrayList\" id=\"arrayList\"\u003e\u003c/bean\u003e \u003cbean class=\"org.example.App\" id=\"app3\"\u003e \u003c!--通过有参构造方法为实例对象进行赋值--\u003e \u003c!--通过形参名赋值--\u003e \u003cconstructor-arg name=\"name\" value=\"毛桑\"\u003e\u003c/constructor-arg\u003e \u003cconstructor-arg name=\"list\" ref=\"arrayList\"\u003e\u003c/constructor-arg\u003e \u003c!--通过下标赋值--\u003e \u003cconstructor-arg index=\"0\" value=\"毛桑\"\u003e\u003c/constructor-arg\u003e \u003cconstructor-arg index=\"1\" ref=\"arrayList\"\u003e\u003c/constructor-arg\u003e \u003c!--通过下标赋值（不建议使用，如果有相同类型的参数就GG）--\u003e \u003cconstructor-arg type=\"java.lang.String\" value=\"毛桑\"\u003e\u003c/constructor-arg\u003e \u003cconstructor-arg type=\"java.util.ArrayList\" ref=\"arrayList\"\u003e\u003c/constructor-arg\u003e \u003c/bean\u003e \u003c!-- c 命名空间的使用--\u003e \u003cbean class=\"org.example.App\" id=\"app4\" c:name=\"毛嘉\"\u003e\u003c/bean\u003e xml的自动装配 必须保证容器中只有一个类型匹配的对象 byName：自动在容器上下文中找set方法对应的小驼峰bean id bytype：自动在容器上下文中找类型匹配的bean \u003cbean class=\"java.util.ArrayList\" id=\"arrayList\"\u003e\u003c/bean\u003e \u003cbean class=\"org.example.App\" id=\"app6\" autowire=\"byName\"\u003e \u003c!--通过有参构造方法为实例对象进行赋值--\u003e \u003cconstructor-arg name=\"name\" value=\"毛桑\"\u003e\u003c/constructor-arg\u003e \u003c!--\u003cconstructor-arg name=\"list\" ref=\"arrayList\"\u003e\u003c/constructor-arg\u003e--\u003e \u003c/bean\u003e 二、通过Annotation注解描述： 使用@Value对基本属性进行初始化 也可以声明在set方法上 ==出现@Value的类必须由spring容器对象创建== 使用@Autowired对引用数据类型初始化（自动装配） 要求spring容器提供类型匹配的对象初始化，必须保证容器中只有一个类型匹配的对象 也可以声明在set方法上 ==出现@Autowired的类必须由spring容器对象创建== 借助@Qualifier提供对象id指定初始化对象 Bean的作用域： singleton单例模式（默认） prototype原型模式：每次从容器getBean时都会产生一个新的对象 \u003cbean class=\"java.util.ArrayList\" id=\"arrayList\" scope=\"prototype\"\u003e\u003c/bean\u003e ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:2","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#2-di依赖注入服务"},{"categories":null,"content":"\r2. DI：依赖注入服务依赖注入服务：IOC的一个扩展，负责对象中属性的初始化 依赖：bean对象的创建依赖于容器 注入：bean对象中的所有属性由容器来注入 DI服务分类： 基本属性初始化 引用类型属性初始化 有参构造方法属性初始化 DI的实现方式： 通过xml文件或注解 初始化 一个类 一、通过xml文件描述： 在spring.xml文件的bean标签中添加： property标签：通过set方法为实例对象进行赋值 name：属性名 value：基本属性值 ref：引用类型属性的bean标签id 1 2 3 4 听歌 看电影 吹牛逼 听歌 看电影 吹牛逼 root 129807 constructor-arg标签：通过有参构造方法为实例对象进行赋值 name：属性名 value：基本属性值 ref：引用类型属性的bean标签id xml的自动装配 必须保证容器中只有一个类型匹配的对象 byName：自动在容器上下文中找set方法对应的小驼峰bean id bytype：自动在容器上下文中找类型匹配的bean 二、通过Annotation注解描述： 使用@Value对基本属性进行初始化 也可以声明在set方法上 ==出现@Value的类必须由spring容器对象创建== 使用@Autowired对引用数据类型初始化（自动装配） 要求spring容器提供类型匹配的对象初始化，必须保证容器中只有一个类型匹配的对象 也可以声明在set方法上 ==出现@Autowired的类必须由spring容器对象创建== 借助@Qualifier提供对象id指定初始化对象 Bean的作用域： singleton单例模式（默认） prototype原型模式：每次从容器getBean时都会产生一个新的对象 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:2","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#bean的作用域"},{"categories":null,"content":"\r3. AOP：面向切面面向切面(aspect)：使用动态代理简化JDK代理设计模式开发难度 目标对象（target）：本次要帮助的某个接口下的某个实现类的实例对象, 目标对象并不会直接出现在程序。所有对于目标对象请求，都由其对应的代理对象进行接收。 切面（aspect）： 切面就是一个类。一个需要在某个接口下所有实现类中指定方法下统一新增的方法 连接点（joinPoint）：接口下需要与新增功能关联的方法。比如 service方法 切入点（pointCut）： 定位地址，用于指向连接点位置 通知（advice）：【切面】与【连接点】的调用顺序 AOP服务中通知分类： 前置通知： 先执行[切面] 再执行[连接点] 【@Before】 后置通知: 先执行[连接点] 再执行[切面] 【@AfterReturning】 环绕通知： 先执行[切面] 再执行[连接点] 最后再执行[切面]【@Around】 异常通知： 只有在[连接点]运行时抛出了异常，才会执行[切面]【@AfterThrowing】 最终通知: 无论[连接点]是否执行成功，最终都要执行[切面] try{}finally{} 【@After】 在spring框架中使用动态代理： 一、 通过xml文件方式 添加spring动态代理aspects依赖 \u003c!-- spring-aspects --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-aspects\u003c/artifactId\u003e \u003cversion\u003e5.3.9\u003c/version\u003e \u003c/dependency\u003e 创建目标接口、目标接口实现类 创建切面类 完成[切面]、[通知] 创建目标对象接口、实现类、实现类功能 创建切面类，写切面方法 在spring.xml中: 创建代理对象，切面对象 配置aop \u003c!--使用bean标签要求spring容器创建代理对象和切面对象--\u003e \u003cbean class=\"com.bjpn.serviceImpl.DeptServiceImpl\" id=\"deptService\"/\u003e \u003cbean class=\"com.bjpn.aspect.MyAspect\" id=\"myAspect\"/\u003e \u003c!--aop配置标签--\u003e \u003caop:config\u003e \u003c!--声明切入点（pointCut），绑定连接点（joinPoint）的具体实现方法--\u003e \u003caop:pointcut id=\"myPointCut\" expression=\"execution(public void com.bjpn.service.BaseService.service())\"/\u003e \u003c!--声明切面，绑定切面对象--\u003e \u003caop:aspect ref=\"myAspect\"\u003e \u003c!--声明通知类型，绑定切面中的增强方法，绑定切入点--\u003e \u003caop:before method=\"newMethod\" pointcut-ref=\"myPointCut\"/\u003e \u003c/aop:aspect\u003e \u003c/aop:config\u003e 测试使用 问：为什么这里要上转型使用接口创建实例对象？ 答：因为AOP动态代理默认使用的是JDK的动态代理，JDK的动态代理需要类有对应的接口，且必须使用接口上转型 补：在IOC中使用spring容器创建实现了接口的对象时，也会自动使用JDK动态代理，需要上转型。如若是使用spring容器创建没有实现接口的对象时，使用的是cglib动态代理，不需要上转型使用。 二、 通过注解方式 添加spring动态代理aspects依赖 \u003c!-- spring-aspects --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-aspects\u003c/artifactId\u003e \u003cversion\u003e5.3.9\u003c/version\u003e \u003c/dependency\u003e 创建目标接口、目标接口实现类 ==使用Spring容器创建== 创建切面类 ==使用Spring容器创建== 完成[切面]、[通知] 创建目标对象接口、实现类、实现类功能 创建切面类，写切面方法newMethod，声明通知方式的注解@Before /** * 加@Component，切面类需要由spring创建 * 加@Aspect，表明此类为切面类（不用手动实现InvocationHandler接口） */ @Component @Aspect //@EnableAspectJAutoProxy(proxyTargetClass = true) //加入这行可替代xml文件中的\u003caop:aspectj-autoproxy/\u003e public class MyAspect { /** * @ Before()，前置注解：先执行【切面】再执行【连接点】 * 设置pointCut，说明与哪些连接点关联 */ @Before(value = \"execution(public void com.bjpn.service.BaseService.service())\") public void newMethod(){ System.out.println(\"service开始运行的时间: \"+new Date()); } @Around(value = \"execution(* * com.bjpn.service.BaseService.*\") public void newMethod2(ProceedingJoinPoint jp){ System.out.println(\"service开始运行的时间: \"+new Date()); //执行方法 jp.proceed(); System.out.println(\"service结束运行的时间: \"+new Date()); } } 在spring.xml中: 通知Spring容器对象在创建代理对象时关联切面类对象和代理对象 \u003c!--声明创建【目标对象】和【代理对象】--\u003e \u003ccontext:component-scan base-package=\"com.bjpn\"/\u003e \u003c!--通知spring容器将切面类对象和代理对象关联--\u003e \u003caop:aspectj-autoproxy /\u003e \u003c!--可以手动设置为cglib代理模式，不需要接口上转型--\u003e \u003c!--\u003caop:aspectj-autoproxy proxy-target-class=\"true\"/\u003e--\u003e 测试使用 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:3","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#3-aop面向切面"},{"categories":null,"content":"\r使用xml文件和注解的区别 基于XML文件索要服务： 会增加项目的容积 相对灵活。可以要求Spring容器对象对某一个类进行多次对象创建 基于Annotation注解索要服务： 有效减少项目的容积 由注解管理的类只能在Spring容器对象拥有一个实例对象 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:4","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用xml文件和注解的区别"},{"categories":null,"content":"\r其他常用方法 在spring.xml中可以导入包含其他spring.xml的内容：import resource=\"ApplicationContexxt.xml\" context.getBeanDefinitionCount();获取Spring容器中对象的数量 context.getBeanDefinitionNames();获取Spring容器中所有对象的id 在AOP中 String methodName = targetMethod.getSignature().getName();获取当前关联方法的名称 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:5","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#其他常用方法"},{"categories":null,"content":"\rSpring框架集成MyBatis MyBatis提供DAO代理服务 Spring容器负责SqlSessionFactory、SqlSession对象、Dao代理对象的创建和初始化 在Spring中使用Mybatis开发： 一、 添加依赖 mysql-jdbc的依赖，负责：Connection / PreparedStatement / ResultSet / Driver mybatis的依赖，负责：SqlSessionFactoryBuilder / Configuration / SqlSessionFactory / SqlSession mybatis-spring的依赖，负责：易于 Spring 创建 SqlSessionFactory 实现类 / SqlSession 实现类 druid的依赖，负责：Connection （优化数据库连接池使用，来自阿里巴巴） spring-context的依赖，负责：ClassPathXmlApplication spring-jdbc的依赖，负责：spring 和 jdbc 的协调管理 \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e8.0.26\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis\u003c/artifactId\u003e \u003cversion\u003e3.5.1\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis-spring\u003c/artifactId\u003e \u003cversion\u003e1.3.1\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edruid\u003c/artifactId\u003e \u003cversion\u003e1.1.12\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-context\u003c/artifactId\u003e \u003cversion\u003e5.3.9\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-jdbc\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e 创建实体类、DAO接口、mapper文件、mybatis-config文件 最好保证mapper文件名和DAO类名一样 最好保证mapper文件和dao类在同一包下 mapper文件的namespace必须是对应DAO接口全限定名 mapper文件中SQL语句的ID必须对应DAO接口的方法名 在mybatis-config.xml只需设置别名和设置即可 在spring.xml中: 使用Spring创建【DruidDataSource】数据库连接池管理对象 使用Spring创建【SqlSessionFactory】对象，通过dataSource指定【Druid】对象 使用Spring创建【MapperScannerConfigurer】对象，通过【SqlSessionFactory】对象创建【Sqlsession】对象，创建【DAO接口实现类】对象，使用时索要即可 \u003c!-- 一、创建配置Druid对象--\u003e \u003cbean class=\"com.alibaba.druid.pool.DruidDataSource\" id=\"dataSource\"\u003e \u003c!--通过driverClassName指定驱动位置--\u003e \u003cproperty name=\"driverClassName\" value=\"com.mysql.cj.jdbc.Driver\"/\u003e \u003c!--配置数据库参数属性--\u003e \u003cproperty name=\"url\" value=\"jdbc:mysql://localhost:3306/bjpowernode\"/\u003e \u003cproperty name=\"username\" value=\"root\"/\u003e \u003cproperty name=\"password\" value=\"129807\"/\u003e \u003c/bean\u003e \u003c!-- 二、创建SqlSessionFactory对象--\u003e \u003cbean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"\u003e \u003c!--通过dataSource指定Druid对象--\u003e \u003cproperty name=\"dataSource\" ref=\"dataSource\"/\u003e \u003c!--通过configLocation指定mybatis配置文件位置--\u003e \u003cproperty name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/\u003e \u003c/bean\u003e \u003c!-- 三、创建MapperScannerConfigurer对象--\u003e \u003cbean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"\u003e \u003c!--生成SqlSession对象--\u003e \u003cproperty name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/\u003e \u003c!--扫描包: 生成DAO接口实现类, 以id为小驼峰类名保存在spring容器中--\u003e \u003cproperty name=\"basePackage\" value=\"com.bjpn.dao\"/\u003e \u003c/bean\u003e 测试使用 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#spring框架集成mybatis"},{"categories":null,"content":"\r实现事务管理 使用TransactionManager事务管理类的实现类：DataSourceTransactionManager Spring容器使用AOP服务将TransactionManager作为切面类与连接点（service方法）进行绑定 在Spring中使用Mybatis实现事务管理： 一、通过XML方法： 添加依赖 \u003c!--事务管理依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-tx\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c!--动态代理的依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-aspects\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e 创建mybatis运行环境，service接口，编写接口实现类 在spring.xml中添加 \u003c!--声明事务管理器--\u003e \u003cbean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"\u003e \u003c!--指定数据库连接池--\u003e \u003cproperty name=\"dataSource\" ref=\"dataSource\"/\u003e \u003c/bean\u003e \u003c!--通知spring容器对象哪个是提供事务服务的对象 事务管理器--\u003e \u003ctx:advice transaction-manager=\"transactionManager\" id=\"transactionInterceptor\"\u003e \u003ctx:attributes\u003e \u003c!--指定方法的事务属性 name:方法名称 isolation：隔离级别 propagation：传播行为 rollback-for：回滚的异常类， 对于自定义的异常要使用全限定名称，系统的异常类可以名称 --\u003e \u003ctx:method name=\"save*\" isolation=\"DEFAULT\" propagation=\"REQUIRED\" rollback-for=\"com.bjpn.crm.exception.AjaxRequestException, com.bjpn.crm.exception.TraditionRequestException\" /\u003e \u003c/tx:attributes\u003e \u003c/tx:advice\u003e \u003c!--通知spring容器对象, 目标方法，位置--\u003e \u003caop:config\u003e \u003c!--绑定切入点：任意返回值类型，service包下所有接口下的所有类，所有有无参数的类--\u003e \u003caop:pointcut id=\"myPointCut\" expression=\"execution(* com.bjpn.service.*.*(..))\"/\u003e \u003c!--绑定容器对象和切入点--\u003e \u003caop:advisor advice-ref=\"transactionInterceptor\" pointcut-ref=\"myPointCut\"/\u003e \u003c/aop:config\u003e 测试使用 二、通过注解方式： 添加依赖 \u003c!--springframework事务管理--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-tx\u003c/artifactId\u003e \u003cversion\u003e4.3.16.RELEASE\u003c/version\u003e \u003c/dependency\u003e 在需要使用事务的连接点（service方法）上声明@Transactional注解 注解向spring容器索要transactionalManager 由transactionalManager扮演切面类，管理事务 在spring.xml中 \u003c!--声明事务管理器--\u003e \u003cbean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"\u003e \u003c!--指定上方声明好的数据库连接池--\u003e \u003cproperty name=\"dataSource\" ref=\"dataSource\"/\u003e \u003c/bean\u003e \u003c!--注解驱动：为所有声明了@Transactional的方法绑定提供事务管理服务--\u003e \u003ctx:annotation-driven transaction-manager=\"transactionManager\"/\u003e 测试使用 使用XMl文件与注解的区别 使用注解的方式需要在每一个业务方法上都添加注解（重复性开发） 推荐使用xml，一次编写让所有业务加上事务 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:1","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#实现事务管理"},{"categories":null,"content":"\r在WEB项目中使用spring 不能用spring容器来创建servler对象 使用spring容器创建service对象 ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#在web项目中使用spring"},{"categories":null,"content":"\r灵活运用监听器 在WEB项目中使用ContextLoaderListener监听器将spring容器对象存在全局作用域对象中 添加依赖 \u003c!--spring-web spring提供的监听器依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-web\u003c/artifactId\u003e \u003cversion\u003e5.3.9\u003c/version\u003e \u003c/dependency\u003e 在web.xml中标签中指定spring.xml的位置，ContextLoaderListener就按照这个文件创建spring容器 \u003c!--指定spring.xml文件位置，确保监听器读取的不是默认的web-inf下的applicationContext.xml文件--\u003e \u003ccontext-param\u003e \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e \u003cparam-value\u003eclasspath:spring.xml\u003c/param-value\u003e \u003c/context-param\u003e 让监听器同时继承ContextLoaderListener类 public class LoaderListener extends ContextLoaderListener implements ServletContextListener{ /** * initWebApplicationContext方法：如果全局作用域对象中不存在spring容器对象，那么就创建它 */ @Override public WebApplicationContext initWebApplicationContext(ServletContext servletContext) { return super.initWebApplicationContext(servletContext); } @Override public void contextInitialized(ServletContextEvent sce) { initWebApplicationContext(sce.getServletContext()); } } 在需要用到spring容器的位置（Servlet 控制器）通过全局作用域对象获取 ApplicationContext context = (ApplicationContext) req.getServletContext().getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE); ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:1","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#灵活运用监听器"},{"categories":null,"content":"\r遇到的问题 在jsp文件中无法使用el表达式 在page指令中添加 isELIgnored=\"false\" ","date":"2021-09-14","objectID":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"Spring自学笔记md版","uri":"/spring%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#遇到的问题"},{"categories":null,"content":"\rMyBatis自学笔记 大连交通大学 信息学院 刘嘉宁 2021-08-22 笔记摘自链接：https://www.bilibili.com/video/BV1NE411Q7Nx ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:0:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#mybatis自学笔记"},{"categories":null,"content":"\r什么是MyBatis： 一个优秀的持久层框架 支持定制化SQL，存储过程以及高级映射 避免了几乎所有的JDBC代码和手动设置参数以及获取结果集 MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:1:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#什么是mybatis"},{"categories":null,"content":"\rMyBatis的特点： 简单易学。 灵活。 解除sql与程序代码的耦合。 提供映射标签，支持对象与数据库的orm字段\"对象-关系映射\"（Object/Relational Mapping）关系映射。 提供对象关系映射标签，支持对象关系组建维护。 提供xml标签，支持编写动态sql。 缺点：sql语句依赖于数据库,不能随意的更换数据库,移植性差 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:2:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#mybatis的特点"},{"categories":null,"content":"\rIDEA中使用maven创建MyBatis项目： 父工程（mybatisProject）中创建配置好的依赖会在子模块（mybatis-01）中被继承 创建maven在pom.xml中添加mysql驱动的依赖，mybatis的依赖。 \u003c!-- MyBatis的依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis\u003c/artifactId\u003e \u003cversion\u003e3.4.6\u003c/version\u003e \u003c/dependency\u003e 在模块src\\main\\resources目录下创建mybatis-config.xml配置文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e \u003c!--核心配置文件--\u003e \u003cconfiguration\u003e \u003cenvironments default=\"development\"\u003e \u003cenvironment id=\"development\"\u003e \u003ctransactionManager type=\"JDBC\"/\u003e \u003cdataSource type=\"POOLED\"\u003e \u003cproperty name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/\u003e \u003cproperty name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?useSSL=true\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8\"/\u003e \u003cproperty name=\"username\" value=\"root\"/\u003e \u003cproperty name=\"password\" value=\"129807\"/\u003e \u003c/dataSource\u003e \u003c/environment\u003e \u003c/environments\u003e \u003c!--注册mapper, 每一个mapper.xml都需要在MyBatis核心配置中注册--\u003e \u003cmappers\u003e \u003cmapper resource=\"com/kuang/dao/UserMapper.xml\"/\u003e \u003c/mappers\u003e \u003c/configuration\u003e 在utils包下封装MybatisUtils工具类读取这个配置文件 /** * sqlSessionFactory --\u003e sqlSession 工具类 * @author 刘嘉宁 */ public class MybatisUtils { private static SqlSessionFactory sqlSessionFactory = null; static{ try { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); } catch (Exception e) { e.printStackTrace(); } } /** * sqlSession中包含了面向数据库执行sql命令所需的所有方法 */ public static SqlSession getSqlSession(){ //openSession(true) 自动提交事务 return sqlSessionFactory.openSession(); } } 在dao包下根据DAO接口创建Mapper的xml文件内容 /** * user表的DAO接口(提供数据库访问对象) * @author 刘嘉宁 */ public interface UserDao { /** * 查询user表中所有信息的方法 * @return 用户的List集合 */ List\u003cUser\u003e getUserList(); } \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003c!--namespace: 绑定一个对应的Dao/Mapper接口--\u003e \u003cmapper namespace=\"com.kuang.dao.UserDao\"\u003e \u003c!--id: namespace中对应的方法， resultType: 返回类型--\u003e \u003cselect id=\"getUserList\" resultType=\"com.kuang.pojo.User\"\u003e select * from 库.user; \u003c/select\u003e \u003c/mapper\u003e ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#idea中使用maven创建mybatis项目"},{"categories":null,"content":"\rIDEA中使用maven创建MyBatis项目： 父工程（mybatisProject）中创建配置好的依赖会在子模块（mybatis-01）中被继承 创建maven在pom.xml中添加mysql驱动的依赖，mybatis的依赖。 org.mybatis mybatis 3.4.6 在模块src\\main\\resources目录下创建mybatis-config.xml配置文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e 在utils包下封装MybatisUtils工具类读取这个配置文件 /** * sqlSessionFactory --\u003e sqlSession 工具类 * @author 刘嘉宁 */ public class MybatisUtils { private static SqlSessionFactory sqlSessionFactory = null; static{ try { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); } catch (Exception e) { e.printStackTrace(); } } /** * sqlSession中包含了面向数据库执行sql命令所需的所有方法 */ public static SqlSession getSqlSession(){ //openSession(true) 自动提交事务 return sqlSessionFactory.openSession(); } } 在dao包下根据DAO接口创建Mapper的xml文件内容 /** * user表的DAO接口(提供数据库访问对象) * @author 刘嘉宁 */ public interface UserDao { /** * 查询user表中所有信息的方法 * @return 用户的List集合 */ List getUserList(); } \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e select * from 库.user; ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#创建maven在pomxml中添加mysql驱动的依赖mybatis的依赖"},{"categories":null,"content":"\rIDEA中使用maven创建MyBatis项目： 父工程（mybatisProject）中创建配置好的依赖会在子模块（mybatis-01）中被继承 创建maven在pom.xml中添加mysql驱动的依赖，mybatis的依赖。 org.mybatis mybatis 3.4.6 在模块src\\main\\resources目录下创建mybatis-config.xml配置文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e 在utils包下封装MybatisUtils工具类读取这个配置文件 /** * sqlSessionFactory --\u003e sqlSession 工具类 * @author 刘嘉宁 */ public class MybatisUtils { private static SqlSessionFactory sqlSessionFactory = null; static{ try { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); } catch (Exception e) { e.printStackTrace(); } } /** * sqlSession中包含了面向数据库执行sql命令所需的所有方法 */ public static SqlSession getSqlSession(){ //openSession(true) 自动提交事务 return sqlSessionFactory.openSession(); } } 在dao包下根据DAO接口创建Mapper的xml文件内容 /** * user表的DAO接口(提供数据库访问对象) * @author 刘嘉宁 */ public interface UserDao { /** * 查询user表中所有信息的方法 * @return 用户的List集合 */ List getUserList(); } \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e select * from 库.user; ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#在模块srcmainresources目录下创建mybatis-configxml配置文件"},{"categories":null,"content":"\rIDEA中使用maven创建MyBatis项目： 父工程（mybatisProject）中创建配置好的依赖会在子模块（mybatis-01）中被继承 创建maven在pom.xml中添加mysql驱动的依赖，mybatis的依赖。 org.mybatis mybatis 3.4.6 在模块src\\main\\resources目录下创建mybatis-config.xml配置文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e 在utils包下封装MybatisUtils工具类读取这个配置文件 /** * sqlSessionFactory --\u003e sqlSession 工具类 * @author 刘嘉宁 */ public class MybatisUtils { private static SqlSessionFactory sqlSessionFactory = null; static{ try { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); } catch (Exception e) { e.printStackTrace(); } } /** * sqlSession中包含了面向数据库执行sql命令所需的所有方法 */ public static SqlSession getSqlSession(){ //openSession(true) 自动提交事务 return sqlSessionFactory.openSession(); } } 在dao包下根据DAO接口创建Mapper的xml文件内容 /** * user表的DAO接口(提供数据库访问对象) * @author 刘嘉宁 */ public interface UserDao { /** * 查询user表中所有信息的方法 * @return 用户的List集合 */ List getUserList(); } \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e select * from 库.user; ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#在utils包下封装mybatisutils工具类读取这个配置文件"},{"categories":null,"content":"\rIDEA中使用maven创建MyBatis项目： 父工程（mybatisProject）中创建配置好的依赖会在子模块（mybatis-01）中被继承 创建maven在pom.xml中添加mysql驱动的依赖，mybatis的依赖。 org.mybatis mybatis 3.4.6 在模块src\\main\\resources目录下创建mybatis-config.xml配置文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e 在utils包下封装MybatisUtils工具类读取这个配置文件 /** * sqlSessionFactory --\u003e sqlSession 工具类 * @author 刘嘉宁 */ public class MybatisUtils { private static SqlSessionFactory sqlSessionFactory = null; static{ try { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); } catch (Exception e) { e.printStackTrace(); } } /** * sqlSession中包含了面向数据库执行sql命令所需的所有方法 */ public static SqlSession getSqlSession(){ //openSession(true) 自动提交事务 return sqlSessionFactory.openSession(); } } 在dao包下根据DAO接口创建Mapper的xml文件内容 /** * user表的DAO接口(提供数据库访问对象) * @author 刘嘉宁 */ public interface UserDao { /** * 查询user表中所有信息的方法 * @return 用户的List集合 */ List getUserList(); } \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e select * from 库.user; ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:3:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#在dao包下根据dao接口创建mapper的xml文件内容"},{"categories":null,"content":"\r增删改的实现： 编写接口添加：删除修改同理 /** * 添加用户 * @param user 用户 * @return 添加成功条数 1:成功 0:失败 */ int addUser(User user); 编写对应的Mapper.xml中的语句添加：删除修改同理 \u003c!--id: namespace中对应的方法, parameter: 形参类型--\u003e \u003cinsert id=\"addUser\" parameterType=\"com.kuang.pojo.User\"\u003e insert into mybatis.user (id, name, pwd) values(#{id}, #{name}, #{pwd}); \u003c/insert\u003e 测试使用添加：删除修改同理 @Test public void addUserTest() { SqlSession sqlSession = null; try { sqlSession = MyBatisUtils.getSqlSession(); UserDao mapper = sqlSession.getMapper(UserDao.class); int res = mapper.addUser(new User(5, \"mike\", \"mike123\")); if (res == 1){ System.out.println(\"添加成功\"); }else { System.out.println(\"添加失败\"); } } catch (Exception e) { e.printStackTrace(); } finally { //增删改时注意提交事务!! sqlSession.commit(); sqlSession.close(); } } ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#增删改的实现"},{"categories":null,"content":"\r增删改的实现： 编写接口添加：删除修改同理 /** * 添加用户 * @param user 用户 * @return 添加成功条数 1:成功 0:失败 */ int addUser(User user); 编写对应的Mapper.xml中的语句添加：删除修改同理 insert into mybatis.user (id, name, pwd) values(#{id}, #{name}, #{pwd}); 测试使用添加：删除修改同理 @Test public void addUserTest() { SqlSession sqlSession = null; try { sqlSession = MyBatisUtils.getSqlSession(); UserDao mapper = sqlSession.getMapper(UserDao.class); int res = mapper.addUser(new User(5, \"mike\", \"mike123\")); if (res == 1){ System.out.println(\"添加成功\"); }else { System.out.println(\"添加失败\"); } } catch (Exception e) { e.printStackTrace(); } finally { //增删改时注意提交事务!! sqlSession.commit(); sqlSession.close(); } } ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#编写接口"},{"categories":null,"content":"\r增删改的实现： 编写接口添加：删除修改同理 /** * 添加用户 * @param user 用户 * @return 添加成功条数 1:成功 0:失败 */ int addUser(User user); 编写对应的Mapper.xml中的语句添加：删除修改同理 insert into mybatis.user (id, name, pwd) values(#{id}, #{name}, #{pwd}); 测试使用添加：删除修改同理 @Test public void addUserTest() { SqlSession sqlSession = null; try { sqlSession = MyBatisUtils.getSqlSession(); UserDao mapper = sqlSession.getMapper(UserDao.class); int res = mapper.addUser(new User(5, \"mike\", \"mike123\")); if (res == 1){ System.out.println(\"添加成功\"); }else { System.out.println(\"添加失败\"); } } catch (Exception e) { e.printStackTrace(); } finally { //增删改时注意提交事务!! sqlSession.commit(); sqlSession.close(); } } ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#编写对应的mapperxml中的语句"},{"categories":null,"content":"\r增删改的实现： 编写接口添加：删除修改同理 /** * 添加用户 * @param user 用户 * @return 添加成功条数 1:成功 0:失败 */ int addUser(User user); 编写对应的Mapper.xml中的语句添加：删除修改同理 insert into mybatis.user (id, name, pwd) values(#{id}, #{name}, #{pwd}); 测试使用添加：删除修改同理 @Test public void addUserTest() { SqlSession sqlSession = null; try { sqlSession = MyBatisUtils.getSqlSession(); UserDao mapper = sqlSession.getMapper(UserDao.class); int res = mapper.addUser(new User(5, \"mike\", \"mike123\")); if (res == 1){ System.out.println(\"添加成功\"); }else { System.out.println(\"添加失败\"); } } catch (Exception e) { e.printStackTrace(); } finally { //增删改时注意提交事务!! sqlSession.commit(); sqlSession.close(); } } ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:4:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#测试使用"},{"categories":null,"content":"\r模糊查询实现方式： 在java执行代码的时候，传递通配符% % HashMap\u003cString, Object\u003e map = new HashMap\u003c\u003e(); map.put(\"userName\", \"%王%\"); 在sql拼接中使用通配符 select * from mybatis.user where name like \"%\"#{userName}\"%\"; ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:5:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#模糊查询实现方式"},{"categories":null,"content":"\rmybatis-config.xml核心配置文件： 属性： 可以实现外部配置文件的引用。 resource引用的.properties配置文件优先级高，属性配置标签中起到补充配置的作用优先级低。 属性配置相当于全局变量，可以在下文使用${ 属性的name }引用到其value \u003c!--属性: 实现引用外置配置文件（优先）--\u003e \u003cproperties resource=\"db.properties\"\u003e \u003c!--在其中增加属性配置--\u003e \u003cproperty name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/\u003e \u003c/properties\u003e 别名： 为java类型设置一个短的别名 为包起别名，默认名是包中的类名首字母小写 \u003c!--别名--\u003e \u003ctypeAliases\u003e \u003c!--为实体类起别名--\u003e \u003ctypeAlias type=\"com.kuang.pojo.User\" alias=\"User\" /\u003e \u003c!--为包起别名，默认名是包中的类名首字母小写--\u003e \u003cpackage name=\"com.kuang.pojo\" /\u003e \u003c/typeAliases\u003e 在实体类上添加注解可以代替第一种方式： @Alias(\"user\") public class User{ ... } 一些java创建的类型都有默认别名: int –\u003e _int Integer –\u003e int Map –\u003e map 设置： 它们会改变 MyBatis 的运行时行为, 常用设置： 设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 环境： 指定事务管理器 指定数据源 \u003c!--环境配置--\u003e \u003cenvironments default=\"development\"\u003e \u003cenvironment id=\"development\"\u003e \u003c!--事务管理器：JDBC/MANAGED--\u003e \u003ctransactionManager type=\"JDBC\"/\u003e \u003c!--数据源：UNPOOLED没有池/POOLED有池/UNDI--\u003e \u003cdataSource type=\"POOLED\"\u003e \u003cproperty name=\"driver\" value=\"${driver}\"/\u003e \u003cproperty name=\"url\" value=\"${url}\"/\u003e \u003cproperty name=\"username\" value=\"${username}\"/\u003e \u003cproperty name=\"password\" value=\"${password}\"/\u003e \u003c/dataSource\u003e \u003c/environment\u003e \u003c/environments\u003e 映射：映射：告诉 MyBatis 去哪里找映射文件 方式一：使用路径绑定xml文件 \u003c!--注册mapper, 每一个mapper.xml都需要在MyBatis核心配置中注册--\u003e \u003cmappers\u003e \u003cmapper resource=\"com/kuang/dao/UserMapper.xml\"/\u003e \u003c/mappers\u003e 方式二：使用class文件绑定 注意1：接口和它的Mapper配置文件必须同名 注意2：接口和它的Mapper配置文件必须在同一包下 \u003c!--注册mapper, 每一个mapper.xml都需要在MyBatis核心配置中注册--\u003e \u003cmappers\u003e \u003cmapper class=\"com.kuang.dao.UserMapper\"/\u003e \u003c/mappers\u003e 方式三：package标签 定位到包下，保证mapper文件在dao包下 \u003cmappers\u003e \u003cpackage name=\"com.bjpn.crm.settings.dao\"/\u003e \u003c/mappers\u003e ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#mybatis-configxml核心配置文件"},{"categories":null,"content":"\rmybatis-config.xml核心配置文件： 属性： 可以实现外部配置文件的引用。 resource引用的.properties配置文件优先级高，属性配置标签中起到补充配置的作用优先级低。 属性配置相当于全局变量，可以在下文使用${ 属性的name }引用到其value 别名： 为java类型设置一个短的别名 为包起别名，默认名是包中的类名首字母小写 在实体类上添加注解可以代替第一种方式： @Alias(\"user\") public class User{ ... } 一些java创建的类型都有默认别名: int –\u003e _int Integer –\u003e int Map –\u003e map 设置： 它们会改变 MyBatis 的运行时行为, 常用设置： 设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 环境： 指定事务管理器 指定数据源 映射：映射：告诉 MyBatis 去哪里找映射文件 方式一：使用路径绑定xml文件 方式二：使用class文件绑定 注意1：接口和它的Mapper配置文件必须同名 注意2：接口和它的Mapper配置文件必须在同一包下 方式三：package标签 定位到包下，保证mapper文件在dao包下 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#属性"},{"categories":null,"content":"\rmybatis-config.xml核心配置文件： 属性： 可以实现外部配置文件的引用。 resource引用的.properties配置文件优先级高，属性配置标签中起到补充配置的作用优先级低。 属性配置相当于全局变量，可以在下文使用${ 属性的name }引用到其value 别名： 为java类型设置一个短的别名 为包起别名，默认名是包中的类名首字母小写 在实体类上添加注解可以代替第一种方式： @Alias(\"user\") public class User{ ... } 一些java创建的类型都有默认别名: int –\u003e _int Integer –\u003e int Map –\u003e map 设置： 它们会改变 MyBatis 的运行时行为, 常用设置： 设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 环境： 指定事务管理器 指定数据源 映射：映射：告诉 MyBatis 去哪里找映射文件 方式一：使用路径绑定xml文件 方式二：使用class文件绑定 注意1：接口和它的Mapper配置文件必须同名 注意2：接口和它的Mapper配置文件必须在同一包下 方式三：package标签 定位到包下，保证mapper文件在dao包下 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#别名"},{"categories":null,"content":"\rmybatis-config.xml核心配置文件： 属性： 可以实现外部配置文件的引用。 resource引用的.properties配置文件优先级高，属性配置标签中起到补充配置的作用优先级低。 属性配置相当于全局变量，可以在下文使用${ 属性的name }引用到其value 别名： 为java类型设置一个短的别名 为包起别名，默认名是包中的类名首字母小写 在实体类上添加注解可以代替第一种方式： @Alias(\"user\") public class User{ ... } 一些java创建的类型都有默认别名: int –\u003e _int Integer –\u003e int Map –\u003e map 设置： 它们会改变 MyBatis 的运行时行为, 常用设置： 设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 环境： 指定事务管理器 指定数据源 映射：映射：告诉 MyBatis 去哪里找映射文件 方式一：使用路径绑定xml文件 方式二：使用class文件绑定 注意1：接口和它的Mapper配置文件必须同名 注意2：接口和它的Mapper配置文件必须在同一包下 方式三：package标签 定位到包下，保证mapper文件在dao包下 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#设置"},{"categories":null,"content":"\rmybatis-config.xml核心配置文件： 属性： 可以实现外部配置文件的引用。 resource引用的.properties配置文件优先级高，属性配置标签中起到补充配置的作用优先级低。 属性配置相当于全局变量，可以在下文使用${ 属性的name }引用到其value 别名： 为java类型设置一个短的别名 为包起别名，默认名是包中的类名首字母小写 在实体类上添加注解可以代替第一种方式： @Alias(\"user\") public class User{ ... } 一些java创建的类型都有默认别名: int –\u003e _int Integer –\u003e int Map –\u003e map 设置： 它们会改变 MyBatis 的运行时行为, 常用设置： 设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 环境： 指定事务管理器 指定数据源 映射：映射：告诉 MyBatis 去哪里找映射文件 方式一：使用路径绑定xml文件 方式二：使用class文件绑定 注意1：接口和它的Mapper配置文件必须同名 注意2：接口和它的Mapper配置文件必须在同一包下 方式三：package标签 定位到包下，保证mapper文件在dao包下 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#环境"},{"categories":null,"content":"\rmybatis-config.xml核心配置文件： 属性： 可以实现外部配置文件的引用。 resource引用的.properties配置文件优先级高，属性配置标签中起到补充配置的作用优先级低。 属性配置相当于全局变量，可以在下文使用${ 属性的name }引用到其value 别名： 为java类型设置一个短的别名 为包起别名，默认名是包中的类名首字母小写 在实体类上添加注解可以代替第一种方式： @Alias(\"user\") public class User{ ... } 一些java创建的类型都有默认别名: int –\u003e _int Integer –\u003e int Map –\u003e map 设置： 它们会改变 MyBatis 的运行时行为, 常用设置： 设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 环境： 指定事务管理器 指定数据源 映射：映射：告诉 MyBatis 去哪里找映射文件 方式一：使用路径绑定xml文件 方式二：使用class文件绑定 注意1：接口和它的Mapper配置文件必须同名 注意2：接口和它的Mapper配置文件必须在同一包下 方式三：package标签 定位到包下，保证mapper文件在dao包下 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:6:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#映射"},{"categories":null,"content":"\r生命周期和作用域： MyBatis执行原理：程序通过mybatis-config.xml文件通过SqlSessionFactoryBuilder建造SqlSessionFactory得到SqlSession对象，通过反射动态代理出接口的mapper对象执行对应方法。 SqlSessionFactoryBuilder： 由用户创建，在执行完build（）方法后自动销毁 SqlSessionFactory 相当于数据库连接池 由SqlSessionFactoryBuilder创建，程序运行期间一直存在，程序结束时销毁 使用单例模式、静态单例模式，最佳作用域为全局作用域 SqlSession 相当于连接到连接池的一个请求，每一个都是单独的线程不是线程安全的，不能共享 在使用时被创建，反射出mapper对象，提交事务后被手动关闭销毁 最佳作用域为请求时或使用时的方法内 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#生命周期和作用域"},{"categories":null,"content":"\r生命周期和作用域： MyBatis执行原理：程序通过mybatis-config.xml文件通过SqlSessionFactoryBuilder建造SqlSessionFactory得到SqlSession对象，通过反射动态代理出接口的mapper对象执行对应方法。 SqlSessionFactoryBuilder： 由用户创建，在执行完build（）方法后自动销毁 SqlSessionFactory 相当于数据库连接池 由SqlSessionFactoryBuilder创建，程序运行期间一直存在，程序结束时销毁 使用单例模式、静态单例模式，最佳作用域为全局作用域 SqlSession 相当于连接到连接池的一个请求，每一个都是单独的线程不是线程安全的，不能共享 在使用时被创建，反射出mapper对象，提交事务后被手动关闭销毁 最佳作用域为请求时或使用时的方法内 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#mybatis执行原理"},{"categories":null,"content":"\r生命周期和作用域： MyBatis执行原理：程序通过mybatis-config.xml文件通过SqlSessionFactoryBuilder建造SqlSessionFactory得到SqlSession对象，通过反射动态代理出接口的mapper对象执行对应方法。 SqlSessionFactoryBuilder： 由用户创建，在执行完build（）方法后自动销毁 SqlSessionFactory 相当于数据库连接池 由SqlSessionFactoryBuilder创建，程序运行期间一直存在，程序结束时销毁 使用单例模式、静态单例模式，最佳作用域为全局作用域 SqlSession 相当于连接到连接池的一个请求，每一个都是单独的线程不是线程安全的，不能共享 在使用时被创建，反射出mapper对象，提交事务后被手动关闭销毁 最佳作用域为请求时或使用时的方法内 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#sqlsessionfactorybuilder"},{"categories":null,"content":"\r生命周期和作用域： MyBatis执行原理：程序通过mybatis-config.xml文件通过SqlSessionFactoryBuilder建造SqlSessionFactory得到SqlSession对象，通过反射动态代理出接口的mapper对象执行对应方法。 SqlSessionFactoryBuilder： 由用户创建，在执行完build（）方法后自动销毁 SqlSessionFactory 相当于数据库连接池 由SqlSessionFactoryBuilder创建，程序运行期间一直存在，程序结束时销毁 使用单例模式、静态单例模式，最佳作用域为全局作用域 SqlSession 相当于连接到连接池的一个请求，每一个都是单独的线程不是线程安全的，不能共享 在使用时被创建，反射出mapper对象，提交事务后被手动关闭销毁 最佳作用域为请求时或使用时的方法内 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#sqlsessionfactory"},{"categories":null,"content":"\r生命周期和作用域： MyBatis执行原理：程序通过mybatis-config.xml文件通过SqlSessionFactoryBuilder建造SqlSessionFactory得到SqlSession对象，通过反射动态代理出接口的mapper对象执行对应方法。 SqlSessionFactoryBuilder： 由用户创建，在执行完build（）方法后自动销毁 SqlSessionFactory 相当于数据库连接池 由SqlSessionFactoryBuilder创建，程序运行期间一直存在，程序结束时销毁 使用单例模式、静态单例模式，最佳作用域为全局作用域 SqlSession 相当于连接到连接池的一个请求，每一个都是单独的线程不是线程安全的，不能共享 在使用时被创建，反射出mapper对象，提交事务后被手动关闭销毁 最佳作用域为请求时或使用时的方法内 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:7:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#sqlsession"},{"categories":null,"content":"\r结果集映射： MyBatis会将mapper.xml中查询到的内容依照resultType返回，在返回时会自动创建所需实例(MyBatis在幕后会自动创建一个resultMap，再基于属性名来映射列到JavaBean的属性上)，会自动找与表中字段名相同的属性名赋值 如何解决表字段名与类属性名不一致：使用结果集映射 解决方式： 为字段起别名，别名与类变量名一致 \u003cselect id=\"getUserById\" resultType=\"User\" parameterType=\"int\"\u003e select id, name, pwd as pswd from mybatis.user where id = #{id}; \u003c/select\u003e 结果集映射：将mapper.xml中select标签的resultType替换为resultMap \u003cresultMap id=\"UserMap\" type=\"User\"\u003e \u003c!--将数据库中的主键字段映射为实体类中的ID--\u003e \u003cid column=\"id\" property=\"ID\" /\u003e \u003c!--将数据库中的pwd字段映射为实体类中的pswd--\u003e \u003cresult column=\"pwd\" property=\"pswd\" /\u003e \u003c/resultMap\u003e \u003c!--id: namespace中对应的方法, resultType: 返回类型, parameter: 形参类型--\u003e \u003cselect id=\"getUserById\" resultMap=\"UserMap\" parameterType=\"int\"\u003e select * from mybatis.user where id = #{id}; \u003c/select\u003e ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:8:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#结果集映射"},{"categories":null,"content":"\r日志工厂： 日志：排错，排查异常用。 日志工厂：logImpl 设置名 描述 有效值 默认值 logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 LOG4J : 通过配置文件灵活控制日志工厂输出内容 STDOUT_LOGGING : 标准日志工厂输出内容 NO_LOGGING : 无日志 log4j： 导包：导入maven中的log4j \u003c!-- https://mvnrepository.com/artifact/log4j/log4j --\u003e \u003cdependency\u003e \u003cgroupId\u003elog4j\u003c/groupId\u003e \u003cartifactId\u003elog4j\u003c/artifactId\u003e \u003cversion\u003e1.2.17\u003c/version\u003e \u003c/dependency\u003e 设置目录实现：设置日志的具体实现为log4j，在mybatis-config.xml中添加： \u003c!--设置--\u003e \u003csettings\u003e \u003c!--设置日志工厂--\u003e \u003csetting name=\"logImpl\" value=\"LOG4J\"/\u003e \u003c/settings\u003e 配置文件：在resources目录下创建log4j.properties配置文件： #将等级为DEBUG的日志信息输出到console和file这两个目的地，console和file的定义在下面的代码 log4j.rootLogger=DEBUG,console,file #控制台输出的相关设置 log4j.appender.console = org.apache.log4j.ConsoleAppender log4j.appender.console.Target = System.out log4j.appender.console.Threshold=DEBUG log4j.appender.console.layout = org.apache.log4j.PatternLayout log4j.appender.console.layout.ConversionPattern=[%c]-%m%n #文件输出的相关设置 log4j.appender.file = org.apache.log4j.RollingFileAppender log4j.appender.file.File=./log/kuang.log log4j.appender.file.MaxFileSize=10mb log4j.appender.file.Threshold=DEBUG log4j.appender.file.layout=org.apache.log4j.PatternLayout log4j.appender.file.layout.ConversionPattern=[%p][%d{yy-MM-dd}][%c]%m%n #日志输出级别 log4j.logger.org.mybatis=DEBUG log4j.logger.java.sql=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.ResultSet=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG 使用: 导包：import org.apache.log4j.Logger; 创建日志类对象，参数为当前类的class：static Logger logger = Logger.getLogger(UserDaoTest.class); 设置日志级别，在适当位置加入： logger.info(\"info: 进入了testlog4j\"); logger.debug(\"debug: 进入了testlog4j\"); logger.error(\"error: 进入了testlog4j\"); 在log/网站名.log下追加日志 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:9:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#日志工厂"},{"categories":null,"content":"\r分页查询： 使用pageHelper：https://pagehelper.github.io/ 通过map传入limit的值： \u003cselect id=\"getUserByLimit\" resultType=\"user\" parameterType=\"map\"\u003e select * from mybatis.user limit #{startIndex},#{pageSize}; \u003c/select\u003e //在测试中：查询第二页的两条数据 Map map = new HashMap(); map.put(\"startIndex\", 2 * 1); map.put(\"pageSize\", 2); List user = mapper.getUserByLimit(map); ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:10:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#分页查询"},{"categories":null,"content":"\r使用注解开发： 面向接口编程：定义与实现的分离，解耦合 不推荐使用注解映射MyBatis 使用注解映射简单的sql语句（当需要用到resultMap等功能就GG） /** * 根据name查询所有用户信息 * @return 用户信息的List集合 */ @Select(\"select * from mybatis.user where name = #{sname};\") List\u003cUser\u003e getUserListById(@Param(\"sname\")int name); ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:11:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#使用注解开发"},{"categories":null,"content":"\rMyBatis底层原理： Resources获取加载全局配置文件 实例化SqlSessionFactoryBuilder构造器 解析配置文件流XMLConfigBuilder Configuration所有的配置信息 SqlSessionFactory实例化 transactional事务管理 创建executor执行器 创建SqlSession 实现CRUD，执行失败返回第六步 提交事务 关闭SqlSession ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:12:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#mybatis底层原理"},{"categories":null,"content":"\rLombok：lombok: 通过简单的注解形式来简化java代码，提高开发人员的开发效率 Lombok没法实现多种参数构造器的重载。 大大降低了源代码的可读性和完整性 使用lombok： 在IDEA中安装lombok插件， 在项目中导入lombok的jar包 在实体类上加注解 @Getter / @Setter：为相应的属性自动生成 Getter / Setter 方法 @FieldNameConstants @ToString：生成一个toString()方法，默认情况下，会输出类名、所有属性（会按照属性定义顺序），用逗号来分割。 @EqualsAndHashCode：生成equals和hasCode @AllArgsConstructor, @RequiredArgsConstructor and @NoArgsConstructor：无参构造器、部分参数构造器、全参构造器。 @Log, @Log4j, @Log4j2, @Slf4j, @XSlf4j, @CommonsLog, @JBossLog, @Flogger, @CustomLog @Data：为类的所有属性自动生成setter/getter、equals、canEqual、hashCode、toString方法，final属性无setter方法。 @Builder @SuperBuilder @Singular @Delegate @Value @Accessors @Wither @With @SneakyThrows @val @var @UtilityClass ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:13:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#lombok"},{"categories":null,"content":"\r多对一的处理： 在子表实体类中组合主表实体类（替代外键） 按照查询嵌套处理： 写两个查询类似子查询，然后再查询第一个的时候带上子查询的内容 \u003cresultMap id=\"studentTeacher\" type=\"Student\"\u003e \u003cresult column=\"id\" property=\"id\" /\u003e \u003cresult column=\"name\" property=\"name\" /\u003e \u003c!--复杂的属性需要单独处理： 对象(关联)：association--\u003e \u003cassociation javaType=\"Teacher\" property=\"teacher\" select=\"getTeacher\" column=\"tid\" /\u003e \u003c/resultMap\u003e \u003cselect id=\"getStudentWithTeacherList\" resultMap=\"studentTeacher\"\u003e select * from student; \u003c/select\u003e \u003cselect id=\"getTeacher\" resultType=\"teacher\"\u003e select * from teacher where id = #{tid(随便写自动匹配)}; \u003c/select\u003e 按照结果嵌套处理： 把要查的SQL写好，然后在resultMap中指定其对应对象、对应名字 \u003cresultMap id=\"studentTeacher2\" type=\"Student\"\u003e \u003cresult column=\"sid\" property=\"id\" /\u003e \u003cresult column=\"sname\" property=\"name\" /\u003e \u003cassociation javaType=\"Teacher\" property=\"teacher\"\u003e \u003cresult column=\"tid\" property=\"id\"/\u003e \u003cresult column=\"tname\" property=\"name\" /\u003e \u003c/association\u003e \u003c/resultMap\u003e \u003cselect id=\"getStudentWithTeacherList2\" resultMap=\"studentTeacher2\"\u003e select s.id sid, s.name sname, t.id tid, t.name tname from student s, teacher t where s. tid = t.id; \u003c/select\u003e ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:14:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#多对一的处理"},{"categories":null,"content":"\r一对多的处理： 在主表实体类中添加子表实体类的集合（一个主对应多个子） 按照查询嵌套处理 两个SQL中都找的是符合条件的内容 \u003cresultMap id=\"teacherStudent2\" type=\"Teacher\"\u003e \u003cresult column=\"id\" property=\"id\"/\u003e \u003cresult column=\"name\" property=\"name\"/\u003e \u003c!--复杂的属性需要单独处理： 集合：collection--\u003e \u003c!--ofType: 集合中的泛型信息--\u003e \u003ccollection javaType=\"List\" ofType=\"Student\" property=\"students\" select=\"getStudentList2\" column=\"id\"/\u003e \u003c/resultMap\u003e \u003cselect id=\"getTeacherWithStudentList2\" resultMap=\"teacherStudent2\"\u003e select * from teacher where id = #{tid}; \u003c/select\u003e \u003cselect id=\"getStudentList2\" resultType=\"Student\"\u003e select * from student where tid = #{tid}; \u003c/select\u003e 按照结果嵌套处理 将每一个查询的字段均重新命名并重新映射 \u003cresultMap id=\"teacherStudent\" type=\"Teacher\"\u003e \u003cresult column=\"tid\" property=\"id\"/\u003e \u003cresult column=\"tname\" property=\"name\"/\u003e \u003ccollection ofType=\"Student\" property=\"students\"\u003e \u003cresult column=\"sid\" property=\"id\" /\u003e \u003cresult column=\"sname\" property=\"name\" /\u003e \u003cresult column=\"stid\" property=\"tid\" /\u003e \u003c/collection\u003e \u003c/resultMap\u003e \u003cselect id=\"getTeacherWithStudentList\" resultMap=\"teacherStudent\" \u003e select t.id tid, t.name tname, s.id sid, s.name sname, s.tid stid from teacher t join student s where t.id = s.tid and t.id = #{tid}; \u003c/select\u003e ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:15:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#一对多的处理"},{"categories":null,"content":"\r动态SQL：什么是动态SQL：指根据不同的条件生成不同的SQL语句（拼接SQL语句），在SQL层面去执行一个逻辑代码。 通过动态内容查询：如果map里有title那就以title为条件，如果map里有author那就以author为条件查询，如果都没有，那就查询所有 \u003cselect id=\"queryBookIf\" parameterType=\"map\" resultType=\"Blog\"\u003e select * from blog where 2\u003e1 \u003c!--if标签，test中为布尔类型表达式（过滤条件）--\u003e \u003cif test=\"title != null\"\u003e and title=#{title} \u003c/if\u003e \u003cif test=\"author != null\"\u003e and author=#{author} \u003c/if\u003e \u003c/select\u003e choose, when, otherwise标签 相当于switch case: …break; defaule \u003cselect id=\"findActiveBlogLike\" resultType=\"Blog\"\u003e SELECT * FROM BLOG WHERE state = ‘ACTIVE’ \u003cchoose\u003e \u003cwhen test=\"title != null\"\u003e AND title like #{title} \u003c/when\u003e \u003cwhen test=\"author != null and author.name != null\"\u003e AND author_name like #{author.name} \u003c/when\u003e \u003cotherwise\u003e AND featured = 1 \u003c/otherwise\u003e \u003c/choose\u003e \u003c/select\u003e if, trim, where/set trim自动去除那些标签的前缀/后缀 where 元素只会在子元素有返回任何内容的情况下才插入 “WHERE” 子句。 set会自动去除多余逗号， \u003cselect id=\"findActiveBlogLike\" resultType=\"Blog\"\u003e SELECT * FROM BLOG \u003cwhere\u003e \u003c!--这里的第一个and会自动插入--\u003e \u003cif test=\"state != null\"\u003e state = #{state} \u003c/if\u003e \u003cif test=\"title != null\"\u003e AND title like #{title} \u003c/if\u003e \u003cif test=\"author != null and author.name != null\"\u003e AND author_name like #{author.name} \u003c/if\u003e \u003c/where\u003e \u003c/select\u003e foreach 对传入的集合进行遍历（格式化）, 常用在in子句上 \u003cselect id=\"selectPostIn\" resultType=\"domain.blog.Post\" parameterType=\"map\"\u003e SELECT * FROM POST P WHERE ID in \u003c!--list是map中的一个key对应的是一个集合 最后拼接为：(item1, item2, item3, ... ) --\u003e \u003cforeach item=\"item\" index=\"index\" collection=\"list\" open=\"(\" separator=\",\" close=\")\"\u003e #{item} \u003c/foreach\u003e \u003c/select\u003e sql标签 把公用的sql代码块独立，允许多处include引用 注意1：最好基于单表来定义sql标签 注意2：不要存在where标签 \u003c!--公用的sql语句块--\u003e \u003csql id=\"if-title-author\"\u003e \u003cif test=\"title != null\"\u003e and title=#{title} \u003c/if\u003e \u003cif test=\"author != null\"\u003e and author=#{author} \u003c/if\u003e \u003c/sql\u003e \u003c!--通过动态内容查询：如果map里有title那就以title为条件，如果map里有author那就以author为条件查询，如果都没有，那就查询所有--\u003e \u003cselect id=\"queryBookIf\" parameterType=\"map\" resultType=\"Blog\"\u003e select * from blog \u003cwhere\u003e \u003cinclude refid=\"if-title-author\"\u003e\u003c/include\u003e \u003c/where\u003e \u003c/select\u003e ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:16:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#动态sql"},{"categories":null,"content":"\r缓存：什么是缓存：临时放在内存中的表数据信息 为什么使用缓存：减少和数据库的交互次数，减少系统开销，提高系统效率 什么样的数据适合使用缓存：经常查询并不经常改变的数据 一级缓存：默认开启，SqlSession级别，本地缓存（最近最少使用） LRU：移除最长时间不用的缓存 一级缓存是以statemntId, param, boundsql, rowsbound为key的hashmap,在下次如果下次查询也匹配到了这个key, 就可以直接取出这个对象而不用去查数据库 当前会话被关闭时，一级缓存就没了，就可以从二级缓存中获取内容 select语句使用缓存， insert、update、delete语句刷新缓存 sqlSession.clearCache()清理缓存 二级缓存：手动开启，namespace级别，全局缓存（先进先出） 当前会话被关闭时，一级缓存就没了，就可以从二级缓存中获取内容（同一个mapper内共享二级缓存） 开启方式： 在mybatis-config.xml中添加setting \u003c!--显式的开启全局缓存--\u003e \u003csetting name=\"cacheEnabled\" value=\"true\"/\u003e 在mapper.xml中添加行 \u003c!--开启二级缓存--\u003e \u003ccache/\u003e 或 \u003ccache eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\"/\u003e 二级缓存问题： \u003ccache/\u003e标签默认readOnly为false，需要实例化实体类解决 用户在查询时先经过mapper，先看二级缓存有没有，再看一级缓存有没有，如果都没有才会查询数据库 自定义缓存： 在cache标签中执行type属性 ehcache：hibernate用到了，略 redis的缓存，略 ","date":"2021-08-22","objectID":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/:17:0","series":null,"tags":null,"title":"MyBatis自学笔记","uri":"/mybatis%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/#缓存"},{"categories":null,"content":"\rSpringCloud 自学笔记 大连交通大学 信息学院 刘嘉宁 笔记摘自 尚硅谷 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:0:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springcloud-自学笔记"},{"categories":null,"content":"\r什么是 SpringCloud 最早是由奶飞公司提出的分布式解决方案，后来被 Spring 公司抄了作业 所有请求都由 服务网关 通过 服务注册和发现 根据 配置中心 找到对应的 SpringBoot 服务模块进行协调和调度 如果有容错 和 限流 比如 降级、熔断 进行服务监控、健康检查和报警 是分布式微服务架构的一站式解决方案 是多种微服务架构落地技术的集合体 是一系列技术的集合，俗称微服务全家桶 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:1:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-springcloud"},{"categories":null,"content":"\r什么是分布式、什么是微服务","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是分布式什么是微服务"},{"categories":null,"content":"\r什么是分布式 分布式系统就是把所有的程序、功能拆分成不同的子系统，部署在多台不同的服务器上 这些子系统相互协作共同对外提供服务，而对用户而言他并不知道后台是多个子系统和多台服务器在提供服务，在使用上和集中式系统一样 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是分布式"},{"categories":null,"content":"\r什么是微服务 微服务是系统架构上的一种设计风格， 它的主旨是将一个原本独立的系统拆分成多个小型服务 这些小型服务都在各自独立的进程中运行，服务之间通过基于 HTTP 的 RESTful API 进行通信协作 被拆分后的每一个小型服务都围绕着系统中的某一项业务功能进行构建， 并且每个服务都是一个独立的项目，可以进行独立的测试、开发和部署等 由于各个独立的服务之间使用的是基于 HTTP 的作为数据通信协作的基础，所以这些微服务可以使用不同的语言来开发 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是微服务"},{"categories":null,"content":"\r两者的区别 分布式强调系统的拆分，微服务也是强调系统的拆分，微服务架构属于分布式架构的范畴 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:2:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#两者的区别"},{"categories":null,"content":"\r微服务架构的优缺点优点： 将系统中的不同功能模块拆分成多个不同的服务，独立地开发和部署，都运行在自己的进程内，每个服务的更新都不影响其他服务的运行 由于是独立部署的，可以更准确地监控每个服务的资源消耗情况，进行性能容量的评估，通过压力测试，也很容易发现各个服务间的性能瓶颈所在 独立开发比较方便，减少代码的冲突、代码的重复，逻辑更加清晰，易于后续的维护与扩展 可以使用不同的编程语言进行开发 缺点： 微服务架构增加了系统维护、部署的难度，导致一些功能模块或代码无法复用 随着系统规模的日渐增长，微服务在一定程度上也会导致系统变得越来越复杂，增加了集成测试的复杂度 随着微服务的增多，数据的一致性问题，服务之间的通信成本等都凸显了出来 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:3:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#微服务架构的优缺点"},{"categories":null,"content":"\rBoot 和 Cloud 版本对应关系 SpringCloud 使用伦敦地铁站命名其版本，Axxx ~ Zxxx (目前 Kilburn 3.0.x) 每当重大 BUG 被修复，就会发布一个 SR (Server Releases 版本) 2021年 Hoxton.SR12 第十二个版本 2020 年开始强烈推荐升级到 SpringCloud 2.0 以上版本 SpringCloud 官网版本对应推荐 https://start.spring.io/actuator/info 在 SpringCloud 官网 LEARN 标签中查看推荐的对应 Boot 版本 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:4:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#boot-和-cloud-版本对应关系"},{"categories":null,"content":"\rSpringCloud 组件的变更\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:5:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springcloud-组件的变更"},{"categories":null,"content":"\r创建 SpringCloud 工程 编程风格：约定 \u003e 配置 \u003e 编码 创建详情见 angenin 的博客笔记 SpringCloud(H版\u0026Alibaba)技术（1-4基础入门，创建项目）CSDN博客 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建-springcloud-工程"},{"categories":null,"content":"\r什么是 RestTemplate RestTemplate 是一个同步的 web http 客户端请求模板工具 它封装了http连接, 可以向一个 REST 接口发送请求并获取响应 postForObject 请求地址，请求参数，返回的对象类型 getForObject 请求地址，返回的对象类型 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-resttemplate"},{"categories":null,"content":"\r如何导入团队自己的工具包 在一个项目中创建多个模块，其中一个专门用来做工具包模块 将自己团队写的 commons 模块使用 maven install 到自己本地仓库中 在需要的模块的 pom 文件中导入工具模块的依赖，实现一处修改处处应用 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#如何导入团队自己的工具包"},{"categories":null,"content":"\rSpringBoot 一般通用配置 pom.xml \u003c!-- 一般通用配置 --\u003e \u003c!-- SpringBoot WEB 启动依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- SpringBoot 测试启动依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c!-- SpringBoot 热部署依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-devtools\u003c/artifactId\u003e \u003cscope\u003eruntime\u003c/scope\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e \u003c!-- lombok 注解开发 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:6:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springboot-一般通用配置-pomxml"},{"categories":null,"content":"\rEureka 服务注册与发现【维护】","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#eureka-服务注册与发现维护"},{"categories":null,"content":"\r什么是服务治理 在传统 RPC 远程调用框架中，管理每个服务与服务之间依赖关系比较复杂 服务治理就是实现服务调用、负载均衡、容错等，实现服务发现与注册 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是服务治理"},{"categories":null,"content":"\r什么是服务发现与注册 在 RPC 远程调用框架核心设计思想在于注册中心, 使用注册中心 (存放服务地址相关信息 (接口地址) ) 管理每个服务与服务之间的一个依赖关系【服务治理】 当服务器启动的时候，会把当前自己服务器的信息 (服务地址、通信地址) 等以别名方式注册到注册中心上，消费者/服务提供者 以该别名的方式去注册中心上获取到实际的服务通信地址，然后再实现 RPC 调用 Eureka 从用 C/S 的设计架构，Eureka Server 作为注册中心，其它微服务使用 Eureka 客户端连接到注册中心并维持心跳连接，维护人员通过 Eureka Server 来监控系统中各个微服务是否运行正常 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是服务发现与注册"},{"categories":null,"content":"\r搭建 Eureka 工程\r创建 Eureka Server 工程步骤 添加 pom 依赖 \u003c!-- eureka-server --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 监控 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 引用自己定义的 api 通用包，可以使用 Payment 支付 Entity --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.atguigu.springcloud\u003c/groupId\u003e \u003cartifactId\u003ecloud-api-commons\u003c/artifactId\u003e \u003cversion\u003e${project.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 一般通用配置 --\u003e 配置 application.yml server: port: 7001 eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false 表示不向注册中心注册自己（想注册也可以，不过没必要） register-with-eureka: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去 检索服务 fetch-registry: false service-url: # 设置与 eurekaServer 交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 在启动类上添加注解 @SpringBootApplication @EnableEurekaServer // 标识此工程是 Eureka Server 服务注册中心 public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run(EurekaMain7001.class, args); } } 访问 localhost:7001 看到 application 为空的，因为此时还没有其它项目注册进来 修改 Eureka Client 工程步骤 添加 Eureka Client 依赖 \u003c!-- eureka-client --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e 在 application.yml 中添加 # 此微服务项目的别名就是上面配置的 spring.application.name eureka: client: # true 表示向注册中心注册自己，默认为 true register-with-eureka: true # 是否从 EurekaServer 抓取已有的注册信息，默认为 true。单节点无所谓，集群必须设置为 true 才能配合 ribbon 使用负载均衡 fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 在启动类上添加注解 @EnableEurekaClient 访问 localhost:7001 看到 application 已经有项目注册进来了applicaiton 的项目名就是在 yml 中配置的 spring.application.name 名称 搭建 Eureka 注册中心集群\r为避免单一注册中心突然宕机导致整体项目不可用，搭建注册中心集群实现 负载均衡、故障容错 Eureka 注册中心集群：相互注册，相互守望 修改 hosts 文件，添加 # 以下为 SpringCloud Eureka 注册中心集群配置 127.0.0.1 eureka7001.com 127.0.0.1 eureka7002.com 127.0.0.1 eureka7003.com 修改两个注册中心的 yml 配置文件 hostname 和 defaultZone 首尾相连，7001 注册 7002，7002 注册 7001 如果是三台互相映射，那么 defaultZone 应写两个地址中间逗号分隔 访问测试 修改生产者和消费者模块的 yml #集群版 defaultZone: http://eureka7001:7001/eureka/,http://eureka7002:7002/eureka/ 启动顺序 先启动 Eureka 注册中心集群 启动生产者服务 启动消费者服务 搭建 生产者 集群 根据原有生产者复制出一份 使用相同的微服务名，修改端口地址 可以看到注册中心中生产者有两个 修改 消费者 连接地址为 生产者服务名 开启 RestTemplate 的负载均衡功能 Ribbon 默认为轮询的负载均衡策略，一次访问 8001 一次访问 8002 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-eureka-工程"},{"categories":null,"content":"\r搭建 Eureka 工程\r创建 Eureka Server 工程步骤 添加 pom 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-server org.springframework.boot spring-boot-starter-actuator com.atguigu.springcloud cloud-api-commons ${project.version} 配置 application.yml server: port: 7001 eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false 表示不向注册中心注册自己（想注册也可以，不过没必要） register-with-eureka: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去 检索服务 fetch-registry: false service-url: # 设置与 eurekaServer 交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 在启动类上添加注解 @SpringBootApplication @EnableEurekaServer // 标识此工程是 Eureka Server 服务注册中心 public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run(EurekaMain7001.class, args); } } 访问 localhost:7001 看到 application 为空的，因为此时还没有其它项目注册进来 修改 Eureka Client 工程步骤 添加 Eureka Client 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 在 application.yml 中添加 # 此微服务项目的别名就是上面配置的 spring.application.name eureka: client: # true 表示向注册中心注册自己，默认为 true register-with-eureka: true # 是否从 EurekaServer 抓取已有的注册信息，默认为 true。单节点无所谓，集群必须设置为 true 才能配合 ribbon 使用负载均衡 fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 在启动类上添加注解 @EnableEurekaClient 访问 localhost:7001 看到 application 已经有项目注册进来了applicaiton 的项目名就是在 yml 中配置的 spring.application.name 名称 搭建 Eureka 注册中心集群\r为避免单一注册中心突然宕机导致整体项目不可用，搭建注册中心集群实现 负载均衡、故障容错 Eureka 注册中心集群：相互注册，相互守望 修改 hosts 文件，添加 # 以下为 SpringCloud Eureka 注册中心集群配置 127.0.0.1 eureka7001.com 127.0.0.1 eureka7002.com 127.0.0.1 eureka7003.com 修改两个注册中心的 yml 配置文件 hostname 和 defaultZone 首尾相连，7001 注册 7002，7002 注册 7001 如果是三台互相映射，那么 defaultZone 应写两个地址中间逗号分隔 访问测试 修改生产者和消费者模块的 yml #集群版 defaultZone: http://eureka7001:7001/eureka/,http://eureka7002:7002/eureka/ 启动顺序 先启动 Eureka 注册中心集群 启动生产者服务 启动消费者服务 搭建 生产者 集群 根据原有生产者复制出一份 使用相同的微服务名，修改端口地址 可以看到注册中心中生产者有两个 修改 消费者 连接地址为 生产者服务名 开启 RestTemplate 的负载均衡功能 Ribbon 默认为轮询的负载均衡策略，一次访问 8001 一次访问 8002 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建-eureka-server-工程步骤"},{"categories":null,"content":"\r搭建 Eureka 工程\r创建 Eureka Server 工程步骤 添加 pom 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-server org.springframework.boot spring-boot-starter-actuator com.atguigu.springcloud cloud-api-commons ${project.version} 配置 application.yml server: port: 7001 eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false 表示不向注册中心注册自己（想注册也可以，不过没必要） register-with-eureka: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去 检索服务 fetch-registry: false service-url: # 设置与 eurekaServer 交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 在启动类上添加注解 @SpringBootApplication @EnableEurekaServer // 标识此工程是 Eureka Server 服务注册中心 public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run(EurekaMain7001.class, args); } } 访问 localhost:7001 看到 application 为空的，因为此时还没有其它项目注册进来 修改 Eureka Client 工程步骤 添加 Eureka Client 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 在 application.yml 中添加 # 此微服务项目的别名就是上面配置的 spring.application.name eureka: client: # true 表示向注册中心注册自己，默认为 true register-with-eureka: true # 是否从 EurekaServer 抓取已有的注册信息，默认为 true。单节点无所谓，集群必须设置为 true 才能配合 ribbon 使用负载均衡 fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 在启动类上添加注解 @EnableEurekaClient 访问 localhost:7001 看到 application 已经有项目注册进来了applicaiton 的项目名就是在 yml 中配置的 spring.application.name 名称 搭建 Eureka 注册中心集群\r为避免单一注册中心突然宕机导致整体项目不可用，搭建注册中心集群实现 负载均衡、故障容错 Eureka 注册中心集群：相互注册，相互守望 修改 hosts 文件，添加 # 以下为 SpringCloud Eureka 注册中心集群配置 127.0.0.1 eureka7001.com 127.0.0.1 eureka7002.com 127.0.0.1 eureka7003.com 修改两个注册中心的 yml 配置文件 hostname 和 defaultZone 首尾相连，7001 注册 7002，7002 注册 7001 如果是三台互相映射，那么 defaultZone 应写两个地址中间逗号分隔 访问测试 修改生产者和消费者模块的 yml #集群版 defaultZone: http://eureka7001:7001/eureka/,http://eureka7002:7002/eureka/ 启动顺序 先启动 Eureka 注册中心集群 启动生产者服务 启动消费者服务 搭建 生产者 集群 根据原有生产者复制出一份 使用相同的微服务名，修改端口地址 可以看到注册中心中生产者有两个 修改 消费者 连接地址为 生产者服务名 开启 RestTemplate 的负载均衡功能 Ribbon 默认为轮询的负载均衡策略，一次访问 8001 一次访问 8002 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#修改-eureka-client-工程步骤"},{"categories":null,"content":"\r搭建 Eureka 工程\r创建 Eureka Server 工程步骤 添加 pom 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-server org.springframework.boot spring-boot-starter-actuator com.atguigu.springcloud cloud-api-commons ${project.version} 配置 application.yml server: port: 7001 eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false 表示不向注册中心注册自己（想注册也可以，不过没必要） register-with-eureka: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去 检索服务 fetch-registry: false service-url: # 设置与 eurekaServer 交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 在启动类上添加注解 @SpringBootApplication @EnableEurekaServer // 标识此工程是 Eureka Server 服务注册中心 public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run(EurekaMain7001.class, args); } } 访问 localhost:7001 看到 application 为空的，因为此时还没有其它项目注册进来 修改 Eureka Client 工程步骤 添加 Eureka Client 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 在 application.yml 中添加 # 此微服务项目的别名就是上面配置的 spring.application.name eureka: client: # true 表示向注册中心注册自己，默认为 true register-with-eureka: true # 是否从 EurekaServer 抓取已有的注册信息，默认为 true。单节点无所谓，集群必须设置为 true 才能配合 ribbon 使用负载均衡 fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 在启动类上添加注解 @EnableEurekaClient 访问 localhost:7001 看到 application 已经有项目注册进来了applicaiton 的项目名就是在 yml 中配置的 spring.application.name 名称 搭建 Eureka 注册中心集群\r为避免单一注册中心突然宕机导致整体项目不可用，搭建注册中心集群实现 负载均衡、故障容错 Eureka 注册中心集群：相互注册，相互守望 修改 hosts 文件，添加 # 以下为 SpringCloud Eureka 注册中心集群配置 127.0.0.1 eureka7001.com 127.0.0.1 eureka7002.com 127.0.0.1 eureka7003.com 修改两个注册中心的 yml 配置文件 hostname 和 defaultZone 首尾相连，7001 注册 7002，7002 注册 7001 如果是三台互相映射，那么 defaultZone 应写两个地址中间逗号分隔 访问测试 修改生产者和消费者模块的 yml #集群版 defaultZone: http://eureka7001:7001/eureka/,http://eureka7002:7002/eureka/ 启动顺序 先启动 Eureka 注册中心集群 启动生产者服务 启动消费者服务 搭建 生产者 集群 根据原有生产者复制出一份 使用相同的微服务名，修改端口地址 可以看到注册中心中生产者有两个 修改 消费者 连接地址为 生产者服务名 开启 RestTemplate 的负载均衡功能 Ribbon 默认为轮询的负载均衡策略，一次访问 8001 一次访问 8002 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-eureka-注册中心集群"},{"categories":null,"content":"\r搭建 Eureka 工程\r创建 Eureka Server 工程步骤 添加 pom 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-server org.springframework.boot spring-boot-starter-actuator com.atguigu.springcloud cloud-api-commons ${project.version} 配置 application.yml server: port: 7001 eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false 表示不向注册中心注册自己（想注册也可以，不过没必要） register-with-eureka: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去 检索服务 fetch-registry: false service-url: # 设置与 eurekaServer 交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 在启动类上添加注解 @SpringBootApplication @EnableEurekaServer // 标识此工程是 Eureka Server 服务注册中心 public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run(EurekaMain7001.class, args); } } 访问 localhost:7001 看到 application 为空的，因为此时还没有其它项目注册进来 修改 Eureka Client 工程步骤 添加 Eureka Client 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 在 application.yml 中添加 # 此微服务项目的别名就是上面配置的 spring.application.name eureka: client: # true 表示向注册中心注册自己，默认为 true register-with-eureka: true # 是否从 EurekaServer 抓取已有的注册信息，默认为 true。单节点无所谓，集群必须设置为 true 才能配合 ribbon 使用负载均衡 fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 在启动类上添加注解 @EnableEurekaClient 访问 localhost:7001 看到 application 已经有项目注册进来了applicaiton 的项目名就是在 yml 中配置的 spring.application.name 名称 搭建 Eureka 注册中心集群\r为避免单一注册中心突然宕机导致整体项目不可用，搭建注册中心集群实现 负载均衡、故障容错 Eureka 注册中心集群：相互注册，相互守望 修改 hosts 文件，添加 # 以下为 SpringCloud Eureka 注册中心集群配置 127.0.0.1 eureka7001.com 127.0.0.1 eureka7002.com 127.0.0.1 eureka7003.com 修改两个注册中心的 yml 配置文件 hostname 和 defaultZone 首尾相连，7001 注册 7002，7002 注册 7001 如果是三台互相映射，那么 defaultZone 应写两个地址中间逗号分隔 访问测试 修改生产者和消费者模块的 yml #集群版 defaultZone: http://eureka7001:7001/eureka/,http://eureka7002:7002/eureka/ 启动顺序 先启动 Eureka 注册中心集群 启动生产者服务 启动消费者服务 搭建 生产者 集群 根据原有生产者复制出一份 使用相同的微服务名，修改端口地址 可以看到注册中心中生产者有两个 修改 消费者 连接地址为 生产者服务名 开启 RestTemplate 的负载均衡功能 Ribbon 默认为轮询的负载均衡策略，一次访问 8001 一次访问 8002 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-生产者-集群"},{"categories":null,"content":"\r信息功能完善及修改 服务名称修改 为生产者添加 eureka.instance.instance-id 属性值 添加访问路径 IP 信息 在生产者配置 yml 中添加 eureka.instance.prefer-ip-address 属性值为 true ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#信息功能完善及修改"},{"categories":null,"content":"\r服务发现 Discovery 通过 服务发现 来获取 Eureka 中现有微服务的信息 为微服务注入 DiscoveryClient @Resource private DiscoveryClient discoveryClient; 通过其 getServices()、discoveryClient.getInstances(\"服务名\") 可以获取到对应服务的一些基本信息 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务发现-discovery"},{"categories":null,"content":"\rEureka 的自我保护机制 在一组客户端与 eureka server 存在网络分区时会自动开启保护，会保护服务注册表中的信息，不会删除注册表中的信息，不会注销任何微服务 出现这一行红字就是保护模式，这属于 CAP 中的 AP 分支 默认情况下 Eureka Server 在一定时间内没有收到某个微服务实例的心跳，将会注销该实例（默认 90 秒） 但是因为网络卡顿、延时、拥挤时，微服务还是健康的，此时并不应该删除该微服务【高可用，健壮性】 所以 Eureka 在短时间内丢失过多客户端时就会自动进入保护模式，宁可保留错误的信息也不盲目注销任何可能健康的服务实例 如何关闭自我保护机制 配置 Eureka Server 注册中心配置 修改 eureka 客户端心跳间隔和直线上限时间 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#eureka-的自我保护机制"},{"categories":null,"content":"\rEureka 的自我保护机制 在一组客户端与 eureka server 存在网络分区时会自动开启保护，会保护服务注册表中的信息，不会删除注册表中的信息，不会注销任何微服务 出现这一行红字就是保护模式，这属于 CAP 中的 AP 分支 默认情况下 Eureka Server 在一定时间内没有收到某个微服务实例的心跳，将会注销该实例（默认 90 秒） 但是因为网络卡顿、延时、拥挤时，微服务还是健康的，此时并不应该删除该微服务【高可用，健壮性】 所以 Eureka 在短时间内丢失过多客户端时就会自动进入保护模式，宁可保留错误的信息也不盲目注销任何可能健康的服务实例 如何关闭自我保护机制 配置 Eureka Server 注册中心配置 修改 eureka 客户端心跳间隔和直线上限时间 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:7:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#如何关闭自我保护机制"},{"categories":null,"content":"\rZookeeper 服务注册与发现 Zookeeper 是一个分布式协调工具，可以实现注册中心功能 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#zookeeper-服务注册与发现"},{"categories":null,"content":"\r临时节点 or 持久节点 Zookeeper 也是有心跳机制，在一定时间内如果一直没心跳返回，Zookeeper就会把服务节点剔除掉 在 Eureka 中如果没有心跳了还会再保护模式中继续服务，所以在 Zookeeper 上的服务节点是 临时节点 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#临时节点-or-持久节点"},{"categories":null,"content":"\r搭建 Zookeeper 工程\r创建 Zookeeper 生产者步骤 在虚拟机中使用 docker 搭建 Zookeeper 服务 略 创建生产者工程，添加 pom 依赖 \u003c!-- Zookeeper --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-zookeeper-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 配置 yml 文件 server: port: 8004 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Zookeeper 到注册中心名称 cloud: zookeeper: connect-string: 192.168.30.129:2181 在主启动类上添加注解 @SpringBootApplication @EnableDiscoveryClient // 该注解用于向使用 consul 或者 Zookeeper 作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run(PaymentMain8004.class, args); } } 进入 docker 中的 zookeeper 并查看当前服务 在有服务连接到 zookeeper 之后 ls / 即可看到 services 目录 services 目录中可以看到在生产者中配置好的微服务别名, 其中可以看到服务流水号 使用 get 命令获取某一服务中的某一注册相关信息 (JSON 格式) 创建 Zookeeper 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Zookeeper 服务中看到消费者别名 Zookeeper 注册中心集群 在不同的服务器中创建多个 Zookeeper 服务 在 yml 配置类中 connect-string: IP:端口, IP:端口 即可 遇到的问题：依赖冲突 由于服务器中 zookeeper 版本较低，而 SpringBoot 启动依赖中默认版本较高 在 POM 中排除自带的高版本 Zookeeper 依赖，自行引入对应版本的依赖即可 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-zookeeper-discovery\u003c/artifactId\u003e \u003cexclusions\u003e \u003c!--先排除自带的zookeeper3.5.3--\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.apache.zookeeper\u003c/groupId\u003e \u003cartifactId\u003ezookeeper\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003c!--添加zookeeper3.4.9版本（引入对应版本的依赖）--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.zookeeper\u003c/groupId\u003e \u003cartifactId\u003ezookeeper\u003c/artifactId\u003e \u003cversion\u003e3.4.9\u003c/version\u003e \u003c/dependency\u003e ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-zookeeper-工程"},{"categories":null,"content":"\r搭建 Zookeeper 工程\r创建 Zookeeper 生产者步骤 在虚拟机中使用 docker 搭建 Zookeeper 服务 略 创建生产者工程，添加 pom 依赖 org.springframework.cloud spring-cloud-starter-zookeeper-discovery 配置 yml 文件 server: port: 8004 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Zookeeper 到注册中心名称 cloud: zookeeper: connect-string: 192.168.30.129:2181 在主启动类上添加注解 @SpringBootApplication @EnableDiscoveryClient // 该注解用于向使用 consul 或者 Zookeeper 作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run(PaymentMain8004.class, args); } } 进入 docker 中的 zookeeper 并查看当前服务 在有服务连接到 zookeeper 之后 ls / 即可看到 services 目录 services 目录中可以看到在生产者中配置好的微服务别名, 其中可以看到服务流水号 使用 get 命令获取某一服务中的某一注册相关信息 (JSON 格式) 创建 Zookeeper 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Zookeeper 服务中看到消费者别名 Zookeeper 注册中心集群 在不同的服务器中创建多个 Zookeeper 服务 在 yml 配置类中 connect-string: IP:端口, IP:端口 即可 遇到的问题：依赖冲突 由于服务器中 zookeeper 版本较低，而 SpringBoot 启动依赖中默认版本较高 在 POM 中排除自带的高版本 Zookeeper 依赖，自行引入对应版本的依赖即可 org.springframework.cloud spring-cloud-starter-zookeeper-discovery org.apache.zookeeper zookeeper org.apache.zookeeper zookeeper 3.4.9 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建-zookeeper-生产者步骤"},{"categories":null,"content":"\r搭建 Zookeeper 工程\r创建 Zookeeper 生产者步骤 在虚拟机中使用 docker 搭建 Zookeeper 服务 略 创建生产者工程，添加 pom 依赖 org.springframework.cloud spring-cloud-starter-zookeeper-discovery 配置 yml 文件 server: port: 8004 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Zookeeper 到注册中心名称 cloud: zookeeper: connect-string: 192.168.30.129:2181 在主启动类上添加注解 @SpringBootApplication @EnableDiscoveryClient // 该注解用于向使用 consul 或者 Zookeeper 作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run(PaymentMain8004.class, args); } } 进入 docker 中的 zookeeper 并查看当前服务 在有服务连接到 zookeeper 之后 ls / 即可看到 services 目录 services 目录中可以看到在生产者中配置好的微服务别名, 其中可以看到服务流水号 使用 get 命令获取某一服务中的某一注册相关信息 (JSON 格式) 创建 Zookeeper 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Zookeeper 服务中看到消费者别名 Zookeeper 注册中心集群 在不同的服务器中创建多个 Zookeeper 服务 在 yml 配置类中 connect-string: IP:端口, IP:端口 即可 遇到的问题：依赖冲突 由于服务器中 zookeeper 版本较低，而 SpringBoot 启动依赖中默认版本较高 在 POM 中排除自带的高版本 Zookeeper 依赖，自行引入对应版本的依赖即可 org.springframework.cloud spring-cloud-starter-zookeeper-discovery org.apache.zookeeper zookeeper org.apache.zookeeper zookeeper 3.4.9 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建-zookeeper-消费者步骤"},{"categories":null,"content":"\r搭建 Zookeeper 工程\r创建 Zookeeper 生产者步骤 在虚拟机中使用 docker 搭建 Zookeeper 服务 略 创建生产者工程，添加 pom 依赖 org.springframework.cloud spring-cloud-starter-zookeeper-discovery 配置 yml 文件 server: port: 8004 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Zookeeper 到注册中心名称 cloud: zookeeper: connect-string: 192.168.30.129:2181 在主启动类上添加注解 @SpringBootApplication @EnableDiscoveryClient // 该注解用于向使用 consul 或者 Zookeeper 作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run(PaymentMain8004.class, args); } } 进入 docker 中的 zookeeper 并查看当前服务 在有服务连接到 zookeeper 之后 ls / 即可看到 services 目录 services 目录中可以看到在生产者中配置好的微服务别名, 其中可以看到服务流水号 使用 get 命令获取某一服务中的某一注册相关信息 (JSON 格式) 创建 Zookeeper 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Zookeeper 服务中看到消费者别名 Zookeeper 注册中心集群 在不同的服务器中创建多个 Zookeeper 服务 在 yml 配置类中 connect-string: IP:端口, IP:端口 即可 遇到的问题：依赖冲突 由于服务器中 zookeeper 版本较低，而 SpringBoot 启动依赖中默认版本较高 在 POM 中排除自带的高版本 Zookeeper 依赖，自行引入对应版本的依赖即可 org.springframework.cloud spring-cloud-starter-zookeeper-discovery org.apache.zookeeper zookeeper org.apache.zookeeper zookeeper 3.4.9 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#zookeeper-注册中心集群"},{"categories":null,"content":"\r搭建 Zookeeper 工程\r创建 Zookeeper 生产者步骤 在虚拟机中使用 docker 搭建 Zookeeper 服务 略 创建生产者工程，添加 pom 依赖 org.springframework.cloud spring-cloud-starter-zookeeper-discovery 配置 yml 文件 server: port: 8004 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Zookeeper 到注册中心名称 cloud: zookeeper: connect-string: 192.168.30.129:2181 在主启动类上添加注解 @SpringBootApplication @EnableDiscoveryClient // 该注解用于向使用 consul 或者 Zookeeper 作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run(PaymentMain8004.class, args); } } 进入 docker 中的 zookeeper 并查看当前服务 在有服务连接到 zookeeper 之后 ls / 即可看到 services 目录 services 目录中可以看到在生产者中配置好的微服务别名, 其中可以看到服务流水号 使用 get 命令获取某一服务中的某一注册相关信息 (JSON 格式) 创建 Zookeeper 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Zookeeper 服务中看到消费者别名 Zookeeper 注册中心集群 在不同的服务器中创建多个 Zookeeper 服务 在 yml 配置类中 connect-string: IP:端口, IP:端口 即可 遇到的问题：依赖冲突 由于服务器中 zookeeper 版本较低，而 SpringBoot 启动依赖中默认版本较高 在 POM 中排除自带的高版本 Zookeeper 依赖，自行引入对应版本的依赖即可 org.springframework.cloud spring-cloud-starter-zookeeper-discovery org.apache.zookeeper zookeeper org.apache.zookeeper zookeeper 3.4.9 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:8:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#遇到的问题依赖冲突"},{"categories":null,"content":"\rConsul 服务注册与发现 官网：https://www.consul.io/intro/index.html 是一套开源的，分布式服务发现 和 配置管理系统 由 HashiCorp 公司用 go 语言开发 主要特点 服务发现：Consul 的客户端可以注册服务，例如 api 或 mysql，其他客户端可以使用 Consul 来发现给定服务的提供者。使用 DNS 或 HTTP，应用程序可以轻松找到它们依赖的服务 健康检测：Consul 客户端可以提供任意数量的运行状况检查，这些检查可以与给定服务（“ Web服务器是否返回 200 OK”）或本地节点（“内存利用率低于90％”）相关。操作员可以使用此信息来监视群集的运行状况，服务发现组件可以使用此信息将流量从不正常的主机发送出去 K-V存储：应用程序可以将 Consul 的分层 键/值 存储用于多种目的，包括动态配置，功能标记，协调，领导者选举等。简单的 HTTP API 使其易于使用 安全的服务通信：Consul 可以为服务生成并分发 TLS 证书，以建立相互 TLS 连接。 意图可用于定义允许哪些服务进行通信。可以使用可以实时更改的意图轻松管理服务分段，而不必使用复杂的网络拓扑和静态防火墙规则 多数据中心：Consul 开箱即用地支持多个数据中心。这意味着 Consul 的用户不必担心会构建其他抽象层以扩展到多个区域 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#consul-服务注册与发现"},{"categories":null,"content":"\r搭建 Consul 工程 在虚拟机中使用 docker 搭建 consul 服务 成功后即可根据虚拟机 IP:8500 进入 consul 管理页面 创建 Consul 生产者步骤 创建生产者工程，配置 POM 文件 \u003c!-- consul --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-consul-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 编写 YML 配置文件 server: port: 8006 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Consul cloud: consul: host: 192.168.30.129 port: 8500 discovery: service-name: ${spring.application.name} # 添加下方配置解决 Consul 红叉问题 heartbeat: enabled: true 在主启动类上添加注解 @EnableDiscoveryClient 在 Consul 的 UI 界面可以看到刚刚注册的生产者服务 此处可以看到服务列表，点进去看到其中有哪些服务实例 创建 Consul 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Consul UI 中看到消费者别名 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-consul-工程"},{"categories":null,"content":"\r搭建 Consul 工程 在虚拟机中使用 docker 搭建 consul 服务 成功后即可根据虚拟机 IP:8500 进入 consul 管理页面 创建 Consul 生产者步骤 创建生产者工程，配置 POM 文件 org.springframework.cloud spring-cloud-starter-consul-discovery 编写 YML 配置文件 server: port: 8006 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Consul cloud: consul: host: 192.168.30.129 port: 8500 discovery: service-name: ${spring.application.name} # 添加下方配置解决 Consul 红叉问题 heartbeat: enabled: true 在主启动类上添加注解 @EnableDiscoveryClient 在 Consul 的 UI 界面可以看到刚刚注册的生产者服务 此处可以看到服务列表，点进去看到其中有哪些服务实例 创建 Consul 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Consul UI 中看到消费者别名 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建-consul-生产者步骤"},{"categories":null,"content":"\r搭建 Consul 工程 在虚拟机中使用 docker 搭建 consul 服务 成功后即可根据虚拟机 IP:8500 进入 consul 管理页面 创建 Consul 生产者步骤 创建生产者工程，配置 POM 文件 org.springframework.cloud spring-cloud-starter-consul-discovery 编写 YML 配置文件 server: port: 8006 spring: # 服务别名 application: name: cloud-provider-payment # 注册 Consul cloud: consul: host: 192.168.30.129 port: 8500 discovery: service-name: ${spring.application.name} # 添加下方配置解决 Consul 红叉问题 heartbeat: enabled: true 在主启动类上添加注解 @EnableDiscoveryClient 在 Consul 的 UI 界面可以看到刚刚注册的生产者服务 此处可以看到服务列表，点进去看到其中有哪些服务实例 创建 Consul 消费者步骤 添加上方同一个依赖 配置上方 yml 文件，注意修改 端口号 和 微服务别名 在主启动类上添加注解 @EnableDiscoveryClient 编写配置类，注意添加 @LoadBalanced 为 RestTemplate 开启负载浚航，配置业务类 开启服务即可在 Consul UI 中看到消费者别名 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:9:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#创建-consul-消费者步骤"},{"categories":null,"content":"\r服务注册与发现 三者的异同 组件名 语言 CAP 服务健康检查 对外暴露接口 SpringCloud 集成 Eureka Java AP 可配 HTTP 已集成 Zookeeper Java CP 支持 客户端 已集成 Consul GO CP 支持 HTPP / DNS 已集成 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务注册与发现-三者的异同"},{"categories":null,"content":"\r什么是 CAP C**（Consistency）**：一致性 A**（Availability）**：可用性 P**（Partition tolerance）**：分区容错性（微服务架构必须保证有P） CAP 理论关注数据是粒度，而不是整体系统设计的策略 Eureka 保证了 AP： 当网络分区出现后，为了保证可用性，系统 B 可以返回旧值，保证系统的可用性。 结论：违背了 一致性 C 的要求，只满足可用性和分区容错，即 AP Consul 和 zookeeper 保证了 CP： 当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性 结论：违背了 可用性 A 的要求，只满足一致性和分区容错，即 CP ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:10:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-cap"},{"categories":null,"content":"\rRibbon 负载均衡服务调用【维护】 Ribbon 是 Netflix 实现的一套客户端 提供客户端的软件 负载均衡 算法和 服务调用，提供完善的配置项（连接超时、重试） Load Balancer（LB）的所有机器，Ribbon 会自动的根据负载均衡规则连接，并且可以很容易的自定义负载均衡算法 在 SpringBoot 提供的 Eureka Client 启动依赖中已经引入了 Ribbon ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ribbon-负载均衡服务调用维护"},{"categories":null,"content":"\r什么是负载均衡 就是将用户的请求平摊到多个服务上，从而达到系统的 HA（高可用） Nginx、LVS、硬件 F5 等 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是负载均衡"},{"categories":null,"content":"\rRibbon 与 Nginx 的区别 Ribbon 是本地负载均衡客户端【进程内 LB】将注册中心的注册信息缓存到 JVM 中，从而在本地实现 RPC 远程服务调用 Nginx 是服务端负载均衡【集中式 LB】客户端的所有请求都会交给 Nginx 实现请求转发，属于是看大门的服务端 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ribbon-与-nginx-的区别"},{"categories":null,"content":"\rRibbon 的工作流程 选择同一区域内负载较少的注册中心 Server 根据用户指定的策略，在 Server 取到的服务注册列表中选择一个地址 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ribbon-的工作流程"},{"categories":null,"content":"\r重温 RestTemplate 官网：https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html getForEntity() 和 getForObject() postForEntity() 和 postForObject() ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#重温-resttemplate"},{"categories":null,"content":"\rRibbon 提供的 IRule 接口 根据特定算法从服务列表中选取一个要访问的服务 IRule 自带的实现类：默认为 RoundRobinRule 轮询 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ribbon-提供的-irule-接口"},{"categories":null,"content":"\r更换 Ribbon 负载均衡规则 Ribbon 的自定义配置类不可以放在 @ComponentScan 所扫描的当前包下以及子包下，否则这个自定义配置类就会被所有的 Ribbon 客户端共享，达不到为指定的 Ribbon 定制配置 而 @SpringBootApplication 注解里就有 @ComponentScan 注解，所以不可以放在主启动类所在的包下。（因为 Ribbon 是客户端（消费者）这边的，所以 Ribbon 的自定义配置类是在客户端（消费者）添加，不需要在提供者或注册中心添加） 在当前包外面新建 com.atguigu.myrule 包 @Configuration public class MySelfRule { @Bean public IRule myRule(){ return new RandomRule(); //负载均衡机制改为随机 } } 为启动类添加注解 name 为指定的服务名（服务名必须与注册中心显示的服务名大小写一致） configuration 为指定服务使用自定义配置（自定义负载均衡机制） @RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\", configuration = MySelfRule.class) 重启此消费者工程，可以看到此时不再是轮询而是随机 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#更换-ribbon-负载均衡规则"},{"categories":null,"content":"\rRibbon 轮询负载均衡原理 轮询算法：当前请求计数 % 集群总数 = N 号服务 1 % 2 = 1 号服务 2 % 2 = 0 号服务 3 % 2 = 1 号服务 由 RoundRobin 实现的 IRule 接口中 choose 方法 public Server choose(ILoadBalancer lb, Object key) { // 判断负载均衡算法是否为 NULL 如果为 NULL 则返回空 if (lb == null) { log.warn(\"no load balancer\"); return null; } Server server = null; int count = 0; while (server == null \u0026\u0026 count++ \u003c 10) {、 // 获取可达的服务 List\u003cServer\u003e reachableServers = lb.getReachableServers(); // 获得所有的服务 List\u003cServer\u003e allServers = lb.getAllServers(); // 获取可达的服务数量、所有的服务数量 int upCount = reachableServers.size(); int serverCount = allServers.size(); // 判断可达的和所有的服务数量是否为 0, 如果为 0 则返回空 if ((upCount == 0) || (serverCount == 0)) { log.warn(\"No up servers available from load balancer: \" + lb); return null; } // 获取到当前轮到的服务下标 int nextServerIndex = incrementAndGetModulo(serverCount); // 获取该下标的服务 server = allServers.get(nextServerIndex); // 如果服务为 NULL 则返回空 if (server == null) { /* Transient. */ Thread.yield(); continue; } if (server.isAlive() \u0026\u0026 (server.isReadyToServe())) { return (server); } // Next. server = null; } if (count \u003e= 10) { log.warn(\"No available alive servers after 10 tries from load balancer: \" + lb); } return server; } 通过 CAS 自旋锁（比较并交换）如果当前值的内存地址和期望值相同则交换并返回 true 否则在此自旋 比较并交换: 将期望值 expect 与传入对象 this 在内存中的偏移量为 valueoffset 的值（旧值）作比较, 如果相等, 就把 update （新值）赋值给 valueoffset , 返回 true 具体的操作是由类 sun.misc.Unsafe 来负责的，Unsafe 类提供了硬件级别的原子操作，使用 native 方法来间接访问操作系统底层（如系统硬件等) ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:7","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ribbon-轮询负载均衡原理"},{"categories":null,"content":"\r手写轮询算法 去除 @LoadBalanced 注解 新建 lb 包，创建 ILoadBalancer 接口（面向接口编程） public interface ILoadBalancer { //传入具体实例的集合，返回选中的实例 ServiceInstance instances(List\u003cServiceInstance\u003e serviceInstance); } 创建实现类 @Component // 加入容器 public class MyLB implements ILoadBalancer { // 新建一个原子整形类 private AtomicInteger atomicInteger = new AtomicInteger(0); // 获取当前访问计数 public final int getAndIncrement() { int current; int next; do { current = this.atomicInteger.get(); // 如果 current 是最大值，重新计算，否则加 1（防止越界） next = current \u003e= Integer.MAX_VALUE ? 0 : current + 1; // 进行 CAS 判断，如果不为 true，进行自旋 } while (!this.atomicInteger.compareAndSet(current, next)); System.out.println(\"****第几次访问，次数next：\" + next); return next; } @Override public ServiceInstance instances(List\u003cServiceInstance\u003e serviceInstance) { // 非空判断 if (serviceInstance.size() \u003c= 0) { return null; } // 进行取余 int index = getAndIncrement() % serviceInstance.size(); // 返回选中的服务实例 return serviceInstance.get(index); } } 在 Controller 中添加方法，使用自己轮询算法获取到的服务实例 URI 进行访问 // 注入自己写的负载均衡 @Resource private ILoadBalancer iLoadBalancer; // 注入获取所有服务实例列表所需的 @Resource private DiscoveryClient discoveryClient; @GetMapping(\"/consumer/payment/lb\") public String getPaymentLB(){ //获取 CLOUD-PAYMENT-SERVICE 服务的所有具体实例 List\u003cServiceInstance\u003e instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); if(instances == null || instances.size() \u003c= 0){ return null; } // 调用自己写的负载均衡轮询 ServiceInstance serviceInstance = iLoadBalancer.instances(instances); // 获取到当前轮到的 URI URI uri = serviceInstance.getUri(); System.out.println(uri); // 使用轮询到的 URI 进行访问 return restTemplate.getForObject(uri + \"/payment/lb\", String.class); } ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:11:8","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#手写轮询算法"},{"categories":null,"content":"\rOpenFeign 服务接口调用 Feign 是一个声明式的 web 服务客户端，让编写 web 服务客户端变得非常容易，只需创建一个接口并在接口上添加注解即可 支持可拔插式的编码器和解码器，就是在参考 Ribbon 的基础上做的一套服务接口加注解方式调用的整合 Feign 已经过时，OpenFeign 替代了它。官网：https://github.com/spring-cloud/spring-cloud-openfeign ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#openfeign-服务接口调用"},{"categories":null,"content":"\r什么是 Feign、OpenFeign Feign 旨让编写 Java HTTP 客户端更容易 在实际开发中，对于服务以来的调用可能远远不止一处，一个接口可能会被多处调用，所以通常需要对每个微服务进行封装一些客户端类来包装这些调用 使用 Feign 只需创建一个接口并使用注解的方式来配置它即可，完成服务提供方的接口绑定 Feign 集成了 Ribbon（维护服务列表信息再通过轮询实现客户端负载均衡）Feign 只需要定义服务绑定接口并以声明式的方法，优雅而简单的实现了服务调用 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-feignopenfeign"},{"categories":null,"content":"\r搭建 OpenFeign 工程 创建消费者工程，添加 POM 依赖 \u003c!-- openfeign --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e 在启动类上添加注解，激活并开启 Feign @SpringBootApplication @EnableFeignClients // 激活 Feign public class OrderFeignMain80 { public static void main(String[] args) { SpringApplication.run(OrderFeignMain80.class, args); } } 在 service 包中创建 FeignService 接口并添加注解指定生产者微服务别名 @FeignClient(value = \"CLOUD-PAYMENT-SERVICE\") public interface PaymentFeignService { @GetMapping(\"/payment/get/{id}\") public CommonResult\u003cPayment\u003e getPaymentById(@PathVariable(\"id\") Long id); } 在控制层中注入 Feign 接口，调用其中方法就是调用生产者 @RestController @Slf4j public class OrderFeignController { @Resource private PaymentFeignService paymentFeignService; @GetMapping(\"/consumer/payment/get/{id}\") public CommonResult\u003cPayment\u003e getPaymentById(@PathVariable(\"id\") Long id) { return paymentFeignService.getPaymentById(id); } } 在启动类上标注激活 Feign 的注解 @EnableFeignClients 创建 FeignClient 的接口（这里是 PaymentFeignService）标注 @FeignClient() 注解并指定生产者服务别名 在这个接口中定义的方法要和生产者中的方法一样（复制过来，包括注解），在业务层中即可注入这个接口调用其方法（也就是调用生产者） ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-openfeign-工程"},{"categories":null,"content":"\rFeign 的超时控制 消费者的超时报错：生产者一个业务需要用 3 秒种才能处理完成，但是消费者只愿意等 1 秒钟，1 秒之后就报错 默认的超时策略遇到这种长流程调用、复杂业务就会出现报错（消费者默认等待 1 秒钟）此时我们需要配置 Feign 的超时策略 # 没提示不管它，可以设置 (或使用 feign.client.config.default.ConnectTimeOut) ribbon: # 指的是建立连接后从服务器读取到可用资源所用的时间 ReadTimeout: 5000 # 指的是建立连接使用的时间，适用于网络状况正常的情况下，两端连接所用的时间 ConnectTimeout: 5000 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#feign-的超时控制"},{"categories":null,"content":"\rFeign 的日志增强 通过调整日志级别来对 Feign 接口调用情况进行监控和输出 在消费者 config.FeignConfig 类中进行配置 import feign.Logger; // 不要导错包 @Configuration public class FeignConfig { @Bean Logger.Level feignLoggerLevel(){ //打印最详细的日志 return Logger.Level.FULL; } } 在 YML 中添加配置 #开启日志的 feign 客户端 logging: level: # feign 日志以什么级别监控哪个接口 com.atguigu.springcloud.service.PaymentFeignService: debug # 写到 Feign 的服务接口 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:12:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#feign-的日志增强"},{"categories":null,"content":"\rHystrix 断路器【维护】","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#hystrix-断路器维护"},{"categories":null,"content":"\r服务降级 解决什么问题 在复杂的分布式体系结构中的应用程序有数十个依赖服务，每个依赖关系都不可避免出现失败 服务雪崩 一个微服务调用 N 个微服务，这 N 个微服务又会调用 M 个微服务… 【扇出】 如果扇出链路上某个微服务调用时间过长或不可用，对第一个服务的调用就会占用越来越多的系统资源 为了解决这种雪崩（级联故障）问题，提出服务降级的概念（链路中断的解决方案） ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务降级-解决什么问题"},{"categories":null,"content":"\r什么是 Hystrix 是一种用于处理分布式的 延迟、容错 的开源库，保证在一个依赖出错的情况下，避免级联故障，以提高分布式系统的弹性 断路器 当监控到某个服务故障后，向调用方法返回一个符合预期的、可处理的备选方案（FallBack），而不是长时间等待或异常 保证服务调用方的线程不会被长时间占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩 官网：https://github.com/Netflix/Hystrix/wiki/How-To-Use ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-hystrix"},{"categories":null,"content":"\r服务降级 相关概念 服务降级（fallback） 在服务出现问题的时候，提供一个备选处理方案（友好提示） 触发降级：运行异常、服务超时、服务熔断、线程池 / 信号量 满 提供者和消费者都可以进行服务降级。（一般都是放在客户端（消费者）） 服务熔断（break） 相当于保险丝达到最大访问量后，拒绝访问，跳闸停电 调用服务降级的方案返回友好提示 服务限流（flowlimit） 当出现高并发情况，一窝蜂的拥挤，此时服务限流让大家排队，每秒处理 N 个，有序进行 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务降级-相关概念"},{"categories":null,"content":"\r搭建 Hystrix 工程 创建生产者工程，配置 POM 文件添加 Hystrix 启动依赖 \u003c!-- hystrix--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e 编写 YML 配置文件，服务端口、微服务名、注册中心 server: port: 8001 spring: application: name: cloud-provider-hystrix-payment eureka: client: register-with-eureka: true fetch-registry: true service-url: # 单机版 defaultZone: http://localhost:7001/eureka 编写启动类，开启 Eureka 配置中心 @SpringBootApplication @EnableEurekaClient public class PaymentHystrixMain8001 { public static void main(String[] args) { SpringApplication.run(PaymentHystrixMain8001.class, args); } } 高并发测试 这里配置两个接口，一个正常接口立即返回内容，一个超时接口等待三秒再返回 这时使用 JMeter 进行压力测试，开启线程组每秒 200 个线程，循环 100 次，向 超时接口 发送 HTTP 请求 此时发现问题：超时接口转圈卡顿，正常接口也发生转圈卡顿 Tomcat 线程池里面的工作线程已经被挤占完毕，没有多余的线程来分解压力和处理。 如果此时再加上消费者请求，还有可能造成 消费端报超时错误 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-hystrix-工程"},{"categories":null,"content":"\r搭建 Hystrix 工程 创建生产者工程，配置 POM 文件添加 Hystrix 启动依赖 org.springframework.cloud spring-cloud-starter-netflix-hystrix 编写 YML 配置文件，服务端口、微服务名、注册中心 server: port: 8001 spring: application: name: cloud-provider-hystrix-payment eureka: client: register-with-eureka: true fetch-registry: true service-url: # 单机版 defaultZone: http://localhost:7001/eureka 编写启动类，开启 Eureka 配置中心 @SpringBootApplication @EnableEurekaClient public class PaymentHystrixMain8001 { public static void main(String[] args) { SpringApplication.run(PaymentHystrixMain8001.class, args); } } 高并发测试 这里配置两个接口，一个正常接口立即返回内容，一个超时接口等待三秒再返回 这时使用 JMeter 进行压力测试，开启线程组每秒 200 个线程，循环 100 次，向 超时接口 发送 HTTP 请求 此时发现问题：超时接口转圈卡顿，正常接口也发生转圈卡顿 Tomcat 线程池里面的工作线程已经被挤占完毕，没有多余的线程来分解压力和处理。 如果此时再加上消费者请求，还有可能造成 消费端报超时错误 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#高并发测试"},{"categories":null,"content":"\r服务降级 的情况 服务提供者超时了，消费者不能一直卡死等待，此时需要服务降级 服务提供者宕机了，消费者不能一直卡死等待，此时需要服务降级 服务提供者没问题，消费者自己出故障、等待时间超了，此时自己处理降级 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务降级-的情况"},{"categories":null,"content":"\r在生产者端 服务降级配置 为容易发生超时的方法上添加注解，指定超时的条件，超时的回调方法 @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = { // 设置自身超时调用时间的峰值为 3 秒，峰值内可以正常运行，超过了需要有兜底的方法处理，服务降级 fallback @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) public String paymentInfo_TimeOut(Integer id) { int timeNumber = 5; try { TimeUnit.SECONDS.sleep(timeNumber); } catch (InterruptedException e) { e.printStackTrace(); } return \"线程池：\" + Thread.currentThread().getName() + \"\\tpaymentInfo_TimeOut，id：\" + id + \"，耗时：\" + timeNumber + \"秒\"; } public String paymentInfo_TimeOutHandler(Integer id) { return \"线程池：\" + Thread.currentThread().getName() + \"\\tpaymentInfo_TimeOutHandler，id：\" + id; } 在启动类上添加注解 @EnableCircuitBreaker // 启用断路器 此时调用接口访问此方法，在满足超时条件时，会自动调用其对应的 fallback 方法【可以看到此处用的是 Hystrix 的线程池中的线程】 如果是运行时异常，也会自动调用其对应的 fallback 方法 SpringBoot 的热部署插件对 @HystrixCommand 内属性的修改不灵，建议手动重启 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#在生产者端-服务降级配置"},{"categories":null,"content":"\r在消费者端 服务降级配置 在消费者的 YML 配置文件中添加，开启 Feign 对 Hystrix 断路器的支持 feign: hystrix: enabled: true 在启动类上添加注解开启 Hystrix 的支持 @EnableHystrix // 其中包含了 @EnableCircuitBreaker 和生产者一样配置断路的处理 @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id){ String result = paymentHystrixService.paymentInfo_TimeOut(id); return result; } public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id){ return \"消费者80，支付系统繁忙\"; } 测试发现： 如果是由于生产者的超时造成的服务降级，则优先进入 消费者 fallback 如果是由于生产者的异常造成的服务降级，则优先进入 生产者 fallback 如果是由于消费者等不及造成的服务降级，则优先进入 消费者 fallback ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:7","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#在消费者端-服务降级配置"},{"categories":null,"content":"\r遇到的问题 每个业务方法都要配置一个兜底方法，导致代码膨胀 除了个别业务有专属 fallback，其它普通业务可以配置全局统一兜底方法：为类添加注解并设置统一兜底方法，在业务方法上添加注解 @Slf4j @RestController @DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\") public class OrderHystrixController { @Resource private PaymentHystrixService paymentHystrixService; @HystrixCommand @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id){ String result = paymentHystrixService.paymentInfo_OK(id); return result; } // ...... 如果有需要独享兜底方法的业务方法也可以根据上方专属 fallback 配置来处理 /** * 全局业务处理兜底 fallback 方法 * * @return 提示 */ public String payment_Global_FallbackMethod(){ return \"消费者80，支付系统繁忙, 进入全局兜底方法\"; } } 兜底方法和业务逻辑混在一起，导致代码混乱，耦合度高 为 FeignClient 接口创建实现类，在实现类中重写所有接口方法，就是兜底方法 为接口 @FeignClient 注解添加 fallback 属性指定到这个实现类上 此时当所有生产者服务都宕机无法做出回应时，就会自动调用这里的兜底方法 但是生产者还是可用状态只是无法在消费者接受的时间内响应的话，会调用消费者的全局兜底方法（有配置独享兜底方法除外） 当生产者发生不是配置的超时问题时（运行时异常）则会调用生产者的兜底方法 此时服务端 provider 已经 down 了，但是我们做了服务降级处理，让客户端在服务端不可用时也会获得提示信息而不会挂起耗死服务器 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:8","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#遇到的问题-a-idhystrixproblem-a"},{"categories":null,"content":"\r服务熔断 的情况 服务调用失败会触发降级，降级会调用其 fallback 方法，无论如何降级的流程是先调用正常方法后调用 fallback 方法 服务熔断是指单位时间内失败的次数过多，也就是降级次数过多，则触发熔断 跳过正常方法直接调用 fallback 方法 熔断后不可用 就像是保险丝跳闸了，需要检测到节点调用响应正常后，恢复调用链路 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:9","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务熔断-的情况"},{"categories":null,"content":"\r在生产者端 服务熔断配置 在生产者 Service 中配置 @HystrixCommand 注解中配置开启断路器，设置在 10 秒时间内，总阈值为 10 次，如果错误率达到 60%（也就是 6 次），跳闸 添加对应控制层方法进行访问 在 10 秒内进行多次错误尝试，触发断路器服务熔断，此时如果再进行正确的访问依然进入 fallback 方法，10 秒后开启半开模式，直到正确的处理请求 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:10","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#在生产者端-服务熔断配置"},{"categories":null,"content":"\r服务限流 的情况 后面会在 SpringCloud Alibaba 中的 Sentinel 说明 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:11","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务限流-的情况"},{"categories":null,"content":"\r总结 如果请求次数的错误率超过指定值，开启熔断，经过一段时间后，变为半开模式然后放进一个请求进行处理，如果请求处理成功，关闭熔断；如果还是报错，继续进入熔断，再经过一段时间后，变为半开模式，再进行对下一个请求进行处理，一直在熔断，半开模式来回切换，直到请求成功，关闭熔断。 断路器在什么时候开始起作用 快照时间窗：断路器确定是否打开 需要统计一些请求和错误数据，而统计的时间范围就是快照时间窗，默认为最近的 10 秒 请求总数阈值：在快照时间窗内，必须满足请求总数阈值才有资格熔断。默认 20，意味着在 10 秒内，如果调用次数不足 20 次，即使所有的请求都超时或失败，断路器也不会打开 错误百分比阈值：当请求总数在快照时间窗内超过了阈值，比如发生了 30 次调用，如果在这 30 次调用中，有 15 次发生了超时异常，也就是通过了 50% 的错误百分比（默认）这时候就会将断路器打开 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:12","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#总结"},{"categories":null,"content":"\rHystrix 的 dashboard 仪表盘 如何搭建按照官网 WIKI：Home · Netflix-Skunkworks/hystrix-dashboard Wiki (github.com) ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:13:13","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#hystrix-的-dashboard-仪表盘"},{"categories":null,"content":"\rZuul 服务网关 zuul 核心人员被挖走了三个、内部分歧，zuul2 的研发过久，spring 公司等不及，自己研发的 Gateway 网关 Zuul 的官网 WIKI：Home · Netflix/zuul Wiki (github.com) Zuul 1.x 是一个基于 Servlet 2.5 阻塞 I/O 的 API Gateway，每次 I/O 操作都是从工作线程中选择一个执行，请求线程被阻塞到工作完成完成 Zuul 1.x 的设计模式和 Nginx 有点像，但是 Nginx 是用 C/C++ 实现的，Zuul 是用 Java 实现具有 JVM 首次加载较慢的特性，性能相对较差 Zuul 2.x 是基于 Netty 非阻塞和支持长连接。SpringCloud 的 Gateway 是 Zuul 的 1.6 倍 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:14:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#zuul-服务网关"},{"categories":null,"content":"\r什么是服务网关 统一的挡在前面进行日志、限流、权鉴、安全加固等 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:14:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是服务网关"},{"categories":null,"content":"\rGateway 服务网关 Gateway 提供一种简单有效的方式来对 API 进行路由 基于 Filter 链的方式提供网关的基本功能：安全、监控/指标、限流 为了提升性能 Gateway 是基于 WebFlux 框架实现的 WebFlux 框架是 Spring5 提供的一种底层使用了高性能的 Reactor 模式通信框架 Netty，在高并发和非阻塞式通信场景下非常有优势 阻塞式 I/O 模型中，例如 Servlet，当请求进入 servlet container 时，servlet container 就会为其绑定一个线程, 在并发不高的场景下这种模型是适用的。但是一旦高并发 (比如用 jemeter 压测) ，线程数量就会上涨，而线程资源代价是昂贵的 (上线文切换，内存消耗大) 严重影响请求的处理时间。在一些简单业务场景下, 不希望为每个 request 分配一个线程， 只需要 1 个或几个线程就能应对极大并发的请求，这种业务场景下 servlet 模型没有优势。 所以 Zuul 1.X 是基于 Servlet 之上的一个阻塞式处理模型, 即 spring 实现了处理所有 request 请求的一个 servlet (DispatcherServlet) 并由该 servlet 阻塞式处理处理。所以Springcloud Zuul无法摆脱 servlet 模型的弊端 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#gateway-服务网关"},{"categories":null,"content":"\rGateway 的特性 动态路由（Route）：能够匹配任何请求属性 集成服务发现功能、Hystrix 的断路器功能 拥有易于编写的 断言（Predicate）和过滤器（Filter） 请求限流功能、支持路径重写 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#gateway-的特性"},{"categories":null,"content":"\rGateway 的核心概念 路由（Route） 路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由 断言（Predicate） 参考的是 java8 的 java.util.function.Predicate 开发人员可以匹配 HTTP 请求中的所有内容（例如请求头或请求参数），如果请求与断言相匹配则进行路由 过滤（Filter） 指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前或者之后对请求进行修改。 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#gateway-的核心概念"},{"categories":null,"content":"\rGateway 工作流程 客户端向 Gateway 发出请求，然后在 Gateway handler Mapping 中找到与请求相匹配的路由【路由转发】 将其发送到 Gateway Web Handler 通过指定的过滤链来将请求发送到实际的服务执行业务逻辑【执行过滤链】 在发送代理请求之前（pre）可以做参数校验、权限校验、流量监控、日志输出、协议转换等 在处理完请求之后（post）可以做相应内容、响应头的修改、日志的输出、流量监控等 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#gateway-工作流程"},{"categories":null,"content":"\r搭建 Gateway 工程 添加 POM 依赖 \u003c!-- gateway --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-gateway\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- eureka client(通过微服务名实现动态路由) --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 一般通用依赖 --\u003e \u003c!-- 此处不需要 spring-boot-starter-web 依赖，因为是网关，用的是 Webflux --\u003e 配置 YML 文件 在配置了网关路由之后，想访问断言中的路径的话就会先经由此项目过滤 server: port: 9527 spring: application: name: cloud-gateway # 下方配置 Gateway cloud: gateway: routes: - id: payment_route # 路由的id, 没有规定规则但要求唯一, 建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言, 路径相匹配的进行路由 - id: payment_route2 # 路由的id, 没有规定规则但要求唯一, 建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言, 路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://eureka7001.com:7001/eureka/ 编写启动类 @SpringBootApplication @EnableEurekaClient public class GatewayMain9527 { public static void main(String[] args) { SpringApplication.run(GatewayMain9527.class, args); } } 测试，此时通过 http://localhost:8001/payment/get/1 也可以访问 第二种配置方式 使用注入 RouteLocator 的 Bean 的方式配置 新建配置类 config.GatewayConfig @Configuration public class GatewayConfig { @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder) { RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(\"path_route_auguigu\", // id r -\u003e r.path(\"/guonei\") // 访问 http://localhost:9527/guonei .uri(\"https://news.baidu.com/\")); // 就会转发到 https://news.baidu.com routes.route(\"path_route_atguigu2\", // id r -\u003e r.path(\"/guoji\") // 访问 http://localhost:9527/guoji .uri(\"https://news.baidu.com/\")); // 就会转发到 https://news.baidu.com return routes.build(); } // @Bean // public RouteLocator customRouteLocator2(RouteLocatorBuilder routeLocatorBuilder){ // RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); // // routes.route(\"path_route_atguigu2\", //id // r -\u003e r.path(\"/guoji\") //访问 http://localhost:9527/guoji // .uri(\"https://news.baidu.com/\")); //就会转发到 https://news.baidu.com // // return routes.build(); // } } 实现动态路由 当前情况下路由地址是写死的，但是生产者往往都是集群，所以需要配置到生产者微服务别名，进行动态路由转发 修改配置文件，开启动态路由功能，并修改提供服务的路由地址为生产者微服务别名 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-gateway-工程"},{"categories":null,"content":"\r搭建 Gateway 工程 添加 POM 依赖 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client 配置 YML 文件 在配置了网关路由之后，想访问断言中的路径的话就会先经由此项目过滤 server: port: 9527 spring: application: name: cloud-gateway # 下方配置 Gateway cloud: gateway: routes: - id: payment_route # 路由的id, 没有规定规则但要求唯一, 建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言, 路径相匹配的进行路由 - id: payment_route2 # 路由的id, 没有规定规则但要求唯一, 建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言, 路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://eureka7001.com:7001/eureka/ 编写启动类 @SpringBootApplication @EnableEurekaClient public class GatewayMain9527 { public static void main(String[] args) { SpringApplication.run(GatewayMain9527.class, args); } } 测试，此时通过 http://localhost:8001/payment/get/1 也可以访问 第二种配置方式 使用注入 RouteLocator 的 Bean 的方式配置 新建配置类 config.GatewayConfig @Configuration public class GatewayConfig { @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder) { RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(\"path_route_auguigu\", // id r -\u003e r.path(\"/guonei\") // 访问 http://localhost:9527/guonei .uri(\"https://news.baidu.com/\")); // 就会转发到 https://news.baidu.com routes.route(\"path_route_atguigu2\", // id r -\u003e r.path(\"/guoji\") // 访问 http://localhost:9527/guoji .uri(\"https://news.baidu.com/\")); // 就会转发到 https://news.baidu.com return routes.build(); } // @Bean // public RouteLocator customRouteLocator2(RouteLocatorBuilder routeLocatorBuilder){ // RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); // // routes.route(\"path_route_atguigu2\", //id // r -\u003e r.path(\"/guoji\") //访问 http://localhost:9527/guoji // .uri(\"https://news.baidu.com/\")); //就会转发到 https://news.baidu.com // // return routes.build(); // } } 实现动态路由 当前情况下路由地址是写死的，但是生产者往往都是集群，所以需要配置到生产者微服务别名，进行动态路由转发 修改配置文件，开启动态路由功能，并修改提供服务的路由地址为生产者微服务别名 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#第二种配置方式"},{"categories":null,"content":"\r搭建 Gateway 工程 添加 POM 依赖 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client 配置 YML 文件 在配置了网关路由之后，想访问断言中的路径的话就会先经由此项目过滤 server: port: 9527 spring: application: name: cloud-gateway # 下方配置 Gateway cloud: gateway: routes: - id: payment_route # 路由的id, 没有规定规则但要求唯一, 建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言, 路径相匹配的进行路由 - id: payment_route2 # 路由的id, 没有规定规则但要求唯一, 建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言, 路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://eureka7001.com:7001/eureka/ 编写启动类 @SpringBootApplication @EnableEurekaClient public class GatewayMain9527 { public static void main(String[] args) { SpringApplication.run(GatewayMain9527.class, args); } } 测试，此时通过 http://localhost:8001/payment/get/1 也可以访问 第二种配置方式 使用注入 RouteLocator 的 Bean 的方式配置 新建配置类 config.GatewayConfig @Configuration public class GatewayConfig { @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder) { RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(\"path_route_auguigu\", // id r -\u003e r.path(\"/guonei\") // 访问 http://localhost:9527/guonei .uri(\"https://news.baidu.com/\")); // 就会转发到 https://news.baidu.com routes.route(\"path_route_atguigu2\", // id r -\u003e r.path(\"/guoji\") // 访问 http://localhost:9527/guoji .uri(\"https://news.baidu.com/\")); // 就会转发到 https://news.baidu.com return routes.build(); } // @Bean // public RouteLocator customRouteLocator2(RouteLocatorBuilder routeLocatorBuilder){ // RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); // // routes.route(\"path_route_atguigu2\", //id // r -\u003e r.path(\"/guoji\") //访问 http://localhost:9527/guoji // .uri(\"https://news.baidu.com/\")); //就会转发到 https://news.baidu.com // // return routes.build(); // } } 实现动态路由 当前情况下路由地址是写死的，但是生产者往往都是集群，所以需要配置到生产者微服务别名，进行动态路由转发 修改配置文件，开启动态路由功能，并修改提供服务的路由地址为生产者微服务别名 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#实现动态路由"},{"categories":null,"content":"\r断言 Predicate 的使用 在项目启动时可以看到由断言工厂加载了很多 Predicate 可以查看官网：Spring Cloud Gateway 关于这部分的介绍 在原有 predicates 下方添加新的断言规则即可（这里 after 表示） 在添加了 cookie 断言时，使用 curl 命令测试 在添加了 Header 断言时，使用 curl 命令测试 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#断言-predicate-的使用"},{"categories":null,"content":"\r过滤器 Filter 的使用 按照生命周期划分 pre 前置过滤 post 后置过滤 按照种类划分 GatewayFilter 单一的（ 31 种） GlobaFilter 全局的（ 10 种） 可以查看官网：Spring Cloud Gateway 关于过滤器的使用 在 Spring 可扫描包下创建 filter.MyLogGateWayFilter 实现 GlobalFilter Ordered 接口 在 filter 方法下写过滤条件 在 getOrder 方法返回当前过滤器优先级，优先级越高越先过滤 @Component @Slf4j public class MyLogGateWayFilter implements GlobalFilter, Ordered { @Override public Mono\u003cVoid\u003e filter(ServerWebExchange exchange, GatewayFilterChain chain) { log.info(\"**************come in MyLogGateWayFilter：\" + new Date()); //获取request中的uname参数 String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\"); if(uname == null){ log.info(\"*******用户名为null，非法用户！！\"); //设置响应，不被接受 exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE); return exchange.getResponse().setComplete(); } //返回chain.filter(exchange)，放行 return chain.filter(exchange); } @Override public int getOrder() { //返回值是过滤器的优先级，越小优先级越高（最小-2147483648，最大2147483648） return 0; } } 测试使用 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:15:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#过滤器-filter-的使用"},{"categories":null,"content":"\rConfig 分布式服务配置 由于微服务种单个服务的粒度相对较小，因此系统中会出现大量的服务。每套系统都需要必要的配置信息才能运行 所以一套集中的、动态的配置管理，为各个不同微服务应用的环境提供一种中心化的外部配置 SpringCLoud Config 提供动态化的配置更新，不同环境不同配置。可以在运行期间动态调整配置，服务不需要重启便可感知到配置的变化并应用新的配置 官网：https://docs.spring.io/spring-cloud-config/docs/current/reference/html/ 服务端：也称微服务配置中心，是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口 客户端：通过配置中心来获取配置内容管理应用资源 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#config-分布式服务配置"},{"categories":null,"content":"\r搭建服务端配置 在 Github 中创建一个名为 springcloud-config 的工程，其中配置文件命名应符合 {application}-{profile}.yml 写法 创建配置中心服务端，在 POM 中添加 config 依赖 \u003c!-- config server --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-config-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 注册中心依赖、一般通用依赖 ... --\u003e 配置 YML 文件 server: port: 3344 spring: application: name: cloud-config-center # 注册进 Eureka 服务器的微服务名 cloud: config: server: git: uri: https://github.com/LiuJJJJN/springcloud-config.git # git 的仓库地址 default-label: main # 读取的分支 # search-paths: # 搜索目录 # - springcloud-config eureka: client: service-url: defaultZone: http://localhost:7001/eureka # 服务注册到的 eureka 地址 配置主启动类，添加注解 @EnableConfigServer @EnableConfigServer @SpringBootApplication public class ConfigCenterMain3344 { public static void main(String[] args) { SpringApplication.run(ConfigCenterMain3344.class, args); } } 修改 Hosts 文件添加映射 127.0.0.1 config-3344 此时访问 config-3344:3344/分支名/文件名 就可以看到 Github 仓库中对应文件的内容 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建服务端配置"},{"categories":null,"content":"\r配置读取规则\r/分支名/XXX-XX.yml 方式：推荐写法 /XXX-XX.yml 方式：使用的配置中的分支，默认 master /XXX-XX.yml/分支名 方式：JSON 串 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置读取规则"},{"categories":null,"content":"\r搭建客户端配置 创建模块添加 POM 依赖 \u003c!-- config client --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-config\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 注册中心依赖、一般通用依赖 ... --\u003e 编写 bootstrap.yml配置文件 bootstrap.yml是系统级的有更高的优先级，优先被加载，不会被本地配置覆盖 SpringCloud 会创建一个 Bootstrap Context 作为 Spring 应用的 Application Context 的父上下文 初始化的时候 Bootstrap Context 负责从外部源加载配置属性并解析配置，他俩共享一个外部获取的 Environment server: port: 3355 spring: application: name: config-client cloud: config: # config 客户端配置 label: main # 分支名称 name: config # 配置文件名称 这三个综合 main 分支上的 config-dev.yml 的配置文件 profile: dev # 读取后缀名称 被读取到 http://config-3344:3344/main/config/dev uri: http://localhost:3344 # 配置中心地址 eureka: client: service-url: defaultZone: http://localhost:7001/eureka #服务注册到的eureka地址 主启动类 @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3355 { public static void main(String[] args) { SpringApplication.run(ConfigClientMain3355.class, args); } } 编写控制层，使用 @Value 注解可读取到 bootstrap.yml 配置中对应文件的 config.info 内容 @RestController public class ConfigClientController { @Value(\"${config.info}\") // 读取 yml 配置中对应文件的 config.info 内容 private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo(){ return configInfo; } } 测试，读取成功 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建客户端配置"},{"categories":null,"content":"\r配置动态刷新问题 当 Github 上的配置文件内容修改之后，Config 服务端可以立即刷新获取到，但是 Config 客户端还是之前的配置，无法刷新到新配置（重启才能获得） 为 Config 客户端添加 Spring 服务监控依赖【除了网关之外，都应添加此依赖】 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e 添加新的 YML 配置 # 暴露监控端点 management: endpoints: web: exposure: include: \"*\" 为业务类添加 @RefreshScope 注解 实现配置自动更新 @RestController @RefreshScope public class ConfigClientController { @Value(\"${config.info}\") // 读取 yml 配置中对应文件的 config.info 内容 private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo(){ return configInfo; } } 测试，先启动 Config 客户端，再修改 Github 中文件内容，再刷新接口获取内容 此时发现：还是无效啊？？？？？？ 此时需要运维人员使用 POST 方式向 http://localhost:3355/actuator/refresh 发送刷新请求 curl -X POST http://localhost:3355/actuator/refresh 再刷新 Config 客户端接口，即可访问刷新后的内容 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:16:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置动态刷新问题"},{"categories":null,"content":"\rBus 消息总线 消息总线可以实现 微服务配置中心 的增强补充：批量刷新，广播、差异化、动态刷新 Bus 消息总线，可以触发一个客户端节点 /bus/refresh 端点，从而刷新所有的客户端配置 Bug 消息总线，可以触发一个配置中心服务端 /bus/refresh 端点，从而刷新所有客户端配置 Bus 就是将 分布式系统的节点 与 轻量级消息系统 链接起来的框架 Bus 整合了 Java 的事件处理机制 和 消息中间件 功能 SpringCloud Bus 支持两种消息代理：RabbitMQ 和 Kafka ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:17:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#bus-消息总线"},{"categories":null,"content":"\r什么是 总线 在微服务架构的系统中，通常会用轻量级的信息代理来构建一个共用的消息主题，让所有微服务实例连接到 由于该主题中产生的信息会被所有实例监听和消费，所以称它为消息总线，让连接在该主题的实例都收到通知 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:17:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#什么是-总线"},{"categories":null,"content":"\r配置 Bus 工程实现全局广播 搭建良好的 RabbitMQ 环境 再创建一个配置中心客户端，以便演示广播效果（参照上方 cloud-config-client-3355 模块） 为配置中心服务端添加信息总线 这里使用 Bus 消息总线向配置中心 Center 发送刷新，为何？ 如果向客户端发送刷新任务，打破了微服务的职责单一性，业务模块不应该承担配置刷新职责 如果向客户端发送刷新任务，破坏了微服务各个节点的对等性，业务模块集群应众生平等 如果向客户端发送刷新任务，有一定的局限性，服务迁移时地址变化，此时刷新需做更多修改 为配置中心服务端添加 POM 依赖 \u003c!-- 添加消息总线 RabbitMQ 的支持 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e 为配置中心服务端添加 YML 配置 spring: rabbitmq: host: 10.211.55.17 port: 5672 # 客户端和 RabbitMQ 进行通信的端口 username: guest password: guest management: endpoints: # 暴露 bus 刷新配置的监控端点 web: exposure: include: 'bus-refresh' 为配置中心客户端添加 POM 依赖 和 YML 配置 \u003c!-- 添加消息总线 RabbitMQ 的支持 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e spring: rabbitmq: host: 192.168.30.129 port: 5672 # 客户端和 RabbitMQ 进行通信的端口 username: guest password: guest # 客户端原先已经暴露了 \"*\" 已经包含了 refresh 监控端点 启动项目，可以发现此时配置中心刷新可以获得到最新版本，但是 ConfigClient 无法刷新到最新版本配置 此时，再刷新客户端集群就都可以访问到最新配置版本了 curl -X POST http://localhost:3344/actuator/bus-refresh ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:17:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置-bus-工程实现全局广播"},{"categories":null,"content":"\r配置 Bus 工程实现定点通知 向配置中心服务端发送刷新请求，并指定只刷新 3355 这个客户端 curl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\" 查看效果 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:17:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置-bus-工程实现定点通知"},{"categories":null,"content":"\r总结 在 Github 仓库更新之前，由配置中心服务端读取仓库中的配置内容，配置客户端订阅配置中心上的 Bus 消息总线消息队列 当 Github 仓库更新之后，配置中心即可通过 Webhook 获取到仓库中的配置内容，当程序员通过 actuator 发送刷新请求之后 客户端监听到消息队列中发布的刷新事件，向配置中心服务端获取配置信息 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:17:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#总结-1"},{"categories":null,"content":"\rStream 消息驱动 是一个构建消息驱动微服务的框架，为一些消息中间件产品提供了个性化的自动化配置实现，引用了：发布-订阅、消费组、分区 三个核心概念 屏蔽底层消息中间件的差异，降低切换版本，统一消息的编程模型（通过使用 Spring Integration 来连接消息代理中间件以实现消息事件驱动） SpringCloud Stream 是用于构建与共享消息传递系统连接的高度可扩展的事件驱动微服务框架 官网：Spring Cloud Stream API 手册：Spring Cloud Stream Reference Documentation ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#stream-消息驱动"},{"categories":null,"content":"\rSpringCloud Stream 的设计思想 传统标准 MQ： 生产者/消费者之间靠消息媒介传递消息内容：Message（约定好的格式：消息头、消息正文、消息附件属性） 消息必须走特定的通道：消息通道 MessageChannel 消息通道里的消息如何被消费（收发处理）：消息通道中的子接口 SubscribableChannel，由 MessageHandler 消息处理器订阅 引入 Stream 之后 RabbitMQ 和 Kafka 架构上的不同：RabbitMQ 有 exchange，Kafka 有 Topic 和 Partitions 分区 通过定义 binder 绑定器作为中间层，实现了应用程序与消息中间件细节之间的解耦、隔离 通过向应用程序暴露统一的 Channel 通道，使得应用程序不需要再考虑不同消息中间件落地实现 Binder：绑定器，可以很方便的连接中间件，屏蔽差异 Channel：通道，是队列 Queue 的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过 Channel 对队列进行配置 Source / Sink：从 Stream 发布消息就是输出，接受消息就是输入。简单的理解就是生产者 / 消费者 常用 API 和注解 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springcloud-stream-的设计思想"},{"categories":null,"content":"\r搭建 Stream 工程\r搭建消息生产者 8801 模块 创建生产者模块 8801 \u003c!-- stream rabbit --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-stream-rabbit\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 注册中心及一般通用依赖... --\u003e 配置 YML 文件 server: port: 8801 spring: application: name: cloud-stream-provider rabbitmq: # 由于 RabbitMQ 是配置在服务器上的, 为避免试图访问 localhost:5672 的第二次连接, 所以 rabbitmq 的相关环境配置在此配置 host: 192.168.30.129 port: 5672 username: guest password: guest cloud: stream: binders: # 在此处配置要绑定的 rabbitmq 的服务信息 defaultRabbit: # 表示定义的名称, 用于 binding 整合 type: rabbit # 消息组件类型 # environment: # 设置 rabbitmq 的相关环境配置 # spring: # rabbitmq: # host: 192.168.30.129 # port: 5672 # username: guest # password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称, 表示这是一个生产者 destination: studyExchange # 表示要使用的 Exchange 名称定义(会自动创建这个交换机) content-type: application/json # 设置消息类型，本次为 json，本文要设置为 “text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置（爆红不影响使用，位置没错） eureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30S) lease-expiration-duration-in-seconds: 5 # 如果超过 5S 间隔就注销节点 默认是90s instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 编写主启动类 @SpringBootApplication public class StreamMQMain8801 { public static void main(String[] args) { SpringApplication.run(StreamMQMain8801.class, args); } } 创建消息发布接口 public interface IMessageProvider { public String send(); } 实现接口，注入消息发送管道，向管道发送一条消息 UUID @EnableBinding(Source.class) // 定义消息的推送管道(是生产者的输出管道) public class IMessageProviderImpl implements IMessageProvider { @Resource private MessageChannel output; // 消息发送管道 @Override public String send() { String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); // MessageBuilder 是 spring 的 integration.support.MessageBuilder System.out.println(\"*******serial: \" + serial); return null; } } 编写控制层代码，调用消息发送功能 @RestController public class SendMessageController { @Resource private IMessageProvider iMessageProvider; @GetMapping(\"/sendMessage\") public String sendMessage(){ return iMessageProvider.send(); } } 此时开启消息队列、注册中心服务、生产者服务，刷新 sendMessage 接口 可以看到消息队列中有消息波峰流量 搭建消息消费者 8802、8803 模块 创建消费者 8802 工程 POM 文件同上方生产者 配置 YML server: port: 8802 spring: application: name: cloud-stream-provider rabbitmq: host: 192.168.30.129 port: 5672 username: guest password: guest cloud: stream: binders: # 在此处配置要绑定的 rabbitmq 的服务信息 defaultRabbit: # 表示定义的名称，用于 binding 整合 type: rabbit # 消息组件类型 bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 **其它和生产者一样, 就是这里 output 变为 input** destination: studyExchange # 表示要使用的 Exchange 名称定义 content-type: application/json # 设置消息类型, 本次为 json，本文要设置为 “text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置（爆红不影响使用，位置没错） eureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30S) lease-expiration-duration-in-seconds: 5 # 如果超过 5S 间隔就注销节点 默认是 90s instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为 IP 地址 配置主启动类同上方生产者 编写消息监听控制层 @EnableBinding(Sink.class) // 定义消息的接收管道(是消费者的输入管道) @Controller public class ReceiveMessageListenerController { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) // 监听 public void input(Message\u003cString\u003e message) { System.out.println(\"消费者1号------\u003e收到的消息：\" + message.getPayload() + \"\\t port：\" + serverPort); } } 测试启动 8802 消费者，此时刷新 8801 的消息发布接口，可以看到 8802 消费者的控制台输出了对应内容，并且可以看到有服务绑定了队列交换机 根据上方步骤创建 8803 消费者模块，注意更改端口号、eureka 主机名避免重复 重复消费问题：当 8801 生产者刷新接口发布消息之后，8802、8803 都接收到了数据进行了消费 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-stream-工程"},{"categories":null,"content":"\r搭建 Stream 工程\r搭建消息生产者 8801 模块 创建生产者模块 8801 org.springframework.cloud spring-cloud-starter-stream-rabbit 配置 YML 文件 server: port: 8801 spring: application: name: cloud-stream-provider rabbitmq: # 由于 RabbitMQ 是配置在服务器上的, 为避免试图访问 localhost:5672 的第二次连接, 所以 rabbitmq 的相关环境配置在此配置 host: 192.168.30.129 port: 5672 username: guest password: guest cloud: stream: binders: # 在此处配置要绑定的 rabbitmq 的服务信息 defaultRabbit: # 表示定义的名称, 用于 binding 整合 type: rabbit # 消息组件类型 # environment: # 设置 rabbitmq 的相关环境配置 # spring: # rabbitmq: # host: 192.168.30.129 # port: 5672 # username: guest # password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称, 表示这是一个生产者 destination: studyExchange # 表示要使用的 Exchange 名称定义(会自动创建这个交换机) content-type: application/json # 设置消息类型，本次为 json，本文要设置为 “text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置（爆红不影响使用，位置没错） eureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30S) lease-expiration-duration-in-seconds: 5 # 如果超过 5S 间隔就注销节点 默认是90s instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 编写主启动类 @SpringBootApplication public class StreamMQMain8801 { public static void main(String[] args) { SpringApplication.run(StreamMQMain8801.class, args); } } 创建消息发布接口 public interface IMessageProvider { public String send(); } 实现接口，注入消息发送管道，向管道发送一条消息 UUID @EnableBinding(Source.class) // 定义消息的推送管道(是生产者的输出管道) public class IMessageProviderImpl implements IMessageProvider { @Resource private MessageChannel output; // 消息发送管道 @Override public String send() { String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); // MessageBuilder 是 spring 的 integration.support.MessageBuilder System.out.println(\"*******serial: \" + serial); return null; } } 编写控制层代码，调用消息发送功能 @RestController public class SendMessageController { @Resource private IMessageProvider iMessageProvider; @GetMapping(\"/sendMessage\") public String sendMessage(){ return iMessageProvider.send(); } } 此时开启消息队列、注册中心服务、生产者服务，刷新 sendMessage 接口 可以看到消息队列中有消息波峰流量 搭建消息消费者 8802、8803 模块 创建消费者 8802 工程 POM 文件同上方生产者 配置 YML server: port: 8802 spring: application: name: cloud-stream-provider rabbitmq: host: 192.168.30.129 port: 5672 username: guest password: guest cloud: stream: binders: # 在此处配置要绑定的 rabbitmq 的服务信息 defaultRabbit: # 表示定义的名称，用于 binding 整合 type: rabbit # 消息组件类型 bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 **其它和生产者一样, 就是这里 output 变为 input** destination: studyExchange # 表示要使用的 Exchange 名称定义 content-type: application/json # 设置消息类型, 本次为 json，本文要设置为 “text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置（爆红不影响使用，位置没错） eureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30S) lease-expiration-duration-in-seconds: 5 # 如果超过 5S 间隔就注销节点 默认是 90s instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为 IP 地址 配置主启动类同上方生产者 编写消息监听控制层 @EnableBinding(Sink.class) // 定义消息的接收管道(是消费者的输入管道) @Controller public class ReceiveMessageListenerController { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) // 监听 public void input(Message message) { System.out.println(\"消费者1号------\u003e收到的消息：\" + message.getPayload() + \"\\t port：\" + serverPort); } } 测试启动 8802 消费者，此时刷新 8801 的消息发布接口，可以看到 8802 消费者的控制台输出了对应内容，并且可以看到有服务绑定了队列交换机 根据上方步骤创建 8803 消费者模块，注意更改端口号、eureka 主机名避免重复 重复消费问题：当 8801 生产者刷新接口发布消息之后，8802、8803 都接收到了数据进行了消费 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建消息生产者-8801-模块"},{"categories":null,"content":"\r搭建 Stream 工程\r搭建消息生产者 8801 模块 创建生产者模块 8801 org.springframework.cloud spring-cloud-starter-stream-rabbit 配置 YML 文件 server: port: 8801 spring: application: name: cloud-stream-provider rabbitmq: # 由于 RabbitMQ 是配置在服务器上的, 为避免试图访问 localhost:5672 的第二次连接, 所以 rabbitmq 的相关环境配置在此配置 host: 192.168.30.129 port: 5672 username: guest password: guest cloud: stream: binders: # 在此处配置要绑定的 rabbitmq 的服务信息 defaultRabbit: # 表示定义的名称, 用于 binding 整合 type: rabbit # 消息组件类型 # environment: # 设置 rabbitmq 的相关环境配置 # spring: # rabbitmq: # host: 192.168.30.129 # port: 5672 # username: guest # password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称, 表示这是一个生产者 destination: studyExchange # 表示要使用的 Exchange 名称定义(会自动创建这个交换机) content-type: application/json # 设置消息类型，本次为 json，本文要设置为 “text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置（爆红不影响使用，位置没错） eureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30S) lease-expiration-duration-in-seconds: 5 # 如果超过 5S 间隔就注销节点 默认是90s instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 编写主启动类 @SpringBootApplication public class StreamMQMain8801 { public static void main(String[] args) { SpringApplication.run(StreamMQMain8801.class, args); } } 创建消息发布接口 public interface IMessageProvider { public String send(); } 实现接口，注入消息发送管道，向管道发送一条消息 UUID @EnableBinding(Source.class) // 定义消息的推送管道(是生产者的输出管道) public class IMessageProviderImpl implements IMessageProvider { @Resource private MessageChannel output; // 消息发送管道 @Override public String send() { String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); // MessageBuilder 是 spring 的 integration.support.MessageBuilder System.out.println(\"*******serial: \" + serial); return null; } } 编写控制层代码，调用消息发送功能 @RestController public class SendMessageController { @Resource private IMessageProvider iMessageProvider; @GetMapping(\"/sendMessage\") public String sendMessage(){ return iMessageProvider.send(); } } 此时开启消息队列、注册中心服务、生产者服务，刷新 sendMessage 接口 可以看到消息队列中有消息波峰流量 搭建消息消费者 8802、8803 模块 创建消费者 8802 工程 POM 文件同上方生产者 配置 YML server: port: 8802 spring: application: name: cloud-stream-provider rabbitmq: host: 192.168.30.129 port: 5672 username: guest password: guest cloud: stream: binders: # 在此处配置要绑定的 rabbitmq 的服务信息 defaultRabbit: # 表示定义的名称，用于 binding 整合 type: rabbit # 消息组件类型 bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 **其它和生产者一样, 就是这里 output 变为 input** destination: studyExchange # 表示要使用的 Exchange 名称定义 content-type: application/json # 设置消息类型, 本次为 json，本文要设置为 “text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置（爆红不影响使用，位置没错） eureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30S) lease-expiration-duration-in-seconds: 5 # 如果超过 5S 间隔就注销节点 默认是 90s instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为 IP 地址 配置主启动类同上方生产者 编写消息监听控制层 @EnableBinding(Sink.class) // 定义消息的接收管道(是消费者的输入管道) @Controller public class ReceiveMessageListenerController { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) // 监听 public void input(Message message) { System.out.println(\"消费者1号------\u003e收到的消息：\" + message.getPayload() + \"\\t port：\" + serverPort); } } 测试启动 8802 消费者，此时刷新 8801 的消息发布接口，可以看到 8802 消费者的控制台输出了对应内容，并且可以看到有服务绑定了队列交换机 根据上方步骤创建 8803 消费者模块，注意更改端口号、eureka 主机名避免重复 重复消费问题：当 8801 生产者刷新接口发布消息之后，8802、8803 都接收到了数据进行了消费 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建消息消费者-88028803-模块"},{"categories":null,"content":"\r重复消费 如果是订单系统，有多个消费者都获取到了订单信息，造成重复消费查复扣款，问题严重 这种情况可以由 消息分组 解决：同一个组内会发生竞争关系，只能有一个消费者可以消费 主题会给每个队列发送消息，而每个队列只有一个消费者可以获得消息（同组广播，不同组轮询） 消费者 8002、8003 组流水号不一致，被认为不同组（这里的流水号就是组名，默认没设置就这样） 为两个消费者都设置 group 属性，并指定相同的 group 名即可解决 此时刷新两次发送消息接口，8802 和 8803 各接收到一条信息 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#重复消费"},{"categories":null,"content":"\r消息持久化 在停掉所有消费者的情况下发送消息、 如果消费者 8802 去除了分组，则重启后无法获取消息 如果消费者 8803 保留了分组，则重启后可以获取消息 因为 8803 没删除 group: groupA ，groupA 队列是在 8801 发送消息前存在的，所以当 8803 停机后再启动，就可以获取到停机时 8801 发送的信息 （ 如果此时同组（队列）里有别的消费者，那么消息会被别的消费者消费掉 ） ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:18:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#消息持久化"},{"categories":null,"content":"\rSleuth 分布式链路追踪 在微服务架构中，每个请求都要经过多个不同的服务节点协同调用才产生最后的请求结果，链路中任意一环出现高延时或错误都会引起整个请求的响应失败 SpringCloud Sleuth 提供了一套完整的服务跟踪的解决方案，并且支持 zipkin 官网：Spring Cloud Sleuth spring-cloud/spring-cloud-sleuth: Distributed tracing for spring cloud (github.com) ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:19:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#sleuth-分布式链路追踪"},{"categories":null,"content":"\r如何使用 下载 zipkin 的 jar 包：Central Repository: io/zipkin/zipkin-server (maven.org) 打开命令行使用 java -jar 命令运行 jar 包 java -jar .\\zipkin-server-2.24.0-exec.jar 启动后访问 http://localhost:9411/zipkin/ 每条链路有一个 trace ID 唯一标识，span 标识发起的请求信息，各个 span 通过 trace ID 关联起来 Trace：类似于树结构的 Span 集合，表示一条调用链路存在的唯一标识 Span：标识每次调用链路来源，说白了 Span 就是一次请求信息 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:19:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#如何使用"},{"categories":null,"content":"\r搭建链路追踪步骤 为服务生产者添加 POM 依赖 \u003c!-- 包含了 sleuth + zipkin --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-zipkin\u003c/artifactId\u003e \u003c/dependency\u003e 为服务生产者添加 YML 配置 zipkin: base-url: http://localhost:9411 # 将监控的数据打到这个地址 sleuth: sampler: probability: 1 # 采样率值介于 0 到 1 之间, 1则表示全部采集（一般不为 1, 不然高并发性能会有影响） 为服务消费者也添加同样的配置 启动注册中心、生产者、消费者服务，访问消费者接口调用生产者，刷新 zipkin 页面 可以看到这次请求的请求路径、请求时间、花费时长 点击 show 按钮 可以看到是哪个消费者接口调用的哪个生产者接口，各自的信息 点击依赖标签页，可以看到各个模块间的依赖关系图示 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:19:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建链路追踪步骤"},{"categories":null,"content":"\rSpringCloud Alibaba 部分 官网：https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md 于 2018.10.31 在 Maven 中央仓库发布了第一个版本 0.2.0 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:0","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springcloud-alibaba-部分"},{"categories":null,"content":"\rSpringCloud Alibaba 能干什么 服务限流降级：默认支持 WebServlet、WebFlux、OpenFeign、RestTemplate、Spring Cloud Gateway、Zuul、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 分布式事务：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 阿里云短信服务：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:1","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#springcloud-alibaba-能干什么"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 \u003c!-- SpringCloud Alibaba nacos --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 \u003c!-- OpenFeign --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nacos-作为服务注册"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#安装-nacos"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-nacos-工程"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置服务生产者"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置服务生产者2"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置服务消费者"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用-feign"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#ap-or-cp"},{"categories":null,"content":"\rNacos 作为服务注册 Nacos：naming（na），Configuration（co），service（s） Dynamic Naming and Configuration Service：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台 Nacos 等价于：eureka + config + Bus 官网：home (nacos.io) 安装 Nacos 获取 Nacos：Releases · alibaba/nacos (github.com) 解压，打开 bin 目录 运行 cmd startup.cmd -m standalone 访问 http://localhost:8848/nacos/ 即可 默认账号：nacos 默认密码：nacos 搭建 Nacos 工程官网：Spring Cloud Alibaba Reference Documentation (spring-cloud-alibaba-group.github.io) 配置服务生产者 新建工程 cloudalibaba-provider-payment9001 添加 Nacos 的 discovery 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 YML 文件 server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 management: endpoints: web: exposure: include: '*' 编写主启动类，添加 @EnableDiscoveryClient 注解 @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class, args); } } 编写控制层 … 启动项目，在 nacos 浏览器界面 服务管理 \u003e 服务列表 中即可看到 配置服务生产者2 投机取巧，使用 IDEA 的 Copy 功能 右键一个实例，选择 Copy Configuration 设置名称、添加 VM Options 值 -DServer.port=9011 此时在 nacos 的界面中即可看到实例数为 2 配置服务消费者 创建 cloudalibaba-consumer-nacos-order83 添加 POM 依赖 编写 YML 配置，注意配置生产者的微服务名称 server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置的 Nacos 地址 # 消费者要访问的微服务名称（成功注册进 nacos 的服务提供者） service-url: nacos-user-service: http://nacos-payment-provider 编写主启动类 如果使用 RestTemplate 则需要编写配置类将 Bean 注入到 Spring 容器中 配置方式 此时就可以用 @Value 读取 YML 中的服务提供者别名作为 serverURL 编写控制层代码 此时可以看到 nacos 中注册进了新的服务 使用 Feign 加入 OpenFeign 依赖 org.springframework.cloud spring-cloud-starter-openfeign 在启动类上添加注解激活 Feign @EnableFeignClients 取消配置类中的 RestTemplate 相关配置 创建接口 PaymentFeignService 、使用 参照代码 AP or CP 前面有说 nacos 是支持 CAP 中的 AP，即 可用性 和 分区容错性 但是实际上 nacos 是可以根据业务选型切换 AP 和 CP 两种模式的，如下图所示，左侧即 AP 右侧即 CP 一般情况下只需保持心跳上报的项目默认就是 AP 模式，AP 模式为了服务的可用性减弱了一致性，因此在此模式下只支持注册临时实例 如果需要在服务级别编辑或存储配置信息，那么 CP 是必须。CP 模式下支持注册持久化实例（是以 Raft 协议为集群运行…） 切换模式：curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode\u0026value=CP' 与其他注册中心特性对比\r","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:2","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#与其他注册中心特性对比"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 \u003c!-- nacos config --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-config\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- nacos discovery --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nacos-作为配置中心"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-nacos-工程-1"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#配置规则公式"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#分类配置"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#data-id-方案"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#group-方案"},{"categories":null,"content":"\rNacos 作为配置中心\r搭建 Nacos 工程 创建模块 cloudalibaba-config-nacos-client3377 添加 Nacos 的 config 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 配置 bootstrap.yml 和 application.yml bootstrap.yml 的优先级高于 application.yml，所以在项目初始化时保证先从配置中心拉去配置信息 这里的意思就是 从 localhost:8848 获取 yml 格式的 dev 环境的配置 bootstrap.yml server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 application.yml spring: profiles: active: dev # 表示开发环境 配置主启动类 NacosConfigClientMain3377 @SpringBootApplication @EnableDiscoveryClient public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run(NacosConfigClientMain3377.class, args); } } 编写控制层代码，标注 @RefreshScope 让其支持配置自动更新 @RefreshScope // 支持 Nacos 的动态刷新功能 @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 配置规则公式 见 Nacos 官网 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html ${prefix}-${spring.profiles.active}.${file-extension} # 也就是 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 由此公式最终可以组成 nacos-config-client-dev.yml 点击加号添加一个配置 Data ID 就是 nacos-config-client-dev.yml 此时运行 3377 项目，访问控制层方法即可获取到在 nacos 中配置的内容 4.此时修改 nacos 中的配置信息，再次刷新控制层接口【动态刷新】不像 Config 需要手动刷新 分类配置 通常在实际开发中会有多种环境 dev 开发环境、test 测试环境、prod 生产环境、预发环境、正式环境 …… 此时就需要对不同的环境进行配置管理 Namespace 命名空间 \u003e Group 组 \u003e Data ID 配置：三者的关系 默认情况：Namespace=public、Group=DEFAULT_GROUP、Cluster=DEFAULT Namespace 实现隔离，不同的环境用不同的 Namespace Group 中可以包含多个微服务 Service Service 中包含多个 Cluster （集群，是对指定微服务的一个虚拟划分） Instance 就是微服务的实例 Data ID 方案 在默认 Namespace 默认 Group 下创建测试环境 Data ID 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: test # 表示测试环境 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-test.yml Group 方案 在默认 Namespace 中创建不同的 Group 组，在组中创建相同的 Data ID 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.group 配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 修改 application.yml 内容 spring: profiles: # active: dev # 表示开发环境 active: info 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 public \u003e DEFAULT_GROUP \u003e nacos-config-client-info.yml Namespace 方案 创建新的命名空间 在配置列表中即可看到新增的命名空间 修改 bootstrap.yml 中内容，添加 spring.cloud.nacos.config.namespace 配置为新命名空间 ID server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # Nacos 服务注册中心地址 config: server-addr: localhost:8848 # Nacos 作为配置中心地址 file-extension: yml # 指定 yml 格式配置 group: TEST_GROUP # 指定从 TEST_GROUP 中读取配置 namespace: d18b3fba-17d6-4492-b9e5-00d0d72ba771 # 指定从此 ID 的 namespace 中读取配置 就可以读取到对应配置 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} # 也就是 DEV \u003e TEST_GROUP \u003e nacos-config-client-dev.yml ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:3","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#namespace-方案"},{"categories":null,"content":"\rNacos 集群和持久化配置 下图的 SLB 在旧版图片中就是 VIP，官网：集群部署说明 (nacos.io) Nacos 默认使用内嵌 Derby 数据库，但是在集群环境下，启动多个默认配置下的 nacos 节点，数据存储存在一致性问题。 因此需要使用集中存储的方式来支持集群化存储，需要 MySQL 数据库 单机模式支持 MySQL 官网说明：Nacos支持三种部署模式 修改 conf 目录中 application.properties 配置文件 导入 conf 下 nacos-mysql.sql 文件到本地数据库 此时开启服务即可发现，此前的配置全部消失了，因为此时用的是本机的 MySQL 数据库中没有数据 Linux 集群生产环境配置 由于我虚拟机 Linux 中运行 Docker 的 Nacos 一直自动结束运行，一时间没调好，很气，故此处略 大致步骤： 安装 MySQL 创建数据库并 Source 进 Nacos 的 sql 文件 修改 application.properties 配置数据库地址、用户名、密码等 修改 nacos 的集群配置 cluster.conf 通过编辑 nacos 的启动脚本startup.sh 使它能够使用不同的端口启动 修改 nginx.conf 使其作为负载均衡器 测试访问：http://IP:1111/nacos/#/login ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#nacos-集群和持久化配置"},{"categories":null,"content":"\rNacos 集群和持久化配置 下图的 SLB 在旧版图片中就是 VIP，官网：集群部署说明 (nacos.io) Nacos 默认使用内嵌 Derby 数据库，但是在集群环境下，启动多个默认配置下的 nacos 节点，数据存储存在一致性问题。 因此需要使用集中存储的方式来支持集群化存储，需要 MySQL 数据库 单机模式支持 MySQL 官网说明：Nacos支持三种部署模式 修改 conf 目录中 application.properties 配置文件 导入 conf 下 nacos-mysql.sql 文件到本地数据库 此时开启服务即可发现，此前的配置全部消失了，因为此时用的是本机的 MySQL 数据库中没有数据 Linux 集群生产环境配置 由于我虚拟机 Linux 中运行 Docker 的 Nacos 一直自动结束运行，一时间没调好，很气，故此处略 大致步骤： 安装 MySQL 创建数据库并 Source 进 Nacos 的 sql 文件 修改 application.properties 配置数据库地址、用户名、密码等 修改 nacos 的集群配置 cluster.conf 通过编辑 nacos 的启动脚本startup.sh 使它能够使用不同的端口启动 修改 nginx.conf 使其作为负载均衡器 测试访问：http://IP:1111/nacos/#/login ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#单机模式支持-mysql"},{"categories":null,"content":"\rNacos 集群和持久化配置 下图的 SLB 在旧版图片中就是 VIP，官网：集群部署说明 (nacos.io) Nacos 默认使用内嵌 Derby 数据库，但是在集群环境下，启动多个默认配置下的 nacos 节点，数据存储存在一致性问题。 因此需要使用集中存储的方式来支持集群化存储，需要 MySQL 数据库 单机模式支持 MySQL 官网说明：Nacos支持三种部署模式 修改 conf 目录中 application.properties 配置文件 导入 conf 下 nacos-mysql.sql 文件到本地数据库 此时开启服务即可发现，此前的配置全部消失了，因为此时用的是本机的 MySQL 数据库中没有数据 Linux 集群生产环境配置 由于我虚拟机 Linux 中运行 Docker 的 Nacos 一直自动结束运行，一时间没调好，很气，故此处略 大致步骤： 安装 MySQL 创建数据库并 Source 进 Nacos 的 sql 文件 修改 application.properties 配置数据库地址、用户名、密码等 修改 nacos 的集群配置 cluster.conf 通过编辑 nacos 的启动脚本startup.sh 使它能够使用不同的端口启动 修改 nginx.conf 使其作为负载均衡器 测试访问：http://IP:1111/nacos/#/login ","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:4","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#linux-集群生产环境配置"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 \u003c!-- SpringCloud alibaba nacos --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- SpringCloud alibaba sentinel-datasource-nacos 持久化需要用到 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.csp\u003c/groupId\u003e \u003cartifactId\u003esentinel-datasource-nacos\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- SpringCloud alibaba sentinel --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-sentinel\u003c/artifactId\u003e \u003c/dependency\u003e 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#sentinel-熔断与限流"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#运行-sentinel"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-sentinel-工程"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#流控规则流量控制规则"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#直接"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#关联"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#链路"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#快速失败"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#warm-up预热--冷启动"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#匀速排队"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#降级规则熔断降级规则"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#rt-慢调用比例"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#异常比例"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#异常数"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#热点规则热点-key-限流"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#参数例外项"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#异常情况"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#系统规则"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#全局-qps"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#sentinelresource-注解"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#按-资源名称-限流--后续处理"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#按照-url-地址限流--后续处理"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#遇到问题"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#自定义限流处理逻辑"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#sentinelresource-注解其他属性"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#服务熔断"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用-resttemplate"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#使用-feign-1"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#常见熔断框架比较"},{"categories":null,"content":"\rSentinel 熔断与限流 中文文档：introduction | Sentinel (sentinelguard.io) Github：alibaba/Sentinel: 面向云原生微服务的高可用流控防护组件 (github.com) Sentinel 用来解决：服务雪崩、服务降级、服务熔断、服务限流 Sentinel 分为两个部分 核心库（ Java 客户端）不依赖任何框架 / 库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持 控制台（ DashBoard ）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器 运行 Sentinel 运行前提：Java 8 环境，8080 端口没有被占用 java -jar .\\sentinel-dashboard-1.8.6.jar 访问 http://localhost:8080/ 即可看到 Sentinel 界面 用户：sentinel 密码：sentinel 搭建 Sentinel 工程 创建模块 cloudalibaba-sentinel-service8401 配置 POM 依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置 YML 文件 server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: # Nacos 服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置 Sentinel dashboard 地址 dashboard: localhost:8080 # 默认 8719 端口，假如被占用了会自动从 8719 端口 +1 进行扫描，直到找到未被占用的端口【通信服务（后台监控服务）】 port: 8719 management: endpoints: web: exposure: include: '*' 编写主启动类 @EnableDiscoveryClient @SpringBootApplication public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class, args); } } 编写控制层 由于 Sentinel 采用懒加载机制，需要调用一次接口才能显示 在簇点链路中就可以看到接口之间的调用关系 流控规则（流量控制规则）\r直接 可以在簇点链路界面中快速对一个接口添加流控 此时 一秒内 点击了多次就会显示 Sentinel 的提示【默认报错】 关联 当关联的资源达到阈值时，就限流自己（例如当支付接口达到阈值时就限流下订单的接口） 当 /testB 达到阈值 QPS 1 时，/testA 限流 使用 postman 进行并发访问 此时 /testA 接口已经被限流 链路 链路就是对一个指定资源进行限流，并且是某个接口调用的这个资源，对这个调用链路进行限流 此处没有测试出效果，略 angenin 的笔记：最新的SpringCloud(H版\u0026Alibaba)技术（19高级部分，熔断与限流【Sentinel】）_angenin的博客-CSDN博客 快速失败 在 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 类中处理，抛出异常 Warm Up（预热 / 冷启动） 官网解释 阙值除以 coldFactor（冷因子，默认值为3），经过预热时长后才会达到阙值 在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中可以看到 默认冷加载因子为 3 ，前几秒 预热时长 内阈值限制在 单机阈值 / 3 ，预热时长 后 阈值慢慢升高至 单机阈值 匀速排队\r让请求以均匀的速度通过，阈值必须设为 QPS 一秒内第二次请求就处于加载状态，点多了就会看到 直接失败 页面 降级规则（熔断降级规则） Sentinel 是没有半开状态的，要么拉闸停用，要么关闭断路器恢复（貌似新版 1.8.0 之后 加入了 Half-Open 探测恢复状态） Sentinel 熔断降级会在调用链路中某个资源出现 不稳定状态 时（例如调用超市或异常比例升高） 对这个资源的调用进行 限制。让请求快速失败，避免影响其他资源而导致级联错误（默认行为抛出 DegradeException） RT 慢调用比例\r添加 testD 方法，执行时间需要 1 秒 Jmeter 设置为每秒 10 个请求，永远循环 当 JMeter 进行时无法访问 这是因为在 1 秒内超过 5 个请求在 200 ms 内没有完成一次请求的处理，断路器打开，微服务不可用 异常比例\r修改 testD 方法，使其抛出异常 当每秒内请求大于 5 次其中有 1 次报错（0.2 » 20%），则断路器打开 当时间窗口结束，1秒后恢复正常 异常数\r当访问 testD 第三次及以上时，进入熔断状态 进入时间窗口期不处理请求 60秒 热点规则（热点 Key 限流） 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流 类似豪猪哥的 @HystrixCommand 注解，Sentinel 提供 @SentinelResource 实现兜底方法的设置等功能 value：资源名，和访问路径一致，去 / blockHandler：兜底方法名 @GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false)String p1, @RequestParam(value = \"p2\", required = false)String p2) { return \"----testHotKey\"; } // 兜底方法 兜底方法参数为 原方法的参数 + BlockException public String deal_testHotKey(String p1, String p2, BlockException exception) { // sentinel 的默认提示都是 Blocked by Sentinel (flow limiting) return \"----deal_testHotKey, o(╥﹏╥)o\"; } 配置热点规则 参数索引是参数下标，从 0 开始 单机阈值是 QPS 的阈值，1 秒内带有第 0 个参数（也就是 p1）的请求超过 1 次，则进入其对应的兜底方法 如果没有配置 blockHandler 属性兜底方法，会直接将错误页面打到前端 @SentinelResource(value = \"testHotKey\") 参数例外项\r当 p1 参数的值为 5 的时候，阈值变为 200 此时就算手速再快也很难点出 200 QPS 异常情况 如果业务方法中抛出了异常，这时候并不是限流规则中的问题，运行时出错 Sentinel 不管，照常抛出异常 @SentinelResource 有 fallback 参数，后续说明 系统规则 官网：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel 系统自适应限流从 整体维度 对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 应用整体维度的，而不是资源维度的，","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:5","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#规则持久化"},{"categories":null,"content":"\rSeata 事务 在分布式系统中，往往不止一个数据库 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题，Seate 就是来保障全局数据一致性问题 例如：商品售卖的业务逻辑被拆分成三个微服务提供支持，分配使用独立的数据库 仓储服务：对给定的商品扣除仓储数量 订单服务：根据采购需求创建订单 账户服务：从用户账户中扣除余额 Seata 官网：Seata Seata 术语 一加三概念组成 一 ID： 全局唯一的事务 ID 三 组件模型： TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 处理过程 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID XID 在微服务调用链路的上下文中传播 RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖 TM 向 TC 发起针对 XID 的全局提交或回滚决议 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求 Seata 的安装部署 前往官网下载 Seata：下载中心 (seata.io) 这里按 0.9.0 版本为例 修改 conf 目录下的 file.conf 文件 修改测试事务组名称 fsp_tx_group 修改事务日志存储模式为 db cj ?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false 创建数据库 seata 导入 conf 目录下的 db_store.sql 修改 conf 目录下 registry.conf 注册配置文件 指明注册中心为 nacos 并配置链接信息 启动 nacos 启动 seata 进入 bin 目录，执行命令 .\\seata-server.bat 看到报错 原因是没找到 MySQL 8 的驱动，可以手动下载驱动 jar 包放到 lib 目录下即可 搭建 Seata 工程\r创建三个数据库 seata_order: 存储订单的数据库 seata_storage: 存储库存的数据库 seata_account: 存储账户信息的数据库 创建对应业务表，并创建各自的 undo_log 表用于记录回滚日志【0.9.0 注意版本差异】 # 创建业务数据库和对应的业务表 # order create database seata_order; use seata_order; CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11)DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结' )ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; select * from t_order; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # storage create database seata_storage; use seata_storage; CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # account create database seata_account; use seata_account; CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_account(`id`,`user_id`,`total`,`used`,`residue`)VALUES('1','1','1000','0','1000'); SELECT * FROM t_account; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL CO","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#seata-事务"},{"categories":null,"content":"\rSeata 事务 在分布式系统中，往往不止一个数据库 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题，Seate 就是来保障全局数据一致性问题 例如：商品售卖的业务逻辑被拆分成三个微服务提供支持，分配使用独立的数据库 仓储服务：对给定的商品扣除仓储数量 订单服务：根据采购需求创建订单 账户服务：从用户账户中扣除余额 Seata 官网：Seata Seata 术语 一加三概念组成 一 ID： 全局唯一的事务 ID 三 组件模型： TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 处理过程 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID XID 在微服务调用链路的上下文中传播 RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖 TM 向 TC 发起针对 XID 的全局提交或回滚决议 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求 Seata 的安装部署 前往官网下载 Seata：下载中心 (seata.io) 这里按 0.9.0 版本为例 修改 conf 目录下的 file.conf 文件 修改测试事务组名称 fsp_tx_group 修改事务日志存储模式为 db cj ?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false 创建数据库 seata 导入 conf 目录下的 db_store.sql 修改 conf 目录下 registry.conf 注册配置文件 指明注册中心为 nacos 并配置链接信息 启动 nacos 启动 seata 进入 bin 目录，执行命令 .\\seata-server.bat 看到报错 原因是没找到 MySQL 8 的驱动，可以手动下载驱动 jar 包放到 lib 目录下即可 搭建 Seata 工程\r创建三个数据库 seata_order: 存储订单的数据库 seata_storage: 存储库存的数据库 seata_account: 存储账户信息的数据库 创建对应业务表，并创建各自的 undo_log 表用于记录回滚日志【0.9.0 注意版本差异】 # 创建业务数据库和对应的业务表 # order create database seata_order; use seata_order; CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11)DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结' )ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; select * from t_order; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # storage create database seata_storage; use seata_storage; CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # account create database seata_account; use seata_account; CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_account(`id`,`user_id`,`total`,`used`,`residue`)VALUES('1','1','1000','0','1000'); SELECT * FROM t_account; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL CO","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#seata-术语"},{"categories":null,"content":"\rSeata 事务 在分布式系统中，往往不止一个数据库 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题，Seate 就是来保障全局数据一致性问题 例如：商品售卖的业务逻辑被拆分成三个微服务提供支持，分配使用独立的数据库 仓储服务：对给定的商品扣除仓储数量 订单服务：根据采购需求创建订单 账户服务：从用户账户中扣除余额 Seata 官网：Seata Seata 术语 一加三概念组成 一 ID： 全局唯一的事务 ID 三 组件模型： TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 处理过程 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID XID 在微服务调用链路的上下文中传播 RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖 TM 向 TC 发起针对 XID 的全局提交或回滚决议 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求 Seata 的安装部署 前往官网下载 Seata：下载中心 (seata.io) 这里按 0.9.0 版本为例 修改 conf 目录下的 file.conf 文件 修改测试事务组名称 fsp_tx_group 修改事务日志存储模式为 db cj ?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false 创建数据库 seata 导入 conf 目录下的 db_store.sql 修改 conf 目录下 registry.conf 注册配置文件 指明注册中心为 nacos 并配置链接信息 启动 nacos 启动 seata 进入 bin 目录，执行命令 .\\seata-server.bat 看到报错 原因是没找到 MySQL 8 的驱动，可以手动下载驱动 jar 包放到 lib 目录下即可 搭建 Seata 工程\r创建三个数据库 seata_order: 存储订单的数据库 seata_storage: 存储库存的数据库 seata_account: 存储账户信息的数据库 创建对应业务表，并创建各自的 undo_log 表用于记录回滚日志【0.9.0 注意版本差异】 # 创建业务数据库和对应的业务表 # order create database seata_order; use seata_order; CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11)DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结' )ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; select * from t_order; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # storage create database seata_storage; use seata_storage; CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # account create database seata_account; use seata_account; CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_account(`id`,`user_id`,`total`,`used`,`residue`)VALUES('1','1','1000','0','1000'); SELECT * FROM t_account; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL CO","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#seata-的安装部署"},{"categories":null,"content":"\rSeata 事务 在分布式系统中，往往不止一个数据库 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题，Seate 就是来保障全局数据一致性问题 例如：商品售卖的业务逻辑被拆分成三个微服务提供支持，分配使用独立的数据库 仓储服务：对给定的商品扣除仓储数量 订单服务：根据采购需求创建订单 账户服务：从用户账户中扣除余额 Seata 官网：Seata Seata 术语 一加三概念组成 一 ID： 全局唯一的事务 ID 三 组件模型： TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 处理过程 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID XID 在微服务调用链路的上下文中传播 RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖 TM 向 TC 发起针对 XID 的全局提交或回滚决议 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求 Seata 的安装部署 前往官网下载 Seata：下载中心 (seata.io) 这里按 0.9.0 版本为例 修改 conf 目录下的 file.conf 文件 修改测试事务组名称 fsp_tx_group 修改事务日志存储模式为 db cj ?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false 创建数据库 seata 导入 conf 目录下的 db_store.sql 修改 conf 目录下 registry.conf 注册配置文件 指明注册中心为 nacos 并配置链接信息 启动 nacos 启动 seata 进入 bin 目录，执行命令 .\\seata-server.bat 看到报错 原因是没找到 MySQL 8 的驱动，可以手动下载驱动 jar 包放到 lib 目录下即可 搭建 Seata 工程\r创建三个数据库 seata_order: 存储订单的数据库 seata_storage: 存储库存的数据库 seata_account: 存储账户信息的数据库 创建对应业务表，并创建各自的 undo_log 表用于记录回滚日志【0.9.0 注意版本差异】 # 创建业务数据库和对应的业务表 # order create database seata_order; use seata_order; CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11)DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结' )ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; select * from t_order; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # storage create database seata_storage; use seata_storage; CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # account create database seata_account; use seata_account; CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_account(`id`,`user_id`,`total`,`used`,`residue`)VALUES('1','1','1000','0','1000'); SELECT * FROM t_account; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL CO","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#搭建-seata-工程"},{"categories":null,"content":"\rSeata 事务 在分布式系统中，往往不止一个数据库 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题，Seate 就是来保障全局数据一致性问题 例如：商品售卖的业务逻辑被拆分成三个微服务提供支持，分配使用独立的数据库 仓储服务：对给定的商品扣除仓储数量 订单服务：根据采购需求创建订单 账户服务：从用户账户中扣除余额 Seata 官网：Seata Seata 术语 一加三概念组成 一 ID： 全局唯一的事务 ID 三 组件模型： TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 处理过程 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID XID 在微服务调用链路的上下文中传播 RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖 TM 向 TC 发起针对 XID 的全局提交或回滚决议 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求 Seata 的安装部署 前往官网下载 Seata：下载中心 (seata.io) 这里按 0.9.0 版本为例 修改 conf 目录下的 file.conf 文件 修改测试事务组名称 fsp_tx_group 修改事务日志存储模式为 db cj ?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false 创建数据库 seata 导入 conf 目录下的 db_store.sql 修改 conf 目录下 registry.conf 注册配置文件 指明注册中心为 nacos 并配置链接信息 启动 nacos 启动 seata 进入 bin 目录，执行命令 .\\seata-server.bat 看到报错 原因是没找到 MySQL 8 的驱动，可以手动下载驱动 jar 包放到 lib 目录下即可 搭建 Seata 工程\r创建三个数据库 seata_order: 存储订单的数据库 seata_storage: 存储库存的数据库 seata_account: 存储账户信息的数据库 创建对应业务表，并创建各自的 undo_log 表用于记录回滚日志【0.9.0 注意版本差异】 # 创建业务数据库和对应的业务表 # order create database seata_order; use seata_order; CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11)DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结' )ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; select * from t_order; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # storage create database seata_storage; use seata_storage; CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # account create database seata_account; use seata_account; CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_account(`id`,`user_id`,`total`,`used`,`residue`)VALUES('1','1','1000','0','1000'); SELECT * FROM t_account; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL CO","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#验证-seata-工程"},{"categories":null,"content":"\rSeata 事务 在分布式系统中，往往不止一个数据库 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题，Seate 就是来保障全局数据一致性问题 例如：商品售卖的业务逻辑被拆分成三个微服务提供支持，分配使用独立的数据库 仓储服务：对给定的商品扣除仓储数量 订单服务：根据采购需求创建订单 账户服务：从用户账户中扣除余额 Seata 官网：Seata Seata 术语 一加三概念组成 一 ID： 全局唯一的事务 ID 三 组件模型： TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 处理过程 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID XID 在微服务调用链路的上下文中传播 RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖 TM 向 TC 发起针对 XID 的全局提交或回滚决议 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求 Seata 的安装部署 前往官网下载 Seata：下载中心 (seata.io) 这里按 0.9.0 版本为例 修改 conf 目录下的 file.conf 文件 修改测试事务组名称 fsp_tx_group 修改事务日志存储模式为 db cj ?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false 创建数据库 seata 导入 conf 目录下的 db_store.sql 修改 conf 目录下 registry.conf 注册配置文件 指明注册中心为 nacos 并配置链接信息 启动 nacos 启动 seata 进入 bin 目录，执行命令 .\\seata-server.bat 看到报错 原因是没找到 MySQL 8 的驱动，可以手动下载驱动 jar 包放到 lib 目录下即可 搭建 Seata 工程\r创建三个数据库 seata_order: 存储订单的数据库 seata_storage: 存储库存的数据库 seata_account: 存储账户信息的数据库 创建对应业务表，并创建各自的 undo_log 表用于记录回滚日志【0.9.0 注意版本差异】 # 创建业务数据库和对应的业务表 # order create database seata_order; use seata_order; CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11)DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结' )ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; select * from t_order; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # storage create database seata_storage; use seata_storage; CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; # account create database seata_account; use seata_account; CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' )ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO t_account(`id`,`user_id`,`total`,`used`,`residue`)VALUES('1','1','1000','0','1000'); SELECT * FROM t_account; CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL CO","date":"0001-01-01","objectID":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/:20:6","series":null,"tags":null,"title":"SpringCloud自学笔记md版","uri":"/springcloud%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0md%E7%89%88/#seata-原理简介"}]